<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2016s on Mark Needham</title>
    <link>https://mneedham.github.io/2016/</link>
    <description>Recent content in 2016s on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 24 Dec 2016 10:45:42 +0000</lastBuildDate>
    
	<atom:link href="https://mneedham.github.io/2016/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Go: First attempt at channels</title>
      <link>https://mneedham.github.io/2016/12/24/go-first-attempt-at-channels/</link>
      <pubDate>Sat, 24 Dec 2016 10:45:42 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/12/24/go-first-attempt-at-channels/</guid>
      <description>In a previous blog post I mentioned that I wanted to extract blips from The ThoughtWorks Radar into a CSV file and I thought this would be a good mini project for me to practice using Go.  In particular I wanted to try using channels and this seemed like a good chance to do that. 
I watched a talk by Rob Pike on designing concurrent applications where he uses the following definition of concurrency:</description>
    </item>
    
    <item>
      <title>Go: cannot execute binary file: Exec format error</title>
      <link>https://mneedham.github.io/2016/12/23/go-cannot-execute-binary-file-exec-format-error/</link>
      <pubDate>Fri, 23 Dec 2016 18:24:12 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/12/23/go-cannot-execute-binary-file-exec-format-error/</guid>
      <description>In an earlier blog post I mentioned that I&#39;d been building an internal application to learn a bit of Go and I wanted to deploy it to AWS. Since the application was only going to live for a couple of days I didn&#39;t want to spend a long time build up anything fancy so my plan was just to build the executable, SSH it to my AWS instance, and then run it.</description>
    </item>
    
    <item>
      <title>Neo4j: Graphing the ThoughtWorks Technology Radar</title>
      <link>https://mneedham.github.io/2016/12/23/neo4j-graphing-the-thoughtworks-technology-radar/</link>
      <pubDate>Fri, 23 Dec 2016 17:40:45 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/12/23/neo4j-graphing-the-thoughtworks-technology-radar/</guid>
      <description>For a bit of Christmas holiday fun I thought it&#39;d be cool to create a graph of the different blips on the ThoughtWorks Technology Radar and how the recommendations have changed over time. I wrote a script to extract each blip (e.g. .NET Core) and the recommendation made in each radar that it appeared in. I ended up with a CSV file:
|----------------------------------------------+----------+-------------| | technology | date | suggestion | |----------------------------------------------+----------+-------------| | AppHarbor | Mar 2012 | Trial | | Accumulate-only data | Nov 2015 | Assess | | Accumulate-only data | May 2015 | Assess | | Accumulate-only data | Jan 2015 | Assess | | Buying solutions you can only afford one of | Mar 2012 | Hold | |----------------------------------------------+----------+-------------|   I then wrote a Cypher script to create the following graph model:   WITH [&amp;quot;Hold&amp;quot;, &amp;quot;Assess&amp;quot;, &amp;quot;Trial&amp;quot;, &amp;quot;Adopt&amp;quot;] AS positions UNWIND RANGE (0, size(positions) - 2) AS index WITH positions[index] AS pos1, positions[index + 1] AS pos2 MERGE (position1:Position {value: pos1}) MERGE (position2:Position {value: pos2}) MERGE (position1)-[:NEXT]-&amp;gt;(position2); load csv with headers from &amp;quot;file:///blips.</description>
    </item>
    
    <item>
      <title>Go: Templating with the Gin Web Framework</title>
      <link>https://mneedham.github.io/2016/12/23/go-templating-with-the-gin-web-framework/</link>
      <pubDate>Fri, 23 Dec 2016 14:30:09 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/12/23/go-templating-with-the-gin-web-framework/</guid>
      <description>I spent a bit of time over the last week building a little internal web application using Go and the Gin Web Framework and it took me a while to get the hang of the templating language so I thought I&#39;d write up some examples.  Before we get started, I&#39;ve got my GOPATH set to the following path: $ echo $GOPATH /Users/markneedham/projects/gocode  And the project containing the examples sits inside the src directory: $ pwd /Users/markneedham/projects/gocode/src/github.</description>
    </item>
    
    <item>
      <title>Docker: Unknown - Unable to query docker version: x509: certificate is valid for</title>
      <link>https://mneedham.github.io/2016/12/21/docker-unknown-unable-to-query-docker-version-x509-certificate-is-valid-for/</link>
      <pubDate>Wed, 21 Dec 2016 07:11:50 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/12/21/docker-unknown-unable-to-query-docker-version-x509-certificate-is-valid-for/</guid>
      <description>I was playing around with Docker locally and somehow ended up with this error when I tried to list my docker machines: $ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS default - virtualbox Running tcp://192.168.99.101:2376 Unknown Unable to query docker version: Get https://192.168.99.101:2376/v1.15/version: x509: certificate is valid for 192.168.99.100, not 192.168.99.101   My Google Fu was weak I couldn&#39;t find any suggestions for what this might mean so I tried shutting it down and starting it again!</description>
    </item>
    
    <item>
      <title>Kubernetes: Simulating a network partition</title>
      <link>https://mneedham.github.io/2016/12/04/kubernetes-simulating-a-network-partition/</link>
      <pubDate>Sun, 04 Dec 2016 12:37:49 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/12/04/kubernetes-simulating-a-network-partition/</guid>
      <description>A couple of weeks ago I wrote a post explaining how to create a Neo4j causal cluster using Kubernetes and ... the I wanted to work out how to simulate a network partition which would put the leader on the minority side and force an election.  We&#39;ve done this on our internal tooling on AWS using the iptables command but unfortunately that isn&#39;t available in my container, which only has the utilities provided by BusyBox.</description>
    </item>
    
    <item>
      <title>Kubernetes: Spinning up a Neo4j 3.1 Causal Cluster</title>
      <link>https://mneedham.github.io/2016/11/25/kubernetes-spinning-up-a-neo4j-3-1-causal-cluster/</link>
      <pubDate>Fri, 25 Nov 2016 16:55:56 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/11/25/kubernetes-spinning-up-a-neo4j-3-1-causal-cluster/</guid>
      <description>A couple of weeks ago I wrote a blog post explaining how I&#39;d created a Neo4j causal cluster using docker containers directly and for my next pet project I wanted to use Kubernetes as an orchestration layer so that I could declaratively change the number of servers in my cluster.  I&#39;d never used Kubernetes before but I saw a presentation showing how to use it to create an Elastic cluster at the GDG Cloud meetup a couple of months ago.</description>
    </item>
    
    <item>
      <title>Kubernetes: Writing hostname to a file</title>
      <link>https://mneedham.github.io/2016/11/22/kubernetes-writing-hostname-to-a-file/</link>
      <pubDate>Tue, 22 Nov 2016 19:56:31 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/11/22/kubernetes-writing-hostname-to-a-file/</guid>
      <description>Over the weekend I spent a bit of time playing around with Kubernetes and to get the hang of the technology I set myself the task of writing the hostname of the machine to a file.  I&#39;m using the excellent minikube tool to create a local Kubernetes cluster for my experiments so the first step is to spin that up:
$ minikube start Starting local Kubernetes cluster... Kubectl is now configured to use the cluster.</description>
    </item>
    
    <item>
      <title>Neo4j 3.1 beta3 &#43; docker: Creating a Causal Cluster</title>
      <link>https://mneedham.github.io/2016/11/13/neo4j-3-1-beta3-docker-creating-a-causal-cluster/</link>
      <pubDate>Sun, 13 Nov 2016 12:30:08 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/11/13/neo4j-3-1-beta3-docker-creating-a-causal-cluster/</guid>
      <description>Over the weekend I&#39;ve been playing around with docker and learning how to spin up a Neo4j Causal Cluster.
Causal Clustering is Neo4j&#39;s new clustering architecture which makes use of Diego Ongaro&#39;s Raft consensus algorithm to ensure writes are committed on a majority of servers. It&#39;ll be available in the 3.1 series of Neo4j which is currently in beta. I&#39;ll be using BETA3 in this post.   I don&#39;t know much about docker but luckily my colleague Kevin Van Gundy wrote a blog post a couple of weeks ago explaining how to spin up Neo4j inside a docker container which was very helpful for getting me started.</description>
    </item>
    
    <item>
      <title>Neo4j: Find the intermediate point between two lat/longs</title>
      <link>https://mneedham.github.io/2016/11/01/neo4j-find-the-intermediate-point-between-two-latlongs/</link>
      <pubDate>Tue, 01 Nov 2016 22:10:57 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/11/01/neo4j-find-the-intermediate-point-between-two-latlongs/</guid>
      <description>Yesterday I wrote a blog post showing how to find the midpoint between two lat/longs using Cypher which worked well as a first attempt at filling in missing locations, but I realised I could do better.  As I mentioned in the last post, when I find a stop that&#39;s missing lat/long coordinates I can usually find two nearby stops that allow me to triangulate this stop&#39;s location.
I also have train routes which indicate the number of seconds it takes to go from one stop to another, which allows me to indicate whether the location-less stop is closer to one stop than the other.</description>
    </item>
    
    <item>
      <title>Neo4j: Find the midpoint between two lat/longs</title>
      <link>https://mneedham.github.io/2016/10/31/neo4j-find-the-midpoint-between-two-latlongs/</link>
      <pubDate>Mon, 31 Oct 2016 19:31:46 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/10/31/neo4j-find-the-midpoint-between-two-latlongs/</guid>
      <description>Over the last couple of weekends I&#39;ve been playing around with some transport data and I wanted to run the A* algorithm to find the quickest route between two stations.
The A* algorithm takes an estimateEvaluator as one of its parameters and the evaluator looks at lat/longs of nodes to work out whether a path is worth following or not. I therefore needed to add lat/longs for each station and I found it surprisingly hard to find this location date for all the points in the dataset.</description>
    </item>
    
    <item>
      <title>Neo4j: Create dynamic relationship type</title>
      <link>https://mneedham.github.io/2016/10/30/neo4j-create-dynamic-relationship-type/</link>
      <pubDate>Sun, 30 Oct 2016 22:12:50 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/10/30/neo4j-create-dynamic-relationship-type/</guid>
      <description>One of the things I&#39;ve often found frustrating when importing data using Cypher, Neo4j&#39;s query language, is that it&#39;s quite difficult to create dynamic relationship types. Say we have a CSV file structured like this:
load csv with headers from &amp;quot;file:///people.csv&amp;quot; AS row RETURN row  ╒═══════════════════════════════════════════════════════╕ │row │ ╞═══════════════════════════════════════════════════════╡ │{node1: Mark, node2: Reshmee, relationship: MARRIED_TO}│ ├───────────────────────────────────────────────────────┤ │{node1: Mark, node2: Alistair, relationship: FRIENDS} │ └───────────────────────────────────────────────────────┘  We want to create nodes with the relationship type specified in the file.</description>
    </item>
    
    <item>
      <title>Neo4j: Dynamically add property/Set dynamic property</title>
      <link>https://mneedham.github.io/2016/10/27/neo4j-dynamically-add-property/</link>
      <pubDate>Thu, 27 Oct 2016 05:29:30 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/10/27/neo4j-dynamically-add-property/</guid>
      <description>I&#39;ve been playing around with a dataset which has the timetable for the national rail in the UK and they give you departure and arrival times of each train in a textual format. For example, the node to represent a stop could be created like this:
CREATE (stop:Stop {arrival: &amp;quot;0802&amp;quot;, departure: &amp;quot;0803H&amp;quot;})   That time format isn&#39;t particular amenable to querying so I wanted to add another property which indicated the number of seconds since the start of the day.</description>
    </item>
    
    <item>
      <title>Neo4j: Detecting rogue spaces in CSV headers with LOAD CSV</title>
      <link>https://mneedham.github.io/2016/10/19/neo4j-detecting-rogue-spaces-in-csv-headers-with-load-csv/</link>
      <pubDate>Wed, 19 Oct 2016 05:16:07 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/10/19/neo4j-detecting-rogue-spaces-in-csv-headers-with-load-csv/</guid>
      <description>Last week I was helping someone load the data from a CSV file into Neo4j and we were having trouble filtering out rows which contained a null value in one of the columns.  This is what the data looked like: load csv with headers from &amp;quot;file:///foo.csv&amp;quot; as row RETURN row  ╒══════════════════════════════════╕ │row │ ╞══════════════════════════════════╡ │{key1: a, key2: (null), key3: c}│ ├──────────────────────────────────┤ │{key1: d, key2: e, key3: f} │ └──────────────────────────────────┘   We&#39;d like to filter out any rows which have &#39;key2&#39; as null, so let&#39;s tweak our query to do that: load csv with headers from &amp;quot;file:///foo.</description>
    </item>
    
    <item>
      <title>Neo4j: requirement failed</title>
      <link>https://mneedham.github.io/2016/10/04/neo4j-requirement-failed/</link>
      <pubDate>Tue, 04 Oct 2016 22:33:43 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/10/04/neo4j-requirement-failed/</guid>
      <description>Last week during a hands on Cypher meetup, using Neo4j&#39;s built in movie dataset, one of the attendees showed me the following query which wasn&#39;t working as expected: MATCH (p:Person)-[:ACTED_IN]-&amp;gt;(movie) RETURN p, COLLECT(movie.title) AS movies ORDER BY COUNT(movies) DESC LIMIT 10  requirement failed   We can get a full stack trace in logs/debug.log if we run the same query from the cypher-shell, which was introduced during one fo the Neo4j 3.</description>
    </item>
    
    <item>
      <title>Neo4j: Procedure call inside a query does not support passing arguments implicitly (pass explicitly after procedure name instead)</title>
      <link>https://mneedham.github.io/2016/10/02/neo4j-procedure-call-inside-a-query-does-not-support-passing-arguments-implicitly-pass-explicitly-after-procedure-name-instead/</link>
      <pubDate>Sun, 02 Oct 2016 10:13:26 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/10/02/neo4j-procedure-call-inside-a-query-does-not-support-passing-arguments-implicitly-pass-explicitly-after-procedure-name-instead/</guid>
      <description>A couple of days I was trying to write a Cypher query to filter the labels in my database. I started with the following procedure call to get the list of all the labels:
CALL db.labels  ╒══════════╕ │label │ ╞══════════╡ │Airport │ ├──────────┤ │Flight │ ├──────────┤ │Airline │ ├──────────┤ │Movie │ ├──────────┤ │AirportDay│ ├──────────┤ │Person │ ├──────────┤ │Engineer │ └──────────┘  I was only interested in labels that contained the letter &#39;a&#39; so I tweaked the query to filter the output of the procedure: CALL db.</description>
    </item>
    
    <item>
      <title>scikit-learn: First steps with log_loss</title>
      <link>https://mneedham.github.io/2016/09/14/scikit-learn-first-steps-with-log_loss/</link>
      <pubDate>Wed, 14 Sep 2016 05:33:38 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/09/14/scikit-learn-first-steps-with-log_loss/</guid>
      <description>Over the last week I&#39;ve spent a little bit of time playing around with the data in the Kaggle TalkingData Mobile User Demographics competition, and came across a notebook written by dune_dweller showing how to run a logistic regression algorithm on the dataset.  The metric used to evaluate the output in this competition is multi class logarithmic loss, which is implemented by the log_loss function in the scikit-learn library.</description>
    </item>
    
    <item>
      <title>scikit-learn: Clustering and the curse of dimensionality</title>
      <link>https://mneedham.github.io/2016/08/27/scikit-learn-clustering-and-the-curse-of-dimensionality/</link>
      <pubDate>Sat, 27 Aug 2016 20:32:09 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/08/27/scikit-learn-clustering-and-the-curse-of-dimensionality/</guid>
      <description>In my last post I attempted to cluster Game of Thrones episodes based on character appearances without much success. After I wrote that post I was flicking through the scikit-learn clustering documentation and noticed the following section which describes some of the weaknesses of the K-means clustering algorithm:  Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”).</description>
    </item>
    
    <item>
      <title>scikit-learn: Trying to find clusters of Game of Thrones episodes</title>
      <link>https://mneedham.github.io/2016/08/25/scikit-learn-trying-to-find-clusters-of-game-of-thrones-episodes/</link>
      <pubDate>Thu, 25 Aug 2016 22:07:25 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/08/25/scikit-learn-trying-to-find-clusters-of-game-of-thrones-episodes/</guid>
      <description>In my last post I showed how to find similar Game of Thrones episodes based on the characters that appear in different episodes. This allowed us to find similar episodes on an episode by episode basis, but I was curious whether there were groups of similar episodes that we could identify. scikit-learn provides several clustering algorithms that can run over our episode vectors and hopefully find clusters of similar episodes.</description>
    </item>
    
    <item>
      <title>Neo4j/scikit-learn: Calculating the cosine similarity of Game of Thrones episodes</title>
      <link>https://mneedham.github.io/2016/08/22/neo4jscikit-learn-calculating-the-cosine-similarity-of-game-of-thrones-episodes/</link>
      <pubDate>Mon, 22 Aug 2016 21:12:54 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/08/22/neo4jscikit-learn-calculating-the-cosine-similarity-of-game-of-thrones-episodes/</guid>
      <description>A couple of months ago Praveena and I created a Game of Thrones dataset to use in a workshop and I thought it&#39;d be fun to run it through some machine learning algorithms and hopefully find some interesting insights.  The dataset is available as CSV files but for this analysis I&#39;m assuming that it&#39;s already been imported into neo4j. If you want to import the data you can run the tutorial by typing the following into the query bar of the neo4j browser: :play http://guides.</description>
    </item>
    
    <item>
      <title>Python: matplotlib, seaborn, virtualenv - Python is not installed as a framework</title>
      <link>https://mneedham.github.io/2016/08/14/python-matplotlibseabornvirtualenv-python-is-not-installed-as-a-framework/</link>
      <pubDate>Sun, 14 Aug 2016 18:56:35 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/08/14/python-matplotlibseabornvirtualenv-python-is-not-installed-as-a-framework/</guid>
      <description>Over the weekend I was following The Marketing Technologist&#39;s content based recommender tutorial but ran into the following exception when trying to import the seaborn library: $ python 5_content_based_recommender/run.py Traceback (most recent call last): File &amp;quot;5_content_based_recommender/run.py&amp;quot;, line 14, in &amp;lt;module&amp;gt; import seaborn as sns File &amp;quot;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/seaborn/__init__.py&amp;quot;, line 6, in &amp;lt;module&amp;gt; from .rcmod import * File &amp;quot;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/seaborn/rcmod.py&amp;quot;, line 8, in &amp;lt;module&amp;gt; from . import palettes, _orig_rc_params File &amp;quot;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/seaborn/palettes.py&amp;quot;, line 12, in &amp;lt;module&amp;gt; from .</description>
    </item>
    
    <item>
      <title>scikit-learn: TF/IDF and cosine similarity for computer science papers</title>
      <link>https://mneedham.github.io/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers/</link>
      <pubDate>Wed, 27 Jul 2016 02:45:28 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers/</guid>
      <description>A couple of months ago I downloaded the meta data for a few thousand computer science papers so that I could try and write a mini recommendation engine to tell me what paper I should read next.  Since I don&#39;t have any data on which people read each paper a collaborative filtering approach is ruled out, so instead I thought I could try content based filtering instead.  Let&#39;s quickly check the Wikipedia definition of content based filtering:  In a content-based recommender system, keywords are used to describe the items and a user profile is built to indicate the type of item this user likes.</description>
    </item>
    
    <item>
      <title>Mahout/Hadoop: org.apache.hadoop.ipc.RemoteException: Server IPC version 9 cannot communicate with client version 4</title>
      <link>https://mneedham.github.io/2016/07/22/mahouthadoop-org-apache-hadoop-ipc-remoteexception-server-ipc-version-9-cannot-communicate-with-client-version-4/</link>
      <pubDate>Fri, 22 Jul 2016 13:55:14 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/22/mahouthadoop-org-apache-hadoop-ipc-remoteexception-server-ipc-version-9-cannot-communicate-with-client-version-4/</guid>
      <description>I&#39;ve been working my way through Dragan Milcevski&#39;s mini tutorial on using Mahout to do content based filtering on documents and reached the final step where I needed to read in the generated item-similarity files.  I got the example compiling by using the following Maven dependency: &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.mahout&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mahout-core&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;0.9&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  Unfortunately when I ran the code I ran into a version incompatibility problem:
Exception in thread &amp;quot;main&amp;quot; org.</description>
    </item>
    
    <item>
      <title>Hadoop: DataNode not starting</title>
      <link>https://mneedham.github.io/2016/07/22/hadoop-datanode-not-starting/</link>
      <pubDate>Fri, 22 Jul 2016 13:31:15 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/22/hadoop-datanode-not-starting/</guid>
      <description>In my continued playing with Mahout I eventually decided to give up using my local file system and use a local Hadoop instead since that seems to have much less friction when following any examples.
 Unfortunately all my attempts to upload any files from my local file system to HDFS were being met with the following exception: java.io.IOException: File /user/markneedham/book2.txt could only be replicated to 0 nodes, instead of 1 at org.</description>
    </item>
    
    <item>
      <title>Mahout: Exception in thread &#34;main&#34; java.lang.IllegalArgumentException: Wrong FS: file:/... expected: hdfs://</title>
      <link>https://mneedham.github.io/2016/07/21/mahout-exception-in-thread-main-java-lang-illegalargumentexception-wrong-fs-file-expected-hdfs/</link>
      <pubDate>Thu, 21 Jul 2016 17:57:41 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/21/mahout-exception-in-thread-main-java-lang-illegalargumentexception-wrong-fs-file-expected-hdfs/</guid>
      <description>I&#39;ve been playing around with Mahout over the last couple of days to see how well it works for content based filtering.
I started following a mini tutorial from Stack Overflow but ran into trouble on the first step: bin/mahout seqdirectory \ --input file:///Users/markneedham/Downloads/apache-mahout-distribution-0.12.2/foo \ --output file:///Users/markneedham/Downloads/apache-mahout-distribution-0.12.2/foo-out \ -c UTF-8 \ -chunk 64 \ -prefix mah  16/07/21 21:19:20 INFO AbstractJob: Command line arguments: {--charset=[UTF-8], --chunkSize=[64], --endPhase=[2147483647], --fileFilterClass=[org.apache.mahout.text.PrefixAdditionFilter], --input=[file:///Users/markneedham/Downloads/apache-mahout-distribution-0.12.2/foo], --keyPrefix=[mah], --method=[mapreduce], --output=[file:///Users/markneedham/Downloads/apache-mahout-distribution-0.</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Detecting duplicates using relationships</title>
      <link>https://mneedham.github.io/2016/07/20/neo4j-cypher-detecting-duplicates-using-relationships/</link>
      <pubDate>Wed, 20 Jul 2016 17:32:19 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/20/neo4j-cypher-detecting-duplicates-using-relationships/</guid>
      <description>I&#39;ve been building a graph of computer science papers on and off for a couple of months and now that I&#39;ve got a few thousand loaded in I realised that there are quite a few duplicates.  They&#39;re not duplicates in the sense that there are multiple entries with the same identifier but rather have different identifiers but seem to be the same paper!  e.g. there are a couple of papers titled &#39;Authentication in the Taos operating system&#39;:  http://dl.</description>
    </item>
    
    <item>
      <title>Python: Scraping elements relative to each other with BeautifulSoup</title>
      <link>https://mneedham.github.io/2016/07/11/python-scraping-elements-relative-to-each-other-with-beautifulsoup/</link>
      <pubDate>Mon, 11 Jul 2016 06:01:22 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/11/python-scraping-elements-relative-to-each-other-with-beautifulsoup/</guid>
      <description>Last week we hosted a Game of Thrones based intro to Cypher at the Women Who Code London meetup and in preparation had to scrape the wiki to build a dataset.  I&#39;ve built lots of datasets this way and it&#39;s a painless experience as long as the pages make liberal use of CSS classes and/or IDs.  Unfortunately the Game of Thrones wiki doesn&#39;t really do that so I had to find another way to extract the data I wanted - extracting elements based on their position to more prominent elements on the page.</description>
    </item>
    
    <item>
      <title>Neo4j 3.0 Drivers - Failed to save the server ID and the certificate received from the server</title>
      <link>https://mneedham.github.io/2016/07/11/neo4j-3-0-drivers-failed-to-save-the-server-id-and-the-certificate-received-from-the-server/</link>
      <pubDate>Mon, 11 Jul 2016 05:21:43 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/11/neo4j-3-0-drivers-failed-to-save-the-server-id-and-the-certificate-received-from-the-server/</guid>
      <description>I&#39;ve been using the Neo4j Java Driver on various local databases over the past week and ran into the following certificate problem a few times: org.neo4j.driver.v1.exceptions.ClientException: Unable to process request: General SSLEngine problem at org.neo4j.driver.internal.connector.socket.SocketClient.start(SocketClient.java:88) at org.neo4j.driver.internal.connector.socket.SocketConnection.&amp;lt;init&amp;gt;(SocketConnection.java:63) at org.neo4j.driver.internal.connector.socket.SocketConnector.connect(SocketConnector.java:52) at org.neo4j.driver.internal.pool.InternalConnectionPool.acquire(InternalConnectionPool.java:113) at org.neo4j.driver.internal.InternalDriver.session(InternalDriver.java:53) Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem at sun.security.ssl.Handshaker.checkThrown(Handshaker.java:1431) at sun.security.ssl.SSLEngineImpl.checkTaskThrown(SSLEngineImpl.java:535) at sun.security.ssl.SSLEngineImpl.writeAppRecord(SSLEngineImpl.java:1214) at sun.security.ssl.SSLEngineImpl.wrap(SSLEngineImpl.java:1186) at javax.net.ssl.SSLEngine.wrap(SSLEngine.java:469) at org.neo4j.driver.internal.connector.socket.TLSSocketChannel.wrap(TLSSocketChannel.java:270) at org.neo4j.driver.internal.connector.socket.TLSSocketChannel.runHandshake(TLSSocketChannel.java:131) at org.neo4j.driver.internal.connector.socket.TLSSocketChannel.&amp;lt;init&amp;gt;(TLSSocketChannel.java:95) at org.neo4j.driver.internal.connector.socket.TLSSocketChannel.&amp;lt;init&amp;gt;(TLSSocketChannel.java:77) at org.neo4j.driver.internal.connector.socket.TLSSocketChannel.&amp;lt;init&amp;gt;(TLSSocketChannel.java:70) at org.</description>
    </item>
    
    <item>
      <title>R: Sentiment analysis of morning pages</title>
      <link>https://mneedham.github.io/2016/07/09/r-sentiment-analysis-of-morning-pages/</link>
      <pubDate>Sat, 09 Jul 2016 06:36:51 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/07/09/r-sentiment-analysis-of-morning-pages/</guid>
      <description>A couple of months ago I came across a cool blog post by Julia Silge where she runs a sentiment analysis algorithm over her tweet stream to see how her tweet sentiment has varied over time.  I wanted to give it a try but couldn&#39;t figure out how to get a dump of my tweets so I decided to try it out on the text from my morning pages writing which I&#39;ve been experimenting with for a few months.</description>
    </item>
    
    <item>
      <title>Python: BeautifulSoup - Insert tag</title>
      <link>https://mneedham.github.io/2016/06/30/python-beautifulsoup-insert-tag/</link>
      <pubDate>Thu, 30 Jun 2016 21:28:35 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/06/30/python-beautifulsoup-insert-tag/</guid>
      <description>I&#39;ve been scraping the Game of Thrones wiki in preparation for a meetup at Women Who Code next week and while attempting to extract character allegiances I wanted to insert missing line breaks to separate different allegiances.  I initially tried creating a line break like this: &amp;gt;&amp;gt;&amp;gt; from bs4 import BeautifulSoup &amp;gt;&amp;gt;&amp;gt; tag = BeautifulSoup(&amp;quot;&amp;lt;br /&amp;gt;&amp;quot;, &amp;quot;html.parser&amp;quot;) &amp;gt;&amp;gt;&amp;gt; tag &amp;lt;br/&amp;gt;   It looks like it should work but later on in my script I check the &#39;name&#39; attribute to work out whether I&#39;ve got a line break and it doesn&#39;t return the value I expected it to: &amp;gt;&amp;gt;&amp;gt; tag.</description>
    </item>
    
    <item>
      <title>Unix: Find files greater than date</title>
      <link>https://mneedham.github.io/2016/06/24/unix-find-files-greater-than-date/</link>
      <pubDate>Fri, 24 Jun 2016 16:56:17 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/06/24/unix-find-files-greater-than-date/</guid>
      <description>For the latter part of the week I&#39;ve been running some tests against Neo4j which generate a bunch of log files and I wanted to filter those files based on the time they were created to do some further analysis.  This is an example of what the directory listing looks like: $ ls -alh foo/database-agent-* -rw-r--r-- 1 markneedham wheel 2.5K 23 Jun 14:00 foo/database-agent-mac17f73-1-logs-archive-201606231300176.tar.gz -rw-r--r-- 1 markneedham wheel 8.</description>
    </item>
    
    <item>
      <title>Unix: Find all text below string in a file</title>
      <link>https://mneedham.github.io/2016/06/19/unix-find-all-text-below-string-in-a-file/</link>
      <pubDate>Sun, 19 Jun 2016 08:36:46 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/06/19/unix-find-all-text-below-string-in-a-file/</guid>
      <description>I recently wanted to parse some text out of a bunch of files so that I could do some sentiment analysis on it. Luckily the text I want is at the end of the file and doesn&#39;t have anything after it but there is text before it that I want to get rid. The files look like this:
# text I don&#39;t care about = Heading of the bit I care about # text I care about  In other words I want to find the line that contains the Heading and then get all the text after that point.</description>
    </item>
    
    <item>
      <title>Unix: Split string using separator</title>
      <link>https://mneedham.github.io/2016/06/19/unix-split-string-using-separator/</link>
      <pubDate>Sun, 19 Jun 2016 07:22:57 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/06/19/unix-split-string-using-separator/</guid>
      <description>I recently found myself needing to iterate over a bunch of &#39;/&#39; separated strings on the command line and extract just the text after the last &#39;/&#39;.  e.g. an example of one of the strings A/B/C  I wanted to write some code that could split on &#39;/&#39; and then pick the 3rd item in the resulting collection. One way of doing this is to echo the string and then pipe it through cut:</description>
    </item>
    
    <item>
      <title>Python: Regex - matching foreign characters/unicode letters</title>
      <link>https://mneedham.github.io/2016/06/18/python-regex-matching-foreign-charactersunicode-letters/</link>
      <pubDate>Sat, 18 Jun 2016 07:38:04 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/06/18/python-regex-matching-foreign-charactersunicode-letters/</guid>
      <description>I&#39;ve been back in the land of screen scrapping this week extracting data from the Game of Thrones wiki and needed to write a regular expression to pull out characters and actors.  Here are some examples of the format of the data:
Peter Dinklage as Tyrion Lannister Daniel Naprous as Oznak zo Pahl(credited as Stunt Performer) Filip Lozić as Young Nobleman Morgan C. Jones as a Braavosi captain Adewale Akinnuoye-Agbaje as Malko  So the pattern is:</description>
    </item>
    
    <item>
      <title>Unix parallel: Populating all the USB sticks</title>
      <link>https://mneedham.github.io/2016/06/01/unix-parallel-populating-all-the-usb-sticks/</link>
      <pubDate>Wed, 01 Jun 2016 05:53:38 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/06/01/unix-parallel-populating-all-the-usb-sticks/</guid>
      <description>The day before Graph Connect Europe 2016 we needed to create a bunch of USB sticks containing Neo4j and the training materials and eventually iterated our way to a half decent approach which made use of the GNU parallel command which I&#39;ve always wanted to use!  But first I needed to get a USB hub so I could do lots of them at the same time. I bought the EasyAcc USB 3.</description>
    </item>
    
    <item>
      <title>Neo4j vs Relational: Refactoring - Extracting node/table</title>
      <link>https://mneedham.github.io/2016/05/22/neo4j-vs-relational-refactoring-extracting-nodetable/</link>
      <pubDate>Sun, 22 May 2016 09:58:38 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/05/22/neo4j-vs-relational-refactoring-extracting-nodetable/</guid>
      <description>In my previous blog post I showed how to add a new property/field to a node with a label/record in a table for a football transfers dataset that I&#39;ve been playing with. After introducing this &#39;nationality&#39; property I realised that I now had some duplication in the model:

   players.nationality and clubs.country are referring to the same countries but they&#39;ve both got them stored as strings so we can&#39;t ensure the integrity of our countries and ensure that we&#39;re referring to the same country.</description>
    </item>
    
    <item>
      <title>Neo4j vs Relational: Refactoring - Add a new field/property</title>
      <link>https://mneedham.github.io/2016/05/22/neo4j-vs-relational-refactoring-add-a-new-fieldproperty/</link>
      <pubDate>Sun, 22 May 2016 09:09:27 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/05/22/neo4j-vs-relational-refactoring-add-a-new-fieldproperty/</guid>
      <description>A couple of months ago I presented a webinar comparing how you&#39;d model and evolve a data model using a Postgres SQL database and Neo4j.
This is what the two data models looked like after the initial data import and before any refactoring/migration had been done:
Relational 

Graph 

I wanted to add a &#39;nationality&#39; property to the players table in the SQL schema and to the nodes with the &#39;Player&#39; label in the graph.</description>
    </item>
    
    <item>
      <title>R: substr - Getting a vector of positions</title>
      <link>https://mneedham.github.io/2016/04/18/r-substr-getting-a-vector-of-positions/</link>
      <pubDate>Mon, 18 Apr 2016 19:49:02 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/04/18/r-substr-getting-a-vector-of-positions/</guid>
      <description>I recently found myself writing an R script to extract parts of a string based on a beginning and end index which is reasonably easy using the substr function: &amp;gt; substr(&amp;quot;mark loves graphs&amp;quot;, 0, 4) [1] &amp;quot;mark&amp;quot;   But what if we have a vector of start and end positions? &amp;gt; substr(&amp;quot;mark loves graphs&amp;quot;, c(0, 6), c(4, 10)) [1] &amp;quot;mark&amp;quot;  Hmmm that didn&#39;t work as I expected! It turns out we actually need to use the substring function instead which wasn&#39;t initially obvious to me on reading the documentation:</description>
    </item>
    
    <item>
      <title>R: tm - Unique words/terms per document</title>
      <link>https://mneedham.github.io/2016/04/11/r-tm-unique-wordsterms-per-document/</link>
      <pubDate>Mon, 11 Apr 2016 05:40:06 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/04/11/r-tm-unique-wordsterms-per-document/</guid>
      <description>I&#39;ve been doing a bit of text mining over the weekend using the R tm package and I wanted to only count a term once per document which isn&#39;t how it works out the box. For example let&#39;s say we&#39;re writing a bit of code to calculate the frequency of terms across some documents. We might write the following code:
library(tm) text = c(&amp;quot;I am Mark I am Mark&amp;quot;, &amp;quot;Neo4j is cool Neo4j is cool&amp;quot;) corpus = VCorpus(VectorSource(text)) tdm = as.</description>
    </item>
    
    <item>
      <title>Neo4j: A procedure for the SLM clustering algorithm</title>
      <link>https://mneedham.github.io/2016/02/28/neo4j-a-procedure-for-the-slm-clustering-algorithm/</link>
      <pubDate>Sun, 28 Feb 2016 20:40:11 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/02/28/neo4j-a-procedure-for-the-slm-clustering-algorithm/</guid>
      <description>In the middle of last year I blogged about the Smart Local Moving algorithm which is used for community detection in networks and with the upcoming introduction of procedures in Neo4j I thought it&#39;d be fun to make that code accessible as one.  If you want to grab the code and follow along it&#39;s sitting on the SLM repository on my github. At the moment the procedure is hard coded to work with a KNOWS relationship between two nodes but that could easily be changed.</description>
    </item>
    
    <item>
      <title>Clojure: First steps with reducers</title>
      <link>https://mneedham.github.io/2016/01/24/clojure-first-steps-with-reducers/</link>
      <pubDate>Sun, 24 Jan 2016 22:01:43 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/01/24/clojure-first-steps-with-reducers/</guid>
      <description>I&#39;ve been playing around with Clojure a bit today in preparation for a talk I&#39;m giving next week and found myself writing the following code to apply the same function to three different scores: (defn log2 [n] (/ (Math/log n) (Math/log 2))) (defn score-item [n] (if (= n 0) 0 (log2 n))) (+ (score-item 12) (score-item 13) (score-item 5)) 9.60733031374961   I&#39;d forgotten about folding over a collection but quickly remembered that I could achieve the same result with the following code: (reduce #(+ %1 (score-item %2)) 0 [12 13 5]) 9.</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - avoid duplicate calls to NOT patterns</title>
      <link>https://mneedham.github.io/2016/01/17/neo4j-cypher-avoid-duplicate-calls-to-not-patterns/</link>
      <pubDate>Sun, 17 Jan 2016 12:19:35 +0000</pubDate>
      
      <guid>https://mneedham.github.io/2016/01/17/neo4j-cypher-avoid-duplicate-calls-to-not-patterns/</guid>
      <description>I&#39;ve been reacquainting myself with the meetup.com dataset ahead of Wednesday&#39;s meetup in London and wanted to write a collaborative filtering type query to work out which groups people in my groups were in. This started simple enough:
MATCH (member:Member {name: &amp;quot;Mark Needham&amp;quot;})-[:MEMBER_OF]-&amp;gt;(group:Group)&amp;lt;-[:MEMBER_OF]-(other:Member)-[:MEMBER_OF]-&amp;gt;(otherGroup:Group) RETURN otherGroup, COUNT(*) AS commonMembers ORDER BY commonMembers DESC LIMIT 5  And doesn&#39;t take too long to run:
Cypher version: CYPHER 2.3, planner: COST. 1084378 total db hits in 1103 ms.</description>
    </item>
    
  </channel>
</rss>