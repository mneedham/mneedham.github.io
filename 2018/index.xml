<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2018s on Mark Needham</title>
    <link>http://mneedham.github.io/2018/</link>
    <description>Recent content in 2018s on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Mar 2018 16:53:33 +0000</lastBuildDate>
    
	<atom:link href="http://mneedham.github.io/2018/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Neo4j: Cypher - Neo.ClientError.Statement.TypeError: Don&#39;t know how to add Double and String</title>
      <link>http://mneedham.github.io/2018/03/14/neo4j-cypher-neo-clienterror-statement-typeerror-dont-know-add-double-string/</link>
      <pubDate>Wed, 14 Mar 2018 16:53:33 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/03/14/neo4j-cypher-neo-clienterror-statement-typeerror-dont-know-add-double-string/</guid>
      <description>I recently upgraded a Neo4j backed application from Neo4j 3.2 to Neo4j 3.3 and came across an interesting change in behaviour around type coercion which led to my application throwing a bunch of errors.  In Neo4j 3.2 and earlier if you added a String to a Double it would coerce the Double to a String and concatenate the values. The following would therefore be valid Cypher: RETURN toFloat(&amp;quot;1.0&amp;quot;) + &amp;quot; Mark&amp;quot; ╒══════════╕ │&amp;quot;result&amp;quot; │ ╞══════════╡ │&amp;quot;1.</description>
    </item>
    
    <item>
      <title>Yelp: Reverse geocoding businesses to extract detailed location information</title>
      <link>http://mneedham.github.io/2018/03/14/yelp-reverse-geocoding-businesses-extract-detailed-location-information/</link>
      <pubDate>Wed, 14 Mar 2018 08:53:04 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/03/14/yelp-reverse-geocoding-businesses-extract-detailed-location-information/</guid>
      <description>I&#39;ve been playing around with the Yelp Open Dataset and wanted to extract more detailed location information for each business.  This is an example of the JSON representation of one business: $ cat dataset/business.json | head -n1 | jq { &amp;quot;business_id&amp;quot;: &amp;quot;FYWN1wneV18bWNgQjJ2GNg&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Dental by Design&amp;quot;, &amp;quot;neighborhood&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;4855 E Warner Rd, Ste B9&amp;quot;, &amp;quot;city&amp;quot;: &amp;quot;Ahwatukee&amp;quot;, &amp;quot;state&amp;quot;: &amp;quot;AZ&amp;quot;, &amp;quot;postal_code&amp;quot;: &amp;quot;85044&amp;quot;, &amp;quot;latitude&amp;quot;: 33.3306902, &amp;quot;longitude&amp;quot;: -111.9785992, &amp;quot;stars&amp;quot;: 4, &amp;quot;review_count&amp;quot;: 22, &amp;quot;is_open&amp;quot;: 1, &amp;quot;attributes&amp;quot;: { &amp;quot;AcceptsInsurance&amp;quot;: true, &amp;quot;ByAppointmentOnly&amp;quot;: true, &amp;quot;BusinessAcceptsCreditCards&amp;quot;: true }, &amp;quot;categories&amp;quot;: [ &amp;quot;Dentists&amp;quot;, &amp;quot;General Dentistry&amp;quot;, &amp;quot;Health &amp;amp; Medical&amp;quot;, &amp;quot;Oral Surgeons&amp;quot;, &amp;quot;Cosmetic Dentists&amp;quot;, &amp;quot;Orthodontists&amp;quot; ], &amp;quot;hours&amp;quot;: { &amp;quot;Friday&amp;quot;: &amp;quot;7:30-17:00&amp;quot;, &amp;quot;Tuesday&amp;quot;: &amp;quot;7:30-17:00&amp;quot;, &amp;quot;Thursday&amp;quot;: &amp;quot;7:30-17:00&amp;quot;, &amp;quot;Wednesday&amp;quot;: &amp;quot;7:30-17:00&amp;quot;, &amp;quot;Monday&amp;quot;: &amp;quot;7:30-17:00&amp;quot; } }   The businesses reside in different countries so I wanted to extract the area/county/state and the country for each of them.</description>
    </item>
    
    <item>
      <title>Running asciidoctor-pdf on TeamCity</title>
      <link>http://mneedham.github.io/2018/03/13/running-asciidoctor-pdf-teamcity/</link>
      <pubDate>Tue, 13 Mar 2018 21:57:14 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/03/13/running-asciidoctor-pdf-teamcity/</guid>
      <description>I&#39;ve been using asciidoctor-pdf to generate PDF and while I was initially running the tool locally I eventually decided to setup a build on TeamCity.  It was a bit trickier than I expected, mostly because I&#39;m not that familiar with deploying Ruby applications, but I thought I&#39;d capture what I&#39;ve done for future me.  I have the following Gemfile that installs asciidoctor-pdf and its dependencies: Gemfile
source &#39;https://rubygems.</description>
    </item>
    
    <item>
      <title>Neo4j Import: java.lang.IllegalStateException: Mixing specified and unspecified group belongings in a single import isn&#39;t supported</title>
      <link>http://mneedham.github.io/2018/03/07/neo4j-import-java-lang-illegalstateexception-mixing-specified-unspecified-group-belongings-single-import-isnt-supported/</link>
      <pubDate>Wed, 07 Mar 2018 03:11:12 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/03/07/neo4j-import-java-lang-illegalstateexception-mixing-specified-unspecified-group-belongings-single-import-isnt-supported/</guid>
      <description>I&#39;ve been working with the Neo4j Import Tool recently after a bit of a break and ran into an interesting error message that I initially didn&#39;t understand.  I had some CSV files containing nodes that I wanted to import into Neo4j. Their contents look like this: $ cat people_header.csv name:ID(Person) $ cat people.csv &amp;quot;Mark&amp;quot; &amp;quot;Michael&amp;quot; &amp;quot;Ryan&amp;quot; &amp;quot;Will&amp;quot; &amp;quot;Jennifer&amp;quot; &amp;quot;Karin&amp;quot; $ cat companies_header.csv name:ID(Company) $ cat companies.csv &amp;quot;Neo4j&amp;quot;   I find it easier to use separate header files because I often make typos with my column names and it&#39;s easier to update a single line file than to open a multi-million line file and change the first line.</description>
    </item>
    
    <item>
      <title>Asciidoctor: Creating a macro</title>
      <link>http://mneedham.github.io/2018/02/19/asciidoctor-creating-macro/</link>
      <pubDate>Mon, 19 Feb 2018 20:51:31 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/02/19/asciidoctor-creating-macro/</guid>
      <description>I&#39;ve been writing the TWIN4j blog for almost a year now and during that time I&#39;ve written a few different asciidoc macros to avoid repetition.  The most recent one I wrote does the formatting around the Featured Community Member of the Week. I call it like this from the asciidoc, passing in the name of the person and a link to an image: featured::https://s3.amazonaws.com/dev.assets.neo4j.com/wp-content/uploads/20180202004247/this-week-in-neo4j-3-february-2018.jpg[name=&amp;quot;Suellen Stringer-Hye&amp;quot;]   The code for the macro has two parts.</description>
    </item>
    
    <item>
      <title>Tensorflow: Kaggle Spooky Authors Bag of Words Model</title>
      <link>http://mneedham.github.io/2018/01/29/tensorflow-kaggle-spooky-authors-bag-words-model/</link>
      <pubDate>Mon, 29 Jan 2018 06:51:10 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/01/29/tensorflow-kaggle-spooky-authors-bag-words-model/</guid>
      <description>I&#39;ve been playing around with some Tensorflow tutorials recently and wanted to see if I could create a submission for Kaggle&#39;s Spooky Author Identification competition that I&#39;ve written about recently.  My model is based on one from the text classification tutorial. The tutorial shows how to create custom Estimators which we can learn more about in a post on the Google Developers blog. Imports  Let&#39;s get started. First, our imports: from __future__ import absolute_import from __future__ import division from __future__ import print_function import numpy as np import pandas as pd import tensorflow as tf from sklearn import preprocessing from sklearn.</description>
    </item>
    
    <item>
      <title>Asciidoc to Asciidoc: Exploding includes</title>
      <link>http://mneedham.github.io/2018/01/23/asciidoc-asciidoc-exploding-includes/</link>
      <pubDate>Tue, 23 Jan 2018 21:11:49 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/01/23/asciidoc-asciidoc-exploding-includes/</guid>
      <description>One of my favourite features in AsciiDoc is the ability to include other files, but when using lots of includes is that it becomes difficult to read the whole document unless you convert it to one of the supported backends. $ asciidoctor --help Usage: asciidoctor [OPTION]... FILE... Translate the AsciiDoc source FILE or FILE(s) into the backend output format (e.g., HTML 5, DocBook 4.5, etc.) By default, the output is written to a file with the basename of the source file and the appropriate extension.</description>
    </item>
    
    <item>
      <title>Strava: Calculating the similarity of two runs</title>
      <link>http://mneedham.github.io/2018/01/18/strava-calculating-similarity-two-runs/</link>
      <pubDate>Thu, 18 Jan 2018 23:35:25 +0000</pubDate>
      
      <guid>http://mneedham.github.io/2018/01/18/strava-calculating-similarity-two-runs/</guid>
      <description>I go running several times a week and wanted to compare my runs against each other to see how similar they are.  I record my runs with the Strava app and it has an API that returns lat/long coordinates for each run in the Google encoded polyline algorithm format.  We can use the polyline library to decode these values into a list of lat/long tuples. For example: import polyline polyline.</description>
    </item>
    
  </channel>
</rss>