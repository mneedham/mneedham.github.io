
<!DOCTYPE html>
<html lang="en-us">

    <head>

        <meta charset="utf-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />

        <meta property="og:title" content=" Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm &middot;  Mark Needham" />
        <meta property="og:site_name" content="Mark Needham" />
        <meta property="og:url" content="https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/" />

    
        <meta property="og:type" content="article" />
        <meta property="og:article:published_time" content="2021-02-03T00:44:37Z" />
        <meta property="og:article:tag" content="neo4j" />
        <meta property="og:article:tag" content="graph-data-science" />
        <meta property="og:article:tag" content="graph-algorithms" />
        

        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:site" content="@markhneedham" />
        <meta name="twitter:creator" content="@markhneedham" />
        <meta name="twitter:title" content="Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm" />
        
          <meta name="twitter:description" content="In this post we&#39;ll explore the HITS link analysis algorithm that was added to the Neo4j Graph Data Science Library in version 1.5.0." />
        
        <meta name="twitter:url" content="https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/" />

      
        
        <meta name="og:image" content="https://www.markhneedham.com/blog//uploads/2021/02/gds-v1.5-hits.png" />
        <meta name="twitter:image:src" content="https://www.markhneedham.com/blog//uploads/2021/02/gds-v1.5-hits.png" />
        <meta name="twitter:image" content="https://www.markhneedham.com/blog//uploads/2021/02/gds-v1.5-hits.png" />
      

    

        <title> Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm &middot;  Mark Needham</title>

    
        <meta name="description" content="In this post we&#39;ll explore the HITS link analysis algorithm that was added to the Neo4j Graph Data Science Library in version 1.5.0." />
    

        <meta name="p:domain_verify" content="fc173d84e3a4de948ed4bda2908afd3e"/>
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

    
        <link href="https://www.markhneedham.com/blog/index.xml" rel="alternate" type="application/rss+xml" title="Mark Needham" />
    

    
        <link rel="canonical" href="https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/" />

    
    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "Article",
        "headline": "Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm",
        "author": {
            "@type": "Person",
            "name": "http://profiles.google.com/100354797468725665406?rel=author"
        },
        "datePublished": "2021-02-03",
        "description": "The Neo4j Graph Data Science Library provides efficiently implemented, parallel versions of common graph algorithms for Neo4j, exposed as Cypher procedures. It recently published version 1.5, which has lots of goodies to play with.\n   In this blog post, we\u0026#8217;re going to explore the newly added HITS algorithm with the help of a citations dataset.\n Launching Neo4j We\u0026#8217;re going to run Neo4j with the Graph Data Science Library using the following Docker Compose configuration:",
        "wordCount":  4325 
    }
    </script>
    

    

<style>
*{padding:0;margin:0}body,html{font-size:1em;line-height:1.65em;font-family:-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif;font-weight:300;color:#444}html{height:100%}body{padding:2em 2.5em 1em 20em}header{border-right:1px #eee solid;padding:2em;position:fixed;top:0;left:0;height:100%;width:13.5em}#content{display:block;width:100%}footer{padding:1em 0 2.5em;font-size:.8em;line-height:1.5em;color:#888}article{border-bottom:.1em #eee solid;padding-bottom:1.7em;max-width:56em}h4,h5,h6,hr,p{margin-top:.9em;margin-bottom:.9em}h1,h2,h3,h4,h5,h6{font-family:"Bree Serif",serif;font-weight:400!important}h1{font-size:2.5em;line-height:1.1em;margin-top:.6em;margin-bottom:.6em}h2{font-size:1.9em;line-height:1.2em;margin-top:.7em;margin-bottom:.7em}h3{font-size:1.4em;line-height:1.3em;margin-top:.8em;margin-bottom:.8em}h4{font-size:1.3em}h5{font-size:1.2em}h6{font-size:1.1em}iframe,img{max-width:100%}a{font-weight:700;text-decoration:none;color:#5cc265}a:hover{text-decoration:underline}h1 a,h2 a,h3 a,h4 a,h5 a,h6 a{font-weight:400!important}strong{font-weight:700}blockquote{border-left:.4em solid #008cc1;padding-left:1.2em;font-size:1.3em}hr{border:0;height:1px;background:#eee}ol,ul{margin-left:3em}code{font-size:1.1em;max-height: 500px;background:#eee}
pre{border-radius: .5em;font-size:.8em;line-height:1.7em;background:#eee;padding:0.5em;word-break:break-all;word-wrap:break-word;white-space:pre;white-space:-moz-pre-wrap;white-space:pre-wrap}input{font-size:1em;padding:.3em}header h1{font-size:1.9em;margin-top:.8em;margin-bottom:.6em}header h1 a{color:#444}header h1 a:hover{text-decoration:none}header #logo img{width:9em;height:9em;border-radius:4.5em;-moz-border-radius:4.5em;-webkit-border-radius:4.5em;border:none}#follow-icons{font-size:.7em;margin-top:-.7em;margin-bottom:1.5em}#follow-icons a{color:#ccc}#follow-icons span{vertical-align:top;margin-left:-.15em;margin-right:-.15em}#follow-icons span .fa-stack-1x{font-size:1.05em;line-height:1.9em}header h6{margin-top:.5em}article span.post-stamp{color:#888}h1.post-title{margin-top:.35em;margin-bottom:.6em}h3.post-title{margin-top:.4em;padding-bottom:.9em;border-bottom:1px solid #eee;font-size:1.2em;color:#444}.post-title .feature-star{font-size:.9em}.feature-star,.separator,.taglist{color:#ccc}.taglist a{background-color:#ccc;color:#fff;display:inline-block;line-height:1.5em;padding:.3em .6em;vertical-align:20%;font-size:.5em;font-family:"Open Sans",sans-serif;font-weight:700!important;text-transform:uppercase;letter-spacing:.05em;border-radius:.25em;-moz-border-radius:.25em;-webkit-border-radius:.25em}#social-bar{margin-top:1.5em;background-color:#eee;padding:.5em}#comments{margin-top:.15em;padding-bottom:.2em;border-bottom:1px solid #eee}.pagination{margin-bottom:1em}footer a{font-weight:300;color:#888;text-decoration:underline}footer a:hover{color:#444;text-decoration:none}@media only screen and (min-width:1281px){body,html{font-size:1.1em}}@media only screen and (max-width:800px){body{padding:0}header{border-right:none;border-bottom:1px #eee solid;position:relative;height:auto;width:auto;text-align:center;padding-bottom:1em}#content{margin-left:0;padding:2em 2em 1em;width:auto}footer{padding:0 2.5em 2em}}@media only screen and (max-width:320px){#content,header{padding:1.2em 1.2em .6em}footer{padding:0 1.5em 1.2em}ol,ul{margin-left:2em}}
</style>

<style>
.stretch{width:100%}
table{border-collapse:collapse;border-spacing:0}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede;}
table thead,table tfoot{background:#008cc1;}
table thead tr th{background:#008cc1;}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table thead tr th {color: #ffffff;}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8);}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6;}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0; margin-top: 0;}
td.tableblock>.content{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{margin-top: 0.5em;}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd){background:#f8f8f7}
table.stripes-none tr,table.stripes-odd tr:nth-of-type(even){background:none}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
td>div.verse{white-space:pre}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock,th.tableblock{font-size:0.8em}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#008cc1;font-weight:350;margin-top:.75em;margin-bottom:.25em}
.admonitionblock {
    margin: 0 0 1.5rem;
    border-left: 4px solid #000000;
    border-radius: .25rem;
}
.admonitionblock.note {
    background-color: #edf2f7;
    color: #19407c;
    border-left-color: #718096;
}
.admonitionblock.warning {
    background-color: #fff6e6;
    color: #19407c;
    border-left-color: #FFA500;
}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;display:none;}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}

tbody tr pre {margin-bottom: 27px}

.colist, .dlist, .exampleblock, .imageblock, .listingblock, .literalblock, .olist, .paragraph, .partintro, .quoteblock, .sidebarblock, .ulist, .verseblock {
    margin: 0 0 1.5rem;
}

.colist {
    margin: 0;
}

.colist table {
    margin: 0;
    border: none;
}

.conum { display: inline-block; color: white !important; background-color: #008cc1; -webkit-border-radius: 100px; border-radius: 100px; text-align: center; width: 20px; height: 20px; font-size: 12px; font-weight: bold; line-height: 20px; font-family: Arial, sans-serif; font-style: normal; position: relative; top: -2px; letter-spacing: -1px; }
.conum * { color: white !important; }
.conum + b { display: none; }
.conum:after { content: attr(data-value); }
.conum:not([data-value]):empty { display: none; }

.colist>table tr>td:first-of-type{ border:0; min-width:0; padding:0 .75em;}
.colist>table tr>td:last-of-type{ border:0; min-width:0; padding:.25em 0}
.colist>table tr:nth-child(even) { background:0 0 }

.listingblock + .colist {
    margin-top: -0.7rem;
}
</style>

    </head>
    <body>
        <header id="header">
            <a id="logo" href="https://www.markhneedham.com/blog/"><img src="https://www.markhneedham.com/blog//me.jpg" alt="Mark Needham" /></a>
            <h1><a href="https://www.markhneedham.com/blog/">Mark Needham</a></h1>
            <p>In this post we&#39;ll explore the HITS link analysis algorithm that was added to the Neo4j Graph Data Science Library in version 1.5.0.</p>

            <div id="follow-icons">
	<a href="http://twitter.com/markhneedham" rel="me"><i class="fa fa-twitter-square fa-2x"></i></a>
	<a href="https://www.youtube.com/channel/UCKEk670ECmteGBehmDjVSSg" rel="me"><i class="fa fa-youtube-square fa-2x"></i></a>
	<a href="http://linkedin.com/in/markhneedham" rel="me"><i class="fa fa-linkedin-square fa-2x"></i></a>
	<a href="http://github.com/mneedham" rel="me"><i class="fa fa-github-square fa-2x"></i></a>
	<a href="mailto:m.h.needham@gmail.com"><i class="fa fa-envelope-square fa-2x"></i></a>
	<a href="https://www.markhneedham.com/blog/index.xml" rel="me"><i class="fa fa-rss-square fa-2x"></i></a>
</div>


            
        </header>

<main id="content">

<article id="" class="2021">
    <div class="post-stamp">
        <time datetime="2021-02-03T00:44:37Z">
            3 Feb 2021
        </time>
        <span class="taglist">
        
        &middot;
        
            <a href="https://www.markhneedham.com/blog/tag/neo4j/">neo4j</a>
        
            <a href="https://www.markhneedham.com/blog/tag/graph-data-science/">graph-data-science</a>
        
            <a href="https://www.markhneedham.com/blog/tag/graph-algorithms/">graph-algorithms</a>
        
        
        </span>
    </div>
    <h1 class="post-title">Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm</h1>
    <div class="paragraph">
<p>The <a href="https://neo4j.com/product/graph-data-science-library/" target="_blank" rel="noopener">Neo4j Graph Data Science Library</a> provides efficiently implemented, parallel versions of common graph algorithms for Neo4j, exposed as Cypher procedures.
It recently published <a href="https://github.com/neo4j/graph-data-science/releases/tag/1.5.0" target="_blank" rel="noopener">version 1.5</a>, which has lots of goodies to play with.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://www.markhneedham.com/blog/
/uploads/2021/02/gds-v1.5-hits.png" alt="gds v1.5 hits">
</div>
</div>
<div class="paragraph">
<p>In this blog post, we&#8217;re going to explore the newly added <a href="https://neo4j.com/docs/graph-data-science/1.5/algorithms/hits/" target="_blank" rel="noopener">HITS algorithm</a> with the help of a citations dataset.</p>
</div>
<div class="sect1">
<h2 id="_launching_neo4j">Launching Neo4j</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We&#8217;re going to run Neo4j with the Graph Data Science Library using the following Docker Compose configuration:</p>
</div>
<div class="listingblock">
<div class="title">docker-compose.yml</div>
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">version: '3.7'
services:
  neo4j:
    image: neo4j:4.2.3-enterprise
    container_name: "neo4j4.2-gds1.5-exploration"
    volumes:
      - ./plugins-4.2:/plugins
      - ./data-4.2:/data
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      - NEO4J_AUTH=neo4j/neo
      - NEO4JLABS_PLUGINS=["apoc", "graph-data-science"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you want to follow along with the examples used in the blog post, you can copy the configuration above to a file titled <code>docker-compose.yml</code>
We can now launch the Neo4j server by running the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose up</code></pre>
</div>
</div>
<div class="paragraph">
<p>After we&#8217;ve launched that command, we need to wait until we see the following output:</p>
</div>
<div class="listingblock">
<div class="title">Output</div>
<div class="content">
<pre class="highlight"><code class="language-text" data-lang="text">neo4j4.2-gds1.5-exploration | 2021-02-03 21:39:15.346+0000 INFO  Bolt enabled on 0.0.0.0:7687.
neo4j4.2-gds1.5-exploration | 2021-02-03 21:39:16.053+0000 INFO  Remote interface available at http://localhost:7474/
neo4j4.2-gds1.5-exploration | 2021-02-03 21:39:16.053+0000 INFO  Started.</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_importing_the_citation_graph">Importing the Citation Graph</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We&#8217;re going to import the Citations Graph from the <a href="https://neo4j.com/graphacademy/training-gdsds-40/enrollment/" target="_blank" rel="noopener">Using a Machine Learning Workflow for Link Prediction</a> online training.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s first connect to Neo4j using the Cypher Shell:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">docker exec -it neo4j4.2-gds1.5-exploration bin/cypher-shell -u neo4j -p neo</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Output</div>
<div class="content">
<pre class="highlight"><code class="language-text" data-lang="text">Connected to Neo4j using Bolt protocol version 4.2 at neo4j://localhost:7687 as user neo4j.
Type :help for a list of available commands or :exit to exit the shell.
Note that Cypher queries must end with a semicolon.
neo4j@neo4j&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The data for the citation graph is available as a set of JSON lines files, which we can find at <a href="https://github.com/mneedham/link-prediction/tree/master/data" class="bare">https://github.com/mneedham/link-prediction/tree/master/data</a>.
Below is an example of one line of one of the files:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">{"authors": ["Tegegne Marew", "Doo-Hwan Bae"], "n_citation": 1, "references": ["2134bf3b-fd89-4724-90ce-5993b4fa3218", "906c17e0-db09-407b-b760-41df5a3f0293", "94f4382e-cfa6-4aec-92b8-3711fc55da54", "9f172585-8d42-4fce-b6ae-aede321f3fd4", "a3aee287-efd0-4b9d-9cda-d47dd192c9f4", "a9a7fd07-ef71-4b3c-8fcf-d7fe114d2148", "d63dd4ae-4b30-484b-8ffc-88d21839ddad"], "title": "Using Classpects for Integrating Non-Functional and Functional Requirements.", "venue": "international conference on software engineering", "year": 2006, "id": "01f1d231-80ae-4cce-b56c-9d821e0924d0"}</code></pre>
</div>
</div>
<div class="paragraph">
<p>We&#8217;re going to use some <a href="https://neo4j.com/labs/apoc/4.2/overview/" target="_blank" rel="noopener">APOC procedures</a> to convert these JSON files into the following graph structure:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://neo4j.com/graphacademy/training-gdsds-40/_images/graph.png" alt="graph">
</div>
<div class="title">Figure 1. Graph Model</div>
</div>
<div class="paragraph">
<p>So we&#8217;ll have the following node labels:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Article</code> - a paper on a topic</p>
</li>
<li>
<p><code>Venue</code> - where the paper was presented</p>
</li>
<li>
<p><code>Author</code> - the person/people that worked on the <code>Article</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And these relationship types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>CITED</code> - which articles were cited by an article</p>
</li>
<li>
<p><code>AUTHOR</code> - which articles were written by a person/people</p>
</li>
<li>
<p><code>VENUE</code> - where an article was presented</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Let&#8217;s first create a new database and setup some constraints to make sure we don&#8217;t end up with duplicates:</p>
</div>
<div class="listingblock">
<div class="title">Create new database and setup constraints</div>
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">CREATE OR REPLACE DATABASE citationsblogpost;
:use citationsblogpost;

CREATE CONSTRAINT ON (a:Article) ASSERT a.index IS UNIQUE;
CREATE CONSTRAINT ON (a:Author) ASSERT a.name IS UNIQUE;
CREATE CONSTRAINT ON (v:Venue) ASSERT v.name IS UNIQUE;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we&#8217;ll import the data:</p>
</div>
<div class="listingblock">
<div class="title">Create citations graph</div>
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">CALL apoc.periodic.iterate(
  'UNWIND ["dblp-ref-0.json", "dblp-ref-1.json", "dblp-ref-2.json", "dblp-ref-3.json"] AS file
   CALL apoc.load.json("https://github.com/mneedham/link-prediction/raw/master/data/" + file)
   YIELD value WITH value
   return value',
  'MERGE (a:Article {index:value.id})
   SET a += apoc.map.clean(value,["id","authors","references", "venue"],[0])
   WITH a, value.authors as authors, value.references AS citations, value.venue AS venue
   MERGE (v:Venue {name: venue})
   MERGE (a)-[:VENUE]-&gt;(v)
   FOREACH(author in authors |
     MERGE (b:Author{name:author})
     MERGE (a)-[:AUTHOR]-&gt;(b))
   FOREACH(citation in citations |
     MERGE (cited:Article {index:citation})
     MERGE (a)-[:CITED]-&gt;(cited))',
   {batchSize: 1000, iterateList: true})
YIELD batches, total, timeTaken, committedOperations;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Results</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">batches</th>
<th class="tableblock halign-left valign-top">total</th>
<th class="tableblock halign-left valign-top">timeTaken</th>
<th class="tableblock halign-left valign-top">committedOperations</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">52</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">51956</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">21</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">51956</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>And finally, a bit of cleanup to remove articles that don&#8217;t have a title:</p>
</div>
<div class="listingblock">
<div class="title">Remove articles that don&#8217;t have a title</div>
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
WHERE not(exists(a.title))
DETACH DELETE a;</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hits_algorithm">HITS Algorithm</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <a href="https://neo4j.com/docs/graph-data-science/1.5/algorithms/hits/" target="_blank" rel="noopener">HITs algorithm</a>, like many other graph algorithms, was invented to do link analysis on web pages.
It is a centrality algorithm, which means that it indicates node importance based on some metric.
We can learn more about it from the <a href="https://en.wikipedia.org/wiki/HITS_algorithm" target="_blank" rel="noopener">HITS Wikipedia page</a>:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>The idea behind Hubs and Authorities stemmed from a particular insight into the creation of web pages when the Internet was originally forming; that is, certain web pages, known as hubs, served as large directories that were not actually authoritative in the information that they held, but were used as compilations of a broad catalog of information that led users direct to other authoritative pages.</p>
</div>
<div class="paragraph">
<p>The scheme therefore assigns two scores for each page: its authority, which estimates the value of the content of the page, and its hub value, which estimates the value of its links to other pages.</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>So a page with a high authority score has high value content, whereas a page with a high hub score links out to important pages.</p>
</div>
<div class="paragraph">
<p>We&#8217;re going to use this algorithm to analyse the citations between articles in our graph, so what does those different scores mean for us?</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An article with a high authority score will likely have a lot of citations, perhaps some of those by other important articles</p>
</li>
<li>
<p>An article with a high hub score can help direct us (via its citations) to the important articles.
It&#8217;s not clear to me that the hub score makes so much sense in this graph because there aren&#8217;t really articles written with the intention of pointing people towards a bunch of other articles!</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Let&#8217;s give the algorithm a try and see what we find.
We can return a list of the available procedures by running the following query:</p>
</div>
<div class="listingblock">
<div class="title">List the HITS procedures</div>
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">CALL gds.list("hits")
YIELD name, description
RETURN name, description;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Results</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">name</th>
<th class="tableblock halign-left valign-top">description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.mutate"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Hyperlink-Induced Topic Search (HITS) is a link analysis algorithm that rates nodes"</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.mutate.estimate"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Returns an estimation of the memory consumption for that procedure."</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.stats"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Hyperlink-Induced Topic Search (HITS) is a link analysis algorithm that rates nodes"</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.stats.estimate"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Returns an estimation of the memory consumption for that procedure."</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.stream"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Hyperlink-Induced Topic Search (HITS) is a link analysis algorithm that rates nodes"</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.stream.estimate"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Returns an estimation of the memory consumption for that procedure."</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.write"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Hyperlink-Induced Topic Search (HITS) is a link analysis algorithm that rates nodes"</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"gds.alpha.hits.write.estimate"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Returns an estimation of the memory consumption for that procedure."</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Before we run the algorithm, we&#8217;ll create a projected graph called <code>citation_graph</code>, by running the following:</p>
</div>
<div class="listingblock">
<div class="title">Create projected graph</div>
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">CALL gds.graph.create("citation_graph", "Article", "CITED");</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Results</caption>
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">nodeProjection</th>
<th class="tableblock halign-left valign-top">relationshipProjection</th>
<th class="tableblock halign-left valign-top">graphName</th>
<th class="tableblock halign-left valign-top">nodeCount</th>
<th class="tableblock halign-left valign-top">relationshipCount</th>
<th class="tableblock halign-left valign-top">createMillis</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">{Article: {properties: {}, label: "Article"}}</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">{CITED: {orientation: "NATURAL", aggregation: "DEFAULT", type: "CITED", properties: {}}}</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"citation_graph"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">51956</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">28706</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">149</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>And now we&#8217;ll run the write version of the algorithm against the projected graph:</p>
</div>
<div class="listingblock">
<div class="title">Run HITS algorithm</div>
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">CALL gds.alpha.hits.write("citation_graph", {
  hitsIterations: 20
})
YIELD writeMillis, nodePropertiesWritten, ranIterations, postProcessingMillis, createMillis, computeMillis;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. Results</caption>
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">writeMillis</th>
<th class="tableblock halign-left valign-top">nodePropertiesWritten</th>
<th class="tableblock halign-left valign-top">ranIterations</th>
<th class="tableblock halign-left valign-top">postProcessingMillis</th>
<th class="tableblock halign-left valign-top">createMillis</th>
<th class="tableblock halign-left valign-top">computeMillis</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">174</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">103912</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">81</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">390</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>By default, this procedure will create <code>pregel_auth</code> and <code>pregel_hub</code> properties on each of the <code>Article</code> nodes storing the computed scores.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_analysing_authority_scores">Analysing authority scores</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Let&#8217;s see which articles rank highest, starting with authority:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
RETURN a.title, a.year, substring(a.abstract, 0, 300) AS abstract,
       [(a)-[:AUTHOR]-&gt;(auth) | auth.name] AS authors,
       round(a.pregel_auth, 3) AS auth
ORDER BY auth DESC
LIMIT 10;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 5. Results</caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 10%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 10%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">a.title</th>
<th class="tableblock halign-left valign-top">a.year</th>
<th class="tableblock halign-left valign-top">abstract</th>
<th class="tableblock halign-left valign-top">authors</th>
<th class="tableblock halign-left valign-top">auth</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1995</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough set theory, introduced by Zdzislaw Pawlak in the early 1980s [11, 12], is a new mathematical tool to deal with vagueness and uncertainty. This approach seems to be of fundamental importance to artificial intelligence (AI) and cognitive sciences, especially in the areas of machine learning, kno"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Jerzy W. Grzymala-Busse", "Wojciech Ziarko", "Zdzisław Pawlak", "Roman Słowiński"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Fuzzy Similarity Relation as a Basis for Rough Approximations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1998</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"The rough sets theory proposed by Pawlak was originally founded on the idea of approximating a given set by means of indiscernibility binary relation, which was assumed to be an equivalence relation (reflexive, symmetric and transitive). With respect to this basic idea, two main theoretical developm"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Roman Słowiński", "Salvatore Greco", "Benedetto Matarazzo"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Toward Intelligent Systems: Calculi of Information Granules"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"We present an approach based on calculi of information granules as a basis for approximate reasoning in intelligent systems. Approximate reasoning schemes are defined by means of information granule construction schemes satisfying some robustness constraints. In distributed environments such schemes"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Andrzej Skowron"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Approximation spaces and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"In this paper, we discuss approximation spaces in a granular computing framework. Such approximation spaces generalise the approaches to concept approximation existing in rough set theory. Approximation spaces are constructed as higher level information granules and are obtained as the result of com"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Andrzej Skowron", "Piotr Synak", "Roman Świniarski"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.038</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Layered learning for concept synthesis"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2004</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"We present a hierarchical scheme for synthesis of concept approximations based on given data and domain knowledge. We also propose a solution, founded on rough set theory, to the problem of con- structing the approximation of higher level concepts by composing the approximation of lower level concep"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Andrzej Skowron", "Jan G. Bazan", "Hung Son Nguyen", "Sinh Hoa Nguyen"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.037</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A Comparison of Several Approaches to Missing Attribute Values in Data Mining"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"In the paper nine different approaches to missing attribute values are presented and compared. Ten input data files were used to investigate the performance of the nine methods to deal with missing attribute values. For testing both naive classification and new classification techniques of LERS (Lea"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Jerzy W. Grzymala-Busse", "Ming Hu"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.036</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Variable Consistency Model of Dominance-Based Rough Sets Approach"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Consideration of preference-orders requires the use of an extended rough set model called Dominance-based Rough Set Approach (DRSA). The rough approximations defined within DRSA are based on consistency in the sense of dominance principle. It requires that objects having not-worse evaluation with re"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Benedetto Matarazzo", "Salvatore Greco", "Roman Słowiński", "Jerzy Stefanowski"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.029</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"RSES and RSESlib - A Collection of Tools for Rough Set Computations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough Set Exploration System - a set of software tools featuring a library of methods and a graphical user interface is presented. Methods, features and abilities of the implemented software are discussed and illustrated with a case study in data analysis."</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Marcin S. Szczuka", "Jan G. Bazan"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A New Version of Rough Set Exploration System"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"We introduce a new version of the Rough Set Exploration System - a software tool featuring a library of methods and a graphical user interface supporting variety of rough-set-based computations. Methods, features and abilities of the implemented software are discussed and illustrated with a case stu"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Marcin S. Szczuka", "Jakub Wróblewski", "Jan G. Bazan"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2003</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">"In this paper, the study of the evolution of approximation space theory and its applications is considered in the context of rough sets introduced by Zdzislaw Pawlak and information granulation as well as computing with words formulated by Lotfi Zadeh. Central to this evolution is the rough-mereolog"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">["Piotr Synak", "James F. Peters", "Andrzej Skowron", "Sheela Ramanna"]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The top article by some distance on this metric is <a href="https://dl.acm.org/doi/10.1145/219717.219791" target="_blank" rel="noopener">"Rough sets"</a>, which was written more than 25 years ago.
I found it interesting that the abstract talks about it being an approach that is fundamental to AI and machine learning, which are important fields in 2021.</p>
</div>
<div class="paragraph">
<p>We can have a look at the hub nodes that point to these articles by running the following query:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
WITH a, [(a)&lt;-[:CITED]-(other) | other] AS citations
WITH a, apoc.coll.sortNodes(citations, "pregel_hub")[..5] AS topHubs
RETURN a.title, a.year,
       round(a.pregel_auth, 3) AS auth,
       [c in topHubs | {article: c.title, score: round(c.pregel_hub, 3)}] AS topHubs
ORDER BY auth DESC
LIMIT 10;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 6. Results</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 55%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">a.title</th>
<th class="tableblock halign-left valign-top">a.year</th>
<th class="tableblock halign-left valign-top">auth</th>
<th class="tableblock halign-left valign-top">topHubs</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1995</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.083, article: "Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"}, {score: 0.082, article: "Some Issues on Rough Sets"}, {score: 0.079, article: "A treatise on rough sets"}, {score: 0.079, article: "Approximate boolean reasoning: foundations and applications in data mining"}, {score: 0.075, article: "Multimodal classification: case studies"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Fuzzy Similarity Relation as a Basis for Rough Approximations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1998</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.082, article: "Some Issues on Rough Sets"}, {score: 0.079, article: "A treatise on rough sets"}, {score: 0.079, article: "Approximate boolean reasoning: foundations and applications in data mining"}, {score: 0.075, article: "On generalized rough fuzzy approximation operators"}, {score: 0.074, article: "Lattices with Interior and Closure Operators and Abstract Approximation Spaces"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Toward Intelligent Systems: Calculi of Information Granules"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.083, article: "Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"}, {score: 0.082, article: "Some Issues on Rough Sets"}, {score: 0.072, article: "Rough sets and information granulation"}, {score: 0.071, article: "A Note on Ziarko&#8217;s Variable Precision Rough Set Model and Nonmonotonic Reasoning"}, {score: 0.071, article: "A Partition Model of Granular Computing"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Approximation spaces and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.038</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.083, article: "Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"}, {score: 0.082, article: "Some Issues on Rough Sets"}, {score: 0.079, article: "A treatise on rough sets"}, {score: 0.075, article: "On generalized rough fuzzy approximation operators"}, {score: 0.074, article: "Matching 2d image segments with genetic algorithms and approximation spaces"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Layered learning for concept synthesis"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2004</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.037</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.083, article: "Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"}, {score: 0.079, article: "A treatise on rough sets"}, {score: 0.079, article: "Approximate boolean reasoning: foundations and applications in data mining"}, {score: 0.075, article: "Multimodal classification: case studies"}, {score: 0.072, article: "P300 wave detection based on rough sets"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A Comparison of Several Approaches to Missing Attribute Values in Data Mining"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.036</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.082, article: "Some Issues on Rough Sets"}, {score: 0.075, article: "The rough set exploration system"}, {score: 0.071, article: "Missing template decomposition method and its implementation in rough set exploration system"}, {score: 0.07, article: "Data with Missing Attribute Values: Generalization of Indiscernibility Relation and Rule Induction"}, {score: 0.07, article: "Characteristic relations for incomplete data: a generalization of the indiscernibility relation"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Variable Consistency Model of Dominance-Based Rough Sets Approach"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.029</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.072, article: "Rough Set Analysis of Preference-Ordered Data"}, {score: 0.072, article: "Variable-precision dominance-based rough set approach"}, {score: 0.071, article: "On variable consistency dominance-based rough set approaches"}, {score: 0.071, article: "Multicriteria choice and ranking using decision rules induced from rough approximation of graded preference relations"}, {score: 0.07, article: "Rough set approach to customer satisfaction analysis"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"RSES and RSESlib - A Collection of Tools for Rough Set Computations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.079, article: "Approximate boolean reasoning: foundations and applications in data mining"}, {score: 0.073, article: "Hybridization of rough sets and statistical learning theory"}, {score: 0.072, article: "Ontology driven concept approximation"}, {score: 0.072, article: "Processing of musical data employing rough sets and artificial neural networks"}, {score: 0.069, article: "A statistical method for determining importance of variables in an information system"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A New Version of Rough Set Exploration System"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.075, article: "Multimodal classification: case studies"}, {score: 0.072, article: "Processing of musical data employing rough sets and artificial neural networks"}, {score: 0.069, article: "Introducing a rule importance measure"}, {score: 0.069, article: "NetTRS induction and postprocessing of decision rules"}, {score: 0.069, article: "Classification of Swallowing Sound Signals: A Rough Set Approach"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2003</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.083, article: "Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"}, {score: 0.079, article: "A treatise on rough sets"}, {score: 0.075, article: "On generalized rough fuzzy approximation operators"}, {score: 0.074, article: "Matching 2d image segments with genetic algorithms and approximation spaces"}, {score: 0.071, article: "Time complexity of decision trees"}]</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Based on the top hubs, it&#8217;s not really obvious why the authority score for "Rough sets" is so much higher than the other articles.
Perhaps if we return the max, min, and average hub scores we&#8217;ll be able to figure it out?</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
WITH a, [(a)&lt;-[:CITED]-(other) | other] AS citations
RETURN a.title, a.year,
       round(a.pregel_auth, 3) AS auth,
       round(apoc.coll.max([c in citations | c.pregel_hub]), 3) AS maxHub,
       round(apoc.coll.min([c in citations | c.pregel_hub]), 3) AS minHub,
       round(apoc.coll.avg([c in citations | c.pregel_hub]), 3) AS averageHub,
       size(citations) AS citations
ORDER BY auth DESC
LIMIT 10;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 7. Results</caption>
<colgroup>
<col style="width: 40%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">a.title</th>
<th class="tableblock halign-left valign-top">a.year</th>
<th class="tableblock halign-left valign-top">auth</th>
<th class="tableblock halign-left valign-top">maxHub</th>
<th class="tableblock halign-left valign-top">minHub</th>
<th class="tableblock halign-left valign-top">averageHub</th>
<th class="tableblock halign-left valign-top">citations</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1995</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.083</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.068</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.069</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">211</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Toward Intelligent Systems: Calculi of Information Granules"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.083</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.003</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.036</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">17</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Fuzzy Similarity Relation as a Basis for Rough Approximations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1998</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.082</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.003</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.061</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Approximation spaces and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.038</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.083</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.055</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Layered learning for concept synthesis"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2004</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.037</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.083</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.003</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.05</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A Comparison of Several Approaches to Missing Attribute Values in Data Mining"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.036</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.082</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.048</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Variable Consistency Model of Dominance-Based Rough Sets Approach"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.029</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.072</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.004</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.061</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"RSES and RSESlib - A Collection of Tools for Rough Set Computations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.079</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.032</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">12</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2003</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.083</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.065</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A New Version of Rough Set Exploration System"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.075</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.038</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>From this output we learn that "Rough sets" is being cited by a lot of articles with a good hub score.
The other articles have a similar <code>maxHub</code> score and some even have a similar <code>averageHub</code>, but their <code>minHub</code> is significantly less.
It also has 10x as many citations as any of the other articles in the top 10, so that would contribute to the higher score as well.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hits_authority_vs_pagerank">HITS Authority vs PageRank</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The HITS Authority score and the PageRank algorithm both compute scores that indicate the importance of a node in a graph, so I was curious whether there was any correlation between the scores.
i.e. do the nodes with the highest HITS authority score also have a high PageRank score?</p>
</div>
<div class="paragraph">
<p>To recap, <a href="https://neo4j.com/docs/graph-data-science/current/algorithms/page-rank/" target="_blank" rel="noopener">this is what PageRank measures</a>:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>The PageRank algorithm measures the importance of each node within the graph, based on the number incoming relationships and the importance of the corresponding source nodes.</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>We can compute the PageRank score for articles, by running the following query:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">CALL gds.pageRank.write("citation_graph", {
  maxIterations: 20,
  writeProperty: "pagerank"
})
YIELD writeMillis, nodePropertiesWritten, ranIterations, postProcessingMillis, createMillis, computeMillis;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 8. Results</caption>
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">writeMillis</th>
<th class="tableblock halign-left valign-top">nodePropertiesWritten</th>
<th class="tableblock halign-left valign-top">ranIterations</th>
<th class="tableblock halign-left valign-top">postProcessingMillis</th>
<th class="tableblock halign-left valign-top">createMillis</th>
<th class="tableblock halign-left valign-top">computeMillis</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">29</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">51956</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">20</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">112</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>And now let&#8217;s put the PageRank scores alongside the HITS Authority scores:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
RETURN a.title, a.year,
       round(a.pregel_auth, 3) AS auth,
       round(a.pagerank, 3) AS pagerank,
       size([(a)&lt;-[:CITED]-(other) | other]) AS citations
ORDER BY auth DESC
LIMIT 10;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 9. Results</caption>
<colgroup>
<col style="width: 60%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">a.title</th>
<th class="tableblock halign-left valign-top">a.year</th>
<th class="tableblock halign-left valign-top">auth</th>
<th class="tableblock halign-left valign-top">pagerank</th>
<th class="tableblock halign-left valign-top">citations</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1995</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">25.609</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">211</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Fuzzy Similarity Relation as a Basis for Rough Approximations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1998</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.738</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Toward Intelligent Systems: Calculi of Information Granules"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.042</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.862</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">17</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Approximation spaces and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.038</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.418</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Layered learning for concept synthesis"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2004</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.037</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.505</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A Comparison of Several Approaches to Missing Attribute Values in Data Mining"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.036</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.896</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Variable Consistency Model of Dominance-Based Rough Sets Approach"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.029</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.471</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"RSES and RSESlib - A Collection of Tools for Rough Set Computations"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.296</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">12</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A New Version of Rough Set Exploration System"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.682</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets and information granulation"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2003</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.375</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Rough Sets is the only one with a high PageRank score as well.
In fact, its PageRank score is the 3rd highest in the graph, which we can see by running the following query:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
RETURN a.title, a.year,
       round(a.pregel_auth, 5) AS auth,
       round(a.pagerank, 5) AS pagerank,
       size([(a)&lt;-[:CITED]-(other) | other]) AS citations
ORDER BY pagerank DESC
LIMIT 10;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 10. Results</caption>
<colgroup>
<col style="width: 60%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">a.title</th>
<th class="tableblock halign-left valign-top">a.year</th>
<th class="tableblock halign-left valign-top">auth</th>
<th class="tableblock halign-left valign-top">pagerank</th>
<th class="tableblock halign-left valign-top">citations</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A method for obtaining digital signatures and public-key cryptosystems"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1978</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5.0E-5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">93.94313</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">125</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Secure communications over insecure channels"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1978</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">79.86924</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1995</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.9902</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">25.60911</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">211</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"An axiomatic basis for computer programming"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1969</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4.4E-4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">23.02937</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">93</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Pastry: Scalable, Decentralized Object Location, and Routing for Large-Scale Peer-to-Peer Systems"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">21.46956</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">108</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"SCRIBE: The Design of a Large-Scale Event Notification Infrastructure"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">19.4863</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">14</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A field study of the software design process for large systems"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1988</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">19.02815</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">53</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Productivity factors and programming environments"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1984</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">18.49935</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Analyzing medium-scale software development"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1978</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16.45275</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A Calculus of Communicating Systems"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1982</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">15.43059</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">55</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>I find it kinda interesting that while these articles have very high transitive importance, their HITS Authority score is very low.
Many of them have a lot of citations as well, but presumably most of those citations aren&#8217;t from hub nodes.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_analysing_hub_scores">Analysing hub scores</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Speaking of hubs, let&#8217;s explore those in a bit more detail.
We can find the articles with the highest hub score, by running the following query:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
WITH a, [(a)-[:CITED]-&gt;(other) | other] AS cited
RETURN a.title, a.year,
       round(a.pregel_hub, 3) AS hub,
       round(apoc.coll.max([c in cited | c.pregel_auth]), 3) AS maxAuth,
       round(apoc.coll.min([c in cited | c.pregel_auth]), 3) AS minAuth,
       round(apoc.coll.avg([c in cited | c.pregel_auth]), 3) AS averageAuth,
       size(cited) AS cited
ORDER BY a.pregel_hub DESC
LIMIT 10;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 11. Results</caption>
<colgroup>
<col style="width: 40%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 10%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">a.title</th>
<th class="tableblock halign-left valign-top">a.year</th>
<th class="tableblock halign-left valign-top">hub</th>
<th class="tableblock halign-left valign-top">maxAuth</th>
<th class="tableblock halign-left valign-top">minAuth</th>
<th class="tableblock halign-left valign-top">averageAuth</th>
<th class="tableblock halign-left valign-top">cited</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.083</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.102</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">12</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Some Issues on Rough Sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2004</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.082</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.134</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">9</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A treatise on rough sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.079</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.145</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Approximate boolean reasoning: foundations and applications in data mining"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.079</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.115</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Multimodal classification: case studies"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.075</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.122</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">9</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"The rough set exploration system"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.075</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.157</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"On generalized rough fuzzy approximation operators"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.075</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.026</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.274</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Lattices with Interior and Closure Operators and Abstract Approximation Spaces"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2009</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.074</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.136</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Matching 2d image segments with genetic algorithms and approximation spaces"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.074</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.154</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Hybridization of rough sets and statistical learning theory"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2011</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.073</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.99</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.214</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The <code>maxAuth</code> scores tell us that all of these articles cite the "Rough sets" article that we came across in the previous section.
There aren&#8217;t really any other articles with a high authority score, so we can assume that nearly all of the hub score is coming from citing "Rough sets".
In any case, let&#8217;s have a look at the other authorities that these articles have cited:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cypher" data-lang="cypher">MATCH (a:Article)
WITH a, [(a)-[:CITED]-&gt;(other) | other] AS cited
WITH a, apoc.coll.sortNodes(cited, "pregel_auth")[..5] AS topAuthorities
RETURN a.title, a.year,
       round(a.pregel_hub, 3) AS hub,
       [c in topAuthorities | {article: c.title, score: round(c.pregel_auth, 3)}] AS topAuthorities
ORDER BY hub DESC
LIMIT 10;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 12. Results</caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 10%;">
<col style="width: 10%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">a.title</th>
<th class="tableblock halign-left valign-top">a.year</th>
<th class="tableblock halign-left valign-top">hub</th>
<th class="tableblock halign-left valign-top">topAuthorities</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.083</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.042, article: "Toward Intelligent Systems: Calculi of Information Granules"}, {score: 0.038, article: "Approximation spaces and information granulation"}, {score: 0.037, article: "Layered learning for concept synthesis"}, {score: 0.026, article: "Rough sets and information granulation"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Some Issues on Rough Sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2004</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.082</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.042, article: "Toward Intelligent Systems: Calculi of Information Granules"}, {score: 0.042, article: "Fuzzy Similarity Relation as a Basis for Rough Approximations"}, {score: 0.038, article: "Approximation spaces and information granulation"}, {score: 0.036, article: "A Comparison of Several Approaches to Missing Attribute Values in Data Mining"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"A treatise on rough sets"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.079</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.042, article: "Fuzzy Similarity Relation as a Basis for Rough Approximations"}, {score: 0.038, article: "Approximation spaces and information granulation"}, {score: 0.037, article: "Layered learning for concept synthesis"}, {score: 0.026, article: "Rough sets and information granulation"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Approximate boolean reasoning: foundations and applications in data mining"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.079</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.042, article: "Fuzzy Similarity Relation as a Basis for Rough Approximations"}, {score: 0.037, article: "Layered learning for concept synthesis"}, {score: 0.026, article: "RSES and RSESlib - A Collection of Tools for Rough Set Computations"}, {score: 0.021, article: "Some Issues on Rough Sets"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Multimodal classification: case studies"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.075</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.037, article: "Layered learning for concept synthesis"}, {score: 0.026, article: "A New Version of Rough Set Exploration System"}, {score: 0.015, article: "The rough set exploration system"}, {score: 0.01, article: "Rough Set Methods in Approximation of Hierarchical Concepts"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"The rough set exploration system"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2005</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.075</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.036, article: "A Comparison of Several Approaches to Missing Attribute Values in Data Mining"}, {score: 0.021, article: "Rough Sets and Decision Algorithms"}, {score: 0.021, article: "In Pursuit of Patterns in Data Reasoning from Data The Rough Set Way"}, {score: 0.015, article: "Classification of Swallowing Sound Signals: A Rough Set Approach"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"On generalized rough fuzzy approximation operators"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.075</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.042, article: "Fuzzy Similarity Relation as a Basis for Rough Approximations"}, {score: 0.038, article: "Approximation spaces and information granulation"}, {score: 0.026, article: "Rough sets and information granulation"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Lattices with Interior and Closure Operators and Abstract Approximation Spaces"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2009</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.074</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.042, article: "Fuzzy Similarity Relation as a Basis for Rough Approximations"}, {score: 0.024, article: "Approximation Operators in Qualitative Data Analysis"}, {score: 0.015, article: "Data with Missing Attribute Values: Generalization of Indiscernibility Relation and Rule Induction"}, {score: 0.005, article: "Algebraic structures for rough sets"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Matching 2d image segments with genetic algorithms and approximation spaces"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2006</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.074</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.038, article: "Approximation spaces and information granulation"}, {score: 0.026, article: "Rough sets and information granulation"}, {score: 0.01, article: "K-means Indiscernibility Relation over Pixels"}, {score: 0.006, article: "Rough ethology: towards a biologically-inspired study of collective behavior in intelligent systems with approximation spaces"}]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">"Hybridization of rough sets and statistical learning theory"</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2011</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.073</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[{score: 0.99, article: "Rough sets"}, {score: 0.038, article: "Approximation spaces and information granulation"}, {score: 0.026, article: "RSES and RSESlib - A Collection of Tools for Rough Set Computations"}, {score: 0.01, article: "Accuracy and Coverage in Rough Set Rule Induction"}, {score: 0.005, article: "Generalized indiscernibility relations: applications for missing values and analysis of structural objects"}]</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The top 2 articles both cited "Toward Intelligent Systems: Calculi of Information Granules", which gives them a marginally higher score than the other 8.
But I don&#8217;t think these hub scores are telling us all that much about these articles.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_in_summary">In Summary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>While I&#8217;m not sure that this is the greatest data set to show off this algorithm, I think the algorithm itself is an interesting addition to the library.
I&#8217;m curious to see how well it would fare on a Twitter graph - perhaps the HITS Hub score would help to identify those accounts that primarily tweet out links to interesting content?
I guess that exploration will have to wait for another post!</p>
</div>
</div>
</div>

    <div id="social-bar">
	<ul class="rrssb-buttons clearfix">
      <li class="email">
          <a href="mailto:?subject=Neo4j%20Graph%20Data%20Science%201.5%3a%20Exploring%20the%20HITS%20Algorithm&amp;body=https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/">
              <span class="icon">
                  <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
                      <path transform="scale(0.014,-0.014) translate(0,-1670)" d="M1792 826v-794q0 -66 -47 -113t-113 -47h-1472q-66 0 -113 47t-47 113v794q44 -49 101 -87q362 -246 497 -345q57 -42 92.5 -65.5t94.5 -48t110 -24.5h1h1q51 0 110 24.5t94.5 48t92.5 65.5q170 123 498 345q57 39 100 87zM1792 1120q0 -79 -49 -151t-122 -123 q-376 -261 -468 -325q-10 -7 -42.5 -30.5t-54 -38t-52 -32.5t-57.5 -27t-50 -9h-1h-1q-23 0 -50 9t-57.5 27t-52 32.5t-54 38t-42.5 30.5q-91 64 -262 182.5t-205 142.5q-62 42 -117 115.5t-55 136.5q0 78 41.5 130t118.5 52h1472q65 0 112.5 -47t47.5 -113z"/>
                  </svg>
              </span>
              <span class="text">Email</span>
          </a>
      </li>
      <li class="facebook">
          <a href="https://www.facebook.com/sharer/sharer.php?u=https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/" class="popup">
              <span class="icon">
                  <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
                      <path d="M27.825,4.783c0-2.427-2.182-4.608-4.608-4.608H4.783c-2.422,0-4.608,2.182-4.608,4.608v18.434 c0,2.427,2.181,4.608,4.608,4.608H14V17.379h-3.379v-4.608H14v-1.795c0-3.089,2.335-5.885,5.192-5.885h3.718v4.608h-3.726 c-0.408,0-0.884,0.492-0.884,1.236v1.836h4.609v4.608h-4.609v10.446h4.916c2.422,0,4.608-2.188,4.608-4.608V4.783z"/>
                  </svg>
              </span>
              <span class="text">Facebook</span>
          </a>
      </li>
			<li class="twitter">
          <a href="http://twitter.com/home?status=Neo4j%20Graph%20Data%20Science%201.5%3a%20Exploring%20the%20HITS%20Algorithm%20https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/" class="popup">
              <span class="icon">
                  <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
		                  <path d="M24.253,8.756C24.689,17.08,18.297,24.182,9.97,24.62c-3.122,0.162-6.219-0.646-8.861-2.32 c2.703,0.179,5.376-0.648,7.508-2.321c-2.072-0.247-3.818-1.661-4.489-3.638c0.801,0.128,1.62,0.076,2.399-0.155 C4.045,15.72,2.215,13.6,2.115,11.077c0.688,0.275,1.426,0.407,2.168,0.386c-2.135-1.65-2.729-4.621-1.394-6.965 C5.575,7.816,9.54,9.84,13.803,10.071c-0.842-2.739,0.694-5.64,3.434-6.482c2.018-0.623,4.212,0.044,5.546,1.683 c1.186-0.213,2.318-0.662,3.329-1.317c-0.385,1.256-1.247,2.312-2.399,2.942c1.048-0.106,2.069-0.394,3.019-0.851 C26.275,7.229,25.39,8.196,24.253,8.756z"/>
                  </svg>
              </span>
              <span class="text">Twitter</span>
          </a>
      </li>
			<li class="linkedin">
          <a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/&amp;title=Neo4j%20Graph%20Data%20Science%201.5%3a%20Exploring%20the%20HITS%20Algorithm&amp;summary=The%20Neo4j%20Graph%20Data%20Science%20Library%20provides%20efficiently%20implemented%2c%20parallel%20versions%20of%20common%20graph%20algorithms%20for%20Neo4j%2c%20exposed%20as%20Cypher%20procedures.%20It%20recently%20published%20version%201.5%2c%20which%20has%20lots%20of%20goodies%20to%20play%20with.%0a%20%20%20In%20this%20blog%20post%2c%20we%26%238217%3bre%20going%20to%20explore%20the%20newly%20added%20HITS%20algorithm%20with%20the%20help%20of%20a%20citations%20dataset.%0a%20Launching%20Neo4j%20We%26%238217%3bre%20going%20to%20run%20Neo4j%20with%20the%20Graph%20Data%20Science%20Library%20using%20the%20following%20Docker%20Compose%20configuration%3a..." class="popup">
              <span class="icon">
                  <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
                      <path d="M25.424,15.887v8.447h-4.896v-7.882c0-1.979-0.709-3.331-2.48-3.331c-1.354,0-2.158,0.911-2.514,1.803 c-0.129,0.315-0.162,0.753-0.162,1.194v8.216h-4.899c0,0,0.066-13.349,0-14.731h4.899v2.088c-0.01,0.016-0.023,0.032-0.033,0.048 h0.033V11.69c0.65-1.002,1.812-2.435,4.414-2.435C23.008,9.254,25.424,11.361,25.424,15.887z M5.348,2.501 c-1.676,0-2.772,1.092-2.772,2.539c0,1.421,1.066,2.538,2.717,2.546h0.032c1.709,0,2.771-1.132,2.771-2.546 C8.054,3.593,7.019,2.501,5.343,2.501H5.348z M2.867,24.334h4.897V9.603H2.867V24.334z"/>
                  </svg>
              </span>
              <span class="text">LinkedIn</span>
          </a>
      </li>
      <li class="tumblr">
					<script>
						document.write('<a href="http://www.tumblr.com/share?v=3&amp;u=' + encodeURIComponent('https:\/\/www.markhneedham.com\/blog\/2021\/02\/03\/neo4j-gdsl-hits-algorithm\/') + '&amp;t=Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm" class="popup">');
					</script>
              <span class="icon">
                  <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
											<path d="M18.02 21.842c-2.029 0.052-2.422-1.396-2.439-2.446v-7.294h4.729V7.874h-4.71V1.592c0 0-3.653 0-3.714 0 s-0.167 0.053-0.182 0.186c-0.218 1.935-1.144 5.33-4.988 6.688v3.637h2.927v7.677c0 2.8 1.7 6.7 7.3 6.6 c1.863-0.03 3.934-0.795 4.392-1.453l-1.22-3.539C19.595 21.6 18.7 21.8 18 21.842z"/>
									</svg>
              </span>
              <span class="text">Tumblr</span>
          <script>document.write('</a>');</script>
      </li>
      <li class="reddit">
          <a href="http://www.reddit.com/submit?url=https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/">
              <span class="icon">
                  <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
											<g>
													<path d="M11.794 15.316c0-1.029-0.835-1.895-1.866-1.895c-1.03 0-1.893 0.865-1.893 1.895s0.863 1.9 1.9 1.9 C10.958 17.2 11.8 16.3 11.8 15.316z"/>
													<path d="M18.1 13.422c-1.029 0-1.895 0.864-1.895 1.895c0 1 0.9 1.9 1.9 1.865c1.031 0 1.869-0.836 1.869-1.865 C19.969 14.3 19.1 13.4 18.1 13.422z"/>
													<path d="M17.527 19.791c-0.678 0.678-1.826 1.006-3.514 1.006c-0.004 0-0.009 0-0.014 0c-0.004 0-0.01 0-0.015 0 c-1.686 0-2.834-0.328-3.51-1.005c-0.264-0.265-0.693-0.265-0.958 0c-0.264 0.265-0.264 0.7 0 1 c0.943 0.9 2.4 1.4 4.5 1.402c0.005 0 0 0 0 0c0.005 0 0 0 0 0c2.066 0 3.527-0.459 4.47-1.402 c0.265-0.264 0.265-0.693 0.002-0.958C18.221 19.5 17.8 19.5 17.5 19.791z"/>
													<path d="M27.707 13.267c0-1.785-1.453-3.237-3.236-3.237c-0.793 0-1.518 0.287-2.082 0.761c-2.039-1.295-4.646-2.069-7.438-2.219 l1.483-4.691l4.062 0.956c0.071 1.4 1.3 2.6 2.7 2.555c1.488 0 2.695-1.208 2.695-2.695C25.881 3.2 24.7 2 23.2 2 c-1.059 0-1.979 0.616-2.42 1.508l-4.633-1.091c-0.344-0.081-0.693 0.118-0.803 0.455l-1.793 5.7 C10.548 8.6 7.7 9.4 5.6 10.75C5.006 10.3 4.3 10 3.5 10.029c-1.785 0-3.237 1.452-3.237 3.2 c0 1.1 0.6 2.1 1.4 2.69c-0.04 0.272-0.061 0.551-0.061 0.831c0 2.3 1.3 4.4 3.7 5.9 c2.299 1.5 5.3 2.3 8.6 2.325c3.228 0 6.271-0.825 8.571-2.325c2.387-1.56 3.7-3.66 3.7-5.917 c0-0.26-0.016-0.514-0.051-0.768C27.088 15.5 27.7 14.4 27.7 13.267z M23.186 3.355c0.74 0 1.3 0.6 1.3 1.3 c0 0.738-0.6 1.34-1.34 1.34s-1.342-0.602-1.342-1.34C21.844 4 22.4 3.4 23.2 3.355z M1.648 13.3 c0-1.038 0.844-1.882 1.882-1.882c0.31 0 0.6 0.1 0.9 0.209c-1.049 0.868-1.813 1.861-2.26 2.9 C1.832 14.2 1.6 13.8 1.6 13.267z M21.773 21.57c-2.082 1.357-4.863 2.105-7.831 2.105c-2.967 0-5.747-0.748-7.828-2.105 c-1.991-1.301-3.088-3-3.088-4.782c0-1.784 1.097-3.484 3.088-4.784c2.081-1.358 4.861-2.106 7.828-2.106 c2.967 0 5.7 0.7 7.8 2.106c1.99 1.3 3.1 3 3.1 4.784C24.859 18.6 23.8 20.3 21.8 21.57z M25.787 14.6 c-0.432-1.084-1.191-2.095-2.244-2.977c0.273-0.156 0.59-0.245 0.928-0.245c1.035 0 1.9 0.8 1.9 1.9 C26.354 13.8 26.1 14.3 25.8 14.605z"/>
											</g>
									</svg>
              </span>
              <span class="text">Reddit</span>
          </a>
      </li>
      <li class="googleplus">
          <a href="https://plus.google.com/share?url=https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/" class="popup">
              <span class="icon">
                  <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
                      <g>
                          <path d="M14.703,15.854l-1.219-0.948c-0.372-0.308-0.88-0.715-0.88-1.459c0-0.748,0.508-1.223,0.95-1.663 c1.42-1.119,2.839-2.309,2.839-4.817c0-2.58-1.621-3.937-2.399-4.581h2.097l2.202-1.383h-6.67c-1.83,0-4.467,0.433-6.398,2.027 C3.768,4.287,3.059,6.018,3.059,7.576c0,2.634,2.022,5.328,5.604,5.328c0.339,0,0.71-0.033,1.083-0.068 c-0.167,0.408-0.336,0.748-0.336,1.324c0,1.04,0.551,1.685,1.011,2.297c-1.524,0.104-4.37,0.273-6.467,1.562 c-1.998,1.188-2.605,2.916-2.605,4.137c0,2.512,2.358,4.84,7.289,4.84c5.822,0,8.904-3.223,8.904-6.41 c0.008-2.327-1.359-3.489-2.829-4.731H14.703z M10.269,11.951c-2.912,0-4.231-3.765-4.231-6.037c0-0.884,0.168-1.797,0.744-2.511 c0.543-0.679,1.489-1.12,2.372-1.12c2.807,0,4.256,3.798,4.256,6.242c0,0.612-0.067,1.694-0.845,2.478 c-0.537,0.55-1.438,0.948-2.295,0.951V11.951z M10.302,25.609c-3.621,0-5.957-1.732-5.957-4.142c0-2.408,2.165-3.223,2.911-3.492 c1.421-0.479,3.25-0.545,3.555-0.545c0.338,0,0.52,0,0.766,0.034c2.574,1.838,3.706,2.757,3.706,4.479 c-0.002,2.073-1.736,3.665-4.982,3.649L10.302,25.609z"/>
                          <polygon points="23.254,11.89 23.254,8.521 21.569,8.521 21.569,11.89 18.202,11.89 18.202,13.604 21.569,13.604 21.569,17.004 23.254,17.004 23.254,13.604 26.653,13.604 26.653,11.89"/>
                      </g>
                  </svg>
              </span>
              <span class="text">Google+</span>
          </a>
      </li>
      <li class="pinterest">
          <script>
						var imgurl = "https:\/\/www.markhneedham.com\/blog\/logo.png";
						var firstimg = document.getElementsByClassName("2021")[0].getElementsByTagName("img")[0];
						if (firstimg !== undefined) {
							imgurl = firstimg.src;
						}
						document.write('<a href="http://pinterest.com/pin/create/button/?url=https:\/\/www.markhneedham.com\/blog\/2021\/02\/03\/neo4j-gdsl-hits-algorithm\/&amp;media=' + imgurl + '&amp;description=Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm" class="popup">');
					</script>
              <span class="icon">
                  <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="28px" height="28px" viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve">
		                  <path d="M14.021,1.57C6.96,1.57,1.236,7.293,1.236,14.355c0,7.062,5.724,12.785,12.785,12.785c7.061,0,12.785-5.725,12.785-12.785 C26.807,7.294,21.082,1.57,14.021,1.57z M15.261,18.655c-1.161-0.09-1.649-0.666-2.559-1.219c-0.501,2.626-1.113,5.145-2.925,6.458 c-0.559-3.971,0.822-6.951,1.462-10.116c-1.093-1.84,0.132-5.545,2.438-4.632c2.837,1.123-2.458,6.842,1.099,7.557 c3.711,0.744,5.227-6.439,2.925-8.775c-3.325-3.374-9.678-0.077-8.897,4.754c0.19,1.178,1.408,1.538,0.489,3.168 C7.165,15.378,6.53,13.7,6.611,11.462c0.131-3.662,3.291-6.227,6.46-6.582c4.007-0.448,7.771,1.474,8.29,5.239 c0.579,4.255-1.816,8.865-6.102,8.533L15.261,18.655z"/>
                  </svg>
              </span>
              <span class="text">Pinterest</span>
          <script>document.write('</a>');</script>
      </li>
      <li class="pocket">
          <a href="https://getpocket.com/save?url=https://www.markhneedham.com/blog/2021/02/03/neo4j-gdsl-hits-algorithm/"  class="popup">
              <span class="icon">
                  <svg width="32px" height="28px" viewBox="0 0 32 28" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sketch="http://www.bohemiancoding.com/sketch/ns">
                      <path d="M28.7817528,0.00172488695 C30.8117487,0.00431221738 31.9749312,1.12074529 31.9644402,3.10781507 C31.942147,6.67703739 32.1336065,10.2669583 31.8057648,13.8090137 C30.7147076,25.5813672 17.2181194,31.8996281 7.20714461,25.3808491 C2.71833574,22.4571656 0.196577202,18.3122624 0.0549495772,12.9357897 C-0.0342233715,9.5774348 0.00642900214,6.21519891 0.0300336062,2.85555035 C0.0405245414,1.1129833 1.21157517,0.0146615391 3.01995012,0.00819321302 C7.34746087,-0.00603710433 11.6775944,0.00431221738 16.0064164,0.00172488695 C20.2644248,0.00172488695 24.5237444,-0.00215610869 28.7817528,0.00172488695 L28.7817528,0.00172488695 Z M8.64885184,7.85611511 C7.38773662,7.99113854 6.66148108,8.42606978 6.29310958,9.33228474 C5.90114134,10.2969233 6.17774769,11.1421181 6.89875951,11.8276216 C9.35282156,14.161969 11.8108164,16.4924215 14.2976518,18.7943114 C15.3844131,19.7966007 16.5354102,19.7836177 17.6116843,18.7813283 C20.0185529,16.5495467 22.4070683,14.2982907 24.7824746,12.0327533 C25.9845979,10.8850542 26.1012707,9.56468083 25.1469132,8.60653379 C24.1361858,7.59255976 22.8449191,7.6743528 21.5890476,8.85191291 C19.9936451,10.3488554 18.3680912,11.8172352 16.8395462,13.3777945 C16.1342655,14.093159 15.7200114,14.0048744 15.0566806,13.3440386 C13.4599671,11.7484252 11.8081945,10.2060421 10.1262706,8.70001155 C9.65564653,8.27936164 9.00411403,8.05345704 8.64885184,7.85611511 L8.64885184,7.85611511 L8.64885184,7.85611511 Z"></path>
                  </svg>
              </span>
              <span class="text">Pocket</span>
          </a>
      </li>
  </ul>
</div>

    <div itemprop="author" itemscope itemtype="http://schema.org/Person">
  <h5>About the author</h5>
  <section>
    <p><a href="https://twitter.com/markhneedham" itemprop="name" rel="author">I'm</a> currently working on real-time user-facing analytics with <a href="https://pinot.apache.org/">Apache Pinot</a> at <a href="https://www.startree.ai/">StarTree</a>. I previously worked on graph analytics at <a href="https://neo4j.com/">Neo4j</a>, where I also I co-authored the <a href="https://neo4j.com/graph-algorithms-book">O'Reilly Graph Algorithms Book</a> with Amy Hodler.</p>
  </section>
</div>

    <div id="comments">
    
    
    
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname = 'markhneedham';
      var disqus_identifier = 'https:\/\/www.markhneedham.com\/blog\/2021\/02\/03\/neo4j-gdsl-hits-algorithm\/';
      var disqus_title = 'Neo4j Graph Data Science 1.5: Exploring the HITS Algorithm';
      var disqus_url = 'https:\/\/www.markhneedham.com\/blog\/2021\/02\/03\/neo4j-gdsl-hits-algorithm\/';
      (function() {
        if (window.location.hostname == "localhost")
                return;

        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
    
</div>

</article>

</main>

  <footer id="footer">
			<section id="footer-message">&copy; Mark Needham. All rights reserved. Powered by <a href="http://gohugo.io" target="_blank">Hugo</a>. <a href="https://github.com/kathyqian/crisp-ghost-theme" target="_blank">Crisp</a> theme by <a href="http://kathyqian.com" target="_blank">Kathy Qian</a>.</section>
		</footer>

    <script>
      (function(c,f){asyncLoader=function(i,h){i.foreach(function(k,j){e(j,d(j),h)});if(typeof h.callback=="function"){var g=setInterval(function(){if(f.readyState==="complete"){clearInterval(g);h.callback()}},10)}};var d=function(g){var h=g.split(".");return h[h.length-1]},e=function(h,i,g){switch(i){case"js":a(h,g);break;case"css":b(h);break;default:break}},a=function(i,h){var g=document.createElement("script");g.type="text/javascript";g.async=true;g.src=i;document.getElementsByTagName("head")[0].appendChild(g)},b=function(g){var h=document.createElement("link");h.type="text/css";h.rel="stylesheet";h.href=g;document.getElementsByTagName("head")[0].appendChild(h)};Array.prototype.foreach=function(h){for(var g=0;g<this.length;g++){h(g,this[g])}}})(this,document);

      var WebFontConfig={google:{families:["Open Sans:300italic,700italic,300,700","Bree+Serif"]}};
      asyncLoader([
        "//netdna.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.css",
        "//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js",
        "//cdnjs.cloudflare.com/ajax/libs/webfont/1.5.16/webfontloader.js",
        "//unpkg.com/@highlightjs/cdn-assets@10.7.2/highlight.min.js"        
      ],{
        callback:function(){
          asyncLoader([
            "https:\/\/www.markhneedham.com\/blog\/css/rrssb.css",
            "https:\/\/www.markhneedham.com\/blog\/js/image-zoom.js",
            "https:\/\/www.markhneedham.com\/blog\/js/gist.min.js",
            "https:\/\/www.markhneedham.com\/blog\/js/rrssb.min.js",
            "https://unpkg.com/highlightjs-cypher/dist/cypher.min.js",
            "//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/default.min.css"
          ], { callback:function() {
              hljs.highlightAll();
          }});
        }
      });
    </script>
	
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-9991626-1"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-9991626-1');
    </script>

    

    


  
	</body>
</html>

