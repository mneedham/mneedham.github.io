+++
draft = false
date="2011-06-26 17:05:07"
title="Bounded Rationality"
tag=['systems-thinking-2']
category=['Systems Thinking']
+++

In '<a href="http://www.amazon.co.uk/Thinking-Systems-Primer-ebook/dp/B001OC6NS6/ref=sr_1_2?ie=UTF8&qid=1309103523&sr=8-2">Thinking In Systems: A Primer</a>' one of the most interesting ideas that Donella Meadows describes is what Herbert Simon coined '<a href="http://en.wikipedia.org/wiki/Bounded_rationality">bounded rationality</a>':

<blockquote>
Bounded rationality means that people make quite reasonable decisions based on the information they have. But they don't have perfect information, especially about more distant parts of the system
</blockquote>

Later on in the chapter the following idea is suggested:

<blockquote>
If you become a manager, you probably will stop seeing labour as a deserving partner in production, and start seeing it as a cost to be minimised.
</blockquote>

This helps explains something that I've noticed happen quite frequently.

Someone who was previously non management gets pulled into a management position and 'mysteriously' starts acting exactly like all the others in that type of role rather than having a holistic view.

The strange thing is that we don't expect this to happen. The person was on 'our' side very recently so surely they should be able to see both perspectives!

Esther Derby referred to this problem in <a href="http://www.markhneedham.com/blog/2011/05/13/xp-2011-esther-derby-still-no-silver-bullets/">her keynote at XP2011</a> where she talked about two different types of information that occur in a system:

<ul>
<li>Day to day information - this is possessed by people 'on the ground'</li>
<li>System information - this is possessed by people 'in management'</li>
</ul>

When the people who recently moved into a management position are challenged on this they will often point out that "you can't see the bigger picture" which is true but still doesn't account for the fact that they probably aren't seeing it either!

We're both just seeing different parts of the system.

Meadows goes on to point out that the design of the system tends to encourage this type of behaviour:

<blockquote>
Seeing how individual decisions are rational within the bounds of the information available does not provide an excuse for narrow-minded behaviour. It provides an understanding of why that behaviour arises.

Taking out one individual from a position of bounded rationality and putting in another person is not likely to make much difference. Blaming the individual rarely helps create a more desirable outcome. 
</blockquote>

Meadows finishes this section of the book with the following suggestion which I think is especially useful in a consulting environment where both consultants and management quite obviously tend to suffer from bounded rationality.

<blockquote>
It's amazing how quickly and easily behaviour changes can come, with even slight enlargement of bounded rationality, by providing better, more complete, timelier information. 
</blockquote>

I've seen various attempts at trying to help people enlarge their bounded rationality at ThoughtWorks, such as:

<ul>
<li>Presentations by the finance director showing where the revenue of the company gets spent</li>
<li>Management team members taking the time to have one on one discussions with consultants </li>
<li>Discussions about the sales pipeline and the types of work available in the market</li>
</ul>

I think if this type of thing happened more frequently then you'd probably see an enlargement of everyone's bounded rationality which would be useful for all involved!
