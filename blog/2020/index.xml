<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2020s on Mark Needham</title>
    <link>https://markhneedham.com/blog/2020/</link>
    <description>Recent content in 2020s on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Apr 2020 00:21:00 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/2020/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>React Semantic-UI: Adding a custom icon to open link in a new window</title>
      <link>https://markhneedham.com/blog/2020/04/13/react-semantic-ui-custom-add-icon-open-new-window/</link>
      <pubDate>Mon, 13 Apr 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/04/13/react-semantic-ui-custom-add-icon-open-new-window/</guid>
      <description>I&amp;#8217;ve been building a little React app that uses the Semantic UI library and found myself wanting to render a custom icon.
 Semantic UI describes an icon as &#34;a glyph used to represent something else&#34;, and there are a big list of in built icons. For example, the following code renders a thumbs up icon:
 import {Icon} from &#34;semantic-ui-react&#34;; &amp;lt;Icon name=&#34;thumbs up outline icon green large&#34; style={{margin: 0}}/&amp;gt;    Figure 1.</description>
    </item>
    
    <item>
      <title>Streamlit: multiselect - AttributeError: &#39;numpy.ndarray&#39; object has no attribute &#39;index&#39;</title>
      <link>https://markhneedham.com/blog/2020/03/31/streamlit-multiselect-numpy-no-attribute-index/</link>
      <pubDate>Tue, 31 Mar 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/03/31/streamlit-multiselect-numpy-no-attribute-index/</guid>
      <description>In this post we&amp;#8217;ll learn how to overcome a problem I encountered while building a small Streamlit application to analyse John Hopkin&amp;#8217;s data on the COVID-19 disease. The examples in this post use a CSV file that contains time series data of deaths in each country.
 I started with the following code to create a multiselect widget that lists all countries and selected the United Kingdom by default:
 import streamlit as st import pandas as pd default_countries = [&#34;</description>
    </item>
    
    <item>
      <title>SPARQL: OR conditions in a WHERE clause using the UNION clause</title>
      <link>https://markhneedham.com/blog/2020/02/07/sparql-or-conditions-where-union-query/</link>
      <pubDate>Fri, 07 Feb 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/02/07/sparql-or-conditions-where-union-query/</guid>
      <description>This is part 4 of my series of posts about querying the Wikidata API, in which I learn how to use SPARQL&amp;#8217;s UNION clause to handle an OR condition in a WHERE clause.
  Figure 1. Using SPARQL&amp;#8217;s UNION clause  But first, some context!
 After running queries against the Wikidata SPARQL API to pull the date of birth and nationality of tennis players into the Australian Open Graph, I noticed that several players hadn&amp;#8217;t actually been updated.</description>
    </item>
    
    <item>
      <title>Neo4j: Enriching an existing graph by querying the Wikidata SPARQL API</title>
      <link>https://markhneedham.com/blog/2020/02/04/neo4j-enriching-existing-graph-wikidata-sparql-api/</link>
      <pubDate>Tue, 04 Feb 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/02/04/neo4j-enriching-existing-graph-wikidata-sparql-api/</guid>
      <description>This is the third post in a series about querying Wikidata&amp;#8217;s SPARQL API. In the first post we wrote some basic queries, in the second we learnt about the SELECT and CONSTRUCT clauses, and in this post we&amp;#8217;re going to import query results into an existing Neo4j graph.
  Figure 1. Enriching a Neo4j Graph with Wikidata  Setting up Neo4j We&amp;#8217;re going to use the following Docker Compose configuration in this blog post:</description>
    </item>
    
    <item>
      <title>Neo4j: Cross database querying with Neo4j Fabric</title>
      <link>https://markhneedham.com/blog/2020/02/03/neo4j-cross-database-querying-fabric/</link>
      <pubDate>Mon, 03 Feb 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/02/03/neo4j-cross-database-querying-fabric/</guid>
      <description>A couple of weeks ago I wrote a QuickGraph blog post about the Australian Open, in which I showed how to use Neo4j 4.0&amp;#8217;s multi database feature.
 In that post we focused on queries that could be run on one database, but the 4.0 release also contains another feature for doing cross database querying - Neo4j Fabric - and we&amp;#8217;re going to learn how to use that in this post.</description>
    </item>
    
    <item>
      <title>Querying Wikidata: SELECT vs CONSTRUCT</title>
      <link>https://markhneedham.com/blog/2020/02/02/querying-wikidata-construct-select/</link>
      <pubDate>Sun, 02 Feb 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/02/02/querying-wikidata-construct-select/</guid>
      <description>In this blog post we&amp;#8217;re going to build upon the newbie&amp;#8217;s guide to querying Wikidata, and learn all about the CONSTRUCT clause.
  Figure 1. SPARQL&amp;#8217;s CONSTRUCT and SELECT clauses  In the newbie&amp;#8217;s guide, we wrote the following query to find a tennis player with the name &#34;Nick Kyrgios&#34; and return their date of birth:
 SELECT * WHERE { ?person wdt:P106 wd:Q10833314 ; rdfs:label &#39;Nick Kyrgios&#39;@en ; wdt:P569 ?</description>
    </item>
    
    <item>
      <title>Neo4j: Finding the longest path</title>
      <link>https://markhneedham.com/blog/2020/01/29/neo4j-finding-longest-path/</link>
      <pubDate>Wed, 29 Jan 2020 15:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/29/neo4j-finding-longest-path/</guid>
      <description>One on my favourite things about storing data in a graph database is executing path based queries against that data. I&amp;#8217;ve been trying to find a way to write such queries against the Australian Open QuickGraph, and in this blog post we&amp;#8217;re going to write what I think of as longest path queries against this graph.
  Figure 1. Finding longest paths in Neo4j  Setting up Neo4j We&amp;#8217;re going to use the following Docker Compose configuration in this blog post:</description>
    </item>
    
    <item>
      <title>A newbie&#39;s guide to querying Wikidata</title>
      <link>https://markhneedham.com/blog/2020/01/29/newbie-guide-querying-wikidata/</link>
      <pubDate>Wed, 29 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/29/newbie-guide-querying-wikidata/</guid>
      <description>After reading one of Jes√∫s Barrasa&amp;#8217;s recent QuickGraph posts about enriching a knowledge graph with data from Wikidata, I wanted to learn how to query the Wikidata API so that I could pull in the data for my own QuickGraphs.
 I want to look up information about tennis players, and one of my favourite players is Nick Kyrgios, so this blog post is going to be all about him.</description>
    </item>
    
    <item>
      <title>Neo4j: Performing a database dump within a Docker container</title>
      <link>https://markhneedham.com/blog/2020/01/28/neo4j-database-dump-docker-container/</link>
      <pubDate>Tue, 28 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/28/neo4j-database-dump-docker-container/</guid>
      <description>Before the release of Neo4j 4.0, taking a dump of a database running within a Docker container was a tricky affair.
 We&amp;#8217;d need to stop the container and remove it, run the container again in bash mode, and finally take a dump of the database. With 4.0 things are simpler.
  Figure 1. Neo4j on Docker  We&amp;#8217;ll be using the following Docker Compose configuration in this blog post:</description>
    </item>
    
    <item>
      <title>Neo4j: Exporting a subset of data from one database to another</title>
      <link>https://markhneedham.com/blog/2020/01/27/neo4j-exporting-subset-database/</link>
      <pubDate>Mon, 27 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/27/neo4j-exporting-subset-database/</guid>
      <description>As part of the preparation for another blog post, I wanted to export a subset of data from one Neo4j database to another one, which seemed like a blog post in its own right.
  Figure 1. Exporting data using APOC&amp;#8217;s Export JSON  Setting up Neo4j We&amp;#8217;re going to use the following Docker Compose configuration in this blog post:
 Dockerfile version: &#39;3.7&#39; services: neo4j: image: neo4j:4.0.0-enterprise container_name: &#34;</description>
    </item>
    
    <item>
      <title>QuickGraph #5: Australian Open</title>
      <link>https://markhneedham.com/blog/2020/01/23/quick-graph-australian-open/</link>
      <pubDate>Thu, 23 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/23/quick-graph-australian-open/</guid>
      <description>It&amp;#8217;s time for another QuickGraph, this one based on data from the Australian Open tennis tournament. We&amp;#8217;re going to use data curated by Jeff Sackmann in the tennis_wta and tennis_atp repositories.
  Figure 1. Australian Open Graph (Background from https://www.freepik.com/free-photo/3d-network-background-with-connecting-lines-dots_3961382.htm)  Setting up Neo4j We&amp;#8217;re going to use the following Docker Compose configuration in this blog post:
 docker-compose.yml version: &#39;3.7&#39; services: neo4j: image: neo4j:4.0.0-enterprise container_name: &#34;quickgraph-aus-open&#34; volumes: - .</description>
    </item>
    
    <item>
      <title>Creating an Interactive UK Official Charts Data App with Streamlit and Neo4j</title>
      <link>https://markhneedham.com/blog/2020/01/16/interactive-uk-charts-quickgraph-neo4j-streamlit/</link>
      <pubDate>Thu, 16 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/16/interactive-uk-charts-quickgraph-neo4j-streamlit/</guid>
      <description>I recently came across Streamlit, a tool that makes it easy to build data based single page web applications. I wanted to give it a try, and the UK Charts QuickGraph that I recently wrote about seemed like a good opportunity for that.
 This blog post starts from where we left off. The data is loaded into Neo4j and we&amp;#8217;ve written some queries to explore different aspects of the dataset.</description>
    </item>
    
    <item>
      <title>Python: Altair - Setting the range of Date values for an axis</title>
      <link>https://markhneedham.com/blog/2020/01/14/altair-range-values-dates-axis/</link>
      <pubDate>Tue, 14 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/14/altair-range-values-dates-axis/</guid>
      <description>In my continued experiments with the Altair visualisation library, I wanted to set a custom range of data values on the x axis of a chart. In this blog post we&amp;#8217;ll learn how to do that.
 We&amp;#8217;ll start where we left off in the last blog post, with the following code that renders a scatterplot containing the chart position of a song on a certain date:
 import altair as alt import pandas as pd import datetime df = pd.</description>
    </item>
    
    <item>
      <title>Python: Altair - TypeError: Object of type date is not JSON serializable</title>
      <link>https://markhneedham.com/blog/2020/01/10/altair-typeerror-object-type-date-not-json-serializable/</link>
      <pubDate>Fri, 10 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/10/altair-typeerror-object-type-date-not-json-serializable/</guid>
      <description>I&amp;#8217;ve been playing with the Altair statistical visualisation library and recently ran into an error while trying to render a DataFrame that contained dates.
 I was trying to render a scatterplot containing the chart position of a song on a certain date, as seen in the code below:
 # pip install altair pandas import altair as alt import pandas as pd import datetime df = pd.DataFrame( [ {&#34;position&#34;: 2, &#34;</description>
    </item>
    
    <item>
      <title>QuickGraph #4: UK Official Singles Chart 2019</title>
      <link>https://markhneedham.com/blog/2020/01/04/quick-graph-uk-official-charts/</link>
      <pubDate>Sat, 04 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/04/quick-graph-uk-official-charts/</guid>
      <description>For our first QuickGraph of the new decade we&amp;#8217;re going to explore data from the Official UK Top 40 Chart. This chart ranks the top 100 songs of the week based on official sales of sales of downloads, CD, vinyl, audio streams and video streams. Every week BBC Radio 1 broadcast the top 40 songs, which explains the name of the chart.
  Figure 1. The Official UK Charts  Scraping the Official Charts I couldn&amp;#8217;t find a dump of the dataset, so we&amp;#8217;re going to use our web scraping skills again.</description>
    </item>
    
    <item>
      <title>Spotify API: Making my first call</title>
      <link>https://markhneedham.com/blog/2020/01/02/spotify-api-making-my-first-call/</link>
      <pubDate>Thu, 02 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/02/spotify-api-making-my-first-call/</guid>
      <description>I wanted to enrich the data for a little music application I&amp;#8217;m working on and realised it would be a perfect opportunity to try out the Spotify API. I want to extract data about individual tracks (via the Tracks API), but before we do that we&amp;#8217;ll need to create an app and have it approved for access to the Spotify API.
   Registering an application After logging into the Spotify Dashboard using my usual Spotify credentials, I was prompted to create an application:</description>
    </item>
    
  </channel>
</rss>