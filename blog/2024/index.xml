<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2024s on Mark Needham</title>
    <link>https://www.markhneedham.com/blog/2024/</link>
    <description>Recent content in 2024s on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Aug 2024 00:44:37 +0000</lastBuildDate><atom:link href="https://www.markhneedham.com/blog/2024/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Searching through AWS Icons</title>
      <link>https://www.markhneedham.com/blog/2024/08/23/searching-aws-icons/</link>
      <pubDate>Thu, 08 Aug 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/08/23/searching-aws-icons/</guid>
      <description>I recently needed to search for an icon in the AWS [asset package](https://aws.amazon.com/architecture/icons/) and wanted to share a little script that I wrote. You wouldn’t think that searching for icons should be that hard, but they’re spread across so many folders and sub-folders that you can spend forever trying to find what you want.
First, let’s import some modules:
import base64 import sys import glob import os And then I’m using the following function to render images in the terminal:</description>
    </item>
    
    <item>
      <title>ClickHouse: Specifying config settings</title>
      <link>https://www.markhneedham.com/blog/2024/08/05/clickhouse-config-settings/</link>
      <pubDate>Mon, 05 Aug 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/08/05/clickhouse-config-settings/</guid>
      <description>We recently had a question on ClickHouse Community Slack about configuring the network_compression_method on an individual query basis and across all requests. Let’s see how to do just that in this blog post.
Set up Let’s start by downloading and running the ClickHouse Server:
curl https://clickhouse.com/ | sh ./clickhouse server Output 2024.08.05 12:01:54.701406 [ 85587882 ] {} &amp;lt;Information&amp;gt; Application: Listening for http://[::1]:8123 2024.08.05 12:01:54.701426 [ 85587882 ] {} &amp;lt;Information&amp;gt; Application: Listening for native protocol (tcp): [::1]:9000 2024.</description>
    </item>
    
    <item>
      <title>Hybrid Search in SQL with DuckDB</title>
      <link>https://www.markhneedham.com/blog/2024/07/28/hybrid-search-sql-duckdb/</link>
      <pubDate>Sun, 28 Jul 2024 01:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/07/28/hybrid-search-sql-duckdb/</guid>
      <description>I’ve been playing around with different approaches for Retrieval Augmented Generation (RAG) recently and came across a blog post describing Reciprocal Rank Fusion, a hybrid search technique. In this blog post, we’re going to explore how to apply this method in SQL using DuckDB.
I’ve created a video showing how to do this on my YouTube channel, Learn Data with Mark, so if you prefer to consume content through that medium, I’ve embedded it below:</description>
    </item>
    
    <item>
      <title>DuckDB: Create a function in SQL</title>
      <link>https://www.markhneedham.com/blog/2024/07/28/duckdb-create-function-sql/</link>
      <pubDate>Sun, 28 Jul 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/07/28/duckdb-create-function-sql/</guid>
      <description>I’ve been learning about Hybrid Search via this blog post, which describes the Reciprocal Rank Fusion algorithm, and I wanted to implement and use it in a DuckDB query.
The formula for the function is shown below:
RRF(d) = Σ(r ∈ R) 1 / (k + r(d))
Where:
d is a document
R is the set of rankers (retrievers)
k is a constant (typically 60)
r(d) is the rank of document d in ranker r</description>
    </item>
    
    <item>
      <title>ClickHouse: Unknown setting &#39;allow_nullable_key&#39;</title>
      <link>https://www.markhneedham.com/blog/2024/06/27/clickhouse-unknown-setting-allow_nullable_key/</link>
      <pubDate>Thu, 27 Jun 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/06/27/clickhouse-unknown-setting-allow_nullable_key/</guid>
      <description>I’ve been playing around with ClickHouse’s Amazon reviews dataset and ran into an interesting problem when trying to set the allow_nullable_key setting. In this blog post, we’ll learn how and why we might choose to set it.
I started off with the following SQL statement to create a table called reviews based on the structure of the Parquet file:
CREATE TABLE reviews ENGINE = MergeTree ORDER BY review_date EMPTY AS ( SELECT * FROM s3(concat( &amp;#39;https://datasets-documentation.</description>
    </item>
    
    <item>
      <title>Mistral 7B function calling with llama.cpp</title>
      <link>https://www.markhneedham.com/blog/2024/06/23/mistral-7b-function-calling-llama-cpp/</link>
      <pubDate>Sun, 23 Jun 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/06/23/mistral-7b-function-calling-llama-cpp/</guid>
      <description>Mistral AI recently released version 3 of their popular 7B model and this one is fine-tuned for function calling. Function calling is a confusing name because the LLM isn’t doing any function calling itself. Instead, it takes a prompt and can then tell you which function you should call in your code and with which parameters.
In this blog post, we’re going to learn how to use this functionality with llama.</description>
    </item>
    
    <item>
      <title>Side by side LLMs with Ollama and Streamlit</title>
      <link>https://www.markhneedham.com/blog/2024/05/11/side-by-side-local-llms-ollama-streamlit/</link>
      <pubDate>Sat, 11 May 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/05/11/side-by-side-local-llms-ollama-streamlit/</guid>
      <description>The recent 0.1.33 release of Ollama added experimental support for running multiple LLMs or the same LLM in parallel. But, to compare models on the same prompt we need a UI and that’s what we’re going to build in this blog post.
I’ve created a video showing how to do this on my YouTube channel, Learn Data with Mark, so if you prefer to consume content through that medium, I’ve embedded it below:</description>
    </item>
    
    <item>
      <title>Semantic Router: Stop LLM chatbots going rogue</title>
      <link>https://www.markhneedham.com/blog/2024/04/14/semantic-router-stop-llm-chatbot-going-rogue/</link>
      <pubDate>Sun, 14 Apr 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/04/14/semantic-router-stop-llm-chatbot-going-rogue/</guid>
      <description>A tricky problem when deploying LLM-based chatbots is working out how to stop them from talking about topics that you don’t want them to talk about. Even with the cleverest prompts, with enough effort and ingenuity, users will figure a way around the guard rails.
However, I recently came across a library called Semantic Router, which amongst other things, seems to provide a solution to this problem. In this blog post, we’re going to explore Semantic Router and see if we can create a chatbot that only talks about a pre-defined set of topics.</description>
    </item>
    
    <item>
      <title>llama.cpp - ValueError: Failed to create llama_context - ggml-common.h file not found</title>
      <link>https://www.markhneedham.com/blog/2024/03/31/llama-cpp-value-error-llama-context-ggml-common-not-found/</link>
      <pubDate>Sun, 31 Mar 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/03/31/llama-cpp-value-error-llama-context-ggml-common-not-found/</guid>
      <description>I’ve been playing around with the outlines library and needed to install llama.cpp as a result. I ran into trouble when trying to offload model layers to the GPU and in this post, I’ll explain how to install llama.cpp so that you don’t have the same issues.
This was how I installed the library initially:
CMAKE_ARGS=&amp;#34;-DLLAMA_METAL=on&amp;#34; pip install llama-cpp-python And then let’s try to load a GGUF model with some layers offloaded to the GPU:</description>
    </item>
    
    <item>
      <title>DuckDB 0.10: Binder Error: No function matches the given name and argument types</title>
      <link>https://www.markhneedham.com/blog/2024/03/09/duckdb-strptime-binder-error-no-function-matches/</link>
      <pubDate>Sat, 09 Mar 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/03/09/duckdb-strptime-binder-error-no-function-matches/</guid>
      <description>In the 0.10 version of DuckDB, a breaking change was made that stops implicit casting to VARCHAR during function binding. In this blog post, we’re going to look at some ways to work around this change when fixing our DuckDB code from 0.9 or earlier.
I have a CSV file that looks like this:
from &amp;#39;people.csv&amp;#39; select *; Output ┌─────────┬─────────────┐ │ name │ dateOfBirth │ │ varchar │ int64 │ ├─────────┼─────────────┤ │ John │ 19950105 │ └─────────┴─────────────┘ The dateOfBirth column isn’t an int64, but that’s how DuckDB has inferred it.</description>
    </item>
    
    <item>
      <title>Clustering YouTube comments using Ollama Embeddings</title>
      <link>https://www.markhneedham.com/blog/2024/02/27/clustering-youtube-comments-ollama-embeddings-nomic/</link>
      <pubDate>Tue, 27 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/27/clustering-youtube-comments-ollama-embeddings-nomic/</guid>
      <description>One of my favourite tools in the LLM space is Ollama and if you want to learn how to use it, there’s no better place than Matt Williams&amp;#39; YouTube channel. His videos get a lot of comments and they tend to contain a treasure trove of the things that people are thinking about and the questions that they have. Matt recently did a video about embeddings in Ollama and I thought it’d be fun to try to get a high-level overview of what’s happening in the comments section.</description>
    </item>
    
    <item>
      <title>python-youtube: Retrieving multiple pages using page token</title>
      <link>https://www.markhneedham.com/blog/2024/02/26/python-youtube-data-page-token/</link>
      <pubDate>Mon, 26 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/26/python-youtube-data-page-token/</guid>
      <description>I’ve been playing around with the YouTube API to analyse comments on YouTube videos and needed to use pagination to get all the comments. In this blog post, we’ll learn how to do that.
But before we do anything, you’ll need to go to console.developers.google.com, create a project and enable YouTube Data API v3.
Figure 1. YouTube Data API Once you’ve done that, create an API key.
Figure 2. Creating an API key Create an environment variable that contains your API key:</description>
    </item>
    
    <item>
      <title>Using environment variables in ClickHouse queries</title>
      <link>https://www.markhneedham.com/blog/2024/02/23/clickhouse-environment-variables/</link>
      <pubDate>Fri, 23 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/23/clickhouse-environment-variables/</guid>
      <description>For quite some time I’ve been wondering how to get access to an environment variable in a ClickHouse Local and finally today I have a solution, which we’ll explore in this blog post.
My reason for wanting to do this is so that I can pass through a ClickHouse Cloud password to use in a remoteSecure function call. I wanted to do this as part of a blog post I wrote showing how to do Hybrid Query Execution with ClickHouse.</description>
    </item>
    
    <item>
      <title>Render a CSV across multiple columns on the terminal/shell</title>
      <link>https://www.markhneedham.com/blog/2024/02/20/shell-render-csv-multiple-columns/</link>
      <pubDate>Tue, 20 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/20/shell-render-csv-multiple-columns/</guid>
      <description>I was recently working with a CSV file that contained a bunch of words and I wanted to render them on the console so that you could see all of them at once without any scrolling. i.e. I wanted the rendering of the CSV file to wrap across columns.
I learned that we can do exactly this using the paste command, so let’s see how to do it.
Imagine we have the CSV file shown below:</description>
    </item>
    
    <item>
      <title>Qdrant/FastEmbed: Content discovery for my blog posts</title>
      <link>https://www.markhneedham.com/blog/2024/02/11/qdrant-fast-embed-content-discovery/</link>
      <pubDate>Sun, 11 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/11/qdrant-fast-embed-content-discovery/</guid>
      <description>I was recently reading Simon Willison’s blog post about embedding algorithms in which he described how he’d used them to create a &amp;#39;related posts&amp;#39; section on his blog post. So, of course, I wanted to see whether I could do the same for my blog as well.
Note I’ve created a video showing how to do this on my YouTube channel, Learn Data with Mark, so if you prefer to consume content through that medium, I’ve embedded it below:</description>
    </item>
    
    <item>
      <title>LLaVA 1.5 vs. 1.6</title>
      <link>https://www.markhneedham.com/blog/2024/02/04/llava-large-multi-modal-model-v1.5-v1.6/</link>
      <pubDate>Sun, 04 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/04/llava-large-multi-modal-model-v1.5-v1.6/</guid>
      <description>LLaVA (or Large Language and Vision Assistant), an open-source large multi-modal model, just released version 1.6. It claims to have improvements over version 1.5, which was released a few months ago:
Increasing the input image resolution to 4x more pixels. This allows it to grasp more visual details. It supports three aspect ratios, up to 672x672, 336x1344, 1344x336 resolution.
Better visual reasoning and OCR capability with an improved visual instruction tuning data mixture.</description>
    </item>
    
    <item>
      <title>Ollama is on PyPi</title>
      <link>https://www.markhneedham.com/blog/2024/01/28/ollama-now-on-pypi/</link>
      <pubDate>Sun, 28 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/28/ollama-now-on-pypi/</guid>
      <description>This week Ollama released a Python/PyPi library to go with their awesome tool for running LLMs on your own machine. You still need to download and run Ollama, but after that you can do almost everything from the library. In this blog post, we’re going to take it for a spin.
I’ve created a video showing how to do this on my YouTube channel, Learn Data with Mark, so if you prefer to consume content through that medium, I’ve embedded it below:</description>
    </item>
    
    <item>
      <title>ClickHouse: Configure default output format</title>
      <link>https://www.markhneedham.com/blog/2024/01/19/clickhouse-configure-output-format/</link>
      <pubDate>Fri, 19 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/19/clickhouse-configure-output-format/</guid>
      <description>When running queries with ClickHouse Local, the results are rendered back to the screen in a table format in blocks. This default format is called PrettyCompact and most of the time this works fine, but sometimes you can end up with multiple mini-tables. In this blog post, we’re going to learn how to change the default format so that all the results show in one table.
But first, let’s see how the problem manifests.</description>
    </item>
    
    <item>
      <title>An introduction to Retrieval Augmented Generation</title>
      <link>https://www.markhneedham.com/blog/2024/01/12/intro-to-retrieval-augmented-generation/</link>
      <pubDate>Fri, 12 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/12/intro-to-retrieval-augmented-generation/</guid>
      <description>Retrieval Augmented Generation (RAG) is a technique used with Large Language Models (LLM) where you augment the prompt with data retrieved from a data store so that the LLM can generate a better answer to the question that is being asked. In this blog post, we’re going to learn the basics of RAG by creating a Question and Answer system on top of the 2023 Wimbledon Championships Wikipedia page.</description>
    </item>
    
    <item>
      <title>Pandas: Exclude columns using regex</title>
      <link>https://www.markhneedham.com/blog/2024/01/05/pandas-exclude-columns-regex/</link>
      <pubDate>Fri, 05 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/05/pandas-exclude-columns-regex/</guid>
      <description>After a few months of using ClickHouse, I’ve got quite used to using the SELECT &amp;lt;expr&amp;gt; EXCEPT modifier, which lets you remove columns based on a regular expression. I wanted to do something similar when working with some data in Pandas and in this blog we’ll explore how to do that.
We’re gonna be working with a CSV file of UK energy and gas tariffs for one of the energy providers.</description>
    </item>
    
    <item>
      <title>ClickHouse: Float equality</title>
      <link>https://www.markhneedham.com/blog/2024/01/04/clickhouse-float-equality/</link>
      <pubDate>Thu, 04 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/04/clickhouse-float-equality/</guid>
      <description>I’ve been playing around with NumPy data in ClickHouse this week and wanted to share what I learnt when checking for equality of float values. Let’s get going!
Creating arrays We’re going to use Python’s NumPy library to create 5 arrays containing 10 values each:
import numpy as np rng = np.random.default_rng(seed=42) rng.random(size=(5, 5)) Output array([[0.28138389, 0.29359376, 0.66191651, 0.55703215, 0.78389821], [0.66431354, 0.40638686, 0.81402038, 0.16697292, 0.02271207], [0.09004786, 0.72235935, 0.46187723, 0.16127178, 0.</description>
    </item>
    
    <item>
      <title>nvim: Unable to create directory for swap file - recovery impossible: permission denied</title>
      <link>https://www.markhneedham.com/blog/2024/01/03/nvim-swap-file-permission-denied/</link>
      <pubDate>Wed, 03 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/03/nvim-swap-file-permission-denied/</guid>
      <description>I was playing around with neovim last week and despite installing it via Homebrew, ran into a weird permissions error. In this blog post, I’ll describe the problem I had and how to solve it.
I installed it like this:
brew install nvim And then tried to create a new file:
nvim foo.py Which resulted in the following error:
Output E303: Unable to create directory &amp;#34;/Users/markhneedham/.local/state/nvim&amp;#34; for swap file, recovery impossible: permission denied E303: Unable to open swap file for &amp;#34;foo.</description>
    </item>
    
    <item>
      <title>ClickHouse: How does a number have a set number of decimal places?</title>
      <link>https://www.markhneedham.com/blog/2024/01/02/clickhouse-set-number-decimal-places/</link>
      <pubDate>Tue, 02 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/02/clickhouse-set-number-decimal-places/</guid>
      <description>I’ve been working with a dataset in ClickHouse where I compute currency values and I really struggled to figure out how to get numbers whose decimal part is divisible by 10 to have a fixed number of decimal places. If you want to do that too, hopefully, this blog post will help.
Let’s start by seeing what happens if we output the number 12.40
SELECT 12.40 AS number; Output ┌─number─┐ │ 12.</description>
    </item>
    
  </channel>
</rss>
