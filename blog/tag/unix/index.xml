<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>unix on Mark Needham</title>
    <link>https://markhneedham.com/blog/tag/unix/</link>
    <description>Recent content in unix on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Oct 2020 00:21:00 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/tag/unix/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Neo4j: Cypher - FOREACH vs CALL {} (subquery)</title>
      <link>https://markhneedham.com/blog/2020/10/29/neo4j-foreach-call-subquery/</link>
      <pubDate>Thu, 29 Oct 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/10/29/neo4j-foreach-call-subquery/</guid>
      <description>:param list =&amp;gt; ({`0`: [7, 9], `1`: [2, 4, 5, 6, 8, 9], `2`: [0, 6, 8, 9], `3`: [1, 2, 6, 9], `4`: [1, 2, 3, 7], `5`: [8, 9], `6`: [2, 4, 5, 7, 8, 9], `7`: [0, 3, 4, 6, 8, 9], `8`: [1, 6, 9], `9`: [0, 1, 3, 5]})   UNWIND keys($list) AS key MERGE (n:Node {id: toInteger(key)}) FOREACH(item IN $list[key] | MERGE (m:Node {id: item}) MERGE (n)-[:CONNECTED_TO]-&amp;gt;(m) ) RETURN n.</description>
    </item>
    
    <item>
      <title>Unix: Get file name without extension from file path</title>
      <link>https://markhneedham.com/blog/2020/08/24/unix-get-file-name-without-extension-from-file-path/</link>
      <pubDate>Mon, 24 Aug 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/08/24/unix-get-file-name-without-extension-from-file-path/</guid>
      <description>I recently found myself needing to extract the file name but not file extension from a bunch of file paths and wanted to share a neat technique that I learnt to do it.
 I started with a bunch of Jupyter notebook files, which I listed usign the following command;
 $ find notebooks/ -maxdepth 1 -iname *ipynb notebooks/09_Predictions_sagemaker.ipynb notebooks/00_Environment.ipynb notebooks/05_Train_Evaluate_Model.ipynb notebooks/01_DataLoading.ipynb notebooks/05_SageMaker.ipynb notebooks/09_Predictions_sagemaker-Copy2.ipynb notebooks/09_Predictions_sagemaker-Copy1.ipynb notebooks/02_Co-Author_Graph.ipynb notebooks/04_Model_Feature_Engineering.ipynb notebooks/09_Predictions_scikit.ipynb notebooks/03_Train_Test_Split.ipynb   If we pick one of those files:</description>
    </item>
    
    <item>
      <title>Unix: Find files greater than date</title>
      <link>https://markhneedham.com/blog/2016/06/24/unix-find-files-greater-than-date/</link>
      <pubDate>Fri, 24 Jun 2016 16:56:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/24/unix-find-files-greater-than-date/</guid>
      <description>$ ls -alh foo/database-agent-* -rw-r--r-- 1 markneedham wheel 2.5K 23 Jun 14:00 foo/database-agent-mac17f73-1-logs-archive-201606231300176.tar.gz -rw-r--r-- 1 markneedham wheel 8.6K 23 Jun 11:49 foo/database-agent-mac19b6b-1-logs-archive-201606231049507.tar.gz -rw-r--r-- 1 markneedham wheel 8.6K 23 Jun 11:49 foo/database-agent-mac1f427-1-logs-archive-201606231049507.tar.gz -rw-r--r-- 1 markneedham wheel 2.5K 23 Jun 14:00 foo/database-agent-mac29389-1-logs-archive-201606231300176.tar.gz -rw-r--r-- 1 markneedham wheel 11K 23 Jun 13:44 foo/database-agent-mac3533f-1-logs-archive-201606231244152.tar.gz -rw-r--r-- 1 markneedham wheel 4.8K 23 Jun 14:00 foo/database-agent-mac35563-1-logs-archive-201606231300176.tar.gz -rw-r--r-- 1 markneedham wheel 3.8K 23 Jun 13:44 foo/database-agent-mac35f7e-1-logs-archive-201606231244165.tar.gz -rw-r--r-- 1 markneedham wheel 4.</description>
    </item>
    
    <item>
      <title>Unix: Find all text below string in a file</title>
      <link>https://markhneedham.com/blog/2016/06/19/unix-find-all-text-below-string-in-a-file/</link>
      <pubDate>Sun, 19 Jun 2016 08:36:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/19/unix-find-all-text-below-string-in-a-file/</guid>
      <description># text I don&amp;#39;t care about = Heading of the bit I care about # text I care about $ cat /tmp/foo.txt # text I don&amp;#39;t care about = Heading of the bit I care about # text I care about $ cat /tmp/foo.txt | sed &amp;#39;1,/Heading of the bit I care about/d&amp;#39; # text I care about $ cat /tmp/foo.txt | sed -e &amp;#39;1,/Heading of the bit I care about/d&amp;#39; -e &amp;#39;/^\s*$/d&amp;#39; # text I care about </description>
    </item>
    
    <item>
      <title>Unix: Split string using separator</title>
      <link>https://markhneedham.com/blog/2016/06/19/unix-split-string-using-separator/</link>
      <pubDate>Sun, 19 Jun 2016 07:22:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/19/unix-split-string-using-separator/</guid>
      <description>A/B/C $ string=&amp;#34;A/B/C&amp;#34; $ echo ${string} | cut -d&amp;#34;/&amp;#34; -f3 C $ echo ${string} | awk -F&amp;#34;/&amp;#34; &amp;#39;{ print $3}&amp;#39; C $ IFS=&amp;#34;/&amp;#34; read -ra ADDR &amp;lt;&amp;lt;&amp;lt; &amp;#34;${string}&amp;#34;; echo ${ADDR[2]} C $ IFS=&amp;#34;/&amp;#34; read -ra ADDR &amp;lt;&amp;lt;&amp;lt; &amp;#34;${string}&amp;#34;; echo ${ADDR[-1]} C $ echo ${string##*/} C </description>
    </item>
    
    <item>
      <title>Unix: Stripping first n bytes in a file / Byte Order Mark (BOM)</title>
      <link>https://markhneedham.com/blog/2015/08/19/unix-stripping-first-n-bytes-in-a-file-byte-order-mark-bom/</link>
      <pubDate>Wed, 19 Aug 2015 23:27:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/19/unix-stripping-first-n-bytes-in-a-file-byte-order-mark-bom/</guid>
      <description>$ time tail -c +4 Casualty7904.csv &amp;gt; Casualty7904_stripped.csv real	0m31.945s user	0m31.370s sys	0m0.518s -c number The location is number bytes. </description>
    </item>
    
    <item>
      <title>Unix: Redirecting stderr to stdout</title>
      <link>https://markhneedham.com/blog/2015/08/15/unix-redirecting-stderr-to-stdout/</link>
      <pubDate>Sat, 15 Aug 2015 15:55:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/15/unix-redirecting-stderr-to-stdout/</guid>
      <description>#!/bin/sh ./neo4j-community-2.2.3/bin/neo4j start $ ./foo.sh &amp;gt; /tmp/output.txt Unable to find any JVMs matching version &amp;#34;1.7&amp;#34;. $ cat /tmp/output.txt Starting Neo4j Server...WARNING: not changing user process [48230]... waiting for server to be ready.... OK. http://localhost:7474/ is ready. #!/bin/sh ./neo4j-community-2.2.3/bin/neo4j start 2&amp;gt;&amp;amp;1 $ ./foo.sh &amp;gt; /tmp/output.txt $ cat /tmp/output.txt Unable to find any JVMs matching version &amp;#34;1.7&amp;#34;. Starting Neo4j Server...WARNING: not changing user process [47989]... waiting for server to be ready.... OK. http://localhost:7474/ is ready.</description>
    </item>
    
    <item>
      <title>Mac OS X: GNU sed -  Hex string replacement / replacing new line characters</title>
      <link>https://markhneedham.com/blog/2015/06/11/mac-os-x-gnu-sed-hex-string-replacement-replacing-new-line-characters/</link>
      <pubDate>Thu, 11 Jun 2015 21:38:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/11/mac-os-x-gnu-sed-hex-string-replacement-replacing-new-line-characters/</guid>
      <description>brew install coreutils brew install gnu-sed --with-default-names $ echo -e &amp;#34;Hello\x0AMark\x0A\x0D&amp;#34; Hello Mark $ echo -e &amp;#34;Hello\x0AMark\x0A\x0D&amp;#34; | \  sed &amp;#39;N;/\x0A[^\x0D]/s/\n/ /&amp;#39; Hello Mark $ echo -e &amp;#34;Hello\x0AMark\x0A\x0DHello\x0AMichael\x0A\x0D&amp;#34; Hello Mark Hello Michael $ echo -e &amp;#34;Hello\x0AMark\x0A\x0DHello\x0AMichael\x0A\x0D&amp;#34; | \  sed &amp;#39;N;/\x0A[^\x0D]/s/\n/ /&amp;#39; Hello Mark Hello Michael </description>
    </item>
    
    <item>
      <title>Unix: Converting a file of values into a comma separated list</title>
      <link>https://markhneedham.com/blog/2015/06/08/unix-converting-a-file-of-values-into-a-comma-separated-list/</link>
      <pubDate>Mon, 08 Jun 2015 22:23:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/08/unix-converting-a-file-of-values-into-a-comma-separated-list/</guid>
      <description>$ cat foo2.txt | head -n 5 1.0 1.0 1.0 1.0 1.0 &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34; $ sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt | head -n 5 &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; $ sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt | tr &amp;#39;\n&amp;#39; &amp;#39;,&amp;#39; &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;, $ paste -s -d &amp;#39;,&amp;#39; &amp;lt;(sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt) &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34; $ paste -s -d &amp;#39;,&amp;#39; &amp;lt;(sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt) | pbcopy </description>
    </item>
    
    <item>
      <title>cURL: POST/Upload multi part form</title>
      <link>https://markhneedham.com/blog/2013/09/23/curl-postupload-multi-part-form/</link>
      <pubDate>Mon, 23 Sep 2013 22:16:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/09/23/curl-postupload-multi-part-form/</guid>
      <description>&amp;lt;form action=&amp;#34;http://foobar.com&amp;#34; method=&amp;#34;POST&amp;#34; enctype=&amp;#34;multipart/form-data&amp;#34;&amp;gt; &amp;lt;p&amp;gt; &amp;lt;label for=&amp;#34;nodes&amp;#34;&amp;gt;File 1:&amp;lt;/label&amp;gt; &amp;lt;input type=&amp;#34;file&amp;#34; name=&amp;#34;file1&amp;#34; id=&amp;#34;file1&amp;#34;&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;p&amp;gt; &amp;lt;label for=&amp;#34;relationships&amp;#34;&amp;gt;File 2:&amp;lt;/label&amp;gt; &amp;lt;input type=&amp;#34;file&amp;#34; name=&amp;#34;file2&amp;#34; id=&amp;#34;file2&amp;#34;&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;input type=&amp;#34;submit&amp;#34; name=&amp;#34;submit&amp;#34; value=&amp;#34;Submit&amp;#34;&amp;gt; &amp;lt;/form&amp;gt; curl &amp;#39;http://foobar.com&amp;#39; -H &amp;#39;Origin: null&amp;#39; -H &amp;#39;Accept-Encoding: gzip,deflate,sdch&amp;#39; -H &amp;#39;Host: foobar.com:7474&amp;#39; -H &amp;#39;Accept-Language: en-US,en;q=0.8&amp;#39; -H &amp;#39;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.95 Safari/537.36&amp;#39; -H &amp;#39;Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryMxYFIg6GFEIPAe6V&amp;#39; -H &amp;#39;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&amp;#39; -H &amp;#39;Cache-Control: max-age=0&amp;#39; -H &amp;#39;Cookie: splashShown1.6=1; undefined=0; _mkto_trk=id:773-GON-065&amp;amp;token:_mch-localhost-1373821432078-37666; JSESSIONID=123cbkxby1rtcj3dwipqzs7yu&amp;#39; -H &amp;#39;Connection: keep-alive&amp;#39; --data-binary $&amp;#39;------WebKitFormBoundaryMxYFIg6GFEIPAe6V\r\nContent-Disposition: form-data; name=&amp;#34;file1&amp;#34;; filename=&amp;#34;file1.</description>
    </item>
    
    <item>
      <title>Unix: tar - Extracting, creating and viewing archives</title>
      <link>https://markhneedham.com/blog/2013/08/22/unix-tar-extracting-creating-and-viewing-archives/</link>
      <pubDate>Thu, 22 Aug 2013 22:56:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/22/unix-tar-extracting-creating-and-viewing-archives/</guid>
      <description>$ wget http://dist.neo4j.org/neo4j-community-1.9.2-unix.tar.gz $ tar -xvf neo4j-community-1.9.2-unix.tar.gz $ wget http://dist.neo4j.org/neo4j-community-1.9.2-unix.tar.gz -o - | tar -xv $ tar -cvzpf neo4j-football.tar.gz neo4j-football/ $ ls -alh neo4j-football.tar.gz -rw-r--r-- 1 markhneedham staff 526M 22 Aug 23:38 neo4j-football.tar.gz $ tar --exclude &amp;#34;data*&amp;#34; --exclude &amp;#34;neo4j-community*&amp;#34; --exclude &amp;#34;.git&amp;#34; -cvzpf neo4j-football.tar.gz neo4j-football/ $ ls -alh neo4j-football.tar.gz -rw-r--r-- 1 markhneedham staff 138M 22 Aug 23:36 neo4j-football.tar.gz $ tar -tvf neo4j-football.tar.gz </description>
    </item>
    
    <item>
      <title>Unix: find, xargs, zipinfo and the &#39;caution: filename not matched:&#39; error</title>
      <link>https://markhneedham.com/blog/2013/06/09/unix-find-xargs-zipinfo-and-the-caution-filename-not-matched-error/</link>
      <pubDate>Sun, 09 Jun 2013 23:10:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/09/unix-find-xargs-zipinfo-and-the-caution-filename-not-matched-error/</guid>
      <description>$ bundle show neo4j-enterprise /Users/markhneedham/.rbenv/versions/jruby-1.7.1/lib/ruby/gems/shared/gems/neo4j-enterprise-1.8.2-java $ cd /Users/markhneedham/.rbenv/versions/jruby-1.7.1/lib/ruby/gems/shared/gems/neo4j-enterprise-1.8.2-java/lib/neo4j-enterprise/jars/ $ find . -iname &amp;#34;*.jar&amp;#34; | xargs zipinfo caution: filename not matched: ./lib/neo4j-enterprise/jars/logback-classic-0.9.30.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/logback-core-0.9.30.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-backup-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-com-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-consistency-check-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-ha-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-udc-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/org.apache.servicemix.bundles.netty-3.2.5.Final_1.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/server-api-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/slf4j-api-1.6.2.jar caution: filename not matched: .</description>
    </item>
    
    <item>
      <title>Unix: Working with parts of large files</title>
      <link>https://markhneedham.com/blog/2013/05/19/unix-working-with-parts-of-large-files/</link>
      <pubDate>Sun, 19 May 2013 21:44:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/19/unix-working-with-parts-of-large-files/</guid>
      <description>$ sed -n &amp;#39;10,15p&amp;#39; data/log/neo4j.0.0.log INFO: Enabling HTTPS on port [7473] May 19, 2013 11:11:52 AM org.neo4j.server.logging.Logger log INFO: No SSL certificate found, generating a self-signed certificate.. May 19, 2013 11:11:53 AM org.neo4j.server.logging.Logger log INFO: Mounted discovery module at [/] May 19, 2013 11:11:53 AM org.neo4j.server.logging.Logger log </description>
    </item>
    
    <item>
      <title>Unix: Checking for open sockets on nginx</title>
      <link>https://markhneedham.com/blog/2013/04/23/unix-checking-for-open-sockets-on-nginx/</link>
      <pubDate>Tue, 23 Apr 2013 23:59:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/23/unix-checking-for-open-sockets-on-nginx/</guid>
      <description>$ ulimit -n 1024 $ ps aux | grep nginx | grep -v grep root 1089 0.0 0.7 105152 2736 ? Ss 17:34 0:00 nginx: master process /usr/sbin/nginx www-data 17474 0.0 0.6 105300 2296 ? S 21:49 0:04 nginx: worker process www-data 17475 0.0 0.7 105300 2856 ? S 21:49 0:04 nginx: worker process www-data 17476 0.0 0.7 105300 2792 ? S 21:49 0:03 nginx: worker process www-data 17477 0.0 0.</description>
    </item>
    
    <item>
      <title>awk: Parsing &#39;free -m&#39; output to get memory usage/consumption</title>
      <link>https://markhneedham.com/blog/2013/04/10/awk-parsing-free-m-output-to-get-memory-usageconsumption/</link>
      <pubDate>Wed, 10 Apr 2013 07:03:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/10/awk-parsing-free-m-output-to-get-memory-usageconsumption/</guid>
      <description>$ free -m total used free shared buffers cached Mem: 365 360 5 0 59 97 -/+ buffers/cache: 203 161 Swap: 767 13 754 $ free -m | awk &amp;#39;/Mem:/ { print $2 } /buffers\/cache/ { print $3 }&amp;#39; 365 203 $ free -m | awk &amp;#39;/Mem:/ { print $2 } /buffers\/cache/ { print $3 }&amp;#39; | awk &amp;#39;BEGIN { RS = &amp;#34;&amp;#34; ; FS = &amp;#34;\n&amp;#34; } { print $2 / $1 }&amp;#39; 0.</description>
    </item>
    
    <item>
      <title>Unix: Counting the number of commas on a line</title>
      <link>https://markhneedham.com/blog/2012/11/10/unix-counting-the-number-of-commas-on-a-line/</link>
      <pubDate>Sat, 10 Nov 2012 16:30:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/10/unix-counting-the-number-of-commas-on-a-line/</guid>
      <description>A few weeks ago I was playing around with some data stored in a CSV file and wanted to do a simple check on the quality of the data by making sure that each line had the same number of fields.
One way this can be done is with awk:
awk -F &amp;#34;,&amp;#34; &amp;#39; { print NF-1 } &amp;#39; file.csv Here we&amp;rsquo;re specifying the file separator -Fas &amp;lsquo;,&amp;rsquo; and then using the NF(number of fields) variable to print how many commas there are on the line.</description>
    </item>
    
    <item>
      <title>Unix: tee</title>
      <link>https://markhneedham.com/blog/2012/07/29/unix-tee/</link>
      <pubDate>Sun, 29 Jul 2012 19:11:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/29/unix-tee/</guid>
      <description>I&amp;rsquo;ve read about the Unix &amp;lsquo;tee&amp;rsquo; command before but never found a reason to use it until the last few weeks.
One of the things I repeatedly do by mistake is open /etc/hostswithout sudo and then try to make changes to it:
$ vi /etc/hosts # Editing it leads to the dreaded &amp;#39;W10: Changing a readonly file&amp;#39; I always used to close the file and then re-open it with sudo but I recently came across an approach which allows us to use &amp;lsquo;tee&amp;rsquo; to get around the problem.</description>
    </item>
    
    <item>
      <title>Learning Unix find: Searching in/Excluding certain folders</title>
      <link>https://markhneedham.com/blog/2011/10/21/learning-unix-find-searching-inexcluding-certain-folders/</link>
      <pubDate>Fri, 21 Oct 2011 21:25:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/21/learning-unix-find-searching-inexcluding-certain-folders/</guid>
      <description>I love playing around with commands on the Unix shell but one of the ones that I&amp;rsquo;ve found the most difficult to learn beyond the very basics is find.
I think this is partially because I find the find man page quite difficult to read and partially because it&amp;rsquo;s usually quicker to work out how to solve my problem with a command I already know than to learn another one.</description>
    </item>
    
    <item>
      <title>Bash: Reusing previous commands</title>
      <link>https://markhneedham.com/blog/2011/10/13/bash-reusing-previous-commands/</link>
      <pubDate>Thu, 13 Oct 2011 19:46:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/13/bash-reusing-previous-commands/</guid>
      <description>A lot of the time when I&amp;rsquo;m using the bash shell I want to re-use commands that I&amp;rsquo;ve previously entered and I&amp;rsquo;ve recently learnt some neat ways to do this from my colleagues Tomand Kief.
If we want to list the history of all the commands we&amp;rsquo;ve entered in a shell session then the following command does the trick:
&amp;gt; history ... 761 sudo port search pdfinfo 762 to_ipad andersen-phd-thesis.pdf 763 vi ~/.</description>
    </item>
    
    <item>
      <title>Unix: Getting the page count of a linearized PDF</title>
      <link>https://markhneedham.com/blog/2011/10/09/unix-getting-the-page-count-of-a-linearized-pdf/</link>
      <pubDate>Sun, 09 Oct 2011 11:34:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/09/unix-getting-the-page-count-of-a-linearized-pdf/</guid>
      <description>We were doing some work last week to rasterize a PDF document into a sequence of images and wanted to get a rough idea of how many pages we&amp;rsquo;d be dealing with if we created an image per page.
The PDFs we&amp;rsquo;re dealing with are linearizedsince they&amp;rsquo;re available for viewing on the web:
The ﬁle is valid PDF in all respects, and is compatible with all existing viewers and other PDF applications.</description>
    </item>
    
    <item>
      <title>Unix: Summing the total time from a log file</title>
      <link>https://markhneedham.com/blog/2011/07/27/unix-summing-the-total-time-from-a-log-file/</link>
      <pubDate>Wed, 27 Jul 2011 23:02:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/07/27/unix-summing-the-total-time-from-a-log-file/</guid>
      <description>As I mentioned in my last postwe&amp;rsquo;ve been doing some profiling of a data ingestion job and as a result have been putting some logging into our code to try and work out where we need to work on.
We end up with a log file peppered with different statements which looks a bit like the following:
18:50:08.086 [akka:event-driven:dispatcher:global-5] DEBUG - Imported document. /Users/mneedham/foo.xml in: 1298 18:50:09.064 [akka:event-driven:dispatcher:global-1] DEBUG - Imported document.</description>
    </item>
    
  </channel>
</rss>