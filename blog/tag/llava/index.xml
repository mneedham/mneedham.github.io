<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>llava on Mark Needham</title>
    <link>https://www.markhneedham.com/blog/tag/llava/</link>
    <description>Recent content in llava on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Feb 2024 00:44:37 +0000</lastBuildDate><atom:link href="https://www.markhneedham.com/blog/tag/llava/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Qdrant/FastEmbed: Content discovery for my blog posts</title>
      <link>https://www.markhneedham.com/blog/2024/02/11/qdrant-fast-embed-content-discovery/</link>
      <pubDate>Sun, 11 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/11/qdrant-fast-embed-content-discovery/</guid>
      <description>I was recently reading Simon Willison’s blog post about embedding algorithms in which he described how he’d used them to create a &amp;#39;related posts&amp;#39; section on his blog post. So, of course, I wanted to see whether I could do the same for my blog as well.
Note I’ve created a video showing how to do this on my YouTube channel, Learn Data with Mark, so if you prefer to consume content through that medium, I’ve embedded it below:</description>
    </item>
    
    <item>
      <title>LLaVA 1.5 vs. 1.6</title>
      <link>https://www.markhneedham.com/blog/2024/02/04/llava-large-multi-modal-model-v1.5-v1.6/</link>
      <pubDate>Sun, 04 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/04/llava-large-multi-modal-model-v1.5-v1.6/</guid>
      <description>LLaVA (or Large Language and Vision Assistant), an open-source large multi-modal model, just released version 1.6. It claims to have improvements over version 1.5, which was released a few months ago:
Increasing the input image resolution to 4x more pixels. This allows it to grasp more visual details. It supports three aspect ratios, up to 672x672, 336x1344, 1344x336 resolution.
Better visual reasoning and OCR capability with an improved visual instruction tuning data mixture.</description>
    </item>
    
  </channel>
</rss>
