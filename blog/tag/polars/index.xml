<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>polars on Mark Needham</title>
    <link>http://localhost:8000/blog/tag/polars/</link>
    <description>Recent content in polars on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jan 2023 02:44:37 +0000</lastBuildDate><atom:link href="http://localhost:8000/blog/tag/polars/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Exporting CSV files to Parquet file format with Pandas, Polars, and DuckDB</title>
      <link>http://localhost:8000/blog/2023/01/06/export-csv-parquet-pandas-polars-duckdb/</link>
      <pubDate>Fri, 06 Jan 2023 02:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2023/01/06/export-csv-parquet-pandas-polars-duckdb/</guid>
      <description>I was recently trying to convert a CSV file to Parquet format and came across a StackOverflow post that described a collection of different options. My CSV file was bigger than the amount of memory I had available, which ruled out some of the methods. In this blog post we’re going to walk through some options for exporting big CSV files to Parquet format.
Note I’ve created a video showing how to do this on my YouTube channel, Learn Data with Mark, so if you prefer to consume content through that medium, I’ve embedded it below:</description>
    </item>
    
  </channel>
</rss>
