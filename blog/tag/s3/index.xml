<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>s3 on Mark Needham</title>
    <link>http://localhost:8000/blog/tag/s3/</link>
    <description>Recent content in s3 on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Sep 2018 07:26:00 +0000</lastBuildDate><atom:link href="http://localhost:8000/blog/tag/s3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Neo4j: Using LOAD CSV to process csv.gz files from S3</title>
      <link>http://localhost:8000/blog/2018/09/05/neo4j-load-csv-gz-s3/</link>
      <pubDate>Wed, 05 Sep 2018 07:26:00 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2018/09/05/neo4j-load-csv-gz-s3/</guid>
      <description>I’ve been building some training material for the GraphConnect conference that happens in a couple of weeks time and I wanted to load gzipped CSV files. I got this working using Cypher’s LOAD CSV command with the file stored locally, but when I uploaded it to S3 it didn’t work as I expected.
I uploaded the file to an S3 bucket and then tried to read it back like this:</description>
    </item>
    
    <item>
      <title>Serverless: S3 - S3BucketPermissions - Action does not apply to any resource(s) in statement</title>
      <link>http://localhost:8000/blog/2017/09/29/serverless-s3-s3bucketpermissions-action-does-not-apply-to-any-resources-in-statement/</link>
      <pubDate>Fri, 29 Sep 2017 06:09:58 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2017/09/29/serverless-s3-s3bucketpermissions-action-does-not-apply-to-any-resources-in-statement/</guid>
      <description>I’ve been playing around with S3 buckets with Serverless, and recently wrote the following code to create an S3 bucket and put a file into that bucket:
const AWS = require(&amp;#34;aws-sdk&amp;#34;); let regionParams = { &amp;#39;region&amp;#39;: &amp;#39;us-east-1&amp;#39; } let s3 = new AWS.S3(regionParams); let s3BucketName = &amp;#34;marks-blog-bucket&amp;#34;; console.log(&amp;#34;Creating bucket: &amp;#34; + s3BucketName); let bucketParams = { Bucket: s3BucketName, ACL: &amp;#34;public-read&amp;#34; }; s3.createBucket(bucketParams).promise() .then(console.log) .catch(console.error); var putObjectParams = { Body: &amp;#34;&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;Hello blog!</description>
    </item>
    
    <item>
      <title>s3cmd: put fails with &#34;`Connection reset by peer`&#34; for large files</title>
      <link>http://localhost:8000/blog/2013/07/30/s3cmd-put-fails-with-connection-reset-by-peer-for-large-files/</link>
      <pubDate>Tue, 30 Jul 2013 16:20:16 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2013/07/30/s3cmd-put-fails-with-connection-reset-by-peer-for-large-files/</guid>
      <description>I recently wanted to copy some large files from an AWS instance into an S3 bucket using s3cmd but ended up with the following error when trying to use the &amp;#39;put&amp;#39; command:
$ s3cmd put /mnt/ebs/myfile.tar s3://mybucket.somewhere.com /mnt/ebs/myfile.tar -&amp;gt; s3://mybucket.somewhere.com/myfile.tar [1 of 1] 1077248 of 12185313280 0% in 1s 937.09 kB/s failed WARNING: Upload failed: /myfile.tar ([Errno 104] Connection reset by peer) WARNING: Retrying on lower speed (throttle=0.00) WARNING: Waiting 3 sec.</description>
    </item>
    
  </channel>
</rss>
