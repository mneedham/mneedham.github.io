<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>s3 on Mark Needham</title>
    <link>https://markhneedham.com/blog/tag/s3/</link>
    <description>Recent content in s3 on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Sep 2018 07:26:00 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/tag/s3/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Neo4j: Using LOAD CSV to process csv.gz files from S3</title>
      <link>https://markhneedham.com/blog/2018/09/05/neo4j-load-csv-gz-s3/</link>
      <pubDate>Wed, 05 Sep 2018 07:26:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/09/05/neo4j-load-csv-gz-s3/</guid>
      <description>I&amp;#8217;ve been building some training material for the GraphConnect conference that happens in a couple of weeks time and I wanted to load gzipped CSV files. I got this working using Cypher&amp;#8217;s LOAD CSV command with the file stored locally, but when I uploaded it to S3 it didn&amp;#8217;t work as I expected.
 I uploaded the file to an S3 bucket and then tried to read it back like this:</description>
    </item>
    
    <item>
      <title>Serverless: S3 - S3BucketPermissions - Action does not apply to any resource(s) in statement</title>
      <link>https://markhneedham.com/blog/2017/09/29/serverless-s3-s3bucketpermissions-action-does-not-apply-to-any-resources-in-statement/</link>
      <pubDate>Fri, 29 Sep 2017 06:09:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/09/29/serverless-s3-s3bucketpermissions-action-does-not-apply-to-any-resources-in-statement/</guid>
      <description>const AWS = require(&amp;#34;aws-sdk&amp;#34;); let regionParams = { &amp;#39;region&amp;#39;: &amp;#39;us-east-1&amp;#39; } let s3 = new AWS.S3(regionParams); let s3BucketName = &amp;#34;marks-blog-bucket&amp;#34;; console.log(&amp;#34;Creating bucket: &amp;#34; + s3BucketName); let bucketParams = { Bucket: s3BucketName, ACL: &amp;#34;public-read&amp;#34; }; s3.createBucket(bucketParams).promise() .then(console.log) .catch(console.error); var putObjectParams = { Body: &amp;#34;&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;Hello blog!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&amp;#34;, Bucket: s3BucketName, Key: &amp;#34;blog.html&amp;#34; }; s3.putObject(putObjectParams).promise() .then(console.log) .catch(console.error); $ curl --head --silent https://s3.amazonaws.com/marks-blog-bucket/blog.html HTTP/1.1 403 Forbidden x-amz-request-id: 512FE36798C0BE4D x-amz-id-2: O1ELGMJ0jjs11WCrNiVNF2z2ssRgtO4+M4H2QQB5025HjIpC54VId0eKZryYeBYN8Pvb8GsolTQ= Content-Type: application/xml Transfer-Encoding: chunked Date: Fri, 29 Sep 2017 05:42:03 GMT Server: AmazonS3 service: marks-blog frameworkVersion: &amp;#34;&amp;gt;=1.</description>
    </item>
    
    <item>
      <title>s3cmd: put fails with “Connection reset by peer” for large files</title>
      <link>https://markhneedham.com/blog/2013/07/30/s3cmd-put-fails-with-connection-reset-by-peer-for-large-files/</link>
      <pubDate>Tue, 30 Jul 2013 16:20:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/30/s3cmd-put-fails-with-connection-reset-by-peer-for-large-files/</guid>
      <description>$ s3cmd put /mnt/ebs/myfile.tar s3://mybucket.somewhere.com /mnt/ebs/myfile.tar -&amp;gt; s3://mybucket.somewhere.com/myfile.tar [1 of 1] 1077248 of 12185313280 0% in 1s 937.09 kB/s failed WARNING: Upload failed: /myfile.tar ([Errno 104] Connection reset by peer) WARNING: Retrying on lower speed (throttle=0.00) WARNING: Waiting 3 sec... /mnt/ebs/myfile.tar -&amp;gt; s3://mybucket.somewhere.com/myfile.tar [1 of 1] 1183744 of 12185313280 0% in 1s 1062.18 kB/s failed WARNING: Upload failed: /myfile.tar ([Errno 104] Connection reset by peer) WARNING: Retrying on lower speed (throttle=0.</description>
    </item>
    
  </channel>
</rss>