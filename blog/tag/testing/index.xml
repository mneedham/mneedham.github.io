<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>testing on Mark Needham</title>
    <link>https://www.markhneedham.com/blog/tag/testing/</link>
    <description>Recent content in testing on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 30 Sep 2012 15:48:10 +0000</lastBuildDate><atom:link href="https://www.markhneedham.com/blog/tag/testing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Testing XML generation with vimdiff</title>
      <link>https://www.markhneedham.com/blog/2012/09/30/testing-xml-generation-with-vimdiff/</link>
      <pubDate>Sun, 30 Sep 2012 15:48:10 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2012/09/30/testing-xml-generation-with-vimdiff/</guid>
      <description>A couple of weeks ago I spent a bit of time writing a Ruby DSL to automate the setup of load balancers, firewall and NAT rules through the VCloud API.
The VCloud API deals primarily in XML so the DSL is just a thin layer which creates the appropriate mark up.
When we started out we configured everything manually through the web console and then exported the XML so the first thing that the DSL needed to do was create XML that matched what we already had.</description>
    </item>
    
    <item>
      <title>Testing: Trying not to overdo it</title>
      <link>https://www.markhneedham.com/blog/2012/03/28/testing-trying-not-to-overdo-it/</link>
      <pubDate>Wed, 28 Mar 2012 00:10:46 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2012/03/28/testing-trying-not-to-overdo-it/</guid>
      <description>The design of the code which contains the main logic of the application that I’m currently working on looks a bit like the diagram on the right hand side:
We load a bunch of stuff from an Oracle database, construct some objects from the data and then invoke a sequence of methods on those objects in order to execute our domain logic.
Typically we might expect to see unit level test against all the classes described in this diagram but we’ve actually been trying out an approach where we don’t test the orchestration code directly but rather only test it via the resource which makes use of it.</description>
    </item>
    
    <item>
      <title>A new found respect for acceptance tests</title>
      <link>https://www.markhneedham.com/blog/2010/07/11/a-new-found-respect-for-acceptance-tests/</link>
      <pubDate>Sun, 11 Jul 2010 17:08:39 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2010/07/11/a-new-found-respect-for-acceptance-tests/</guid>
      <description>On the project that I’ve been working on over the past few months one of the key benefits of the application was its ability to perform various calculations based on user input.
In order to check that these calculators are producing the correct outputs we created a series of acceptance tests that ran directly against one of the objects in the system.
We did this by defining the inputs and expected outputs for each scenario in an excel spreadsheet which we converted into a CSV file before reading that into an NUnit test.</description>
    </item>
    
    <item>
      <title>TDD: Driving from the assertion up</title>
      <link>https://www.markhneedham.com/blog/2010/06/14/tdd-driving-from-the-assertion-up/</link>
      <pubDate>Mon, 14 Jun 2010 22:46:00 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2010/06/14/tdd-driving-from-the-assertion-up/</guid>
      <description>About a year ago I wrote a post about a book club we ran in Sydney covering &amp;#39;The readability of tests&amp;#39; from Steve Freeman and Nat Pryce’s book in which they suggest that their preferred way of writing tests is to drive them from the assertion up:
Write Tests Backwards Although we stick to a canonical format for test code, we don’t necessarily write tests from top to bottom. What we often do is: write the test name, which helps us decide what we want to achieve; write the call to the target code, which is the entry point for the feature; write the expectations and assertions, so we know what effects the feature should have; and, write the setup and teardown to define the context for the test.</description>
    </item>
    
    <item>
      <title>Late integration: Some thoughts</title>
      <link>https://www.markhneedham.com/blog/2010/04/18/late-integration-some-thoughts/</link>
      <pubDate>Sun, 18 Apr 2010 21:19:23 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2010/04/18/late-integration-some-thoughts/</guid>
      <description>John Daniels has an interesting post summarising GOOSgaggle, an event run a few weeks ago where people met up to talk about the ideas in &amp;#39;Growing Object Oriented Software, Guided by Tests&amp;#39;.
It’s an interesting post and towards the end he states the following:
Given these two compelling justifications for starting with end-to-end tests, why is it that many people apparently don’t start there? We came up with two possibilities, although there may be many others:</description>
    </item>
    
    <item>
      <title>TDD: Consistent test structure</title>
      <link>https://www.markhneedham.com/blog/2010/03/24/tdd-consistent-test-structure/</link>
      <pubDate>Wed, 24 Mar 2010 06:53:55 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2010/03/24/tdd-consistent-test-structure/</guid>
      <description>While pairing with Damian we came across the fairly common situation where we’d written two different tests - one to handle the positive case and one the negative case.
While tidying up the tests after we’d got them passing we noticed that the test structure wasn’t exactly the same. The two tests looked a bit like this:
[Test] public void ShouldSetSomethingIfWeHaveAFoo() { var aFoo = FooBuilder.Build.WithBar(&amp;#34;bar&amp;#34;).WithBaz(&amp;#34;baz&amp;#34;).AFoo(); // some random setup // some stubs/expectations var result = new Controller(.</description>
    </item>
    
    <item>
      <title>Preventing systematic errors: An example</title>
      <link>https://www.markhneedham.com/blog/2010/03/13/preventing-systematic-errors-an-example/</link>
      <pubDate>Sat, 13 Mar 2010 23:26:23 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2010/03/13/preventing-systematic-errors-an-example/</guid>
      <description>James Shore has an interesting recent blog post where he describes some alternatives to over reliance on acceptance testing and one of the ideas that he describes is fixing the process whenever a bug is found in exploratory testing.
He describes two ways of preventing bugs from making it through to exploratory testing:
Make the bug impossible
Catch the bug automatically
Sometimes we can prevent defects by changing the design of our system so that type of defect is impossible.</description>
    </item>
    
    <item>
      <title>TDD: Only mock types you own</title>
      <link>https://www.markhneedham.com/blog/2009/12/13/tdd-only-mock-types-you-own/</link>
      <pubDate>Sun, 13 Dec 2009 21:47:04 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/12/13/tdd-only-mock-types-you-own/</guid>
      <description>Liz recently posted about mock objects and the original &amp;#39;mock roles, not objects&amp;#39; paper and one thing that stood out for me is the idea that we should only mock types that we own.
I think this is quite an important guideline to follow otherwise we can end up in a world of pain.
One area which seems particularly vulnerable to this type of thing is when it comes to testing code which interacts with Hibernate.</description>
    </item>
    
    <item>
      <title>TDD: Combining the when and then steps</title>
      <link>https://www.markhneedham.com/blog/2009/11/14/tdd-combining-the-when-and-then-steps/</link>
      <pubDate>Sat, 14 Nov 2009 00:17:57 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/11/14/tdd-combining-the-when-and-then-steps/</guid>
      <description>I’ve written before about my favoured approach of writing tests in such a way that they have clear &amp;#39;Given/When/Then&amp;#39; sections and something which I come across quite frequently is tests where the latter steps have been combined into one method call which takes care of both of these.
An example of this which I came across recently was roughly like this:
@Test public void shouldCalculatePercentageDifferences() { verifyPercentage(50, 100, 100); verifyPercentage(100, 100, 0); verifyPercentage(100, 50, -50); } private void verifyPercentage(int originalValue, int newValue, int expectedValue) { assertEquals(expectedValue, new PercentageCalculator().</description>
    </item>
    
    <item>
      <title>Testing End Points: Integration tests vs Contract tests</title>
      <link>https://www.markhneedham.com/blog/2009/10/25/testing-integration-points-integration-tests-vs-contract-tests/</link>
      <pubDate>Sun, 25 Oct 2009 00:04:12 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/10/25/testing-integration-points-integration-tests-vs-contract-tests/</guid>
      <description>We recently changed the way that we test against our main integration point on the project I’ve been working on so that in our tests we retrieve the service object from our dependency injection container instead of &amp;#39;newing&amp;#39; one up.
Our tests therefore went from looking like this:
[Test] public void ShouldTestSomeService() { var someService = new SomeService(); // and so on } To something more like this:
[Test] public void ShouldTestSomeService() { var someService = UnityFactory.</description>
    </item>
    
    <item>
      <title>Test Doubles: My current approach</title>
      <link>https://www.markhneedham.com/blog/2009/07/14/test-doubles-my-current-approach/</link>
      <pubDate>Tue, 14 Jul 2009 13:23:52 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/07/14/test-doubles-my-current-approach/</guid>
      <description>My colleague Sarah Taraporewalla recently wrote about her thoughts on test doubles (to use Gerard Meszaros&amp;#39; language) and it got me thinking about the approach I generally take in this area.
Stub objects I use stubs mostly to control the output of depended on components of the system under test where we don’t want to verify those outputs.
Most of the time I make use of the mocking library’s ability to stub out method calls on these dependencies.</description>
    </item>
    
    <item>
      <title>Book Club: The Readability of Tests - Growing Object Oriented Software (Steve Freeman/Nat Pryce)</title>
      <link>https://www.markhneedham.com/blog/2009/06/20/book-club-the-readability-of-tests-growing-object-oriented-software-steve-freemannat-pryce/</link>
      <pubDate>Sat, 20 Jun 2009 11:26:51 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/06/20/book-club-the-readability-of-tests-growing-object-oriented-software-steve-freemannat-pryce/</guid>
      <description>Our technical book club this week focused on &amp;#39;The Readability of Tests&amp;#39; chapter from Steve Freeman &amp;amp; Nat Pryce’s upcoming book &amp;#39;Growing Object Oriented Software, guide by tests&amp;#39;.
I’ve been reading through some of the other chapters online and I thought this would be an interesting chapter to talk about as people seem to have different opinions on how DRY tests should be, how we build test data, how we name tests and so on.</description>
    </item>
    
    <item>
      <title>Writing unit tests can be fun</title>
      <link>https://www.markhneedham.com/blog/2009/04/25/writing-unit-tests-can-be-fun/</link>
      <pubDate>Sat, 25 Apr 2009 19:51:10 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/04/25/writing-unit-tests-can-be-fun/</guid>
      <description>I recently came across Pavel Brodzinski’s blog and while browsing through some of his most recent posts I came across one discussing when unit testing doesn’t work.
The majority of what Pavel says I’ve seen happen before on projects I’ve worked on but I disagree with his suggestion that writing unit tests is boring:
Writing unit tests is boring. That’s not amusing or challenging algorithmic problem. That’s not cool hacking trick which you can show off with in front of your geeky friends.</description>
    </item>
    
    <item>
      <title>I don&#39;t have time not to test!</title>
      <link>https://www.markhneedham.com/blog/2009/04/18/i-dont-have-time-not-to-test/</link>
      <pubDate>Sat, 18 Apr 2009 09:25:17 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/04/18/i-dont-have-time-not-to-test/</guid>
      <description>I recently read a blog post by Joshua Lockwood where he spoke of some people who claim they don’t have time to test.
Learning the TDD approach to writing code has been one of best things that I’ve learnt over the last few years - before I worked at ThoughtWorks I didn’t know how to do it and the only way I could verify whether something worked was to load up the application and manually check it.</description>
    </item>
    
    <item>
      <title>TDD: Balancing DRYness and Readability</title>
      <link>https://www.markhneedham.com/blog/2009/04/13/tdd-balancing-dryness-and-readability/</link>
      <pubDate>Mon, 13 Apr 2009 00:47:00 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/04/13/tdd-balancing-dryness-and-readability/</guid>
      <description>I wrote previously about creating DRY tests and after some conversations with my colleagues recently about the balance between reducing duplication but maintaining readability I think I’ve found the compromise between the two that works best for me.
The underlying idea is that in any unit test I want to be aiming for a distinct 3 sections in the test - Given/When/Then, Arrange/Act/Assert or whatever your favourite description for those is.</description>
    </item>
    
    <item>
      <title>TDD: Test DRYness</title>
      <link>https://www.markhneedham.com/blog/2009/01/30/tdd-test-dryness/</link>
      <pubDate>Fri, 30 Jan 2009 11:16:27 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/01/30/tdd-test-dryness/</guid>
      <description>I had a discussion recently with Fabio about DRYness in our tests and how we don’t tend to adhere to this principal as often in test code as in production code.
I think certainly some of the reason for this is that we don’t take as much care of our test code as we do production code but for me at least some of it is down to the fact that if we make our tests too DRY then they become very difficult to read and perhaps more importantly, very difficult to debug when there is a failure.</description>
    </item>
    
    <item>
      <title>TDD: Design tests for failure</title>
      <link>https://www.markhneedham.com/blog/2009/01/28/tdd-design-tests-for-failure/</link>
      <pubDate>Wed, 28 Jan 2009 00:48:16 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2009/01/28/tdd-design-tests-for-failure/</guid>
      <description>As with most code, tests are read many more times than they are written and as the majority of the time the reason for reading them is to identify a test failure I think it makes sense that we should be designing our tests with failure in mind.
Several ideas come to mind when thinking about ways to write/design our tests so that when we do have to read them our task is made easier.</description>
    </item>
    
    <item>
      <title>Testing First vs Testing Last</title>
      <link>https://www.markhneedham.com/blog/2008/12/22/testing-first-vs-testing-last/</link>
      <pubDate>Mon, 22 Dec 2008 21:39:22 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/12/22/testing-first-vs-testing-last/</guid>
      <description>I recently posted about my experiences of testing last where it became clear to me how important writing the test before the code is.
If we view the tests purely as a way of determining whether or not our code works correctly for a given set of examples then it doesn’t make much difference whether we test before or after we have written the code.
If on the other hand we want to get more value out of our tests such as having them the tests act as documentation, drive the design of our APIs and generally prove useful reading to ourself and others in future then a test first approach is the way to go.</description>
    </item>
    
    <item>
      <title>TDD: Mock expectations in Setup</title>
      <link>https://www.markhneedham.com/blog/2008/12/19/tdd-mock-expectations-in-setup/</link>
      <pubDate>Fri, 19 Dec 2008 20:57:23 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/12/19/tdd-mock-expectations-in-setup/</guid>
      <description>One of the ideas that I mentioned in a recent post about what I consider to be a good unit test was the ideas that we shouldn’t necessarily consider the DRY (Don’t Repeat Yourself) principle to be our number one driver.
I consider putting mock expectations in the setup methods of our tests to be one of those occasions where we shouldn’t obey this principle and I thought this would be fairly unanimously agreed upon but putting the question to the Twittersphere led to mixed opinions.</description>
    </item>
    
    <item>
      <title>Testing: What is a defect?</title>
      <link>https://www.markhneedham.com/blog/2008/12/18/testing-what-is-a-defect/</link>
      <pubDate>Thu, 18 Dec 2008 22:34:48 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/12/18/testing-what-is-a-defect/</guid>
      <description>One of the key ideas that I have learnt from my readings of The Toyota Way and Taaichi Ohno’s Workplace Management is that we should strive not to pass defects through the system to the next process, which you should consider to be your customer.
As a developer the next process for each story is the testing phase where the testers will (amongst other things) run through the acceptance criteria and then do some exploratory testing for scenarios which weren’t explicitly part of the acceptance criteria.</description>
    </item>
    
    <item>
      <title>TDD: One test at a time</title>
      <link>https://www.markhneedham.com/blog/2008/12/09/tdd-one-test-at-a-time/</link>
      <pubDate>Tue, 09 Dec 2008 22:07:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/12/09/tdd-one-test-at-a-time/</guid>
      <description>My colleague Sarah Taraporewalla has written a series of posts recently about her experiences with TDD and introducing it at her current client.
While I agreed with the majority of the posts, one thing I found interesting was that in the conversation with a TDDer there were two tests being worked on at the same time (at least as far as I understand from the example).
This means that there will be two tests failing if we run our test suite, something which I try to avoid wherever possible.</description>
    </item>
    
    <item>
      <title>What makes a good unit test?</title>
      <link>https://www.markhneedham.com/blog/2008/12/04/what-make-a-good-unit-test/</link>
      <pubDate>Thu, 04 Dec 2008 00:31:29 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/12/04/what-make-a-good-unit-test/</guid>
      <description>Following on from my post around the definition of a unit test, a recent discussion on the Test Driven Development mailing list led me to question what my own approach is for writing unit tests.
To self quote from my previous post:
A well written unit test in my book should be simple to understand and run quickly.
Quite simple in theory but as I have learnt (and am still learning) the hard way, much harder to do in practice.</description>
    </item>
    
    <item>
      <title>TDD: If it&#39;s hard to test reflect on your approach</title>
      <link>https://www.markhneedham.com/blog/2008/11/30/tdd-if-its-hard-to-test-reflect-on-your-approach/</link>
      <pubDate>Sun, 30 Nov 2008 18:42:29 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/11/30/tdd-if-its-hard-to-test-reflect-on-your-approach/</guid>
      <description>Chad Myers gets it spot on in his recent post about not testing private methods - private methods are private because they should be inaccessible from outside the class and their functionality should be tested via one of the public methods that calls them.
I’ve found that when a piece of code seems really difficult to test without exposing a private method then we’re probably trying to test that functionality from the wrong place.</description>
    </item>
    
    <item>
      <title>TDD: Suffering from testing last</title>
      <link>https://www.markhneedham.com/blog/2008/11/28/tdd-suffering-from-testing-last/</link>
      <pubDate>Fri, 28 Nov 2008 00:34:24 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/11/28/tdd-suffering-from-testing-last/</guid>
      <description>I’ve always been a big proponent of writing tests before writing code, and I roll off the standard reasons to people who question this approach:
They help to drive the design
They provide a safety net when making future changes
They provide a way of communicating the intent of the code to the rest of the team
And so on. Despite knowing all this I recently took a non test driven approach to writing some bits of code - we were keen to get the system working end to end so it seemed a trade off worth making to prove that it was doable.</description>
    </item>
    
    <item>
      <title>Testing Test Code</title>
      <link>https://www.markhneedham.com/blog/2008/11/23/testing-test-code/</link>
      <pubDate>Sun, 23 Nov 2008 23:21:46 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/11/23/testing-test-code/</guid>
      <description>One of the interesting discussions that has come up on several projects I’ve worked on is whether or not we should test code that was written purely to help us test production code.
One of the main arguments used against testing test utility code is that it is not production code and therefore perhaps doesn’t need to be held to the same standards because it lacks the complexity of production code.</description>
    </item>
    
    <item>
      <title>Testing Hibernate mappings: Setting up test data</title>
      <link>https://www.markhneedham.com/blog/2008/10/30/testing-hibernate-mappings-setting-up-test-data/</link>
      <pubDate>Thu, 30 Oct 2008 23:24:14 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/10/30/testing-hibernate-mappings-setting-up-test-data/</guid>
      <description>Continuing with my mini Hibernate mappings series, this post talks about the different ways of setting up the test data for our Hibernate tests.
Where to test the mappings from?
How to test for equality?
How to setup the test data?
There are a couple of ways that we can setup data for Hibernate tests.
Insert Hibernate Object This approach involves creating a new object and saving it to the database using the save method on the Hibernate session.</description>
    </item>
    
    <item>
      <title>Testing Hibernate mappings: Testing Equality</title>
      <link>https://www.markhneedham.com/blog/2008/10/29/testing-hibernate-mappings-testing-equality/</link>
      <pubDate>Wed, 29 Oct 2008 18:03:36 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/10/29/testing-hibernate-mappings-testing-equality/</guid>
      <description>I started a mini Hibernate series with my last post where I spoke of there being three main areas to think about when it comes to testing:
Where to test the mappings from?
How to test for equality?
How to setup the test data?
Once we have worked out where to test the mappings from, if we have decided to test them through either our repository tests or directly from the Hibernate session then we have some choices to make around how to test for equality.</description>
    </item>
    
    <item>
      <title>Testing Hibernate mappings: Where to test from?</title>
      <link>https://www.markhneedham.com/blog/2008/10/27/testing-hibernate-mappings-where-to-test-from/</link>
      <pubDate>Mon, 27 Oct 2008 22:55:15 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/10/27/testing-hibernate-mappings-where-to-test-from/</guid>
      <description>I’ve had the opportunity to work with Hibernate and it’s .NET twin NHibernate on several of my projects and one of the more interesting decisions around its use is working out the best way to test the hibernate mappings that hook together our domain model and the database.
There are three decisions to make around how best to do this:
Where to test the mappings from?
How to test for equality?</description>
    </item>
    
    <item>
      <title>Selenium - Selecting the original window</title>
      <link>https://www.markhneedham.com/blog/2008/10/25/selenium-selecting-the-original-window/</link>
      <pubDate>Sat, 25 Oct 2008 01:55:18 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/10/25/selenium-selecting-the-original-window/</guid>
      <description>I’ve not used Selenium much in my time - all of my previous projects have been client side applications or service layers - but I’ve spent a bit of time getting acquainted with it this week.
While activating some acceptance tests this week I noticed quite a strange error happening if the tests ran in a certain order:
com.thoughtworks.selenium.SeleniumException: ERROR: Current window or frame is closed! at com.thoughtworks.selenium.HttpCommandProcessor.doCommand(HttpCommandProcessor.java:73) at com.</description>
    </item>
    
    <item>
      <title>Using test guided techniques for spiking</title>
      <link>https://www.markhneedham.com/blog/2008/10/12/using-test-guided-techniques-for-spiking/</link>
      <pubDate>Sun, 12 Oct 2008 13:49:35 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/10/12/using-test-guided-techniques-for-spiking/</guid>
      <description>I think that out of all the Extreme Programming practices Test Driven Development is the one which I like the best. I feel it provides a structure for development work and helps me to remain focused on what I am trying to achieve rather than writing code which may not necessarily be needed.
However, there are times when it’s difficult to use a TDD approach, and Pat Kua suggested earlier this year that if you’re using a TDD approach all the time you’re doing something wrong.</description>
    </item>
    
    <item>
      <title>It&#39;s not all about the acceptance tests</title>
      <link>https://www.markhneedham.com/blog/2008/10/03/its-not-all-about-the-acceptance-tests/</link>
      <pubDate>Fri, 03 Oct 2008 01:26:13 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/10/03/its-not-all-about-the-acceptance-tests/</guid>
      <description>A few of my colleagues recently posted their opinions about acceptance tests which tied in nicely with a discussion about acceptance testing that was had at the Alt.NET conference in London.
For the sake of argument I will assume that when we refer to acceptance tests we are talking about tests at the GUI level which are being automatically driven by a tool, usually Selenium but maybe something like White if it is a client side application.</description>
    </item>
    
    <item>
      <title>Testing with Joda Time</title>
      <link>https://www.markhneedham.com/blog/2008/09/24/testing-with-joda-time/</link>
      <pubDate>Wed, 24 Sep 2008 05:11:20 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/09/24/testing-with-joda-time/</guid>
      <description>The alternative to dealing with java.util.Date which I wrote about in a previous post is to make use of the Joda Time library. I’m led to believe that a lot of the ideas from Joda Time will in fact be in Java 7.
Nevertheless when testing with Joda Time there are times when it would be useful for us to have control over the time our code is using.</description>
    </item>
    
    <item>
      <title>Testing file system operations</title>
      <link>https://www.markhneedham.com/blog/2008/09/17/testing-file-system-operations/</link>
      <pubDate>Wed, 17 Sep 2008 15:48:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2008/09/17/testing-file-system-operations/</guid>
      <description>On my previous project one of the areas that we needed to work out how to test was around interaction with the file system.
The decision that we needed to make was whether we should unit test this type of functionality or whether it could just be covered by a functional test.
To Unit Test One of the patterns to use when unit testing things like this is the Gateway pattern.</description>
    </item>
    
  </channel>
</rss>
