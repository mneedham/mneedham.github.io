<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine-learning-2 on Mark Needham</title>
    <link>https://markhneedham.com/blog/tag/machine-learning-2/</link>
    <description>Recent content in machine-learning-2 on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 Aug 2016 20:32:09 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/tag/machine-learning-2/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>scikit-learn: Clustering and the curse of dimensionality</title>
      <link>https://markhneedham.com/blog/2016/08/27/scikit-learn-clustering-and-the-curse-of-dimensionality/</link>
      <pubDate>Sat, 27 Aug 2016 20:32:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/08/27/scikit-learn-clustering-and-the-curse-of-dimensionality/</guid>
      <description>But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”).
Running a dimensionality reduction algorithm such as PCA prior to k-means clustering can alleviate this problem and speed up the computations.
from sklearn.metrics.pairwise import cosine_similarity import numpy as np def distances(a, b): return np.linalg.norm(a-b), cosine_similarity([a, b])[0][1] def mixed(n_zeros, n_ones): return np.concatenate((np.repeat([1], n_ones), np.repeat([0], n_zeros)), axis=0) def ones(n_ones): return np.repeat([1], n_ones) print distances(mixed(2, 2), ones(4)) print distances(mixed(3, 3), ones(6)) print distances(mixed(50, 50), ones(100)) print distances(mixed(300, 300), ones(600)) (1.</description>
    </item>
    
    <item>
      <title>Neo4j/scikit-learn: Calculating the cosine similarity of Game of Thrones episodes</title>
      <link>https://markhneedham.com/blog/2016/08/22/neo4jscikit-learn-calculating-the-cosine-similarity-of-game-of-thrones-episodes/</link>
      <pubDate>Mon, 22 Aug 2016 21:12:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/08/22/neo4jscikit-learn-calculating-the-cosine-similarity-of-game-of-thrones-episodes/</guid>
      <description>:play http://guides.neo4j.com/got Episode 1 = [1, 1, 0] Episode 2 = [0, 1, 1] &amp;gt;&amp;gt;&amp;gt; from sklearn.metrics.pairwise import cosine_similarity &amp;gt;&amp;gt;&amp;gt; one = [1,1,0] &amp;gt;&amp;gt;&amp;gt; two = [0,1,1] &amp;gt;&amp;gt;&amp;gt; cosine_similarity([one, two]) array([[ 1. , 0.5], [ 0.5, 1. ]]) from neo4j.v1 import GraphDatabase, basic_auth driver = GraphDatabase.driver(&amp;#34;bolt://localhost&amp;#34;, auth=basic_auth(&amp;#34;neo4j&amp;#34;, &amp;#34;neo&amp;#34;)) session = driver.session() rows = session.run(&amp;#34;&amp;#34;&amp;#34; MATCH (c:Character), (e:Episode) OPTIONAL MATCH (c)-[appearance:APPEARED_IN]-&amp;gt;(e) RETURN e, c, appearance ORDER BY e.id, c.id&amp;#34;&amp;#34;&amp;#34;) &amp;gt;&amp;gt;&amp;gt; for row in rows: print row &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5415 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Addam Marbrand&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Addam_Marbrand&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5882 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Adrack Humble&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Adrack_Humble&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=6747 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aegon V Targaryen&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aegon_V_Targaryen&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5750 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aemon&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aemon&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5928 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aeron Greyjoy&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aeron_Greyjoy&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5503 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aerys II Targaryen&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aerys_II_Targaryen&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=6753 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alannys Greyjoy&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alannys_Greyjoy&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=6750 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alerie Tyrell&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alerie_Tyrell&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5753 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alliser Thorne&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alliser_Thorne&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5858 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alton Lannister&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alton_Lannister&amp;#39;}&amp;gt; appearance=None&amp;gt; episodes = {} for row in rows: if episodes.</description>
    </item>
    
    <item>
      <title>Mahout: Exception in thread &#34;main&#34; java.lang.IllegalArgumentException: Wrong FS: file:/... expected: hdfs://</title>
      <link>https://markhneedham.com/blog/2016/07/21/mahout-exception-in-thread-main-java-lang-illegalargumentexception-wrong-fs-file-expected-hdfs/</link>
      <pubDate>Thu, 21 Jul 2016 17:57:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/07/21/mahout-exception-in-thread-main-java-lang-illegalargumentexception-wrong-fs-file-expected-hdfs/</guid>
      <description>bin/mahout seqdirectory \ --input file:///Users/markneedham/Downloads/apache-mahout-distribution-0.12.2/foo \ --output file:///Users/markneedham/Downloads/apache-mahout-distribution-0.12.2/foo-out \ -c UTF-8 \ -chunk 64 \ -prefix mah 16/07/21 21:19:20 INFO AbstractJob: Command line arguments: {--charset=[UTF-8], --chunkSize=[64], --endPhase=[2147483647], --fileFilterClass=[org.apache.mahout.text.PrefixAdditionFilter], --input=[file:///Users/markneedham/Downloads/apache-mahout-distribution-0.12.2/foo], --keyPrefix=[mah], --method=[mapreduce], --output=[file:///Users/markneedham/Downloads/apache-mahout-distribution-0.12.2/foo-out], --startPhase=[0], --tempDir=[temp]} 16/07/21 21:19:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 16/07/21 21:19:20 INFO deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir 16/07/21 21:19:20 INFO deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.</description>
    </item>
    
    <item>
      <title>How I met your mother: Story arcs</title>
      <link>https://markhneedham.com/blog/2015/04/03/how-i-met-your-mother-story-arcs/</link>
      <pubDate>Fri, 03 Apr 2015 23:31:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/03/how-i-met-your-mother-story-arcs/</guid>
      <description>#!/bin/bash find_term() { arc=${1} searchTerm=${2} episodes=$(grep --color -iE &amp;#34;${searchTerm}&amp;#34; data/import/sentences.csv | awk -F&amp;#34;,&amp;#34; &amp;#39;{ print $2 }&amp;#39; | sort | uniq) for episode in ${episodes}; do echo ${arc},${episode} done } find_term &amp;#34;Bro Code&amp;#34; &amp;#34;bro code&amp;#34; find_term &amp;#34;Legendary&amp;#34; &amp;#34;legen(.*)ary&amp;#34; find_term &amp;#34;Slutty Pumpkin&amp;#34; &amp;#34;slutty pumpkin&amp;#34; find_term &amp;#34;Magician&amp;#39;s Code&amp;#34; &amp;#34;magician&amp;#39;s code&amp;#34; find_term &amp;#34;Thanksgiving&amp;#34; &amp;#34;thanksgiving&amp;#34; find_term &amp;#34;The Playbook&amp;#34; &amp;#34;playbook&amp;#34; find_term &amp;#34;Slap Bet&amp;#34; &amp;#34;slap bet&amp;#34; find_term &amp;#34;Wrestlers and Robots&amp;#34; &amp;#34;wrestlers&amp;#34; find_term &amp;#34;Robin Sparkles&amp;#34; &amp;#34;sparkles&amp;#34; find_term &amp;#34;Blue French Horn&amp;#34; &amp;#34;blue french horn&amp;#34; find_term &amp;#34;Olive Theory&amp;#34; &amp;#34;olive&amp;#34; find_term &amp;#34;Thank You Linus&amp;#34; &amp;#34;thank you, linus&amp;#34; find_term &amp;#34;Have you met.</description>
    </item>
    
    <item>
      <title>Kaggle Titanic: Python pandas attempt</title>
      <link>https://markhneedham.com/blog/2013/10/30/kaggle-titanic-python-pandas-attempt/</link>
      <pubDate>Wed, 30 Oct 2013 07:26:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/10/30/kaggle-titanic-python-pandas-attempt/</guid>
      <description>import pandas as pd def addrow(df, row): return df.append(pd.DataFrame(row), ignore_index=True) def fare_in_bucket(fare, fare_bracket_size, bucket): return (fare &amp;gt; bucket * fare_bracket_size) &amp;amp; (fare &amp;lt;= ((bucket+1) * fare_bracket_size)) def build_survival_table(training_file): fare_ceiling = 40 train_df = pd.read_csv(training_file) train_df[train_df[&amp;#39;Fare&amp;#39;] &amp;gt;= 39.0] = 39.0 fare_bracket_size = 10 number_of_price_brackets = fare_ceiling / fare_bracket_size number_of_classes = 3 #There were 1st, 2nd and 3rd classes on board  survival_table = pd.DataFrame(columns=[&amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;PriceDist&amp;#39;, &amp;#39;Survived&amp;#39;, &amp;#39;NumberOfPeople&amp;#39;]) for pclass in range(1, number_of_classes + 1): # add 1 to handle 0 start for bucket in range(0, number_of_price_brackets): for sex in [&amp;#39;female&amp;#39;, &amp;#39;male&amp;#39;]: survival = train_df[(train_df[&amp;#39;Sex&amp;#39;] == sex) &amp;amp; (train_df[&amp;#39;Pclass&amp;#39;] == pclass) &amp;amp; fare_in_bucket(train_df[&amp;#34;Fare&amp;#34;], fare_bracket_size, bucket)] row = [dict(Pclass=pclass, Sex=sex, PriceDist = bucket, Survived = round(survival[&amp;#39;Survived&amp;#39;].</description>
    </item>
    
    <item>
      <title>Feature Extraction/Selection - What I&#39;ve learnt so far</title>
      <link>https://markhneedham.com/blog/2013/02/10/feature-extractionselection-what-ive-learnt-so-far/</link>
      <pubDate>Sun, 10 Feb 2013 15:42:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/02/10/feature-extractionselection-what-ive-learnt-so-far/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: A feature extraction #fail</title>
      <link>https://markhneedham.com/blog/2013/01/31/kaggle-digit-recognizer-a-feature-extraction-fail/</link>
      <pubDate>Thu, 31 Jan 2013 23:24:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/31/kaggle-digit-recognizer-a-feature-extraction-fail/</guid>
      <description>I&amp;rsquo;ve written a few blog postsabout our attempts at the Kaggle Digit Recogniserproblem and one thing we haven&amp;rsquo;t yet tried is feature extraction.
Many people go straight from a data set to applying an algorithm. But there’s a huge space in between of important stuff. It’s easy to run a piece of code that predicts or classifies. That’s not the hard part. The hard part is doing it well.
One needs to conduct exploratory data analysis as I’ve emphasized; and conduct feature selection as Will Cukierski emphasized.</description>
    </item>
    
    <item>
      <title>Mahout: Parallelising the creation of DecisionTrees</title>
      <link>https://markhneedham.com/blog/2012/12/27/mahout-parallelising-the-creation-of-decisiontrees/</link>
      <pubDate>Thu, 27 Dec 2012 00:08:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/27/mahout-parallelising-the-creation-of-decisiontrees/</guid>
      <description>List&amp;lt;Node&amp;gt; trees = new ArrayList&amp;lt;Node&amp;gt;(); MultiDecisionForest forest = MultiDecisionForest.load(new Configuration(), new Path(&amp;#34;/path/to/mahout-tree&amp;#34;)); trees.addAll(forest.getTrees()); MultiDecisionForest forest = new MultiDecisionForest(trees); deb http://ppa.launchpad.net/ieltonf/ppa/ubuntu oneiric main deb-src http://ppa.launchpad.net/ieltonf/ppa/ubuntu oneiric main parallelise-forests.sh#!/bin/bash start=`date` startTime=`date &amp;#39;+%s&amp;#39;` numberOfRuns=$1 seq 1 ${numberOfRuns} | parallel -P 8 &amp;#34;./build-forest.sh&amp;#34; end=`date` endTime=`date &amp;#39;+%s&amp;#39;` echo &amp;#34;Started: ${start}&amp;#34; echo &amp;#34;Finished: ${end}&amp;#34; echo &amp;#34;Took: &amp;#34; $(expr $endTime - $startTime) build-forest.sh#!/bin/bash java -Xmx1024m -cp target/machinenursery-1.0.0-SNAPSHOT-standalone.jar main.java.MahoutPlaybox </description>
    </item>
    
    <item>
      <title>Weka: Saving and loading classifiers</title>
      <link>https://markhneedham.com/blog/2012/12/12/weka-saving-and-loading-classifiers/</link>
      <pubDate>Wed, 12 Dec 2012 00:04:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/12/weka-saving-and-loading-classifiers/</guid>
      <description>MultilayerPerceptron classifier = new MultilayerPerceptron(); classifier.buildClassifier(instances); // instances gets passed in from elsewhere  Debug.saveToFile(&amp;#34;/path/to/weka-neural-network&amp;#34;, classifier); SerializedClassifier classifier = new SerializedClassifier(); classifier.setModelFile(new File(&amp;#34;/path/to/weka-neural-network&amp;#34;)); </description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: Weka AdaBoost attempt</title>
      <link>https://markhneedham.com/blog/2012/11/29/kaggle-digit-recognizer-weka-adaboost-attempt/</link>
      <pubDate>Thu, 29 Nov 2012 17:09:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/29/kaggle-digit-recognizer-weka-adaboost-attempt/</guid>
      <description>In our latest attempt at Kaggle&amp;rsquo;s Digit RecognizerJenand I decided to try out boostingon our random forest algorithm, an approach that Jen had come across in a talk at the Clojure Conj.
We couldn&amp;rsquo;t find any documentation that it was possible to apply boosting to Mahout&amp;rsquo;s random forest algorithm but we knew it was possible with Wekaso we decided to use that instead!
As I understand it the way that boosting works in the context of random forests is that each of the trees in the forest will be assigned a weight based on how accurately it&amp;rsquo;s able to classify the data set and these weights are then used in the voting stage.</description>
    </item>
    
    <item>
      <title>A first failed attempt at Natural Language Processing</title>
      <link>https://markhneedham.com/blog/2012/11/24/a-first-failed-attempt-at-natural-language-processing/</link>
      <pubDate>Sat, 24 Nov 2012 19:43:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/24/a-first-failed-attempt-at-natural-language-processing/</guid>
      <description>One of the things I find fascinating about dating websites is that the profiles of people are almost identical so I thought it would be an interesting exercise to grab some of the free text that people write about themselves and prove the similarity.
I&amp;rsquo;d been talking to Matt Biddulphabout some Natural Language Processing (NLP) stuff he&amp;rsquo;d been working on and he wrote up a bunch of libraries, articles and books that he&amp;rsquo;d found useful.</description>
    </item>
    
    <item>
      <title>Mahout: Using a saved Random Forest/DecisionTree</title>
      <link>https://markhneedham.com/blog/2012/10/27/mahout-using-a-saved-random-forestdecisiontree/</link>
      <pubDate>Sat, 27 Oct 2012 22:03:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/27/mahout-using-a-saved-random-forestdecisiontree/</guid>
      <description>One of the things that I wanted to do while playing around with random forestsusing Mahoutwas to save the random forest and then use use it again which is something Mahout does cater for.
It was actually much easier to do this than I&amp;rsquo;d expected and assuming that we already have a DecisionForestbuilt we&amp;rsquo;d just need the following code to save it to disc:
int numberOfTrees = 1; Data data = loadData(.</description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: Mahout Random Forest attempt</title>
      <link>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-mahout-random-forest-attempt/</link>
      <pubDate>Sat, 27 Oct 2012 20:24:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-mahout-random-forest-attempt/</guid>
      <description>I&amp;rsquo;ve written previously about the K-meansapproachthat Jenand I took when trying to solve Kaggle&amp;rsquo;s Digit Recognizerand having stalled at about 80% accuracy we decided to try one of the algorithms suggested in the tutorials section- the random forest!
We initially used a clojure random forests librarybut struggled to build the random forest from the training set data in a reasonable amount of time so we switched to Mahout&amp;rsquo;s versionwhich is based on Leo Breiman&amp;rsquo;s random forestspaper.</description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: K-means optimisation attempt</title>
      <link>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-k-means-optimisation-attempt/</link>
      <pubDate>Sat, 27 Oct 2012 12:27:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-k-means-optimisation-attempt/</guid>
      <description>I recently wrote a blog post explaining how Jenand I used the K-means algorithmto classify digits in Kaggle&amp;rsquo;s Digit Recognizer problemand one of the things we&amp;rsquo;d read was that with this algorithm you often end up with situations where it&amp;rsquo;s difficult to classify a new item because if falls between two labels.
We decided to have a look at the output of our classifier function to see whether or not that was the case.</description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: A K-means attempt</title>
      <link>https://markhneedham.com/blog/2012/10/23/kaggle-digit-recognizer-a-k-means-attempt/</link>
      <pubDate>Tue, 23 Oct 2012 19:04:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/23/kaggle-digit-recognizer-a-k-means-attempt/</guid>
      <description>Over the past couple of months Jen and I have been playing around with the Kaggle Digit Recognizer problem- a &amp;lsquo;competition&amp;rsquo; created to introduce people to Machine Learning.
You are given an input file which contains multiple rows each containing 784 pixel values representing a 28x28 pixel image as well as a label indicating which number that image actually represents.
One of the algorithms that we tried out for this problem was a variation on the k-means clusteringone whereby we took the values at each pixel location for each of the labels and came up with an average value for each pixel.</description>
    </item>
    
  </channel>
</rss>