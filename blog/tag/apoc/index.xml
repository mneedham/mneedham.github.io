<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apoc on Mark Needham</title>
    <link>https://markhneedham.com/blog/tag/apoc/</link>
    <description>Recent content in Apoc on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 May 2020 00:21:00 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/tag/apoc/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>QuickGraph #7: An entity graph of TWIN4j using APOC NLP</title>
      <link>https://markhneedham.com/blog/2020/05/05/quick-graph-building-entity-graph-twin4j-apoc-nlp/</link>
      <pubDate>Tue, 05 May 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/05/05/quick-graph-building-entity-graph-twin4j-apoc-nlp/</guid>
      <description>One of the most popular use cases for Neo4j is knowledge graphs, and part of that process involves using NLP to create a graph structure from raw text. If we were doing a serious NLP project we&amp;#8217;d want to use something like GraphAware Hume, but in this blog post we&amp;#8217;re going to learn how to add basic NLP functionality to our graph applications.
  Figure 1. Building an entity graph of TWIN4j using APOC NLP  APOC NLP The big cloud providers (AWS, GCP, and Azure) all have Natural Language Processing APIs and, although their APIs aren&amp;#8217;t identical, they all let us extract entities, key phrases, and sentiment from text documents.</description>
    </item>
    
    <item>
      <title>QuickGraph #6: COVID-19 Taxonomy Graph</title>
      <link>https://markhneedham.com/blog/2020/04/21/quick-graph-covid-19-taxonomy/</link>
      <pubDate>Tue, 21 Apr 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/04/21/quick-graph-covid-19-taxonomy/</guid>
      <description>It&amp;#8217;s been several months since our last QuickGraph and the world feels very different than it was back then. I&amp;#8217;ve been reading a couple of books about viruses - Spillover and Pale Rider - and am now very curious to learn more about the medical terms reference in the books.
 With the Pre Release of neosemantics (n10s) for Neo4j 4.0, I thought it would be interesting to create a graph of the taxonomy of the virus that caused COVID-19, using data extracted from Wikidata&amp;#8217;s SPARQL API.</description>
    </item>
    
    <item>
      <title>Neo4j: Finding the longest path</title>
      <link>https://markhneedham.com/blog/2020/01/29/neo4j-finding-longest-path/</link>
      <pubDate>Wed, 29 Jan 2020 15:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/29/neo4j-finding-longest-path/</guid>
      <description>One on my favourite things about storing data in a graph database is executing path based queries against that data. I&amp;#8217;ve been trying to find a way to write such queries against the Australian Open QuickGraph, and in this blog post we&amp;#8217;re going to write what I think of as longest path queries against this graph.
  Figure 1. Finding longest paths in Neo4j  Setting up Neo4j We&amp;#8217;re going to use the following Docker Compose configuration in this blog post:</description>
    </item>
    
    <item>
      <title>Neo4j: Exporting a subset of data from one database to another</title>
      <link>https://markhneedham.com/blog/2020/01/27/neo4j-exporting-subset-database/</link>
      <pubDate>Mon, 27 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/27/neo4j-exporting-subset-database/</guid>
      <description>As part of the preparation for another blog post, I wanted to export a subset of data from one Neo4j database to another one, which seemed like a blog post in its own right.
  Figure 1. Exporting data using APOC&amp;#8217;s Export JSON  Setting up Neo4j We&amp;#8217;re going to use the following Docker Compose configuration in this blog post:
 Dockerfile version: &#39;3.7&#39; services: neo4j: image: neo4j:4.0.0-enterprise container_name: &#34;</description>
    </item>
    
    <item>
      <title>QuickGraph #5: Australian Open</title>
      <link>https://markhneedham.com/blog/2020/01/23/quick-graph-australian-open/</link>
      <pubDate>Thu, 23 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/23/quick-graph-australian-open/</guid>
      <description>It&amp;#8217;s time for another QuickGraph, this one based on data from the Australian Open tennis tournament. We&amp;#8217;re going to use data curated by Jeff Sackmann in the tennis_wta and tennis_atp repositories.
  Figure 1. Australian Open Graph (Background from https://www.freepik.com/free-photo/3d-network-background-with-connecting-lines-dots_3961382.htm)  Setting up Neo4j We&amp;#8217;re going to use the following Docker Compose configuration in this blog post:
 docker-compose.yml version: &#39;3.7&#39; services: neo4j: image: neo4j:4.0.0-enterprise container_name: &#34;quickgraph-aus-open&#34; volumes: - .</description>
    </item>
    
    <item>
      <title>QuickGraph #4: UK Official Singles Chart 2019</title>
      <link>https://markhneedham.com/blog/2020/01/04/quick-graph-uk-official-charts/</link>
      <pubDate>Sat, 04 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/04/quick-graph-uk-official-charts/</guid>
      <description>For our first QuickGraph of the new decade we&amp;#8217;re going to explore data from the Official UK Top 40 Chart. This chart ranks the top 100 songs of the week based on official sales of sales of downloads, CD, vinyl, audio streams and video streams. Every week BBC Radio 1 broadcast the top 40 songs, which explains the name of the chart.
  Figure 1. The Official UK Charts  Scraping the Official Charts I couldn&amp;#8217;t find a dump of the dataset, so we&amp;#8217;re going to use our web scraping skills again.</description>
    </item>
    
    <item>
      <title>QuickGraph #3: Itsu Allergens</title>
      <link>https://markhneedham.com/blog/2019/12/23/quick-graph-itsu-allergens/</link>
      <pubDate>Mon, 23 Dec 2019 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/12/23/quick-graph-itsu-allergens/</guid>
      <description>As someone who&amp;#8217;s allergic to lots of different things, the introduction of allergen charts in restaurants over the last few years has been very helpful. These charts are often hidden away in PDF files, but the Asian inspired Itsu restaurant have all this information available on their online menus. This therefore seemed like a great opportunity for another QuickGraph.
   Scraping the Itsu website I wrote a couple of Python scripts to download each of the menu items and then extract the product name, description, and allergens.</description>
    </item>
    
    <item>
      <title>Neo4j: Approximate string matching/similarity</title>
      <link>https://markhneedham.com/blog/2019/09/18/neo4j-string-matching-similarity/</link>
      <pubDate>Wed, 18 Sep 2019 00:47:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/09/18/neo4j-string-matching-similarity/</guid>
      <description>I&amp;#8217;ve been playing with the Brexit Graph over the last few days, and wanted to map the MPs that I got from CommonsVotes with data from the TheyWorkForYou API.
 I already had voting records loaded into Neo4j, but to recap, this is how I did that:
 UNWIND [655,656,657,658,659,660,661,662,711, 669, 668, 667, 666, 664] AS division LOAD CSV FROM &#34;https://github.com/mneedham/graphing-brexit/raw/master/data/commonsvotes/Division&#34; + division + &#34;.csv&#34; AS row // Create motion nodes WITH division, collect(row) AS rows MERGE (motion:Motion {division: trim(split(rows[0][0], &#34;</description>
    </item>
    
    <item>
      <title>Neo4j: apoc.load.csv - Neo.ClientError.Statement.SyntaxError: Type mismatch: expected Float, Integer, Number or String but was Any </title>
      <link>https://markhneedham.com/blog/2019/09/05/neo4j-apoc-load-csv-type-mismatch-expected-float-integer-number-string/</link>
      <pubDate>Thu, 05 Sep 2019 00:47:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/09/05/neo4j-apoc-load-csv-type-mismatch-expected-float-integer-number-string/</guid>
      <description>The Neo4j APOC library&#39;s Load CSV procedure is very useful if you want more control over the import process than the LOAD CSV clause allows. I found myself using it last week to import a CSV file of embeddings, because I wanted to know the line number of the row in the CSV file while importing the data.
 I had a file that looked like this, which I put into the import directory:</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Nested Path Comprehensions vs OPTIONAL MATCH</title>
      <link>https://markhneedham.com/blog/2019/08/23/neo4j-cypher-path-comprehensions-optional-match/</link>
      <pubDate>Fri, 23 Aug 2019 00:47:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/08/23/neo4j-cypher-path-comprehensions-optional-match/</guid>
      <description>While writing my previous post about Cypher nested path comprehensions, I realised that for this particular problem, the OPTIONAL MATCH clause is a better choice.
 To recap, we have the following graph:
 MERGE (club:Club {name: &#34;Man Utd&#34;}) MERGE (league:League {name: &#34;Premier League&#34;}) MERGE (country:Country {name: &#34;England&#34;}) MERGE (club)-[:IN_LEAGUE]-&amp;gt;(league) MERGE (league)-[:IN_COUNTRY]-&amp;gt;(country) MERGE (club2:Club {name: &#34;Juventus&#34;}) MERGE (league2:League {name: &#34;Serie A&#34;}) MERGE (club2)-[:IN_LEAGUE]-&amp;gt;(league2)     We started the post with the following query that returns (club)-[:IN_LEAGUE]&amp;#8594;(league)-[:IN_COUNTRY]&amp;#8594;(country) paths:</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Nested Path Comprehensions</title>
      <link>https://markhneedham.com/blog/2019/08/22/neo4j-cypher-nested-pattern-comprehensions/</link>
      <pubDate>Thu, 22 Aug 2019 11:08:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/08/22/neo4j-cypher-nested-pattern-comprehensions/</guid>
      <description>I&amp;#8217;ve recently been building an application using the GRANDstack, which uses nested Cypher path comprehensions to translate GraphQL queries to Cypher ones. I&amp;#8217;d not done this before, so I was quite curious how this feature worked. We&amp;#8217;ll explore it using the following dataset:
 MERGE (club:Club {name: &#34;Man Utd&#34;}) MERGE (league:League {name: &#34;Premier League&#34;}) MERGE (country:Country {name: &#34;England&#34;}) MERGE (club)-[:IN_LEAGUE]-&amp;gt;(league) MERGE (league)-[:IN_COUNTRY]-&amp;gt;(country) MERGE (club2:Club {name: &#34;Juventus&#34;}) MERGE (league2:League {name: &#34;Serie A&#34;</description>
    </item>
    
    <item>
      <title>Neo4j: Conditional WHERE clause with APOC</title>
      <link>https://markhneedham.com/blog/2019/07/31/neo4j-conditional-where-query-apoc/</link>
      <pubDate>Wed, 31 Jul 2019 11:08:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/07/31/neo4j-conditional-where-query-apoc/</guid>
      <description>Sometimes we want to be able to vary our Cypher queries based on the value of a parameter. I came across such a situation today, and thought I&amp;#8217;d share how I solved it using the APOC library.
 Let&amp;#8217;s first setup some sample data:
 UNWIND range(0, 5) AS id CREATE (:Person {name: &#34;person-&#34; + id})   Now, if we want to get all pairs of people, we could write the following query:</description>
    </item>
    
    <item>
      <title>Neo4j: keep/filter keys in a map using APOC</title>
      <link>https://markhneedham.com/blog/2019/05/12/neo4j-keep-filter-keys-map-apoc/</link>
      <pubDate>Sun, 12 May 2019 17:58:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/05/12/neo4j-keep-filter-keys-map-apoc/</guid>
      <description>In this post we&amp;#8217;ll learn how to write a Cypher query to create a node in Neo4j containing some of the keys from a map. This post assumes that the APOC library is installed.
 We&amp;#8217;ll start by creating a map that contains data from my twitter profile:
 :param document =&amp;gt; { id: 14707949, name: &#34;Mark Needham&#34;, username: &#34;markhneedham&#34;, bio: &#34;Developer Relations @neo4j&#34;, location: &#34;London, United Kingdom&#34;, url: &#34;http://www.markhneedham.com&#34;, join_date: &#34;</description>
    </item>
    
    <item>
      <title>Neo4j: Delete all nodes</title>
      <link>https://markhneedham.com/blog/2019/04/14/neo4j-delete-all-nodes/</link>
      <pubDate>Sun, 14 Apr 2019 12:52:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/04/14/neo4j-delete-all-nodes/</guid>
      <description>When experimenting with a new database, at some stage we&amp;#8217;ll probably want to delete all our data and start again. I was trying to do this with Neo4j over the weekend and it didn&amp;#8217;t work as I expected, so I thought I&amp;#8217;d write the lessons I learned.
 We&amp;#8217;ll be using Neo4j via the Neo4j Desktop with the default settings. This means that we have a maximum heap size of 1GB.</description>
    </item>
    
    <item>
      <title>Neo4j: Delete/Remove dynamic properties</title>
      <link>https://markhneedham.com/blog/2019/03/14/neo4j-delete-dynamic-properties/</link>
      <pubDate>Thu, 14 Mar 2019 06:42:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/03/14/neo4j-delete-dynamic-properties/</guid>
      <description>Irfan and I were playing with a dataset earlier today, and having run a bunch of graph algorithms, we had a lot of properties that we wanted to clear out.
 The following Cypher query puts Neo4j into the state that we were dealing with.
 CREATE (:Node {name: &#34;Mark&#34;, pagerank: 2.302, louvain: 1, lpa: 4 }) CREATE (:Node {name: &#34;Michael&#34;, degree: 23, triangles: 12, betweeness: 48.70 }) CREATE (:Node {name: &#34;</description>
    </item>
    
    <item>
      <title>Neo4j: APOC - Caused by: java.io.RuntimeException: Can&#39;t read url or key file (No such file or directory)</title>
      <link>https://markhneedham.com/blog/2019/01/12/neo4j-apoc-file-not-found-exception-no-such-file-directory/</link>
      <pubDate>Sat, 12 Jan 2019 19:05:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/01/12/neo4j-apoc-file-not-found-exception-no-such-file-directory/</guid>
      <description>I&amp;#8217;ve been using Neo4j&amp;#8217;s APOC library to load some local JSON files this week, and ran into an interesting problem.
 The LOAD CSV tool assumes that any files you load locally are in the import directory, so I&amp;#8217;ve got into the habit of putting my data there. Let&amp;#8217;s check what I&amp;#8217;m trying to import by opening the import directory:
   What&amp;#8217;s in there?
   Just the one JSON file needs processing.</description>
    </item>
    
    <item>
      <title>Neo4j: Storing inferred relationships with APOC triggers</title>
      <link>https://markhneedham.com/blog/2018/11/05/neo4j-inferred-relationships-apoc-triggers/</link>
      <pubDate>Mon, 05 Nov 2018 06:15:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/11/05/neo4j-inferred-relationships-apoc-triggers/</guid>
      <description>One of my favourite things about modelling data in graphs is how easy it makes it to infer relationships between pieces of data based on other relationships. In this post we&amp;#8217;re going to learn how to compute and store those inferred relationships using the triggers feature from the APOC library.
 Meetup Graph Before we get to that, let&amp;#8217;s first understand what we mean when we say inferred relationship. We&amp;#8217;ll create a small graph containing Person, Meetup, and Topic nodes with the following query:</description>
    </item>
    
    <item>
      <title>Neo4j Graph Algorithms: Visualising Projected Graphs</title>
      <link>https://markhneedham.com/blog/2018/10/31/neo4j-graph-algorithms-visualise-projected-graph/</link>
      <pubDate>Wed, 31 Oct 2018 18:12:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/10/31/neo4j-graph-algorithms-visualise-projected-graph/</guid>
      <description>A few weeks ago I wrote a blog post showing how to work out the best tennis player of all time using the Weighted PageRank algorithm, and in the process created a projected credibility graph which I want to explore in more detail in this post.
 As I pointed out in that post, sometimes the graph model doesn&amp;#8217;t fit well with what the algorithm expects, so we need to project the graph on which we run graph algorithms.</description>
    </item>
    
    <item>
      <title>Neo4j: Building a graph of Strava activities</title>
      <link>https://markhneedham.com/blog/2018/06/12/neo4j-building-strava-graph/</link>
      <pubDate>Tue, 12 Jun 2018 05:30:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/06/12/neo4j-building-strava-graph/</guid>
      <description>In my last post I showed how to import activities from Strava&amp;#8217;s API into Neo4j using only the APOC library, but that was only part of the graph so I thought I&amp;#8217;d share the rest of what I&amp;#8217;ve done.
 The Graph Model In the previous post I showed how to import nodes with Run label, but there are some other pieces of data that I wanted to import as well.</description>
    </item>
    
    <item>
      <title>Neo4j APOC: Importing data from Strava&#39;s paginated JSON API</title>
      <link>https://markhneedham.com/blog/2018/06/05/neo4j-apoc-loading-data-strava-paginated-json-api/</link>
      <pubDate>Tue, 05 Jun 2018 05:30:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/06/05/neo4j-apoc-loading-data-strava-paginated-json-api/</guid>
      <description>Over the weekend I&amp;#8217;ve been playing around with loading data from the Strava API into Neo4j and I started with the following Python script which creates a node with a Run label for each of my activities.
 If you want to follow along on your own data you&amp;#8217;ll need to get an API key via the &#39;My API Application&#39; section of the website. Once you&amp;#8217;ve got that put it in the TOKEN environment variable and you should be good to go.</description>
    </item>
    
    <item>
      <title>AWS: Spinning up a Neo4j instance with APOC installed</title>
      <link>https://markhneedham.com/blog/2017/09/30/aws-spinning-up-a-neo4j-instance-with-apoc-installed/</link>
      <pubDate>Sat, 30 Sep 2017 21:23:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/09/30/aws-spinning-up-a-neo4j-instance-with-apoc-installed/</guid>
      <description>One of the first things I do after installing Neo4j is install the APOC library, but I find it&#39;s a bit of a manual process when spinning up a server on AWS so I wanted to simplify it a bit.  There&#39;s already a Neo4j AMI which installs Neo4j 3.2.0 and my colleague Michael pointed out that we could download APOC into the correct folder by writing a script and sending it as UserData.</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Create Cypher map with dynamic keys</title>
      <link>https://markhneedham.com/blog/2017/09/19/neo4j-cypher-create-cypher-map-with-dynamic-keys/</link>
      <pubDate>Tue, 19 Sep 2017 19:30:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/09/19/neo4j-cypher-create-cypher-map-with-dynamic-keys/</guid>
      <description>I was recently trying to create a map in a Cypher query but wanted to have dynamic keys in that map. I started off with this query: WITH &amp;quot;a&amp;quot; as dynamicKey, &amp;quot;b&amp;quot; as dynamicValue RETURN { dynamicKey: dynamicValue } AS map ╒══════════════════╕ │&amp;quot;map&amp;quot; │ ╞══════════════════╡ │{&amp;quot;dynamicKey&amp;quot;:&amp;quot;b&amp;quot;}│ └──────────────────┘   Not quite what we want! We want dynamicKey to be evaluated rather than treated as a literal. As usual, APOC comes to the rescue!</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Rounding of floating point numbers/BigDecimals</title>
      <link>https://markhneedham.com/blog/2017/08/13/neo4j-cypher-rounding-of-floating-point-numbersbigdecimals/</link>
      <pubDate>Sun, 13 Aug 2017 07:23:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/08/13/neo4j-cypher-rounding-of-floating-point-numbersbigdecimals/</guid>
      <description>I was doing some data cleaning a few days ago and wanting to multiply a value by 1 million. My Cypher code to do this looked like this: with &amp;quot;8.37&amp;quot; as rawNumeric RETURN toFloat(rawNumeric) * 1000000 AS numeric ╒═════════════════╕ │&amp;quot;numeric&amp;quot; │ ╞═════════════════╡ │8369999.999999999│ └─────────────────┘   Unfortunately that suffers from the classic rounding error when working with floating point numbers. I couldn&#39;t figure out a way to solve it using pure Cypher, but there tends to be an APOC function to solve every problem and this was no exception.</description>
    </item>
    
    <item>
      <title>Neo4j: Create dynamic relationship type</title>
      <link>https://markhneedham.com/blog/2016/10/30/neo4j-create-dynamic-relationship-type/</link>
      <pubDate>Sun, 30 Oct 2016 22:12:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/10/30/neo4j-create-dynamic-relationship-type/</guid>
      <description>One of the things I&#39;ve often found frustrating when importing data using Cypher, Neo4j&#39;s query language, is that it&#39;s quite difficult to create dynamic relationship types. Say we have a CSV file structured like this:
load csv with headers from &amp;quot;file:///people.csv&amp;quot; AS row RETURN row  ╒═══════════════════════════════════════════════════════╕ │row │ ╞═══════════════════════════════════════════════════════╡ │{node1: Mark, node2: Reshmee, relationship: MARRIED_TO}│ ├───────────────────────────────────────────────────────┤ │{node1: Mark, node2: Alistair, relationship: FRIENDS} │ └───────────────────────────────────────────────────────┘  We want to create nodes with the relationship type specified in the file.</description>
    </item>
    
  </channel>
</rss>