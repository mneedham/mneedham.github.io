<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pinot on Mark Needham</title>
    <link>https://www.markhneedham.com/blog/tag/pinot/</link>
    <description>Recent content in pinot on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Nov 2022 02:44:37 +0000</lastBuildDate><atom:link href="https://www.markhneedham.com/blog/tag/pinot/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Pinot: Unable to render templates on ingestion job spec template file</title>
      <link>https://www.markhneedham.com/blog/2022/11/14/apache-pinot-unable-to-render-templates/</link>
      <pubDate>Mon, 14 Nov 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/11/14/apache-pinot-unable-to-render-templates/</guid>
      <description>I was recently trying to ingest some JSON files into Apache Pinot from an S3 bucket and came across an exception when trying to pass a variable to the LaunchDataIngestionJob command
I was using the following ingestion job specification:
config/job-spec.yml executionFrameworkSpec: name: &amp;#39;standalone&amp;#39; segmentGenerationJobRunnerClassName: &amp;#39;org.apache.pinot.plugin.ingestion.batch.standalone.SegmentGenerationJobRunner&amp;#39; segmentTarPushJobRunnerClassName: &amp;#39;org.apache.pinot.plugin.ingestion.batch.standalone.SegmentTarPushJobRunner&amp;#39; segmentUriPushJobRunnerClassName: &amp;#39;org.apache.pinot.plugin.ingestion.batch.standalone.SegmentUriPushJobRunner&amp;#39; jobType: SegmentCreationAndTarPush inputDirURI: &amp;#39;s3://marks-st-cloud-bucket/events/&amp;#39; includeFileNamePattern: &amp;#39;glob:**/*.json&amp;#39; outputDirURI: &amp;#39;/data&amp;#39; overwriteOutput: true pinotFSSpecs: - scheme: s3 className: org.apache.pinot.plugin.filesystem.S3PinotFS configs: region: &amp;#39;eu-west-2&amp;#39; - scheme: file className: org.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Import JSON data from a CSV file - Illegal Json Path: $[&#39;id&#39;] does not match document</title>
      <link>https://www.markhneedham.com/blog/2022/07/21/apache-pinot-import-json-data-csv-file-illegal-json-path-does-not-match-document/</link>
      <pubDate>Thu, 21 Jul 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/07/21/apache-pinot-import-json-data-csv-file-illegal-json-path-does-not-match-document/</guid>
      <description>I’ve been working on an Apache Pinot dataset where I ingested a JSON document stored in a CSV file. I made a mistake with the representation of the JSON and it took me a while to figure out what I’d done wrong.
We’ll go through it in this blog post.
Figure 1. Apache Pinot: Import JSON data from a CSV file - Illegal Json Path: $[&amp;#39;id&amp;#39;] does not match document Setup We’re going to spin up a local instance of Pinot and Kafka using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Skipping periodic task: Task: PinotTaskManager</title>
      <link>https://www.markhneedham.com/blog/2022/06/23/apache-pinot-skipping-periodic-task-pinot-task-manager/</link>
      <pubDate>Thu, 23 Jun 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/06/23/apache-pinot-skipping-periodic-task-pinot-task-manager/</guid>
      <description>As I mentioned in my last blog post, I’ve been working on an Apache Pinot recipe showing how to ingest data from S3 and after I’d got that working I moved onto using the SegmentGenerationAndPushTask to poll S3 and ingest files automatically.
It took me longer than it should have to get this working and hopefully this blog post will help you avoid the problems that I had.
Figure 1.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Speeding up queries with IdSets</title>
      <link>https://www.markhneedham.com/blog/2022/04/08/apache-pinot-speeding-up-queries-id-set/</link>
      <pubDate>Fri, 08 Apr 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/04/08/apache-pinot-speeding-up-queries-id-set/</guid>
      <description>As I continue to build an Apache Pinot demo using CryptoWatch data, I found myself needing to optimise some queries so that the real-time dashboard would render more quickly. I did this using IdSets and in this blog post we’ll learn about those and how to use them.
Figure 1. Apache Pinot: Speeding up queries with IdSets Pinot Schema For the purpose of this blog post we don’t need to know how to configure the Pinot schema and tables, but we do need to know that we’re working with trades and pairs tables, whose schemas are shown below:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Lookup Join - 500 Error - Unsupported function: lookup with 4 parameters</title>
      <link>https://www.markhneedham.com/blog/2022/04/05/apache-pinot-lookup-join-internal-error-unsupported-function/</link>
      <pubDate>Tue, 05 Apr 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/04/05/apache-pinot-lookup-join-internal-error-unsupported-function/</guid>
      <description>I’m currently working on an Apache Pinot demo using data from Crypto Watch, in which I was using the lookup function and had a bug in my query that didn’t return the clearest error message. In this blog post we’ll have a look at the query and how to fix it.
Figure 1. Apache Pinot: Lookup Join - 500 Error - Unsupported function: lookup with 4 parameters The query that I was writing was using the lookup function to return the name of the base asset in a transaction:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Failed to generate segment - Input path {} does not exist</title>
      <link>https://www.markhneedham.com/blog/2022/03/17/apache-pinot-failed-to-generated-segment-input-path-does-not-exist/</link>
      <pubDate>Thu, 17 Mar 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/03/17/apache-pinot-failed-to-generated-segment-input-path-does-not-exist/</guid>
      <description>In this blog post we’re going to learn how to work around a bug when trying to ingest CSV files with the same name into Apache Pinot. I came across this issue while writing a recipe showing how to import data files from different directories.
Figure 1. Apache Pinot: Failed to generate segment - Input path {} does not exist Setup We’re going to spin up a local instance of Pinot and Kafka using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Deleting instances in a bad state</title>
      <link>https://www.markhneedham.com/blog/2022/02/21/apache-pinot-delete-instances-bad-state/</link>
      <pubDate>Mon, 21 Feb 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/02/21/apache-pinot-delete-instances-bad-state/</guid>
      <description>Sometimes when I start up a local Pinot cluster after doing a hard shutdown (by restarting my computer) I noticed that the Pinot Data Explorer shows controllers, brokers, or servers in a bad state. In this blog post we’ll see how to get rid of those bad instances.
Figure 1. Apache Pinot: Deleting instances in a bad state The screenshot below shows several instances in the bad state.
Figure 2.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Resetting a segment after an invalid JSON Transformation</title>
      <link>https://www.markhneedham.com/blog/2022/01/31/pinot-resetting-segment-invalid-json-transformation/</link>
      <pubDate>Mon, 31 Jan 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/31/pinot-resetting-segment-invalid-json-transformation/</guid>
      <description>I recently had a typo in a Pinot ingestion transformation function and wanted to have Pinot re-process the Kafka stream without having to restart all the things. In this blog post we’ll learn how to do that.
Figure 1. Apache Pinot: Resetting a segment after an invalid JSON Transformation Setup We’re going to spin up a local instance of Pinot and Kafka using the following Docker compose config:
docker-compose.yml version: &amp;#39;3.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Sorted indexes on real-time tables</title>
      <link>https://www.markhneedham.com/blog/2022/01/20/apache-pinot-sorted-indexes-realtime-tables/</link>
      <pubDate>Thu, 20 Jan 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/20/apache-pinot-sorted-indexes-realtime-tables/</guid>
      <description>I’ve recently been learning all about Apache Pinot’s sorted forward indexes, and in my first blog post I explained how they work for offline tables. In this blog post we’ll learn how sorted indexes work with real-time tables.
Figure 1. Apache Pinot: Sorted indexes on real-time tables Launch Components We’re going to spin up a local instance of Pinot and Kafka using the following Docker compose config:
docker-compose.yml version: &amp;#39;3.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Sorted indexes on offline tables</title>
      <link>https://www.markhneedham.com/blog/2022/01/19/apache-pinot-sorted-indexes-offline-tables/</link>
      <pubDate>Wed, 19 Jan 2022 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/19/apache-pinot-sorted-indexes-offline-tables/</guid>
      <description>I’ve recently been learning all about Apache Pinot’s sorted forward indexes. I was initially going to explain how they work for offline and real-time tables, but the post got a bit long, so instead we’ll have two blog posts. In this one we’ll learn how sorted indexes are applied for offline tables.
Figure 1. Apache Pinot: Sorted indexes on offline tables Launch Components We’re going to spin up a local instance of Pinot using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Checking which indexes are defined</title>
      <link>https://www.markhneedham.com/blog/2022/01/13/apache-pinot-which-indexes-are-defined/</link>
      <pubDate>Thu, 13 Jan 2022 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/13/apache-pinot-which-indexes-are-defined/</guid>
      <description>One of the most common questions in the Apache Pinot community Slack is how to work out which indexes are defined on columns in Pinot segments. This blog post will attempt to answer that question.
Figure 1. Apache Pinot: Checking which indexes are defined Setup First, we’re going to spin up a local instance of Pinot using the following Docker compose config:
docker-compose.yml version: &amp;#39;3.7&amp;#39; services: zookeeper: image: zookeeper:3.5.6 hostname: zookeeper container_name: zookeeper-indexes ports: - &amp;#34;2181:2181&amp;#34; environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 pinot-controller: image: apachepinot/pinot:0.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Exploring range queries</title>
      <link>https://www.markhneedham.com/blog/2021/12/07/apache-pinot-exploring-range-queries/</link>
      <pubDate>Tue, 07 Dec 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/12/07/apache-pinot-exploring-range-queries/</guid>
      <description>In our last post about the Chicago Crimes dataset and Apache Pinot, we learnt how to use various indexes to filter columns by exact values. In this post we’re going to learn how to write range queries against the dataset.
Figure 1. Apache Pinot - Range Queries Recap To recap, the Chicago Crimes dataset contains more than 7 million crimes committed in Chicago from 2001 until today. For each crime we have various identifiers, a timestamp, location, and codes reprsenting the type of crime that’s been committed.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Copying a segment to a new table</title>
      <link>https://www.markhneedham.com/blog/2021/12/06/apache-pinot-copy-segment-new-table/</link>
      <pubDate>Mon, 06 Dec 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/12/06/apache-pinot-copy-segment-new-table/</guid>
      <description>In this post we’ll learn how to use the same Pinot segment in multiple tables.
Figure 1. Apache Pinot - Copy segment to another table Setup First, we’re going to spin up a local instance of Pinot using the following Docker compose config:
docker-compose.yml version: &amp;#39;3.7&amp;#39; services: zookeeper: image: zookeeper:3.5.6 hostname: zookeeper container_name: manual-zookeeper ports: - &amp;#34;2181:2181&amp;#34; environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 pinot-controller: image: apachepinot/pinot:0.9.0 command: &amp;#34;StartController -zkAddress manual-zookeeper:2181&amp;#34; container_name: &amp;#34;manual-pinot-controller&amp;#34; volumes: - .</description>
    </item>
    
    <item>
      <title>Apache Pinot: Convert DateTime string to Timestamp - IllegalArgumentException: Invalid timestamp</title>
      <link>https://www.markhneedham.com/blog/2021/12/03/apache-pinot-convert-datetime-string-timestamp-invalid-timestamp/</link>
      <pubDate>Fri, 03 Dec 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/12/03/apache-pinot-convert-datetime-string-timestamp-invalid-timestamp/</guid>
      <description>In this post we’ll learn how to deal with a field that contains DateTime strings when importing a CSV file into Apache Pinot. We’ll also cover some of the error messages that you’ll see if you do it the wrong way.
Figure 1. Apache Pinot - Convert DateTime string to Timestamp Setup We’re going to spin up a local instance of Pinot using the following Docker compose config:
docker-compose.yml version: &amp;#39;3.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Exploring indexing techniques on Chicago Crimes</title>
      <link>https://www.markhneedham.com/blog/2021/11/30/apache-pinot-exploring-index-chicago-crimes/</link>
      <pubDate>Tue, 30 Nov 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/11/30/apache-pinot-exploring-index-chicago-crimes/</guid>
      <description>In Neha Pawar’s recent blog post, What Makes Apache Pinot fast?, she summarises it with the following sentence:
At the heart of the system, Pinot is a columnar store with several smart optimizations that can be applied at various stages of the query by the different Pinot components. Some of the most commonly used and impactful optimizations are data partitioning strategies, segment assignment strategies, smart query routing techniques, a rich set of indexes for filter optimizations, and aggregation optimization techniques.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Importing CSV files with columns containing spaces</title>
      <link>https://www.markhneedham.com/blog/2021/11/25/apache-pinot-csv-columns-spaces/</link>
      <pubDate>Thu, 25 Nov 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/11/25/apache-pinot-csv-columns-spaces/</guid>
      <description>I’ve been playing around with one of my favourite datasets from the Chicago Data Portal and spent a while figuring out how to import columns that contain spaces into Apache Pinot. In this blog post we’ll learn how to do that using a subset of the data.
Setup We’re going to spin up a local instance of Pinot using the following Docker compose config:
docker-compose.yml version: &amp;#39;3.7&amp;#39; services: zookeeper: image: zookeeper:3.</description>
    </item>
    
    <item>
      <title>Apache Pinot: org.apache.helix.HelixException: Cluster structure is not set up for cluster: PinotCluster</title>
      <link>https://www.markhneedham.com/blog/2021/11/23/apache-pinot-helix-exception-cluster-structure-not-set-up/</link>
      <pubDate>Tue, 23 Nov 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/11/23/apache-pinot-helix-exception-cluster-structure-not-set-up/</guid>
      <description>In my continued exploration of Apache Pinot, I wanted to spin up all the components individually rather than relying on one of the QuickStarts that takes care of that for me. In doing so I came across an interesting error that we’ll explore in this post.
Setup We’re going to spin up a local instance of Pinot using the following Docker compose config:
version: &amp;#39;3.7&amp;#39; services: zookeeper: image: zookeeper:3.5.6 hostname: zookeeper container_name: manual-zookeeper ports: - &amp;#34;2181:2181&amp;#34; environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 pinot-controller: image: apachepinot/pinot:0.</description>
    </item>
    
    <item>
      <title>Apache Pinot: BadQueryRequestException - Cannot convert value to type: LONG</title>
      <link>https://www.markhneedham.com/blog/2021/07/16/pinot-bad-query-request-exception-cannot-convert-value-long/</link>
      <pubDate>Fri, 16 Jul 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/07/16/pinot-bad-query-request-exception-cannot-convert-value-long/</guid>
      <description>In my continued exploration of Apache Pinot I’ve been trying out the GitHub events recipe , which imports data from the GitHub events stream into Pinot. In this blog post I want to show how I worked around an exception I was getting when trying to filter the data by one of the timestamp’s column.
Setup We’re going to spin up a local instance of Pinot using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Analysing England&#39;s Covid case data</title>
      <link>https://www.markhneedham.com/blog/2021/06/22/pinot-analysing-england-covid-cases/</link>
      <pubDate>Tue, 22 Jun 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/06/22/pinot-analysing-england-covid-cases/</guid>
      <description>As I mentioned in my last blog post, I’ve been playing around with Apache Pinot, a data store that’s optimised for user facing analytical workloads.
My understanding is that Pinot is a really good fit for datasets where:
The query patterns are of an analytical nature e.g. slicing and dicing on any columns.
We’re ingesting the data in real time from a stream of events. Kenny Bastani has some cool blog posts showing how to do this with Wikipedia and GitHub, and Jackie Jiang showed how to analyse Meetup’s RSVP stream in last week’s Pinot meeetup.</description>
    </item>
    
    <item>
      <title>Apache Pinot: {&#39;errorCode&#39;: 410, &#39;message&#39;: &#39;BrokerResourceMissingError&#39;}</title>
      <link>https://www.markhneedham.com/blog/2021/06/21/pinot-broker-resource-missing/</link>
      <pubDate>Mon, 21 Jun 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/06/21/pinot-broker-resource-missing/</guid>
      <description>I’ve recently been playing around with Apache Pinot, a realtime analytical data store that’s used for user facing analytics use cases. In this blog post I want to walk through some challenges I had connecting to Pinot using the Python driver and how I got things working.
I’m running Pinot locally using the Docker image, which I setup in a Docker compose file:
docker-compose.yml version: &amp;#39;3.7&amp;#39; services: pinot: image: apachepinot/pinot:0.</description>
    </item>
    
  </channel>
</rss>
