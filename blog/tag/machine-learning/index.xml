<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Mark Needham</title>
    <link>https://markhneedham.com/blog/tag/machine-learning/</link>
    <description>Recent content in Machine Learning on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Jan 2018 06:51:10 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/tag/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow: Kaggle Spooky Authors Bag of Words Model</title>
      <link>https://markhneedham.com/blog/2018/01/29/tensorflow-kaggle-spooky-authors-bag-words-model/</link>
      <pubDate>Mon, 29 Jan 2018 06:51:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/01/29/tensorflow-kaggle-spooky-authors-bag-words-model/</guid>
      <description>I&#39;ve been playing around with some Tensorflow tutorials recently and wanted to see if I could create a submission for Kaggle&#39;s Spooky Author Identification competition that I&#39;ve written about recently.  My model is based on one from the text classification tutorial. The tutorial shows how to create custom Estimators which we can learn more about in a post on the Google Developers blog. Imports  Let&#39;s get started. First, our imports: from __future__ import absolute_import from __future__ import division from __future__ import print_function import numpy as np import pandas as pd import tensorflow as tf from sklearn import preprocessing from sklearn.</description>
    </item>
    
    <item>
      <title>scikit-learn: Using GridSearch to tune the hyper-parameters of VotingClassifier</title>
      <link>https://markhneedham.com/blog/2017/12/10/scikit-learn-using-gridsearch-tune-hyper-parameters-votingclassifier/</link>
      <pubDate>Sun, 10 Dec 2017 07:55:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/12/10/scikit-learn-using-gridsearch-tune-hyper-parameters-votingclassifier/</guid>
      <description>In my last blog post I showed how to create a multi class classification ensemble using scikit-learn&#39;s VotingClassifier and finished mentioning that I didn&#39;t know which classifiers should be part of the ensemble.  We need to get a better score with each of the classifiers in the ensemble otherwise they can be excluded.  We have a TF/IDF based classifier as well as well as the classifiers I wrote about in the last post.</description>
    </item>
    
    <item>
      <title>scikit-learn: Building a multi class classification ensemble</title>
      <link>https://markhneedham.com/blog/2017/12/05/scikit-learn-building-multi-class-classification-ensemble/</link>
      <pubDate>Tue, 05 Dec 2017 22:19:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/12/05/scikit-learn-building-multi-class-classification-ensemble/</guid>
      <description>For the Kaggle Spooky Author Identification I wanted to combine multiple classifiers together into an ensemble and found the VotingClassifier that does exactly that.  We need to predict the probability that a sentence is written by one of three authors so the VotingClassifier needs to make a &#39;soft&#39; prediction. If we only needed to know the most likely author we could have it make a &#39;hard&#39; prediction instead.  We start with three classifiers which generate different n-gram based features.</description>
    </item>
    
  </channel>
</rss>