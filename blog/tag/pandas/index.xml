<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pandas on Mark Needham</title>
    <link>http://localhost:8000/blog/tag/pandas/</link>
    <description>Recent content in pandas on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jan 2023 02:44:37 +0000</lastBuildDate><atom:link href="http://localhost:8000/blog/tag/pandas/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Exporting CSV files to Parquet file format with Pandas, Polars, and DuckDB</title>
      <link>http://localhost:8000/blog/2023/01/06/export-csv-parquet-pandas-polars-duckdb/</link>
      <pubDate>Fri, 06 Jan 2023 02:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2023/01/06/export-csv-parquet-pandas-polars-duckdb/</guid>
      <description>I was recently trying to convert a CSV file to Parquet format and came across a StackOverflow post that described a collection of different options. My CSV file was bigger than the amount of memory I had available, which ruled out some of the methods. In this blog post weâ€™re going to walk through some options for exporting big CSV files to Parquet format.
Note Iâ€™ve created a video showing how to do this on my YouTube channel, Learn Data with Mark, so if you prefer to consume content through that medium, Iâ€™ve embedded it below:</description>
    </item>
    
    <item>
      <title>Pandas: Add row to DataFrame</title>
      <link>http://localhost:8000/blog/2021/05/13/pandas-add-row-to-dataframe-with-index/</link>
      <pubDate>Thu, 13 May 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/05/13/pandas-add-row-to-dataframe-with-index/</guid>
      <description>Usually when Iâ€™m working with Pandas DataFrames I want to add new columns of data, but I recently wanted to add a row to an existing DataFrame. It turns out there are more than one ways to do that, which weâ€™ll explore in this blog post.
Letâ€™s start by importing Pandas into our Python script:
import pandas as pd Weâ€™ll start from a DataFrame that has two rows and the columns name and age:</description>
    </item>
    
    <item>
      <title>Altair/Pandas: TypeError: Cannot interpret &#39;Float64Dtype()&#39; as a data type</title>
      <link>http://localhost:8000/blog/2021/04/28/altair-pandas-cannot-interpret-float64dtype-as-data-type/</link>
      <pubDate>Wed, 28 Apr 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/04/28/altair-pandas-cannot-interpret-float64dtype-as-data-type/</guid>
      <description>I ran into an interesting problem when trying to use Altair to visualise a Pandas DataFrame containing vaccination rates of different parts of England. In this blog post weâ€™ll look at how to work around this issue.
First, letâ€™s install Pandas, numpy, and altair:
pip install pandas altair numpy And now weâ€™ll import those modules into a Python script or Jupyter notebook:
import pandas as pd import altair as alt import numpy as np Next, weâ€™ll create a DataFrame containing the vaccinations rates of a couple of regions:</description>
    </item>
    
    <item>
      <title>Pandas: Compare values in DataFrame to previous days</title>
      <link>http://localhost:8000/blog/2021/04/21/pandas-compare-dataframe-to-previous-days/</link>
      <pubDate>Wed, 21 Apr 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/04/21/pandas-compare-dataframe-to-previous-days/</guid>
      <description>Iâ€™m still playing around with Covid vaccine data, this time exploring how the number of doses varies week by week. I want to know how many more (or less) vaccines have been done on a given day compared to that same day last week.
Weâ€™ll be using Pandas in this blog post, so letâ€™s first install that library and import it:
Install Pandas pip install pandas Import module import pandas as pd And now letâ€™s create a DataFrame containing a subset of the data that Iâ€™m working with:</description>
    </item>
    
    <item>
      <title>Vaccinating England: The Data (cleanup)</title>
      <link>http://localhost:8000/blog/2021/04/17/england-covid-vaccination-rates-the-data/</link>
      <pubDate>Sat, 17 Apr 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/04/17/england-covid-vaccination-rates-the-data/</guid>
      <description>Over the last 13 months Iâ€™ve spent countless hours looking at dashboards that showed Coronavirus infection rates, death rates, and numbers of people vaccinated. The UK government host a dashboard at coronavirus.data.gov.uk, which contains charts and tables showing all of the above.
One thing I havenâ€™t been able to find, however, is a drill down of vaccinations by local area and age group. So Iâ€™m going to try to build my own!</description>
    </item>
    
    <item>
      <title>Pandas - Format DataFrame numbers with commas and control decimal places</title>
      <link>http://localhost:8000/blog/2021/04/11/pandas-format-dataframe-numbers-commas-decimals/</link>
      <pubDate>Sun, 11 Apr 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/04/11/pandas-format-dataframe-numbers-commas-decimals/</guid>
      <description>Iâ€™m still playing around with the UKâ€™s COVID-19 vaccination data and in this blog post weâ€™ll learn how to format a DataFrame that contains a mix of string and numeric values.
Note On 10th November 2022 I created a video that covers the same content as this blog post. Let me know if itâ€™s helpful ðŸ˜Š
Weâ€™ll be using Pandas&amp;#39; styling functionality, which generates CSS and HTML, so if you want to follow along youâ€™ll need to install Pandas and Jupyter:</description>
    </item>
    
    <item>
      <title>Pandas - Dividing two DataFrames (TypeError: unsupported operand type(s) for /: &#39;str&#39; and &#39;str&#39;)</title>
      <link>http://localhost:8000/blog/2021/04/08/pandas-divide-dataframes-unsupported-operand-type-str/</link>
      <pubDate>Thu, 08 Apr 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/04/08/pandas-divide-dataframes-unsupported-operand-type-str/</guid>
      <description>Iâ€™ve been doing some more exploration of the UK Coronavirus vaccine data, this time looking at the number of people vaccinated by Local Tier Local Authority. The government publish data showing the number of people vaccinated in each authority by age group, as well as population estimates for each cohort.
Having loaded that data into two Pandas DataFrames, I wanted to work out the % of people vaccinated per age group per local area.</description>
    </item>
    
    <item>
      <title>Altair - Remove margin/padding on discrete X axis</title>
      <link>http://localhost:8000/blog/2021/04/02/altair-discrete-x-axis-margin-padding/</link>
      <pubDate>Fri, 02 Apr 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/04/02/altair-discrete-x-axis-margin-padding/</guid>
      <description>One of the Altair charts on my Covid Vaccine Dashboards Streamlit app shows the % of first doses, but when I first created it there was some padding on the X axis that I wanted to remove. In this blog post weâ€™ll learn how to do that.
Pre requisites Letâ€™s start by installing the following libraries:
pip install pandas altair altair_viewer Next letâ€™s import them, as shown below:
import pandas as pd import altair as alt Visualising % of first doses Now weâ€™re going to create a DataFrame that contains two columns - one contains the year and week number, the other the percentage of 1st doses administered.</description>
    </item>
    
    <item>
      <title>Pandas: Filter column value in array/list - ValueError: The truth value of a Series is ambiguous</title>
      <link>http://localhost:8000/blog/2021/03/28/pandas-column-value-in-array-list-truth-value-ambiguous/</link>
      <pubDate>Sun, 28 Mar 2021 00:44:37 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2021/03/28/pandas-column-value-in-array-list-truth-value-ambiguous/</guid>
      <description>The UK government publishes Coronavirus vaccinations data on coronavirus.data.gov.uk, but I wanted to create some different visualisations so I downloaded the data and have been playing with it in the mneedham/covid-vaccines GitHub repository.
I massaged the data so that I have rows in a Pandas DataFrame representing the numbers of first doses, second doses, and total doses done each day. I then wanted to filter this DataFrame based on the type of dose, but initially got a bit stuck.</description>
    </item>
    
    <item>
      <title>Pandas: Create matplotlib plot with x-axis label not index</title>
      <link>http://localhost:8000/blog/2018/12/21/pandas-plot-x-axis-index/</link>
      <pubDate>Fri, 21 Dec 2018 16:57:00 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2018/12/21/pandas-plot-x-axis-index/</guid>
      <description>Iâ€™ve been using matplotlib a bit recently, and wanted to share a lesson I learnt about choosing the label of the x-axis. Letâ€™s first import the libraries weâ€™ll use in this post:
import pandas as pd import matplotlib.pyplot as plt And now weâ€™ll create a DataFrame of values that we want to chart:
df = pd.DataFrame({ &amp;#34;name&amp;#34;: [&amp;#34;Mark&amp;#34;, &amp;#34;Arya&amp;#34;, &amp;#34;Praveena&amp;#34;], &amp;#34;age&amp;#34;: [34, 1, 31] }) df This is what our DataFrame looks like:</description>
    </item>
    
    <item>
      <title>Pandas: ValueError: The truth value of a Series is ambiguous.</title>
      <link>http://localhost:8000/blog/2017/07/26/pandas-valueerror-the-truth-value-of-a-series-is-ambiguous/</link>
      <pubDate>Wed, 26 Jul 2017 21:41:55 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2017/07/26/pandas-valueerror-the-truth-value-of-a-series-is-ambiguous/</guid>
      <description>Iâ€™ve been playing around with Kaggle in my spare time over the last few weeks and came across an unexpected behaviour when trying to add a column to a dataframe.
First letâ€™s get Pandaâ€™s into our program scope:
Prerequisites import pandas as pd Now weâ€™ll create a data frame to play with for the duration of this post:
&amp;gt;&amp;gt;&amp;gt; df = pd.DataFrame({&amp;#34;a&amp;#34;: [1,2,3,4,5], &amp;#34;b&amp;#34;: [2,3,4,5,6]}) &amp;gt;&amp;gt;&amp;gt; df a b 0 5 2 1 6 6 2 0 8 3 3 2 4 1 6 Letâ€™s say we want to create a new column which returns True if either of the numbers are odd.</description>
    </item>
    
    <item>
      <title>Pandas/scikit-learn: get_dummies test/train sets - ValueError: shapes not aligned</title>
      <link>http://localhost:8000/blog/2017/07/05/pandasscikit-learn-get_dummies-testtrain-sets-valueerror-shapes-not-aligned/</link>
      <pubDate>Wed, 05 Jul 2017 15:42:08 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2017/07/05/pandasscikit-learn-get_dummies-testtrain-sets-valueerror-shapes-not-aligned/</guid>
      <description>Iâ€™ve been using pandaâ€™s https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html function to generate dummy columns for categorical variables to use with scikit-learn, but noticed that it sometimes doesnâ€™t work as I expect.
Prerequisites import pandas as pd import numpy as np from sklearn import linear_model Letâ€™s say we have the following training and test sets:
Training set train = pd.DataFrame({&amp;#34;letter&amp;#34;:[&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;, &amp;#34;D&amp;#34;], &amp;#34;value&amp;#34;: [1, 2, 3, 4]}) X_train = train.drop([&amp;#34;value&amp;#34;], axis=1) X_train = pd.</description>
    </item>
    
    <item>
      <title>Pandas: Find rows where column/field is null</title>
      <link>http://localhost:8000/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</link>
      <pubDate>Wed, 05 Jul 2017 14:31:04 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</guid>
      <description>In my continued playing around with the Kaggle house prices dataset I wanted to find any columns/fields that have null values in.
If we want to get a count of the number of null fields by column we can use the following code, adapted from Poonam Ligadeâ€™s kernel:
Prerequisites import pandas as pd Count the null columns train = pd.read_csv(&amp;#34;train.csv&amp;#34;) null_columns=train.columns[train.isnull().any()] train[null_columns].isnull().sum() LotFrontage 259 Alley 1369 MasVnrType 8 MasVnrArea 8 BsmtQual 37 BsmtCond 37 BsmtExposure 38 BsmtFinType1 37 BsmtFinType2 38 Electrical 1 FireplaceQu 690 GarageType 81 GarageYrBlt 81 GarageFinish 81 GarageQual 81 GarageCond 81 PoolQC 1453 Fence 1179 MiscFeature 1406 dtype: int64 So there are lots of different columns containing null values.</description>
    </item>
    
    <item>
      <title>Python: Find the highest value in a group</title>
      <link>http://localhost:8000/blog/2015/01/25/python-find-the-highest-value-in-a-group/</link>
      <pubDate>Sun, 25 Jan 2015 12:47:01 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2015/01/25/python-find-the-highest-value-in-a-group/</guid>
      <description>In my continued playing around with a How I met your mother data set I needed to find out the last episode that happened in a season so that I could use it in a chart I wanted to plot.
I had this CSV file containing each of the episodes:
$ head -n 10 data/import/episodes.csv NumberOverall,NumberInSeason,Episode,Season,DateAired,Timestamp 1,1,/wiki/Pilot,1,&amp;#34;September 19, 2005&amp;#34;,1127084400 2,2,/wiki/Purple_Giraffe,1,&amp;#34;September 26, 2005&amp;#34;,1127689200 3,3,/wiki/Sweet_Taste_of_Liberty,1,&amp;#34;October 3, 2005&amp;#34;,1128294000 4,4,/wiki/Return_of_the_Shirt,1,&amp;#34;October 10, 2005&amp;#34;,1128898800 5,5,/wiki/Okay_Awesome,1,&amp;#34;October 17, 2005&amp;#34;,1129503600 6,6,/wiki/Slutty_Pumpkin,1,&amp;#34;October 24, 2005&amp;#34;,1130108400 7,7,/wiki/Matchmaker,1,&amp;#34;November 7, 2005&amp;#34;,1131321600 8,8,/wiki/The_Duel,1,&amp;#34;November 14, 2005&amp;#34;,1131926400 9,9,/wiki/Belly_Full_of_Turkey,1,&amp;#34;November 21, 2005&amp;#34;,1132531200 I started out by parsing the CSV file into a dictionary of (seasons -&amp;gt; episode ids):</description>
    </item>
    
    <item>
      <title>pandas: Adding a column to a DataFrame (based on another DataFrame)</title>
      <link>http://localhost:8000/blog/2013/10/30/pandas-adding-a-column-to-a-dataframe-based-on-another-dataframe/</link>
      <pubDate>Wed, 30 Oct 2013 06:12:08 +0000</pubDate>
      
      <guid>http://localhost:8000/blog/2013/10/30/pandas-adding-a-column-to-a-dataframe-based-on-another-dataframe/</guid>
      <description>Nathan and I have been working on the Titanic Kaggle problem using the pandas data analysis library and one thing we wanted to do was add a column to a DataFrame indicating if someone survived.
We had the following (simplified) DataFrame containing some information about customers on board the Titanic:
def addrow(df, row): return df.append(pd.DataFrame(row), ignore_index=True) customers = pd.DataFrame(columns=[&amp;#39;PassengerId&amp;#39;,&amp;#39;Pclass&amp;#39;,&amp;#39;Name&amp;#39;,&amp;#39;Sex&amp;#39;,&amp;#39;Fare&amp;#39;]) customers = addrow(customers, [dict(PassengerId=892, Pclass=3, Name=&amp;#34;Kelly, Mr. James&amp;#34;, Sex=&amp;#34;male&amp;#34;, Fare=7.8292)]) customers = addrow(customers, [dict(PassengerId=893, Pclass=3, Name=&amp;#34;Wilkes, Mrs.</description>
    </item>
    
  </channel>
</rss>
