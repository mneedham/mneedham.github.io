<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>clickhouse on Mark Needham</title>
    <link>https://www.markhneedham.com/blog/tag/clickhouse/</link>
    <description>Recent content in clickhouse on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Nov 2024 00:44:37 +0000</lastBuildDate><atom:link href="https://www.markhneedham.com/blog/tag/clickhouse/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PIVOTing data in ClickHouse and DuckDB</title>
      <link>https://www.markhneedham.com/blog/2024/11/15/pivot-clickhouse-duckdb/</link>
      <pubDate>Fri, 15 Nov 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/11/15/pivot-clickhouse-duckdb/</guid>
      <description>I really like DuckDB’s PIVOT clause and along with some others wish that ClickHouse supported it too. Sadly it doesn’t, but we can get pretty close to this functionality using ClickHouse’s aggregate function combinators. In this blog post, I’m going to go through each of the examples in the DuckDB documentation and show how to do the equivalent in ClickHouse.
Set up First, we need to setup the sample data.</description>
    </item>
    
    <item>
      <title>ClickHouse: A hacky way to default parameters in a view</title>
      <link>https://www.markhneedham.com/blog/2024/11/25/clickhouse-view-hacky-default-parameters/</link>
      <pubDate>Fri, 25 Oct 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/11/25/clickhouse-view-hacky-default-parameters/</guid>
      <description>ClickHouse recently added support for runtime provided parameters in views, so I wanted to try it when querying the MidJourney messages dataset. It worked pretty well, but I ran into problems when trying to define default parameters, which is what we’re going to explore in this blog post.
Let’s launch ClickHouse Local:
clickhouse -m --max_http_get_redirects=10 --output_format_pretty_row_numbers=0 We need to set max_http_get_redirects so that it can handle redirects in the Hugging Face URL, and output_format_pretty_row_numbers is so that it won’t put numbers in front of each result row.</description>
    </item>
    
    <item>
      <title>ClickHouse: Specifying config settings</title>
      <link>https://www.markhneedham.com/blog/2024/08/05/clickhouse-config-settings/</link>
      <pubDate>Mon, 05 Aug 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/08/05/clickhouse-config-settings/</guid>
      <description>We recently had a question on ClickHouse Community Slack about configuring the network_compression_method on an individual query basis and across all requests. Let’s see how to do just that in this blog post.
Set up Let’s start by downloading and running the ClickHouse Server:
curl https://clickhouse.com/ | sh ./clickhouse server Output 2024.08.05 12:01:54.701406 [ 85587882 ] {} &amp;lt;Information&amp;gt; Application: Listening for http://[::1]:8123 2024.08.05 12:01:54.701426 [ 85587882 ] {} &amp;lt;Information&amp;gt; Application: Listening for native protocol (tcp): [::1]:9000 2024.</description>
    </item>
    
    <item>
      <title>ClickHouse: Unknown setting &#39;allow_nullable_key&#39;</title>
      <link>https://www.markhneedham.com/blog/2024/06/27/clickhouse-unknown-setting-allow_nullable_key/</link>
      <pubDate>Thu, 27 Jun 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/06/27/clickhouse-unknown-setting-allow_nullable_key/</guid>
      <description>I’ve been playing around with ClickHouse’s Amazon reviews dataset and ran into an interesting problem when trying to set the allow_nullable_key setting. In this blog post, we’ll learn how and why we might choose to set it.
I started off with the following SQL statement to create a table called reviews based on the structure of the Parquet file:
CREATE TABLE reviews ENGINE = MergeTree ORDER BY review_date EMPTY AS ( SELECT * FROM s3(concat( &amp;#39;https://datasets-documentation.</description>
    </item>
    
    <item>
      <title>Using environment variables in ClickHouse queries</title>
      <link>https://www.markhneedham.com/blog/2024/02/23/clickhouse-environment-variables/</link>
      <pubDate>Fri, 23 Feb 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/02/23/clickhouse-environment-variables/</guid>
      <description>For quite some time I’ve been wondering how to get access to an environment variable in a ClickHouse Local and finally today I have a solution, which we’ll explore in this blog post.
My reason for wanting to do this is so that I can pass through a ClickHouse Cloud password to use in a remoteSecure function call. I wanted to do this as part of a blog post I wrote showing how to do Hybrid Query Execution with ClickHouse.</description>
    </item>
    
    <item>
      <title>ClickHouse: Configure default output format</title>
      <link>https://www.markhneedham.com/blog/2024/01/19/clickhouse-configure-output-format/</link>
      <pubDate>Fri, 19 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/19/clickhouse-configure-output-format/</guid>
      <description>When running queries with ClickHouse Local, the results are rendered back to the screen in a table format in blocks. This default format is called PrettyCompact and most of the time this works fine, but sometimes you can end up with multiple mini-tables. In this blog post, we’re going to learn how to change the default format so that all the results show in one table.
But first, let’s see how the problem manifests.</description>
    </item>
    
    <item>
      <title>ClickHouse: Float equality</title>
      <link>https://www.markhneedham.com/blog/2024/01/04/clickhouse-float-equality/</link>
      <pubDate>Thu, 04 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/04/clickhouse-float-equality/</guid>
      <description>I’ve been playing around with NumPy data in ClickHouse this week and wanted to share what I learnt when checking for equality of float values. Let’s get going!
Creating arrays We’re going to use Python’s NumPy library to create 5 arrays containing 10 values each:
import numpy as np rng = np.random.default_rng(seed=42) rng.random(size=(5, 5)) Output array([[0.28138389, 0.29359376, 0.66191651, 0.55703215, 0.78389821], [0.66431354, 0.40638686, 0.81402038, 0.16697292, 0.02271207], [0.09004786, 0.72235935, 0.46187723, 0.16127178, 0.</description>
    </item>
    
    <item>
      <title>ClickHouse: How does a number have a set number of decimal places?</title>
      <link>https://www.markhneedham.com/blog/2024/01/02/clickhouse-set-number-decimal-places/</link>
      <pubDate>Tue, 02 Jan 2024 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2024/01/02/clickhouse-set-number-decimal-places/</guid>
      <description>I’ve been working with a dataset in ClickHouse where I compute currency values and I really struggled to figure out how to get numbers whose decimal part is divisible by 10 to have a fixed number of decimal places. If you want to do that too, hopefully, this blog post will help.
Let’s start by seeing what happens if we output the number 12.40
SELECT 12.40 AS number; Output ┌─number─┐ │ 12.</description>
    </item>
    
    <item>
      <title>ClickHouse: S3Queue Table Engine -  DB::Exception: There is no Zookeeper configuration in server config</title>
      <link>https://www.markhneedham.com/blog/2023/12/13/clickhouse-s3queue-no-zookeeper-configuration/</link>
      <pubDate>Wed, 13 Dec 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/12/13/clickhouse-s3queue-no-zookeeper-configuration/</guid>
      <description>This week I’ve been making a video showing how to use ClickHouse’s S3Queue table engine, which allows streaming import of files in an S3 bucket. The S3Queue table engine was released in version 23.8, but only received &amp;#39;production-ready&amp;#39; status in version 23.11. In this blog post, we’ll walk through the steps to getting this to work locally and the mistakes that I made along the way.
I configured an S3 bucket, added 10 files containing 100,000 rows of JSON each, and made sure that I’d set the AWS_PROFILE environment variable so that ClickHouse Server could read from the bucket.</description>
    </item>
    
    <item>
      <title>ClickHouse: Tuples - Code: 47. DB::Exception: Missing columns: while processing query:</title>
      <link>https://www.markhneedham.com/blog/2023/12/04/clickhouse-tuples-missing-columns/</link>
      <pubDate>Mon, 04 Dec 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/12/04/clickhouse-tuples-missing-columns/</guid>
      <description>I’ve been playing around with the Mid Journey Parquet metadata that I wrote about in my last blog post and struggled quite a bit to get the query to do what I wanted. Come along on a journey with me and we’ll figure it out together.
We’re querying the metadata of a Parquet file that contains the metadata (I know!) of images created by the Mid Journey generative AI service.</description>
    </item>
    
    <item>
      <title>Summing columns in remote Parquet files using ClickHouse</title>
      <link>https://www.markhneedham.com/blog/2023/11/15/clickhouse-summing-columns-remote-files/</link>
      <pubDate>Wed, 15 Nov 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/11/15/clickhouse-summing-columns-remote-files/</guid>
      <description>I’m an avid reader of Simon Willison’s TIL blog and enjoyed a recent post showing how to sum the size of all the Midjourney images stored on Discord. He did this by querying a bunch of Parquet files stored on Hugging Face with DuckDB. I was curious whether I could do the same thing using ClickHouse and in this blog post, we’re going to find out.
The dataset that we’re going to use is available at vivym/midjourney-messages.</description>
    </item>
    
    <item>
      <title>ClickHouse - How to get the first &#39;n&#39; values from an array</title>
      <link>https://www.markhneedham.com/blog/2023/11/09/clickhouse-array-first-n-values/</link>
      <pubDate>Thu, 09 Nov 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/11/09/clickhouse-array-first-n-values/</guid>
      <description>I was recently working with some very long arrays in ClickHouse and I wanted to select just a few values so that they didn’t take up the entire screen. The way I thought would &amp;#39;just work&amp;#39; ™ didn’t, so this blog documents how to do it.
If you want to follow along, you’ll need to install ClickHouse. On a Mac, Brew is a pretty good option:
brew install clickhouse Once you’ve done that, launch ClickHouse Local:</description>
    </item>
    
    <item>
      <title>ClickHouse - AttributeError: &#39;NoneType&#39; object has no attribute &#39;array&#39;</title>
      <link>https://www.markhneedham.com/blog/2023/11/08/clickhouse-client-array-nonetype-no-attribute/</link>
      <pubDate>Wed, 08 Nov 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/11/08/clickhouse-client-array-nonetype-no-attribute/</guid>
      <description>I was querying a ClickHouse server from a Python script a couple of days ago and ran into an error message when trying to create a Pandas DataFrame. In this blog, we’ll see the error message and how to fix it.
I’m gonna assume that we have a ClickHouse Server running and we’re going to connect to it like this:
./clickhouse client Output ClickHouse client version 23.10.1.1709 (official build). Connecting to localhost:9000 as user default.</description>
    </item>
    
    <item>
      <title>ClickHouse - DB::Exception:: there is no writeable access storage in user directories (ACCESS_STORAGE_FOR_INSERTION_NOT_FOUND)</title>
      <link>https://www.markhneedham.com/blog/2023/11/07/clickhouse-no-writeable-access-storage/</link>
      <pubDate>Tue, 07 Nov 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/11/07/clickhouse-no-writeable-access-storage/</guid>
      <description>I’ve been working with ClickHouse’s access control/account management as part of a video that I created showing how to login to a ClickHouse server with an SSH key, but getting it all setup locally was a bit fiddly. In this blog post, we’ll go through the mistakes I made and how to fix them.
I initially tried starting the ClickHouse server:
./clickhouse server Connecting to it with a client:</description>
    </item>
    
    <item>
      <title>ClickHouse: Convert date or datetime to epoch</title>
      <link>https://www.markhneedham.com/blog/2023/11/06/clickhouse-date-to-epoch/</link>
      <pubDate>Mon, 06 Nov 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/11/06/clickhouse-date-to-epoch/</guid>
      <description>I’ve been working with dates in ClickHouse today and I wanted to convert some values into epoch seconds/milliseconds to use with another tool. We’re going to document how to do that in this blog post, for future me if no one else.
Let’s start an instance of ClickHouse Local:
clickhouse local -m And now we’ll write a query that returns the current date/time:
SELECT now() AS time; Output ┌────────────────time─┐ │ 2023-11-06 14:58:19 │ └─────────────────────┘ If we want to convert this value to epoch seconds, we can use the toUnixTimestamp function.</description>
    </item>
    
    <item>
      <title>ClickHouse: Nested type Array(String) cannot be inside Nullable type (ILLEGAL_TYPE_OF_ARGUMENT)</title>
      <link>https://www.markhneedham.com/blog/2023/11/03/clickhouse-nested-type-cannot-be-inside-nullable-type/</link>
      <pubDate>Fri, 03 Nov 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/11/03/clickhouse-nested-type-cannot-be-inside-nullable-type/</guid>
      <description>I’ve been working with some data that’s in CSV format but has tab-separated values in some columns. In this blog post, we’re going to learn how to process that data in ClickHouse.
The CSV file that we’re working with looks like this:
Table 1. data.csv value foo	bar
We’ll launch ClickHouse Local (clickhouse local) and then run the following:
FROM file(&amp;#39;data.csv&amp;#39;, CSVWithNames) SELECT *; Output ┌─value─────┐ │ foo bar │ └───────────┘ Let’s try to split the value field on tab using the splitByString function:</description>
    </item>
    
    <item>
      <title>ClickHouse: Code: 60. DB::Exception: Table does not exist</title>
      <link>https://www.markhneedham.com/blog/2023/10/16/clickhouse-local-table-does-not-exist/</link>
      <pubDate>Mon, 16 Oct 2023 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/10/16/clickhouse-local-table-does-not-exist/</guid>
      <description>I’ve been playing with clickhouse-local again this week and ran into an interesting issue when persisting a table that I thought I’d document for future Mark.
You can install ClickHouse on your machine by running the following command:
curl https://clickhouse.com/ | sh Or you could use HomeBrew if you’re working on a Mac:
brew install clickhouse We can then launch clickhouse-local, which lets you run ClickHouse in what I think of as an embedded mode.</description>
    </item>
    
    <item>
      <title>ClickHouse: How to unpack or unnest an array</title>
      <link>https://www.markhneedham.com/blog/2023/07/03/clickhouse-unpack-unnest-array/</link>
      <pubDate>Mon, 03 Jul 2023 04:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2023/07/03/clickhouse-unpack-unnest-array/</guid>
      <description>I recently came across clickhouse-local via this article in the MotherDuck monthly newsletter and I wanted to give it a try on my expected goals dataset. One of the first things that I wanted to do was unpack an array and in this blog post, we’ll learn how to do that.
I installed Clickhouse by running the following command:
curl https://clickhouse.com/ | sh And then launched the clickhouse-local CLI like this:</description>
    </item>
    
  </channel>
</rss>
