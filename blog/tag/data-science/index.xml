<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data-science on Mark Needham</title>
    <link>https://www.markhneedham.com/blog/tag/data-science/</link>
    <description>Recent content in data-science on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 May 2018 08:12:21 +0000</lastBuildDate><atom:link href="https://www.markhneedham.com/blog/tag/data-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Predicting movie genres with node2Vec and Tensorflow</title>
      <link>https://www.markhneedham.com/blog/2018/05/11/node2vec-tensorflow/</link>
      <pubDate>Fri, 11 May 2018 08:12:21 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2018/05/11/node2vec-tensorflow/</guid>
      <description>In my previous post we looked at how to get up and running with the node2Vec algorithm, and in this post we’ll learn how we can feed graph embeddings into a simple Tensorflow model.
Recall that node2Vec takes in a list of edges (or relationships) and gives us back an embedding (array of numbers) for each node.
This time we’re going to run the algorithm over a movies recommendation dataset from the Neo4j Sandbox.</description>
    </item>
    
    <item>
      <title>Exploring node2vec - a graph embedding algorithm</title>
      <link>https://www.markhneedham.com/blog/2018/05/11/exploring-node2vec-graph-embedding-algorithm/</link>
      <pubDate>Fri, 11 May 2018 08:08:21 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2018/05/11/exploring-node2vec-graph-embedding-algorithm/</guid>
      <description>In my explorations of graph based machine learning, one algorithm I came across is called node2Vec. The paper describes it as &amp;#34;an algorithmic framework for learning continuous feature representations for nodes in networks&amp;#34;.
So what does the algorithm do? From the website:
The node2vec framework learns low-dimensional representations for nodes in a graph by optimizing a neighborhood preserving objective. The objective is flexible, and the algorithm accommodates for various definitions of network neighborhoods by simulating biased random walks.</description>
    </item>
    
    <item>
      <title>Tensorflow 1.8: Hello World using the Estimator API</title>
      <link>https://www.markhneedham.com/blog/2018/05/05/tensorflow-18-hello-world-using-estimator-api/</link>
      <pubDate>Sat, 05 May 2018 00:31:34 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2018/05/05/tensorflow-18-hello-world-using-estimator-api/</guid>
      <description>Over the last week I’ve been going over various Tensorflow tutorials and one of the best ones when getting started is Sidath Asiri’s Hello World in TensorFlow, which shows how to build a simple linear classifier on the Iris dataset.
I’ll use the same data as Sidath, so if you want to follow along you’ll need to download these files:
iris_training.csv
iris_test.csv
Loading data The way we load data will remain exactly the same - we’ll still be reading it into a Pandas dataframe:</description>
    </item>
    
    <item>
      <title>PyData London 2018 Conference Experience Report</title>
      <link>https://www.markhneedham.com/blog/2018/04/29/pydata-london-2018/</link>
      <pubDate>Sun, 29 Apr 2018 11:54:02 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2018/04/29/pydata-london-2018/</guid>
      <description>Over the last few days I attended PyData London 2018 and wanted to share my experience. The PyData series of conferences aim to bring together users and developers of data analysis tools to share ideas and learn from each other. I presented a talk on building a recommendation with Python and Neo4j at the 2016 version but didn’t attend last year.
The organisers said there were ~ 550 attendees spread over 1 day of tutorials and 2 days of talks.</description>
    </item>
    
    <item>
      <title>Pandas: ValueError: The truth value of a Series is ambiguous.</title>
      <link>https://www.markhneedham.com/blog/2017/07/26/pandas-valueerror-the-truth-value-of-a-series-is-ambiguous/</link>
      <pubDate>Wed, 26 Jul 2017 21:41:55 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2017/07/26/pandas-valueerror-the-truth-value-of-a-series-is-ambiguous/</guid>
      <description>I’ve been playing around with Kaggle in my spare time over the last few weeks and came across an unexpected behaviour when trying to add a column to a dataframe.
First let’s get Panda’s into our program scope:
Prerequisites import pandas as pd Now we’ll create a data frame to play with for the duration of this post:
&amp;gt;&amp;gt;&amp;gt; df = pd.DataFrame({&amp;#34;a&amp;#34;: [1,2,3,4,5], &amp;#34;b&amp;#34;: [2,3,4,5,6]}) &amp;gt;&amp;gt;&amp;gt; df a b 0 5 2 1 6 6 2 0 8 3 3 2 4 1 6 Let’s say we want to create a new column which returns True if either of the numbers are odd.</description>
    </item>
    
    <item>
      <title>Pandas: Find rows where column/field is null</title>
      <link>https://www.markhneedham.com/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</link>
      <pubDate>Wed, 05 Jul 2017 14:31:04 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</guid>
      <description>In my continued playing around with the Kaggle house prices dataset I wanted to find any columns/fields that have null values in.
If we want to get a count of the number of null fields by column we can use the following code, adapted from Poonam Ligade’s kernel:
Prerequisites import pandas as pd Count the null columns train = pd.read_csv(&amp;#34;train.csv&amp;#34;) null_columns=train.columns[train.isnull().any()] train[null_columns].isnull().sum() LotFrontage 259 Alley 1369 MasVnrType 8 MasVnrArea 8 BsmtQual 37 BsmtCond 37 BsmtExposure 38 BsmtFinType1 37 BsmtFinType2 38 Electrical 1 FireplaceQu 690 GarageType 81 GarageYrBlt 81 GarageFinish 81 GarageQual 81 GarageCond 81 PoolQC 1453 Fence 1179 MiscFeature 1406 dtype: int64 So there are lots of different columns containing null values.</description>
    </item>
    
    <item>
      <title>scikit-learn: Random forests - Feature Importance</title>
      <link>https://www.markhneedham.com/blog/2017/06/16/scikit-learn-random-forests-feature-importance/</link>
      <pubDate>Fri, 16 Jun 2017 05:55:29 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2017/06/16/scikit-learn-random-forests-feature-importance/</guid>
      <description>As I mentioned in a blog post a couple of weeks ago, I’ve been playing around with the Kaggle House Prices competition and the most recent thing I tried was training a random forest regressor.
Unfortunately, although it gave me better results locally it got a worse score on the unseen data, which I figured meant I’d overfitted the model.
I wasn’t really sure how to work out if that theory was true or not, but by chance I was reading Chris Albon’s blog and found a post where he explains how to inspect the importance of every feature in a random forest.</description>
    </item>
    
    <item>
      <title>Luigi: An ExternalProgramTask example - Converting JSON to CSV</title>
      <link>https://www.markhneedham.com/blog/2017/03/25/luigi-externalprogramtask-example-converting-json-csv/</link>
      <pubDate>Sat, 25 Mar 2017 14:09:59 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2017/03/25/luigi-externalprogramtask-example-converting-json-csv/</guid>
      <description>I’ve been playing around with the Python library Luigi which is used to build pipelines of batch jobs and I struggled to find an example of an ExternalProgramTask so this is my attempt at filling that void.
I’m building a little data pipeline to get data from the meetup.com API and put it into CSV files that can be loaded into Neo4j using the LOAD CSV command.
The first task I created calls the /groups endpoint and saves the result into a JSON file:</description>
    </item>
    
  </channel>
</rss>
