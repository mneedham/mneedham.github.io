<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data-science on Mark Needham</title>
    <link>https://markhneedham.com/blog/tag/data-science/</link>
    <description>Recent content in data-science on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 May 2018 08:12:21 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/tag/data-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Predicting movie genres with node2Vec and Tensorflow</title>
      <link>https://markhneedham.com/blog/2018/05/11/node2vec-tensorflow/</link>
      <pubDate>Fri, 11 May 2018 08:12:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/05/11/node2vec-tensorflow/</guid>
      <description>In my previous post we looked at how to get up and running with the node2Vec algorithm, and in this post we&amp;#8217;ll learn how we can feed graph embeddings into a simple Tensorflow model.
 Recall that node2Vec takes in a list of edges (or relationships) and gives us back an embedding (array of numbers) for each node.
 This time we&amp;#8217;re going to run the algorithm over a movies recommendation dataset from the Neo4j Sandbox.</description>
    </item>
    
    <item>
      <title>Exploring node2vec - a graph embedding algorithm</title>
      <link>https://markhneedham.com/blog/2018/05/11/exploring-node2vec-graph-embedding-algorithm/</link>
      <pubDate>Fri, 11 May 2018 08:08:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/05/11/exploring-node2vec-graph-embedding-algorithm/</guid>
      <description>In my explorations of graph based machine learning, one algorithm I came across is called node2Vec. The paper describes it as &#34;an algorithmic framework for learning continuous feature representations for nodes in networks&#34;.
 So what does the algorithm do? From the website:
  The node2vec framework learns low-dimensional representations for nodes in a graph by optimizing a neighborhood preserving objective. The objective is flexible, and the algorithm accommodates for various definitions of network neighborhoods by simulating biased random walks.</description>
    </item>
    
    <item>
      <title>Tensorflow 1.8: Hello World using the Estimator API</title>
      <link>https://markhneedham.com/blog/2018/05/05/tensorflow-18-hello-world-using-estimator-api/</link>
      <pubDate>Sat, 05 May 2018 00:31:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/05/05/tensorflow-18-hello-world-using-estimator-api/</guid>
      <description>Over the last week I&amp;#8217;ve been going over various Tensorflow tutorials and one of the best ones when getting started is Sidath Asiri&amp;#8217;s Hello World in TensorFlow, which shows how to build a simple linear classifier on the Iris dataset.
 I&amp;#8217;ll use the same data as Sidath, so if you want to follow along you&amp;#8217;ll need to download these files:
   iris_training.csv
  iris_test.csv
   Loading data The way we load data will remain exactly the same - we&amp;#8217;ll still be reading it into a Pandas dataframe:</description>
    </item>
    
    <item>
      <title>PyData London 2018 Conference Experience Report</title>
      <link>https://markhneedham.com/blog/2018/04/29/pydata-london-2018/</link>
      <pubDate>Sun, 29 Apr 2018 11:54:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/04/29/pydata-london-2018/</guid>
      <description>Over the last few days I attended PyData London 2018 and wanted to share my experience. The PyData series of conferences aim to bring together users and developers of data analysis tools to share ideas and learn from each other. I presented a talk on building a recommendation with Python and Neo4j at the 2016 version but didn&amp;#8217;t attend last year.
 The organisers said there were ~ 550 attendees spread over 1 day of tutorials and 2 days of talks.</description>
    </item>
    
    <item>
      <title>Pandas: ValueError: The truth value of a Series is ambiguous.</title>
      <link>https://markhneedham.com/blog/2017/07/26/pandas-valueerror-the-truth-value-of-a-series-is-ambiguous/</link>
      <pubDate>Wed, 26 Jul 2017 21:41:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/07/26/pandas-valueerror-the-truth-value-of-a-series-is-ambiguous/</guid>
      <description>import pandas as pd &amp;gt;&amp;gt;&amp;gt; df = pd.DataFrame({&amp;#34;a&amp;#34;: [1,2,3,4,5], &amp;#34;b&amp;#34;: [2,3,4,5,6]}) &amp;gt;&amp;gt;&amp;gt; df a b 0 5 2 1 6 6 2 0 8 3 3 2 4 1 6 &amp;gt;&amp;gt;&amp;gt; divmod(df[&amp;#34;a&amp;#34;], 2)[1] &amp;gt; 0 0 True 1 False 2 True 3 False 4 True Name: a, dtype: bool &amp;gt;&amp;gt;&amp;gt; divmod(df[&amp;#34;b&amp;#34;], 2)[1] &amp;gt; 0 0 False 1 True 2 False 3 True 4 False Name: b, dtype: bool &amp;gt;&amp;gt;&amp;gt; df[&amp;#34;anyOdd&amp;#34;] = (divmod(df[&amp;#34;a&amp;#34;], 2)[1] &amp;gt; 0) or (divmod(df[&amp;#34;b&amp;#34;], 2)[1] &amp;gt; 0) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/kaggle/house-prices/a/lib/python3.</description>
    </item>
    
    <item>
      <title>Pandas: Find rows where column/field is null</title>
      <link>https://markhneedham.com/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</link>
      <pubDate>Wed, 05 Jul 2017 14:31:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</guid>
      <description>import pandas as pd train = pd.read_csv(&amp;#34;train.csv&amp;#34;) null_columns=train.columns[train.isnull().any()] train[null_columns].isnull().sum() LotFrontage 259 Alley 1369 MasVnrType 8 MasVnrArea 8 BsmtQual 37 BsmtCond 37 BsmtExposure 38 BsmtFinType1 37 BsmtFinType2 38 Electrical 1 FireplaceQu 690 GarageType 81 GarageYrBlt 81 GarageFinish 81 GarageQual 81 GarageCond 81 PoolQC 1453 Fence 1179 MiscFeature 1406 dtype: int64 print(train[train[&amp;#34;Electrical&amp;#34;].isnull()][null_columns]) LotFrontage Alley MasVnrType MasVnrArea BsmtQual BsmtCond BsmtExposure \ 1379 73.0 NaN None 0.0 Gd TA No BsmtFinType1 BsmtFinType2 Electrical FireplaceQu GarageType GarageYrBlt \ 1379 Unf Unf NaN NaN BuiltIn 2007.</description>
    </item>
    
    <item>
      <title>scikit-learn: Random forests - Feature Importance</title>
      <link>https://markhneedham.com/blog/2017/06/16/scikit-learn-random-forests-feature-importance/</link>
      <pubDate>Fri, 16 Jun 2017 05:55:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/06/16/scikit-learn-random-forests-feature-importance/</guid>
      <description>import numpy as np import pandas as pd from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import train_test_split # We&amp;#39;ll use this library to make the display pretty from tabulate import tabulate train = pd.read_csv(&amp;#39;train.csv&amp;#39;) # the model can only handle numeric values so filter out the rest data = train.select_dtypes(include=[np.number]).interpolate().dropna() y = train.SalePrice X = data.drop([&amp;#34;SalePrice&amp;#34;, &amp;#34;Id&amp;#34;], axis=1) X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33) clf = RandomForestRegressor(n_jobs=2, n_estimators=1000) model = clf.</description>
    </item>
    
    <item>
      <title>Luigi: An ExternalProgramTask example - Converting JSON to CSV</title>
      <link>https://markhneedham.com/blog/2017/03/25/luigi-externalprogramtask-example-converting-json-csv/</link>
      <pubDate>Sat, 25 Mar 2017 14:09:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/03/25/luigi-externalprogramtask-example-converting-json-csv/</guid>
      <description>import luigi import requests import json from collections import Counter class GroupsToJSON(luigi.Task): key = luigi.Parameter() lat = luigi.Parameter() lon = luigi.Parameter() def run(self): seed_topic = &amp;#34;nosql&amp;#34; uri = &amp;#34;https://api.meetup.com/2/groups?&amp;amp;topic={0}&amp;amp;lat={1}&amp;amp;lon={2}&amp;amp;key={3}&amp;#34;.format(seed_topic, self.lat, self.lon, self.key) r = requests.get(uri) all_topics = [topic[&amp;#34;urlkey&amp;#34;] for result in r.json()[&amp;#34;results&amp;#34;] for topic in result[&amp;#34;topics&amp;#34;]] c = Counter(all_topics) topics = [entry[0] for entry in c.most_common(10)] groups = {} for topic in topics: uri = &amp;#34;https://api.meetup.com/2/groups?&amp;amp;topic={0}&amp;amp;lat={1}&amp;amp;lon={2}&amp;amp;key={3}&amp;#34;.format(topic, self.lat, self.lon, self.key) r = requests.</description>
    </item>
    
  </channel>
</rss>