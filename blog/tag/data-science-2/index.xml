<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data-science-2 on Mark Needham</title>
    <link>https://markhneedham.com/blog/tag/data-science-2/</link>
    <description>Recent content in data-science-2 on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 Oct 2015 10:03:57 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/tag/data-science-2/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploring (potential) data entry errors in the Land Registry data set</title>
      <link>https://markhneedham.com/blog/2015/10/18/exploring-potential-data-entry-errors-in-the-land-registry-data-set/</link>
      <pubDate>Sun, 18 Oct 2015 10:03:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/18/exploring-potential-data-entry-errors-in-the-land-registry-data-set/</guid>
      <description>&amp;gt; library(data.table) &amp;gt; dt = fread(&amp;#34;pp-complete.csv&amp;#34;, header = FALSE) &amp;gt; dt[1:5] V1 V2 V3 V4 V5 1: {0C7ADEF5-878D-4066-B785-0000003ED74A} 163000 2003-02-21 00:00 UB5 4PJ T 2: {35F67271-ABD4-40DA-AB09-00000085B9D3} 247500 2005-07-15 00:00 TA19 9DD D 3: {B20B1C74-E8E1-4137-AB3E-0000011DF342} 320000 2010-09-10 00:00 W4 1DZ F 4: {7D6B0915-C56B-4275-AF9B-00000156BCE7} 104000 1997-08-27 00:00 NE61 2BH D 5: {47B60101-B64C-413D-8F60-000002F1692D} 147995 2003-05-02 00:00 PE33 0RU D V6 V7 V8 V9 V10 V11 V12 1: N F 106 READING ROAD NORTHOLT NORTHOLT 2: N F 58 ADAMS MEADOW ILMINSTER ILMINSTER 3: N L 58 WHELLOCK ROAD LONDON 4: N F 17 WESTGATE MORPETH MORPETH 5: N F 4 MASON GARDENS WEST WINCH KING&amp;#39;S LYNN V13 V14 V15 1: EALING GREATER LONDON A 2: SOUTH SOMERSET SOMERSET A 3: EALING GREATER LONDON A 4: CASTLE MORPETH NORTHUMBERLAND A 5: KING&amp;#39;S LYNN AND WEST NORFOLK NORFOLK A &amp;gt; dt = dt[, V2:= as.</description>
    </item>
    
    <item>
      <title>Data Science: Mo&#39; Data Mo&#39; Problems</title>
      <link>https://markhneedham.com/blog/2014/06/28/data-science-mo-data-mo-problems/</link>
      <pubDate>Sat, 28 Jun 2014 23:35:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/06/28/data-science-mo-data-mo-problems/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data Science: Don&#39;t build a crawler (if you can avoid it!)</title>
      <link>https://markhneedham.com/blog/2013/09/19/data-science-dont-build-a-crawler-if-you-can-avoid-it/</link>
      <pubDate>Thu, 19 Sep 2013 06:55:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/09/19/data-science-dont-build-a-crawler-if-you-can-avoid-it/</guid>
      <description>$ head -n 5 uris.txt https://www.some-made-up-place.com/page1.html https://www.some-made-up-place.com/page2.html https://www.some-made-up-place.com/page3.html https://www.some-made-up-place.com/page4.html https://www.some-made-up-place.com/page5.html $ cat uris.txt | time xargs wget ... Total wall clock time: 3.7s Downloaded: 60 files, 625K in 0.7s (870 KB/s) 3.73 real 0.03 user 0.09 sys cat uris.txt | time xargs -n1 -P10 wget 1.65 real 0.20 user 0.21 sys </description>
    </item>
    
    <item>
      <title>Micro Services Style Data Work Flow</title>
      <link>https://markhneedham.com/blog/2013/02/18/micro-services-style-data-work-flow/</link>
      <pubDate>Mon, 18 Feb 2013 22:16:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/02/18/micro-services-style-data-work-flow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data Science: Discovery work</title>
      <link>https://markhneedham.com/blog/2012/12/09/data-science-discovery-work/</link>
      <pubDate>Sun, 09 Dec 2012 10:36:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/09/data-science-discovery-work/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nygard Big Data Model: The Investigation Stage</title>
      <link>https://markhneedham.com/blog/2012/10/10/nygard-big-data-model-the-investigation-stage/</link>
      <pubDate>Wed, 10 Oct 2012 00:00:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/10/nygard-big-data-model-the-investigation-stage/</guid>
      <description>Earlier this year Michael Nygard wrote an extremely detailed post about his experiences in the world of big data projectsand included in the post was the following diagram which I&amp;rsquo;ve found very useful.
Ashokand I have been doing some work in this area helping one of our clients make sense of and visualise some of their data and we realised retrospectively that we were very acting very much in the investigation stage of the model.</description>
    </item>
    
    <item>
      <title>Strata Conf London: Day 2 Wrap Up</title>
      <link>https://markhneedham.com/blog/2012/10/03/strata-conf-london-day-2-wrap-up/</link>
      <pubDate>Wed, 03 Oct 2012 06:46:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/03/strata-conf-london-day-2-wrap-up/</guid>
      <description>Yesterday I attended the second day of Strata Conf Londonand these are the some of the things I learned from the talks I attended:
British Rail were trying to solve a graph problem when people didn&amp;rsquo;t know about graphs and Dijkstra&amp;rsquo;s algorithm hadn&amp;rsquo;t been inventedand it was effectively invented on this project but never publicised. John&amp;rsquo;s suggestion here was that we need to share the stuff that we&amp;rsquo;re doing so that people don&amp;rsquo;t re-invent the wheel.</description>
    </item>
    
    <item>
      <title>Strata Conf London: Day 1 Wrap Up</title>
      <link>https://markhneedham.com/blog/2012/10/02/strata-conf-london-day-1-wrap-up/</link>
      <pubDate>Tue, 02 Oct 2012 23:42:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/02/strata-conf-london-day-1-wrap-up/</guid>
      <description>For the past couple of days I attended the first Strata Conf to be held in London- a conference which seems to bring together people from the data science and big data worldsto talk about the stuff they&amp;rsquo;re doing.
Since I&amp;rsquo;ve been playing around with a couple of different things in this area over the last 4/5 months I thought it&amp;rsquo;d be interesting to come along and see what people much more experienced in this area had to say!</description>
    </item>
    
    <item>
      <title>Data Science: Making sense of the data</title>
      <link>https://markhneedham.com/blog/2012/09/30/data-science-making-sense-of-the-data/</link>
      <pubDate>Sun, 30 Sep 2012 14:58:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/30/data-science-making-sense-of-the-data/</guid>
      <description>Over the past month or so Ashokand I have been helping one of our clients explore and visualise some of their data and one of the first things we needed to do was make sense of the data that was available.
Ashok suggested that we work with a subset of our eventual data setso that we could get a feel for the data and quickly see whether what we were planning to do made sense.</description>
    </item>
    
    <item>
      <title>Data Science: Scrapping the data together</title>
      <link>https://markhneedham.com/blog/2012/09/30/data-science-scrapping-the-data-together/</link>
      <pubDate>Sun, 30 Sep 2012 13:44:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/30/data-science-scrapping-the-data-together/</guid>
      <description>On Friday Martin, Darrenand I were discussing the ThoughtWorks graph that I was working on earlier in the year and Martin pointed out that an interesting aspect of this type of work is that the data you want to work with isn&amp;rsquo;t easily available.
You therefore need to find a way to scrap the data together to make some headway and then maybe at a later stage once some progress has been made it will become easier to replace that with a cleaner solution.</description>
    </item>
    
  </channel>
</rss>