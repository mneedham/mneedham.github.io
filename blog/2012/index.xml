<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2012s on Mark Needham</title>
    <link>https://markhneedham.com/blog/2012/</link>
    <description>Recent content in 2012s on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Dec 2012 23:59:42 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/2012/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TextMate Bundles location on Mountain Lion</title>
      <link>https://markhneedham.com/blog/2012/12/31/textmate-bundles-location-on-mountain-lion/</link>
      <pubDate>Mon, 31 Dec 2012 23:59:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/textmate-bundles-location-on-mountain-lion/</guid>
      <description>$ cd /Applications/TextMate.app/Contents/SharedSupport/Bundles $ git clone git://github.com/swannodette/textmate-clojure.git Clojure.tmbundle $ osascript -e &amp;#39;tell app &amp;#34;TextMate&amp;#34; to reload bundles&amp;#39; $ cd /Applications/TextMate.app/Contents/SharedSupport/Bundles $ git clone https://github.com/textmate/haskell.tmbundle.git haskell.tmbundle $ osascript -e &amp;#39;tell app &amp;#34;TextMate&amp;#34; to reload bundles&amp;#39; </description>
    </item>
    
    <item>
      <title>Haskell: Downloading the core library source code</title>
      <link>https://markhneedham.com/blog/2012/12/31/haskell-downloading-the-core-library-source-code/</link>
      <pubDate>Mon, 31 Dec 2012 22:39:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/haskell-downloading-the-core-library-source-code/</guid>
      <description>git clone https://github.com/ghc/ghc.git cd ghc ./sync-all get darcs get http://darcs.haskell.org/packages/base/ # gets most of the packages we&amp;#39;d be interested in darcs get http://darcs.haskell.org/packages/array/ # gets the array package </description>
    </item>
    
    <item>
      <title>Haskell: Strictness and the monadic bind</title>
      <link>https://markhneedham.com/blog/2012/12/31/haskell-strictness-and-the-monadic-bind/</link>
      <pubDate>Mon, 31 Dec 2012 22:27:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/haskell-strictness-and-the-monadic-bind/</guid>
      <description>union :: IO (IOArray Int Int) -&amp;gt; Int -&amp;gt; Int -&amp;gt; IO (IOArray Int Int) union arrayContainer x y = do actualArray &amp;lt;- arrayContainer ls &amp;lt;- getAssocs actualArray leader1 &amp;lt;- readArray actualArray x leader2 &amp;lt;- readArray actualArray y let newValues = (map (\(index, value) -&amp;gt; (index, leader1)) . filter (\(index, value) -&amp;gt; value == leader2)) ls sequence $ map (\(idx, val) -&amp;gt; writeArray actualArray idx val) newValues return actualArray union :: IO (IOArray Int Int) -&amp;gt; Int -&amp;gt; Int -&amp;gt; IO (IOArray Int Int) union arrayContainer x y = do actualArray &amp;lt;- arrayContainer ls &amp;lt;- getAssocs actualArray leader1 &amp;lt;- readArray actualArray x leader2 &amp;lt;- readArray actualArray y let newValues = (map (\(index, value) -&amp;gt; (index, leader1)) .</description>
    </item>
    
    <item>
      <title>Haskell: An impressively non performant union find</title>
      <link>https://markhneedham.com/blog/2012/12/31/haskell-an-impressively-non-performant-union-find/</link>
      <pubDate>Mon, 31 Dec 2012 20:44:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/haskell-an-impressively-non-performant-union-find/</guid>
      <description>To paraphrase from my previous post about how we use the union find data structure:&amp;gt; let uf = emptyEquivalence (0,9) [(0,0),(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9)] &amp;gt; components $ equate 0 1 uf [(0,0),(1,0),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9)] &amp;gt; components $ equate 8 9 $ equate 0 1 $ uf [(0,0),(1,0),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,8)] &amp;gt; components $ equate 0 8 $ equate 8 9 $ equate 0 1 $ uf [(0,0),(1,0),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,0),(9,8)] class UnionFind def initialize(n) @leaders = 1.upto(n).inject([]) { |leaders, i| leaders[i] = i; leaders } end def connected?</description>
    </item>
    
    <item>
      <title>Bitwise operations in Ruby and Haskell</title>
      <link>https://markhneedham.com/blog/2012/12/31/bitwise-operations-in-ruby-and-haskell/</link>
      <pubDate>Mon, 31 Dec 2012 13:14:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/bitwise-operations-in-ruby-and-haskell/</guid>
      <description>&amp;gt; &amp;#34;10000&amp;#34;.to_i(2) =&amp;gt; 16 &amp;gt; import Data.Char &amp;gt; (foldr (\c s -&amp;gt; s * 2 + c) 0 . reverse . map digitToInt) &amp;#34;10000&amp;#34; 16 &amp;#39;10000&amp;#39; XOR &amp;#39;10000&amp;#39; &amp;gt; 16 ^ 16 =&amp;gt; 0 &amp;gt; [0,1,2,4,16].map { |x| 16 ^ x } =&amp;gt; [16, 17, 18, 20, 0] &amp;gt; bits = 5 &amp;gt; offsets = (0..(bits - 1)).map { |x| 2 ** x } =&amp;gt; [1, 2, 4, 8, 16] &amp;gt; offsets = (0.</description>
    </item>
    
    <item>
      <title>Gamification and Software: Some thoughts</title>
      <link>https://markhneedham.com/blog/2012/12/31/gamification-and-software-some-thoughts/</link>
      <pubDate>Mon, 31 Dec 2012 10:57:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/gamification-and-software-some-thoughts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Haskell: Using qualified imports to avoid polluting the namespace</title>
      <link>https://markhneedham.com/blog/2012/12/30/haskell-using-qualified-imports-to-avoid-polluting-the-namespace/</link>
      <pubDate>Sun, 30 Dec 2012 23:16:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/30/haskell-using-qualified-imports-to-avoid-polluting-the-namespace/</guid>
      <description>import System.IO import Data.List.Split import Data.Char import Data.Bits import Control.Monad import Data.Map import Data.Set import Data.List import Data.Maybe clustering.hs:53:43: Ambiguous occurrence `filter&amp;#39; It could refer to either `Data.List.filter&amp;#39;, imported from `Data.List&amp;#39; at clustering.hs:11:1-16 (and originally defined in `GHC.List&amp;#39;) or `Data.Set.filter&amp;#39;, imported from `Data.Set&amp;#39; at clustering.hs:10:1-16 or `Data.Map.filter&amp;#39;, imported from `Data.Map&amp;#39; at clustering.hs:9:1-16 &amp;gt; import qualified Data.Map &amp;gt; Data.Map.assocs $ Data.Map.fromList [(1,2), (3,7)] [(1,2),(3,7)] import System.IO import Data.List.Split import Data.Char import Data.</description>
    </item>
    
    <item>
      <title>Haskell: Pattern matching a list</title>
      <link>https://markhneedham.com/blog/2012/12/30/haskell-pattern-matching-a-list/</link>
      <pubDate>Sun, 30 Dec 2012 22:39:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/30/haskell-pattern-matching-a-list/</guid>
      <description>&amp;gt; import Data.Bits &amp;gt; map (\pair -&amp;gt; (pair !! 0) .|. (pair !! 1)) [[1,2], [3,4]] [3,7] &amp;gt; map (\(x:y:_) -&amp;gt; x .|. y) [[1,2], [3,4]] [3,7] </description>
    </item>
    
    <item>
      <title>Haskell: A cleaner way of initialising a map</title>
      <link>https://markhneedham.com/blog/2012/12/29/haskell-a-cleaner-way-of-initialising-a-map/</link>
      <pubDate>Sat, 29 Dec 2012 20:14:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/29/haskell-a-cleaner-way-of-initialising-a-map/</guid>
      <description>import Data.Map toMap :: [Int] -&amp;gt; Map Int [Int] toMap nodes = fromList $ map asMapEntry $ (groupIgnoringIndex . sortIgnoringIndex) nodesWithIndexes where nodesWithIndexes = (zip [0..] nodes) groupIgnoringIndex = groupBy (\(_,x) (_,y) -&amp;gt; x == y) sortIgnoringIndex = sortBy (\(_,x) (_,y) -&amp;gt; x `compare` y) asMapEntry :: [(Int, Int)] -&amp;gt; (Int, [Int]) asMapEntry nodesWithIndexes = ((snd . head) nodesWithIndexes, Prelude.foldl (\acc (x,_) -&amp;gt; acc ++ [x]) [] nodesWithIndexes) &amp;gt; assocs $ toMap [1,2,5,7,2,4] [(1,[0]),(2,[4,1]),(4,[5]),(5,[2]),(7,[3])] &amp;gt; let emptyMap = empty :: Map Int [Int] &amp;gt; assocs $ foldl (\acc (id,val) -&amp;gt; insertWith (++) val [id] acc) emptyMap nodesWithIndexes [(1,[0]),(2,[4,1]),(4,[5]),(5,[2]),(7,[3])] </description>
    </item>
    
    <item>
      <title>Haskell: Initialising a map</title>
      <link>https://markhneedham.com/blog/2012/12/29/haskell-initialising-a-map/</link>
      <pubDate>Sat, 29 Dec 2012 19:27:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/29/haskell-initialising-a-map/</guid>
      <description>nodes = [1,2,5,7,2,4] @magical_hash = {} nodes.each_with_index do |node, index| @magical_hash[node] ||= [] @magical_hash[node] &amp;lt;&amp;lt; index end =&amp;gt; {1=&amp;gt;[0], 2=&amp;gt;[1, 4], 5=&amp;gt;[2], 7=&amp;gt;[3], 4=&amp;gt;[5]} &amp;gt; let nodesMap = Data.Map.fromList [(1, [0]), (2, [1,4]), (5, [2]), (7, [3]), (4, [5])] &amp;gt; Data.Map.assocs nodesMap [(1,[0]),(2,[1,4]),(4,[5]),(5,[2]),(7,[3])] &amp;gt; zip [0..] [1,2,5,7,2,4] [(0,1),(1,2),(2,5),(3,7),(4,2),(5,4)] groupIgnoringIndex = groupBy (\(_,x) (_,y) -&amp;gt; x == y) sortIgnoringIndex = sortBy (\(_,x) (_,y) -&amp;gt; x `compare` y) &amp;gt; (groupIgnoringIndex . sortIgnoringIndex) (zip [0.</description>
    </item>
    
    <item>
      <title>Sed: Replacing characters with a new line</title>
      <link>https://markhneedham.com/blog/2012/12/29/sed-replacing-characters-with-a-new-line/</link>
      <pubDate>Sat, 29 Dec 2012 17:49:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/29/sed-replacing-characters-with-a-new-line/</guid>
      <description>[(1,2), (3,4)â€¦] sed -E -e &amp;#39;s/, \(/\\n(/g&amp;#39; ruby_union.txt sed -E -e &amp;#34;s/,\(/\ /g&amp;#34; ruby_union.txt $ echo &amp;#34;mark\r\nneedham&amp;#34; mark\r\nneedham $ echo -e &amp;#34;mark\r\nneedham&amp;#34; mark needham sed -E -e &amp;#34;s/, \(/\\`echo -e &amp;#39;\n\r&amp;#39;`/g&amp;#34; ruby_union.txt $ echo &amp;#34;[(1,2), (3,4), (5,6)]&amp;#34; | sed -E -e &amp;#34;s/, \(/\\`echo -e &amp;#39;\n\r&amp;#39;`/g&amp;#34; -e &amp;#39;s/\[|]|\)|\(//g&amp;#39; 1,2 3,4 5,6 </description>
    </item>
    
    <item>
      <title>Restricting your own learning</title>
      <link>https://markhneedham.com/blog/2012/12/27/restricting-your-own-learning/</link>
      <pubDate>Thu, 27 Dec 2012 00:45:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/27/restricting-your-own-learning/</guid>
      <description>  as in I got paid. I&amp;rsquo;d never claim to be professional in any other way :-D  </description>
    </item>
    
    <item>
      <title>Mahout: Parallelising the creation of DecisionTrees</title>
      <link>https://markhneedham.com/blog/2012/12/27/mahout-parallelising-the-creation-of-decisiontrees/</link>
      <pubDate>Thu, 27 Dec 2012 00:08:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/27/mahout-parallelising-the-creation-of-decisiontrees/</guid>
      <description>List&amp;lt;Node&amp;gt; trees = new ArrayList&amp;lt;Node&amp;gt;(); MultiDecisionForest forest = MultiDecisionForest.load(new Configuration(), new Path(&amp;#34;/path/to/mahout-tree&amp;#34;)); trees.addAll(forest.getTrees()); MultiDecisionForest forest = new MultiDecisionForest(trees); deb http://ppa.launchpad.net/ieltonf/ppa/ubuntu oneiric main deb-src http://ppa.launchpad.net/ieltonf/ppa/ubuntu oneiric main parallelise-forests.sh#!/bin/bash start=`date` startTime=`date &amp;#39;+%s&amp;#39;` numberOfRuns=$1 seq 1 ${numberOfRuns} | parallel -P 8 &amp;#34;./build-forest.sh&amp;#34; end=`date` endTime=`date &amp;#39;+%s&amp;#39;` echo &amp;#34;Started: ${start}&amp;#34; echo &amp;#34;Finished: ${end}&amp;#34; echo &amp;#34;Took: &amp;#34; $(expr $endTime - $startTime) build-forest.sh#!/bin/bash java -Xmx1024m -cp target/machinenursery-1.0.0-SNAPSHOT-standalone.jar main.java.MahoutPlaybox </description>
    </item>
    
    <item>
      <title>The Tracer Bullet Approach: An example</title>
      <link>https://markhneedham.com/blog/2012/12/24/the-tracer-bullet-approach-an-example/</link>
      <pubDate>Mon, 24 Dec 2012 09:09:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/24/the-tracer-bullet-approach-an-example/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Kruskal&#39;s Algorithm using union find in Ruby</title>
      <link>https://markhneedham.com/blog/2012/12/23/kruskals-algorithm-using-union-find-in-ruby/</link>
      <pubDate>Sun, 23 Dec 2012 21:43:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/23/kruskals-algorithm-using-union-find-in-ruby/</guid>
      <description>class UnionFind def initialize(n) @leaders = 1.upto(n).inject([]) { |leaders, i| leaders[i] = i; leaders } end def connected?(id1,id2) @leaders[id1] == @leaders[id2] end def union(id1,id2) leader_1, leader_2 = @leaders[id1], @leaders[id2] @leaders.map! {|i| (i == leader_1) ? leader_2 : i } end end &amp;gt; uf = UnionFind.new 5 =&amp;gt; #&amp;lt;UnionFind:0x45e5a9b3 @leaders=[nil, 1, 2, 3, 4, 5]&amp;gt; &amp;gt; uf.connected?(1,2) =&amp;gt; false &amp;gt; uf.union(1,2) =&amp;gt; [nil, 2, 2, 3, 4, 5] &amp;gt; uf.union(2,3) =&amp;gt; [nil, 3, 3, 3, 4, 5] set = UnionFind.</description>
    </item>
    
    <item>
      <title>Kruskal&#39;s Algorithm in Ruby</title>
      <link>https://markhneedham.com/blog/2012/12/23/kruskals-algorithm-in-ruby/</link>
      <pubDate>Sun, 23 Dec 2012 14:18:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/23/kruskals-algorithm-in-ruby/</guid>
      <description>@minimum_spanning_tree = [] edges = file.drop(1). map { |x| x.gsub(/\n/, &amp;#34;&amp;#34;).split(&amp;#34; &amp;#34;).map(&amp;amp;:to_i) }. map { |one, two, weight| { :from =&amp;gt; one, :to =&amp;gt; two, :weight =&amp;gt; weight}}. sort_by { |x| x[:weight]} edges.each do |edge| @minimum_spanning_tree &amp;lt;&amp;lt; edge unless has_cycles edge end def has_cycles(edge) node_one, node_two = edge[:from], edge[:to] @minimum_spanning_tree.each { |x| x[:explored] = false } cycle_between(node_one, node_two, @minimum_spanning_tree.dup) end def cycle_between(one, two, edges) adjacent_edges = edges.select { |edge| edge[:to] == one || edge[:from] == one} return false if adjacent_edges.</description>
    </item>
    
    <item>
      <title>Prim&#39;s algorithm using a heap/priority queue in Ruby</title>
      <link>https://markhneedham.com/blog/2012/12/15/prims-algorithm-using-a-heappriority-queue-in-ruby/</link>
      <pubDate>Sat, 15 Dec 2012 16:31:05 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/15/prims-algorithm-using-a-heappriority-queue-in-ruby/</guid>
      <description>MAX_VALUE = (2**(0.size * 8 -2) -1) adjacency_matrix = create_adjacency_matrix @nodes_spanned_so_far, spanning_tree_cost = [1], 0 heap = PriorityQueue.new nodes_left_to_cover.each do |node| cheapest_nodes = get_edges(adjacency_matrix, node-1). select { |_, other_node_index| @nodes_spanned_so_far.include?(other_node_index + 1) } || [] cheapest = cheapest_nodes.inject([]) do |all_edges, (weight, index)| all_edges &amp;lt;&amp;lt; { :start =&amp;gt; node, :end =&amp;gt; index + 1, :weight =&amp;gt; weight } all_edges end.sort { |x,y| x[:weight] y[:weight] }.first weight = !cheapest.nil? ? cheapest[:weight]: MAX_VALUE heap[node] = weight end while !</description>
    </item>
    
    <item>
      <title>Prim&#39;s Algorithm in Ruby</title>
      <link>https://markhneedham.com/blog/2012/12/15/prims-algorithm-in-ruby/</link>
      <pubDate>Sat, 15 Dec 2012 02:51:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/15/prims-algorithm-in-ruby/</guid>
      <description>adjacency_matrix = create_adjacency_matrix first_edge = select_first_edge(adjacency_matrix) @nodes_spanned_so_far, @edges = [first_edge[:start], first_edge[:end]], [first_edge] while !nodes_left_to_cover.empty? cheapest_edge = find_cheapest_edge(adjacency_matrix, @nodes_spanned_so_far, number_of_nodes) @edges &amp;lt;&amp;lt; cheapest_edge @nodes_spanned_so_far &amp;lt;&amp;lt; cheapest_edge[:start] end def find_cheapest_edge(adjacency_matrix, nodes_spanned_so_far, number_of_nodes) available_nodes = (0..number_of_nodes-1).to_a.reject { |node_index| nodes_spanned_so_far.include?(node_index + 1) } cheapest_edges = available_nodes.inject([]) do |acc, node_index| get_edges(adjacency_matrix, node_index).select { |_, other_node_index| nodes_spanned_so_far.include?(other_node_index + 1) }.each do |weight, other_node_index| acc &amp;lt;&amp;lt; { :start =&amp;gt; node_index + 1, :end =&amp;gt; other_node_index + 1, :weight =&amp;gt; weight } end acc end cheapest_edges.</description>
    </item>
    
    <item>
      <title>Weka: Saving and loading classifiers</title>
      <link>https://markhneedham.com/blog/2012/12/12/weka-saving-and-loading-classifiers/</link>
      <pubDate>Wed, 12 Dec 2012 00:04:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/12/weka-saving-and-loading-classifiers/</guid>
      <description>MultilayerPerceptron classifier = new MultilayerPerceptron(); classifier.buildClassifier(instances); // instances gets passed in from elsewhere  Debug.saveToFile(&amp;#34;/path/to/weka-neural-network&amp;#34;, classifier); SerializedClassifier classifier = new SerializedClassifier(); classifier.setModelFile(new File(&amp;#34;/path/to/weka-neural-network&amp;#34;)); </description>
    </item>
    
    <item>
      <title>rsyncing to an AWS instance</title>
      <link>https://markhneedham.com/blog/2012/12/11/rsyncing-to-an-aws-instance/</link>
      <pubDate>Tue, 11 Dec 2012 23:44:05 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/11/rsyncing-to-an-aws-instance/</guid>
      <description>ssh -l ubuntu -i ~/Downloads/machinenursery.pem ec2-54-242-108-142.compute-1.amazonaws.com rsync --progress &amp;#39;ssh -i /Users/markhneedham/Downloads/machinenursery.pem&amp;#39; -avz target/ ubuntu@ec2-54-242-108-142.compute-1.amazonaws.com:machinenursery Permission denied (publickey). rsync: connection unexpectedly closed (0 bytes received so far) [sender] rsync error: unexplained error (code 255) at /SourceCache/rsync/rsync-42/rsync/io.c(452) [sender=2.6.9] rsync --progress --rsh &amp;#39;ssh -i /Users/markhneedham/Downloads/machinenursery.pem&amp;#39; -avz target/ ubuntu@ec2-54-242-108-142.compute-1.amazonaws.com:machine nursery </description>
    </item>
    
    <item>
      <title>apt-get update: 416 Requested Range Not Satisfiable</title>
      <link>https://markhneedham.com/blog/2012/12/10/apt-get-update-416-requested-range-not-satisfiable/</link>
      <pubDate>Mon, 10 Dec 2012 00:39:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/10/apt-get-update-416-requested-range-not-satisfiable/</guid>
      <description>Err http://us-west-1.ec2.archive.ubuntu.com/ubuntu/ i386 Packages 416 Requested Range Not Satisfiable Fetched 5,079B in 2s (2,296B/s) W: Failed to fetch http://us-west-1.ec2.archive.ubuntu.com/ubuntu/dists/maverick-updates/main/binary-i386/Packages.gz 416 Requested Range Not Satisfiable sudo rm -rf /var/lib/apt/lists/partial/* </description>
    </item>
    
    <item>
      <title>Data Science: Discovery work</title>
      <link>https://markhneedham.com/blog/2012/12/09/data-science-discovery-work/</link>
      <pubDate>Sun, 09 Dec 2012 10:36:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/09/data-science-discovery-work/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Micro Services: Plugging in 3rd party components</title>
      <link>https://markhneedham.com/blog/2012/12/04/micro-services-plugging-in-3rd-party-components/</link>
      <pubDate>Tue, 04 Dec 2012 23:38:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/04/micro-services-plugging-in-3rd-party-components/</guid>
      <description></description>
    </item>
    
    <item>
      <title>There&#39;s No such thing as a &#39;DevOps Team&#39;: Some thoughts</title>
      <link>https://markhneedham.com/blog/2012/11/30/theres-no-such-thing-as-a-devops-team-some-thoughts/</link>
      <pubDate>Fri, 30 Nov 2012 16:56:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/30/theres-no-such-thing-as-a-devops-team-some-thoughts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: Weka AdaBoost attempt</title>
      <link>https://markhneedham.com/blog/2012/11/29/kaggle-digit-recognizer-weka-adaboost-attempt/</link>
      <pubDate>Thu, 29 Nov 2012 17:09:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/29/kaggle-digit-recognizer-weka-adaboost-attempt/</guid>
      <description>In our latest attempt at Kaggle&amp;rsquo;s Digit RecognizerJenand I decided to try out boostingon our random forest algorithm, an approach that Jen had come across in a talk at the Clojure Conj.
We couldn&amp;rsquo;t find any documentation that it was possible to apply boosting to Mahout&amp;rsquo;s random forest algorithm but we knew it was possible with Wekaso we decided to use that instead!
As I understand it the way that boosting works in the context of random forests is that each of the trees in the forest will be assigned a weight based on how accurately it&amp;rsquo;s able to classify the data set and these weights are then used in the voting stage.</description>
    </item>
    
    <item>
      <title>Micro Services: The curse of code &#39;duplication&#39;</title>
      <link>https://markhneedham.com/blog/2012/11/28/micro-services-the-curse-of-code-duplication/</link>
      <pubDate>Wed, 28 Nov 2012 08:11:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/28/micro-services-the-curse-of-code-duplication/</guid>
      <description>A common approach we&amp;rsquo;ve been taking on some of the applications I&amp;rsquo;ve worked on recently is to decompose the system we&amp;rsquo;re building into smaller micro serviceswhich are independently deployable and communicate with each other over HTTP.
An advantage of decomposing systems like that is that we could have separate teams working on each service and then make use of a consumer driven contractas a way of ensuring the contract between them is correct.</description>
    </item>
    
    <item>
      <title>Jersey: com.sun.jersey.api.client.ClientHandlerException: A message body reader for Java class [...] and MIME media type application/json was not found</title>
      <link>https://markhneedham.com/blog/2012/11/28/jersey-com-sun-jersey-api-client-clienthandlerexception-a-message-body-reader-for-java-class-and-mime-media-type-applicationjson-was-not-found/</link>
      <pubDate>Wed, 28 Nov 2012 06:03:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/28/jersey-com-sun-jersey-api-client-clienthandlerexception-a-message-body-reader-for-java-class-and-mime-media-type-applicationjson-was-not-found/</guid>
      <description>We&amp;rsquo;ve used the Jerseylibrary on the last couple of Java based applications that I&amp;rsquo;ve worked on and one thing we&amp;rsquo;ve done on both of them is write services that communicate with each other using JSON.
On both occasions we didn&amp;rsquo;t quite setup the Jersey client correctly and ended up with an error along these lines when making a call to an end point:
com.sun.jersey.api.client.ClientHandlerException: A message body reader for Java class java.</description>
    </item>
    
    <item>
      <title>IntelliJ Debug Mode: Viewing beyond 100 frames/items in an array</title>
      <link>https://markhneedham.com/blog/2012/11/26/intellij-debug-mode-viewing-beyond-100-framesitems-in-an-array/</link>
      <pubDate>Mon, 26 Nov 2012 04:28:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/26/intellij-debug-mode-viewing-beyond-100-framesitems-in-an-array/</guid>
      <description>In my continued attempts at the Kaggle Digit Recognizerproblem I&amp;rsquo;ve been playing around with the encoglibrary to try and build a neural networks solution to the problem.
Unfortunately it&amp;rsquo;s not quite working at the moment so I wanted to debug the code and see whether the input parameters were being correctly translated from the CSV file.
Each input is an array containing 784 values but by default IntelliJ restricts you to seeing 100 elements which wasn&amp;rsquo;t helpful in my case since the early values tend to all be 0 and it&amp;rsquo;s not until you get half way through that you see different values:</description>
    </item>
    
    <item>
      <title>A first failed attempt at Natural Language Processing</title>
      <link>https://markhneedham.com/blog/2012/11/24/a-first-failed-attempt-at-natural-language-processing/</link>
      <pubDate>Sat, 24 Nov 2012 19:43:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/24/a-first-failed-attempt-at-natural-language-processing/</guid>
      <description>One of the things I find fascinating about dating websites is that the profiles of people are almost identical so I thought it would be an interesting exercise to grab some of the free text that people write about themselves and prove the similarity.
I&amp;rsquo;d been talking to Matt Biddulphabout some Natural Language Processing (NLP) stuff he&amp;rsquo;d been working on and he wrote up a bunch of libraries, articles and books that he&amp;rsquo;d found useful.</description>
    </item>
    
    <item>
      <title>Core Competency</title>
      <link>https://markhneedham.com/blog/2012/11/24/core-competency/</link>
      <pubDate>Sat, 24 Nov 2012 12:44:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/24/core-competency/</guid>
      <description>For at least the last few years I&amp;rsquo;ve heard colleagues talk about working out the core competency of our clients businesses and I&amp;rsquo;d confused myself into thinking that the software we helped them build was the core competency.
I think Martin Fowler best explains how technology and business core competences work in his post about utility and strategic projectswhere he describes the difference between these like so:
The thing I&amp;rsquo;d be getting confused about was thinking that the software isthe core competency but as Martin points out the software is actually there to supportthe core competency.</description>
    </item>
    
    <item>
      <title>Windows line endings: Exception in thread &#39;main&#39; java.io.FileNotFoundException /opt/app/config.yml^M (no such file or directory)</title>
      <link>https://markhneedham.com/blog/2012/11/24/windows-line-endings-exception-in-thread-main-java-io-filenotfoundexception-optappconfig-ymlm-no-such-file-or-directory/</link>
      <pubDate>Sat, 24 Nov 2012 09:04:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/24/windows-line-endings-exception-in-thread-main-java-io-filenotfoundexception-optappconfig-ymlm-no-such-file-or-directory/</guid>
      <description>As I mentioned in my previous postwe&amp;rsquo;ve been making it possible to deploy our application to a new environment and as part of this we defined an upstartscript which would run the JAR.
We tend to edit code on Windows and then test it out on the vagrant VM afterwards.
The end of our upstart script looked a bit like this:
script cd /opt/app java -jar /opt/app/app.jar /opt/app/config.yml end script Unfortunately when we tried to launch the application using &amp;lsquo;start app&amp;rsquo; we got this error:</description>
    </item>
    
    <item>
      <title>Java: java.lang.UnsupportedClassVersionError - Unsupported major.minor version 51.0</title>
      <link>https://markhneedham.com/blog/2012/11/24/java-java-lang-unsupportedclassversionerror-unsupported-major-minor-version-51-0/</link>
      <pubDate>Sat, 24 Nov 2012 08:49:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/24/java-java-lang-unsupportedclassversionerror-unsupported-major-minor-version-51-0/</guid>
      <description>On my current project we&amp;rsquo;ve spent the last day or so setting up an environment where we can deploy a couple of micro services to.
Although the machines are Windows based we&amp;rsquo;re deploying the application onto a vagrantmanaged VM since the production environment will be a flavour of Linux.
Initially I was getting quite confused about whether or not we were in the VM or not and ended up with this error when trying to run the compiled JAR:</description>
    </item>
    
    <item>
      <title>Looking inside the black box</title>
      <link>https://markhneedham.com/blog/2012/11/21/looking-inside-the-black-box/</link>
      <pubDate>Wed, 21 Nov 2012 19:42:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/21/looking-inside-the-black-box/</guid>
      <description>I recently came across a really interesting post about black box abstractionby Angeleah where she talks about developers desire to know how things work and the need to understand when and when not to follow that instinct.
Angeleah defines black box abstraction like so:
We have to be particularly careful about knowing how far to look inside the black box when working with new systems that we know nothing about.</description>
    </item>
    
    <item>
      <title>Learning: Switching between theory and practice</title>
      <link>https://markhneedham.com/blog/2012/11/19/learning-switching-between-theory-and-practice/</link>
      <pubDate>Mon, 19 Nov 2012 13:31:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/19/learning-switching-between-theory-and-practice/</guid>
      <description>In one of my first ever blog posts I wrote about the differences I&amp;rsquo;d experienced in learning the theory about a topic and then seeing it in practice.
The way I remember learning at school and university was that you learn all the theory first and then put it into practice but I typically don&amp;rsquo;t find myself doing this whenever I learn something new.
I spent a bit of time over the weekend learning more about neural networks as my colleague Jen Smithsuggested this might be a more effective technique for getting a higher accuracy scoreon the Kaggle Digit Recogniserproblem.</description>
    </item>
    
    <item>
      <title>Incremental/iterative development: Breaking down work</title>
      <link>https://markhneedham.com/blog/2012/11/19/incrementaliterative-development-breaking-down-work/</link>
      <pubDate>Mon, 19 Nov 2012 08:50:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/19/incrementaliterative-development-breaking-down-work/</guid>
      <description>Over the past couple of years I&amp;rsquo;ve worked on several different applications and one thing they had in common was that they had a huge feature which would take a few months to complete and initially seemed difficult to break down.
Since we favoured an incremental/iterative approach to building these features and wanted to add value in short feedback cycles we needed to find a way to break them down.</description>
    </item>
    
    <item>
      <title>Buy vs Build: Driving from the problem</title>
      <link>https://markhneedham.com/blog/2012/11/17/buy-vs-build-driving-from-the-problem/</link>
      <pubDate>Sat, 17 Nov 2012 16:56:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/17/buy-vs-build-driving-from-the-problem/</guid>
      <description>My colleague Erik Doernenburghas written a couple of articles recently discussing the reasons why people buyand build IT solutionsand one part in particular resonated with me:
I feel like there&amp;rsquo;s a mindset change once you start thinking which package you could buy to solve your problem whereby you stop solving the problem you actually have and focus instead on what features the package offers.
Package software almost by definition tends to be written for a generic case of a problem and as Erik points out might not solve the problem that a business has.</description>
    </item>
    
    <item>
      <title>Web Operations: Feature flags to turn off failing parts of infrastructure</title>
      <link>https://markhneedham.com/blog/2012/11/13/web-operations-feature-flags-to-turn-off-failing-parts-of-infrastructure/</link>
      <pubDate>Tue, 13 Nov 2012 12:19:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/13/web-operations-feature-flags-to-turn-off-failing-parts-of-infrastructure/</guid>
      <description>On most of the projects I&amp;rsquo;ve worked on over the last couple of years we&amp;rsquo;ve made use of feature togglesthat we used to turn pending features on and off while they were still being built but while reading Web OperationsI came across another usage.
In the chapter titled &amp;lsquo;Dev and Ops Collaboration and Cooperation&amp;rsquo; Paul Hammondsuggests the following:
We&amp;rsquo;d mainly use this approach to disable peripheral functionality such as the ability to comment on a site whose main purpose is to deliver news.</description>
    </item>
    
    <item>
      <title>Unix: Counting the number of commas on a line</title>
      <link>https://markhneedham.com/blog/2012/11/10/unix-counting-the-number-of-commas-on-a-line/</link>
      <pubDate>Sat, 10 Nov 2012 16:30:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/10/unix-counting-the-number-of-commas-on-a-line/</guid>
      <description>A few weeks ago I was playing around with some data stored in a CSV file and wanted to do a simple check on the quality of the data by making sure that each line had the same number of fields.
One way this can be done is with awk:
awk -F &amp;#34;,&amp;#34; &amp;#39; { print NF-1 } &amp;#39; file.csv Here we&amp;rsquo;re specifying the file separator -Fas &amp;lsquo;,&amp;rsquo; and then using the NF(number of fields) variable to print how many commas there are on the line.</description>
    </item>
    
    <item>
      <title>Clojure: Thread last (-&gt;&gt;) vs Thread first (-&gt;)</title>
      <link>https://markhneedham.com/blog/2012/11/06/clojure-thread-last-vs-thread-first/</link>
      <pubDate>Tue, 06 Nov 2012 12:42:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/06/clojure-thread-last-vs-thread-first/</guid>
      <description>In many of the Clojure examples that I&amp;rsquo;ve come across the thread last (-&amp;raquo;)macro is used to make it easier (for people from a non lispy background!) to see the transformations that the initial data structure is going through.
In one of my recent posts I showed how Jen &amp;amp; I had rewritten Mahout&amp;rsquo;s entropy function in Clojure:
(defn calculate-entropy [counts data-size] (-&amp;gt;&amp;gt; counts (remove #{0}) (map (partial individual-entropy data-size)) (reduce +))) Here we are using the thread last operator to first pass countsas the last argument of the removefunction on the next line, then to pass the result of that to the mapfunction on the next line and so on.</description>
    </item>
    
    <item>
      <title>Emacs/Clojure: Starting out with paredit</title>
      <link>https://markhneedham.com/blog/2012/10/31/emacsclojure-starting-out-with-paredit/</link>
      <pubDate>Wed, 31 Oct 2012 08:41:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/31/emacsclojure-starting-out-with-paredit/</guid>
      <description>I&amp;rsquo;ve been complaining recently to Jenand Bruceabout the lack of a beginner&amp;rsquo;s guide to emacs paredit modewhich seems to be the defacto approach for people working with Clojure and both pointed me to the paredit cheat sheet.
While it&amp;rsquo;s very comprehensive, I found that it&amp;rsquo;s a little overwhelming for a complete newbie like myself.
I therefore thought it&amp;rsquo;d be useful to write a bit about a couple of things that I&amp;rsquo;ve picked up from pairing with Jen on little bits of Clojure over the last couple of months.</description>
    </item>
    
    <item>
      <title>Clojure: Mahout&#39;s &#39;entropy&#39; function</title>
      <link>https://markhneedham.com/blog/2012/10/30/clojure-mahouts-entropy-function/</link>
      <pubDate>Tue, 30 Oct 2012 22:46:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/30/clojure-mahouts-entropy-function/</guid>
      <description>As I mentioned in a coupleof previous postsJenand I have been playing around with Mahout random forestsand for a few hours last week we spent some time looking through the code to see how it worked.
In particular we came across an entropy function which is used to determine how good a particular &amp;lsquo;split&amp;rsquo; point in a decision tree is going to be.
I quite like the following definition:
Information Theory (developed by Claude Shannon 1948) defines this value of uncertainty as entropy, a probability-based measure used to calculate the amount of uncertainty.</description>
    </item>
    
    <item>
      <title>Mahout: Using a saved Random Forest/DecisionTree</title>
      <link>https://markhneedham.com/blog/2012/10/27/mahout-using-a-saved-random-forestdecisiontree/</link>
      <pubDate>Sat, 27 Oct 2012 22:03:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/27/mahout-using-a-saved-random-forestdecisiontree/</guid>
      <description>One of the things that I wanted to do while playing around with random forestsusing Mahoutwas to save the random forest and then use use it again which is something Mahout does cater for.
It was actually much easier to do this than I&amp;rsquo;d expected and assuming that we already have a DecisionForestbuilt we&amp;rsquo;d just need the following code to save it to disc:
int numberOfTrees = 1; Data data = loadData(.</description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: Mahout Random Forest attempt</title>
      <link>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-mahout-random-forest-attempt/</link>
      <pubDate>Sat, 27 Oct 2012 20:24:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-mahout-random-forest-attempt/</guid>
      <description>I&amp;rsquo;ve written previously about the K-meansapproachthat Jenand I took when trying to solve Kaggle&amp;rsquo;s Digit Recognizerand having stalled at about 80% accuracy we decided to try one of the algorithms suggested in the tutorials section- the random forest!
We initially used a clojure random forests librarybut struggled to build the random forest from the training set data in a reasonable amount of time so we switched to Mahout&amp;rsquo;s versionwhich is based on Leo Breiman&amp;rsquo;s random forestspaper.</description>
    </item>
    
    <item>
      <title>Retrospectives: An alternative safety check</title>
      <link>https://markhneedham.com/blog/2012/10/27/retrospectives-an-alternative-safety-check/</link>
      <pubDate>Sat, 27 Oct 2012 18:21:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/27/retrospectives-an-alternative-safety-check/</guid>
      <description>At the start of most of the retrospectives I&amp;rsquo;ve been part of we&amp;rsquo;ve followed the safety check ritual whereby each person participating has to write a number from 1-5 on a sticky describing how they&amp;rsquo;ll be participating in the retrospective.
1 means you&amp;rsquo;ll probably keep quiet and not say much, 5 means you&amp;rsquo;re perfectly comfortable saying anything and the other numbers fall in between those two extremes.
In my experiences it&amp;rsquo;s a bit of a fruitless exercise because its viewed that a higher number is &amp;lsquo;better&amp;rsquo; and therefore the minimum people will tend to write down is &amp;lsquo;3&amp;rsquo; because they don&amp;rsquo;t want to stand out or cause a problem.</description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: K-means optimisation attempt</title>
      <link>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-k-means-optimisation-attempt/</link>
      <pubDate>Sat, 27 Oct 2012 12:27:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/27/kaggle-digit-recognizer-k-means-optimisation-attempt/</guid>
      <description>I recently wrote a blog post explaining how Jenand I used the K-means algorithmto classify digits in Kaggle&amp;rsquo;s Digit Recognizer problemand one of the things we&amp;rsquo;d read was that with this algorithm you often end up with situations where it&amp;rsquo;s difficult to classify a new item because if falls between two labels.
We decided to have a look at the output of our classifier function to see whether or not that was the case.</description>
    </item>
    
    <item>
      <title>Configuration in DNS</title>
      <link>https://markhneedham.com/blog/2012/10/24/configuration-in-dns/</link>
      <pubDate>Wed, 24 Oct 2012 17:40:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/24/configuration-in-dns/</guid>
      <description>In the latest version of the ThoughtWorks Technology Radarone of the areas covered is &amp;lsquo;configuration in DNS&amp;rsquo;, a term which I first came across earlier in the year from a mailing list post by my former colleague Daniel Worthington-Bodart.
The radar describes it like so:
As I alluded to in my post about creating environment agnostic machinesone of the techniques that we&amp;rsquo;ve used to achieve this is configuration in DNS, whereby we use fully qualified domain names (FQDN) for services in our configuration files and have DNS resolve them.</description>
    </item>
    
    <item>
      <title>Kaggle Digit Recognizer: A K-means attempt</title>
      <link>https://markhneedham.com/blog/2012/10/23/kaggle-digit-recognizer-a-k-means-attempt/</link>
      <pubDate>Tue, 23 Oct 2012 19:04:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/23/kaggle-digit-recognizer-a-k-means-attempt/</guid>
      <description>Over the past couple of months Jen and I have been playing around with the Kaggle Digit Recognizer problem- a &amp;lsquo;competition&amp;rsquo; created to introduce people to Machine Learning.
You are given an input file which contains multiple rows each containing 784 pixel values representing a 28x28 pixel image as well as a label indicating which number that image actually represents.
One of the algorithms that we tried out for this problem was a variation on the k-means clusteringone whereby we took the values at each pixel location for each of the labels and came up with an average value for each pixel.</description>
    </item>
    
    <item>
      <title>How we&#39;re using story points</title>
      <link>https://markhneedham.com/blog/2012/10/21/how-were-using-story-points/</link>
      <pubDate>Sun, 21 Oct 2012 23:08:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/21/how-were-using-story-points/</guid>
      <description>A couple of weeks ago Joshua Kerievsky wrote a post describing how he and his teams don&amp;rsquo;t use story points anymorebecause of the problems they&amp;rsquo;d had with them which included:
On the team I&amp;rsquo;m currently working on we still estimate the relative size of stories using points but we don&amp;rsquo;t use velocity per iteration to keep score - most of the time it&amp;rsquo;s barely even mentioned.
Instead for the past couple of months we&amp;rsquo;ve just been using the velocity to see whether or not we were going to achieve the minimum viable infrastructure (MVI)that we needed to have done before launch.</description>
    </item>
    
    <item>
      <title>Do the simple thing</title>
      <link>https://markhneedham.com/blog/2012/10/21/do-the-simple-thing/</link>
      <pubDate>Sun, 21 Oct 2012 21:35:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/21/do-the-simple-thing/</guid>
      <description>One of the most unexpected things that I picked up while pairing with Ashokfor a few days in August/September is his ability to pick the simplest solutionwhen confronted with a problem.
On numerous occasions we&amp;rsquo;d be trying to do something and I&amp;rsquo;d end up on a yak shaving mission trying to get a complicated approach to work while he watched on with bemusement.
I thought I&amp;rsquo;d actually learnt this lesson from working with Ashok but on a couple of occasions over the last week I&amp;rsquo;ve caught myself doing the same thing again!</description>
    </item>
    
    <item>
      <title>Environment agnostic machines and applications</title>
      <link>https://markhneedham.com/blog/2012/10/14/environment-agnostic-machines-and-applications/</link>
      <pubDate>Sun, 14 Oct 2012 18:49:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/14/environment-agnostic-machines-and-applications/</guid>
      <description>On my current project we&amp;rsquo;ve been setting up production and staging environments and Shodhancame up with the idea of making staging and production identical to the point that a machine wouldn&amp;rsquo;t even know what environment it was in.
Identical in this sense means:
The only thing that differs is that the external IPs to access machines differ and therefore the NATed address that they display to the world when making any outgoing requests is also different.</description>
    </item>
    
    <item>
      <title>Play Framework 2.0: Rendering JSON data in the view</title>
      <link>https://markhneedham.com/blog/2012/10/14/play-framework-2-0-rendering-json-data-in-the-view/</link>
      <pubDate>Sun, 14 Oct 2012 09:28:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/14/play-framework-2-0-rendering-json-data-in-the-view/</guid>
      <description>I&amp;rsquo;ve been playing around with the Play Frameworkwhich we&amp;rsquo;re using to front a bunch of visualisations and one thing I wanted to do is send a data structure to a view and then convert that into JSON.
I&amp;rsquo;ve got a simple controller which looks like this:
package controllers; import play.mvc.Controller; import play.mvc.Result; import views.html.*; public class SalesByCategory extends Controller { public static Result index() { ArrayList&amp;lt;Map&amp;lt;String, Object&amp;gt;&amp;gt; series = new ArrayList&amp;lt;Map&amp;lt;String, Object&amp;gt;&amp;gt;(); Map&amp;lt;String, Object&amp;gt; oneSeries = new HashMap&amp;lt;String, Object&amp;gt;(); oneSeries.</description>
    </item>
    
    <item>
      <title>Varnish: Purging the cache</title>
      <link>https://markhneedham.com/blog/2012/10/10/varnish-purging-the-cache/</link>
      <pubDate>Wed, 10 Oct 2012 23:28:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/10/varnish-purging-the-cache/</guid>
      <description>We&amp;rsquo;re using varnishto cache all the requests that come through our web servers and especially in our pre-production environments we deploy quite frequently and want to see the changes that we&amp;rsquo;ve made.
This means that we need to purge the pages we&amp;rsquo;re accessing from varnish so that it will actually pass the request through to the application server and serve up the latest version of the page.
For some reason my google-fu when trying to remember/work out how to do this has always been weak but my colleague Shodhanhelped me understand how to do this today so I thought I better record it so I don&amp;rsquo;t forget!</description>
    </item>
    
    <item>
      <title>Nygard Big Data Model: The Investigation Stage</title>
      <link>https://markhneedham.com/blog/2012/10/10/nygard-big-data-model-the-investigation-stage/</link>
      <pubDate>Wed, 10 Oct 2012 00:00:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/10/nygard-big-data-model-the-investigation-stage/</guid>
      <description>Earlier this year Michael Nygard wrote an extremely detailed post about his experiences in the world of big data projectsand included in the post was the following diagram which I&amp;rsquo;ve found very useful.
Ashokand I have been doing some work in this area helping one of our clients make sense of and visualise some of their data and we realised retrospectively that we were very acting very much in the investigation stage of the model.</description>
    </item>
    
    <item>
      <title>Mac OS X: Removing Byte Order Mark with an editor</title>
      <link>https://markhneedham.com/blog/2012/10/07/mac-os-x-removing-byte-order-mark-with-an-editor/</link>
      <pubDate>Sun, 07 Oct 2012 10:43:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/07/mac-os-x-removing-byte-order-mark-with-an-editor/</guid>
      <description>About a month ago I wrote about some problems I was having working with Windows generated CSV fileswhich had a Byte Order Mark (BOM) at the beginning of the file and I described a way to get rid of it using awk.
It&amp;rsquo;s a bit of a long winded process though and I always forget what the parameters I need to pass to awk are so I thought it would probably be quicker if I could just work out a way to get rid of the BOM using an editor.</description>
    </item>
    
    <item>
      <title>Strata Conf London: Day 2 Wrap Up</title>
      <link>https://markhneedham.com/blog/2012/10/03/strata-conf-london-day-2-wrap-up/</link>
      <pubDate>Wed, 03 Oct 2012 06:46:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/03/strata-conf-london-day-2-wrap-up/</guid>
      <description>Yesterday I attended the second day of Strata Conf Londonand these are the some of the things I learned from the talks I attended:
British Rail were trying to solve a graph problem when people didn&amp;rsquo;t know about graphs and Dijkstra&amp;rsquo;s algorithm hadn&amp;rsquo;t been inventedand it was effectively invented on this project but never publicised. John&amp;rsquo;s suggestion here was that we need to share the stuff that we&amp;rsquo;re doing so that people don&amp;rsquo;t re-invent the wheel.</description>
    </item>
    
    <item>
      <title>Strata Conf London: Day 1 Wrap Up</title>
      <link>https://markhneedham.com/blog/2012/10/02/strata-conf-london-day-1-wrap-up/</link>
      <pubDate>Tue, 02 Oct 2012 23:42:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/02/strata-conf-london-day-1-wrap-up/</guid>
      <description>For the past couple of days I attended the first Strata Conf to be held in London- a conference which seems to bring together people from the data science and big data worldsto talk about the stuff they&amp;rsquo;re doing.
Since I&amp;rsquo;ve been playing around with a couple of different things in this area over the last 4/5 months I thought it&amp;rsquo;d be interesting to come along and see what people much more experienced in this area had to say!</description>
    </item>
    
    <item>
      <title>neo4j: Handling SUM&#39;s scientific notation</title>
      <link>https://markhneedham.com/blog/2012/09/30/neo4j-handling-sums-scientific-notation/</link>
      <pubDate>Sun, 30 Sep 2012 19:47:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/30/neo4j-handling-sums-scientific-notation/</guid>
      <description>In some of the recent work I&amp;rsquo;ve been doing with neo4j the queries I&amp;rsquo;ve written have been summing up the values from multiple nodes and after a certain number is reached the value returned used scientific notation.
For example in a cypher query like this:
START category = node:categories(&amp;#39;category_id:1&amp;#39;) MATCH p = category-[:has_child*1..5]-&amp;gt;subCategory-[:has_product]-&amp;gt;product-[:sold]-&amp;gt;sales RETURN EXTRACT(n in NODES(p) : n.category_id?),subCategory.category_id, SUM(sales.sales) I might get a result set like this:
+------------------------------------------------------------------------------------------------+ | EXTRACT(n in NODES(p) : n.</description>
    </item>
    
    <item>
      <title>Testing XML generation with vimdiff</title>
      <link>https://markhneedham.com/blog/2012/09/30/testing-xml-generation-with-vimdiff/</link>
      <pubDate>Sun, 30 Sep 2012 15:48:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/30/testing-xml-generation-with-vimdiff/</guid>
      <description>A couple of weeks ago I spent a bit of time writing a Ruby DSL to automate the setup of load balancers, firewall and NAT rules through the VCloud API.
The VCloud API deals primarily in XML so the DSL is just a thin layer which creates the appropriate mark up.
When we started out we configured everything manually through the web console and then exported the XML so the first thing that the DSL needed to do was create XML that matched what we already had.</description>
    </item>
    
    <item>
      <title>Data Science: Making sense of the data</title>
      <link>https://markhneedham.com/blog/2012/09/30/data-science-making-sense-of-the-data/</link>
      <pubDate>Sun, 30 Sep 2012 14:58:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/30/data-science-making-sense-of-the-data/</guid>
      <description>Over the past month or so Ashokand I have been helping one of our clients explore and visualise some of their data and one of the first things we needed to do was make sense of the data that was available.
Ashok suggested that we work with a subset of our eventual data setso that we could get a feel for the data and quickly see whether what we were planning to do made sense.</description>
    </item>
    
    <item>
      <title>Data Science: Scrapping the data together</title>
      <link>https://markhneedham.com/blog/2012/09/30/data-science-scrapping-the-data-together/</link>
      <pubDate>Sun, 30 Sep 2012 13:44:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/30/data-science-scrapping-the-data-together/</guid>
      <description>On Friday Martin, Darrenand I were discussing the ThoughtWorks graph that I was working on earlier in the year and Martin pointed out that an interesting aspect of this type of work is that the data you want to work with isn&amp;rsquo;t easily available.
You therefore need to find a way to scrap the data together to make some headway and then maybe at a later stage once some progress has been made it will become easier to replace that with a cleaner solution.</description>
    </item>
    
    <item>
      <title>Upstart: Job getting stuck in the start/killed state</title>
      <link>https://markhneedham.com/blog/2012/09/29/upstart-job-getting-stuck-in-the-startkilled-state/</link>
      <pubDate>Sat, 29 Sep 2012 09:56:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/29/upstart-job-getting-stuck-in-the-startkilled-state/</guid>
      <description>We&amp;rsquo;re using upstartto handle the processes running on our machines and since the haproxypackage only came package with an init.d script we wanted to make it upstartified.
When defining an upstart script you need to specify an expectstanza in which you specify whether or not the process which you&amp;rsquo;re launching is going to fork.
However, most Unix services will &amp;ldquo;daemonize&amp;rdquo;, meaning that they will create a new process (using fork(2)) which is a child of the initial process.</description>
    </item>
    
    <item>
      <title>Java: Parsing CSV files</title>
      <link>https://markhneedham.com/blog/2012/09/23/java-parsing-csv-files/</link>
      <pubDate>Sun, 23 Sep 2012 22:46:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/23/java-parsing-csv-files/</guid>
      <description>As I mentioned in a previous post I recently moved a bunch of neo4j data loading code from Ruby to Javaand as part of that process I needed to parse some CSV files.
In Ruby I was using FasterCSVwhich became the standard CSV library from Ruby 1.9but it&amp;rsquo;s been a while since I had to parse CSV files in Java so I wasn&amp;rsquo;t sure which library to use.
I needed a library which could parse a comma separated file where there might be commas in the values of one of the fields.</description>
    </item>
    
    <item>
      <title>Network Address Translation</title>
      <link>https://markhneedham.com/blog/2012/09/23/network-address-translation/</link>
      <pubDate>Sun, 23 Sep 2012 19:23:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/23/network-address-translation/</guid>
      <description>I&amp;rsquo;ve often heard people talking about Network Address Translation (NAT) but I never really understood exactly how it worked until we started configuring some virtual data centres on my current project.
This is an attempt at documenting my own current understanding so I won&amp;rsquo;t forget in future.
In our case we&amp;rsquo;ve been provisioning a bunch of machines into different private networks, and each machine therefore has an IP in the range of IPv4 addresses reserved for private networks:</description>
    </item>
    
    <item>
      <title>neo4j: The Batch Inserter and the sunk cost fallacy</title>
      <link>https://markhneedham.com/blog/2012/09/23/neo4j-the-batch-inserter-and-the-sunk-cost-fallacy/</link>
      <pubDate>Sun, 23 Sep 2012 10:29:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/23/neo4j-the-batch-inserter-and-the-sunk-cost-fallacy/</guid>
      <description>About a year and a half ago I wrote about the sunk cost fallacywhich is defined like so:
The Truth: Your decisions are tainted by the emotional investments you accumulate, and the more you invest in something the harder it becomes to abandon it.
Over the past few weeks Ashokand I have been doing some exploration of one of our client&amp;rsquo;s data by modelling it in a neo4j graph and seeing what interesting things the traversals reveal.</description>
    </item>
    
    <item>
      <title>Finding ways to use bash command line history shortcuts</title>
      <link>https://markhneedham.com/blog/2012/09/19/finding-ways-to-use-bash-command-line-history-shortcuts/</link>
      <pubDate>Wed, 19 Sep 2012 07:00:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/19/finding-ways-to-use-bash-command-line-history-shortcuts/</guid>
      <description>A couple of months ago I wrote about a bunch of command line history shortcutsthat Philhad taught me and after recently coming across Peteris Krumins&amp;rsquo; bash history cheat sheetI thought it&amp;rsquo;d be interesting to find some real ways to use them.
A few weeks ago I wrote about a UTF-8 byte order mark (BOM) that I wanted to remove from a fileI was working on and I realised this evening that there were some other files with the same problem.</description>
    </item>
    
    <item>
      <title>zsh: Don&#39;t verify substituted history expansion a.k.a.  disabling histverify</title>
      <link>https://markhneedham.com/blog/2012/09/16/zsh-dont-verify-substituted-history-expansion-a-k-a-disabling-histverify/</link>
      <pubDate>Sun, 16 Sep 2012 13:35:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/16/zsh-dont-verify-substituted-history-expansion-a-k-a-disabling-histverify/</guid>
      <description>I use zshon my Mac terminal and in general I prefer it to bash but it has an annoying default setting whereby when you try to repeat a command via substituted history expansion it asks you to verify that.
For example let&amp;rsquo;s say by mistake I try to vi into a directory rather than cd&amp;rsquo;ing into it:
vi ~/.oh-my-zsh If I try to cd into the directory by using &amp;lsquo;!$&amp;rsquo; to grab the last argument from the previous command it will make me confirm that I want to do this:</description>
    </item>
    
    <item>
      <title>cURL and the case of the carriage return</title>
      <link>https://markhneedham.com/blog/2012/09/15/curl-and-the-case-of-the-carriage-return/</link>
      <pubDate>Sat, 15 Sep 2012 09:06:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/15/curl-and-the-case-of-the-carriage-return/</guid>
      <description>We were doing some work this week where we needed to make a couple of calls to an API via a shell script and in the first call we wanted to capture one of the lines of the HTTP response headers and use that as in input to the second call.
The way we were doing this was something like the following:
#!/bin/bash # We were actually grabbing a different header but for the sake # of this post we&amp;#39;ll say it was &amp;#39;Set-Cookie&amp;#39; AUTH_HEADER=`curl -I http://www.</description>
    </item>
    
    <item>
      <title>Bash: Piping data into a command using heredocs</title>
      <link>https://markhneedham.com/blog/2012/09/15/bash-piping-data-into-a-command-using-heredocs/</link>
      <pubDate>Sat, 15 Sep 2012 07:54:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/15/bash-piping-data-into-a-command-using-heredocs/</guid>
      <description>I&amp;rsquo;ve been playing around with some data modelled in neo4j recently and one thing I wanted to do is run an adhoc query in the neo4j-shelland grab the results and do some text manipulation on them.
For example I wrote a query which outputted the following to the screen and I wanted to sum together all the values in the 3rd column:
| [&amp;#34;1&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;3&amp;#34;] | &amp;#34;3&amp;#34; | 1234567 | | [&amp;#34;4&amp;#34;,&amp;#34;5&amp;#34;,&amp;#34;6&amp;#34;] | &amp;#34;6&amp;#34; | 8910112 | Initially I was pasting the output into a text file and then running the following sequence of commands to work it out:</description>
    </item>
    
    <item>
      <title>Unix: Caught out by shell significant characters</title>
      <link>https://markhneedham.com/blog/2012/09/13/unix-caught-out-by-shell-significant-characters/</link>
      <pubDate>Thu, 13 Sep 2012 00:17:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/13/unix-caught-out-by-shell-significant-characters/</guid>
      <description>One of the applications that Philand I were deploying today needed a MySQL server and part of our puppet code to provision that node type runs a command to setup the privileges for a database user.
The unevaluated puppet code reads like this:
/usr/bin/mysql -h ${host} -uroot ${rootpassarg} -e &amp;#34;grant all on ${name}.* to ${user}@&amp;#39;${remote_host}&amp;#39; identified by &amp;#39;$password&amp;#39;; flush privileges;&amp;#34; In the application we were deploying that expanded into something like this:</description>
    </item>
    
    <item>
      <title>While waiting for VMs to provision...</title>
      <link>https://markhneedham.com/blog/2012/09/12/while-waiting-for-vms-to-provision/</link>
      <pubDate>Wed, 12 Sep 2012 22:53:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/12/while-waiting-for-vms-to-provision/</guid>
      <description>Philand I spent part of the day provisioning new virtual machines for some applications that we need to deploy which involves running a provisioning script and then opening another terminal and repeatedly trying to ssh into the box until it succeeds.
Eventually we got bored of doing that so we figured out a nice little one liner to use instead:
while :; do ssh 10.0.0.2; done The &amp;lsquo;:&amp;rsquo; is a bash noopand is defined like so:</description>
    </item>
    
    <item>
      <title>neo4j/cypher: CREATE UNIQUE - &#34;SyntaxException: string matching regex `$&#39; expected but `p&#39; found&#34;</title>
      <link>https://markhneedham.com/blog/2012/09/09/neo4jcypher-create-unique-syntaxexception-string-matching-regex-expected-but-p-found/</link>
      <pubDate>Sun, 09 Sep 2012 22:29:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/09/neo4jcypher-create-unique-syntaxexception-string-matching-regex-expected-but-p-found/</guid>
      <description>I&amp;rsquo;ve been playing around with the mutating cypher syntax of neo4j which allows you to make changes to the graph as well as query it, a feature introduced into cypher in May in release 1.8 M01.
I was trying to make use of the &amp;lsquo;CREATE UNIQUE&amp;rsquo; syntax which allows you to create nodes/relationships if they&amp;rsquo;re missing but won&amp;rsquo;t do anything if they already exists.
I had something like the following:</description>
    </item>
    
    <item>
      <title>logstash not picking up some files</title>
      <link>https://markhneedham.com/blog/2012/09/07/logstash-not-picking-up-some-files/</link>
      <pubDate>Fri, 07 Sep 2012 23:49:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/07/logstash-not-picking-up-some-files/</guid>
      <description>We&amp;rsquo;re using logstashto collect all the logs across the different machines that we use in various environments and had noticed that on some of the nodes log files which we&amp;rsquo;d told the logstash-client to track weren&amp;rsquo;t being collected.
We wanted to check what the open file descriptors of logstash-client were so we first had to grab its process id:
$ ps aux | grep logstash logstash 19896 134 9.1 711404 187768 ?</description>
    </item>
    
    <item>
      <title>Apt-Cacher-Server: Extra junk at end of file</title>
      <link>https://markhneedham.com/blog/2012/09/07/apt-cacher-server-extra-junk-at-end-of-file/</link>
      <pubDate>Fri, 07 Sep 2012 15:45:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/07/apt-cacher-server-extra-junk-at-end-of-file/</guid>
      <description>We&amp;rsquo;ve been installing Apt-Cache-Serverso that we can cache some of the packages that we&amp;rsquo;re installing using apt-get on our own network.
(Almost) Following the instructions from the home page we added the following to /etc/apt/apt.conf.d/01proxy:
Acquire::http::Proxy &amp;#34;http://apt-cache-server:3142&amp;#34; And when we ran &amp;lsquo;apt-get update&amp;rsquo; we were getting the following error:
E: Syntax error /etc/apt/apt.conf.d/01proxy:2: Extra junk at end of file We initially thought it must be a problem with having an extra space or line ending but it turns out we had just left off the semi colon.</description>
    </item>
    
    <item>
      <title>A rogue &#34;\357\273\277&#34; (UTF-8 byte order mark)</title>
      <link>https://markhneedham.com/blog/2012/09/03/a-rogue-357273277-utf-8-byte-order-mark/</link>
      <pubDate>Mon, 03 Sep 2012 06:31:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/03/a-rogue-357273277-utf-8-byte-order-mark/</guid>
      <description>We&amp;rsquo;ve been loading some data into neo4j from a CSV file - creating one node per row and using the value in the first column as the index lookup for the node.
Unfortunately the index lookup wasn&amp;rsquo;t working for the first row but was for every other row.
By coincidence we started saving each row into a hash map and were then able to see what was going wrong:
require &amp;#39;rubygems&amp;#39; require &amp;#39;fastercsv&amp;#39; things = FasterCSV.</description>
    </item>
    
    <item>
      <title>Book Review: The Retrospective Handbook - Pat Kua</title>
      <link>https://markhneedham.com/blog/2012/08/31/book-review-the-retrospective-handbook-pat-kua/</link>
      <pubDate>Fri, 31 Aug 2012 21:18:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/31/book-review-the-retrospective-handbook-pat-kua/</guid>
      <description>My colleague Pat Kuarecently published a book he&amp;rsquo;s been working on for the first half of the year titled &amp;lsquo;The Retrospective Handbook&amp;rsquo; - a book in which Pat shares his experiences with retrospectives and gives advice to budding facilitators.
I was intrigued what the book would be like because the skill gap between Pat and me with respect to facilitating retrospectives is huge and I&amp;rsquo;ve often found that experts in a subject can have a tendency to be a bit preachy when writing about their subject!</description>
    </item>
    
    <item>
      <title>The Curse Of Knowledge</title>
      <link>https://markhneedham.com/blog/2012/08/28/the-curse-of-knowledge/</link>
      <pubDate>Tue, 28 Aug 2012 21:22:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/28/the-curse-of-knowledge/</guid>
      <description>My colleague Anand Vishwanathrecently recommended the book &amp;lsquo;Made To Stick&amp;rsquo; and one thing that has really stood out for me while reading it is the idea of the &amp;lsquo;The Curse Of Knowledge&amp;rsquo; which is described like so:
This is certainly something I imagine that most people have experienced, perhaps for the first time at school when we realised that the best teacher of a subject isn&amp;rsquo;t necessarily the person who is best at the subject.</description>
    </item>
    
    <item>
      <title>Ruby: Finding where gems are</title>
      <link>https://markhneedham.com/blog/2012/08/25/ruby-finding-where-gems-are/</link>
      <pubDate>Sat, 25 Aug 2012 10:00:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/25/ruby-finding-where-gems-are/</guid>
      <description>In my infrequent travels into Ruby land I always seem to forget where the gems that I&amp;rsquo;ve installed actually live on the file system but my colleague Nickrecently showed me a neat way of figuring it out.
If I&amp;rsquo;m in the folder that contains all my ThoughtWorks graph code I&amp;rsquo;d just need to run the following command:
$ gem which rubygems /Users/mneedham/.rbenv/versions/jruby-1.6.7/lib/ruby/site_ruby/1.8/rubygems.rb I then loaded up irb and wrote a simple cypher query executed using neography:</description>
    </item>
    
    <item>
      <title>puppetdb: Failed to submit &#39;replace catalog&#39; command for client to PuppetDB at puppetmaster:8081: [500 Server Error]</title>
      <link>https://markhneedham.com/blog/2012/08/16/puppetdb-failed-to-submit-replace-catalog-command-for-client-to-puppetdb-at-puppetmaster8081-500-server-error/</link>
      <pubDate>Thu, 16 Aug 2012 23:31:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/16/puppetdb-failed-to-submit-replace-catalog-command-for-client-to-puppetdb-at-puppetmaster8081-500-server-error/</guid>
      <description>I&amp;rsquo;m still getting used to the idea of following the logswhen working out what&amp;rsquo;s going wrong with distributed systems but it worked well when trying to work out why our puppet client which was throwing this error when we ran &amp;lsquo;puppet agent -tdv&amp;rsquo;:
err: Could not retrieve catalog from remote server: Error 400 on SERVER: Failed to submit &amp;#39;replace catalog&amp;#39; command for client to PuppetDB at puppetmaster:8081: [500 Server Error] We were seeing the same error in /var/log/syslogon the puppet master and a quick look at the process list didn&amp;rsquo;t show that the puppet master or puppetdb services were under a particularly heavy load.</description>
    </item>
    
    <item>
      <title>Presentations; Tell a story</title>
      <link>https://markhneedham.com/blog/2012/08/14/presentations-tell-a-story/</link>
      <pubDate>Tue, 14 Aug 2012 22:16:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/14/presentations-tell-a-story/</guid>
      <description>A few years ago before an F# talk that I gave at the .NET user group in Sydney my colleague Erik Doernenburg gave me some advice about how I should structure the talk.
(paraphrasing)If two people give a talk on the same topic they therefore end up being fairly similar talks even though each person may have a totally different perspective.
Erik suggested that people would find it much more interesting if I told a story about what I&amp;rsquo;d learnt about my topic (in this case F#).</description>
    </item>
    
    <item>
      <title>SSHing onto machines via a jumpbox</title>
      <link>https://markhneedham.com/blog/2012/08/10/sshing-onto-machines-via-a-jumpbox/</link>
      <pubDate>Fri, 10 Aug 2012 00:58:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/10/sshing-onto-machines-via-a-jumpbox/</guid>
      <description>We wanted to be able to ssh into some machines which were behind a firewall so we set up a jumpboxwhich our firewall directed any traffic on port 22 towards.
Initially if we wanted to SSH onto a machine inside the network we&amp;rsquo;d have to do a two step process:
$ ssh jumpbox # now on the jumpbx $ ssh internal-network-machine That got a bit annoying after a while so Samshowed us a neat way of proxying the second ssh command through the first one by making use of netcat.</description>
    </item>
    
    <item>
      <title>VCloud Guest Customization Script : [: postcustomization: unexpected operator</title>
      <link>https://markhneedham.com/blog/2012/08/06/vcloud-guest-customization-script-postcustomization-unexpected-operator/</link>
      <pubDate>Mon, 06 Aug 2012 21:50:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/06/vcloud-guest-customization-script-postcustomization-unexpected-operator/</guid>
      <description>We have been doing some work to automatically provision machines using the VCloud API via fog and one of the things we wanted to do was run a custom script the first time that a node powers on.
The following explains how customization scripts work:
We wanted the script to run only when passed the &amp;lsquo;postcustomization&amp;rsquo; flag because our script relied on some networking configuration which hadn&amp;rsquo;t yet been done in the &amp;lsquo;precustomization&amp;rsquo; state.</description>
    </item>
    
    <item>
      <title>neo4j: Creating a custom index with neo4j.rb</title>
      <link>https://markhneedham.com/blog/2012/08/05/neo4j-creating-a-custom-index-with-neo4j-rb/</link>
      <pubDate>Sun, 05 Aug 2012 09:45:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/05/neo4j-creating-a-custom-index-with-neo4j-rb/</guid>
      <description>As I mentioned in my last postI&amp;rsquo;ve been playing around with the TFL Bus stop location and routes APIand one thing I wanted to do was load all the bus stops into a neo4j database using the neo4j.rbgem.
I initially populated the database via neographybut it was taking around 20 minutes each run and I figured it&amp;rsquo;d probably be much quicker to populate it directly rather than using the REST API.</description>
    </item>
    
    <item>
      <title>London Bus Stops API: Mapping northing/easting values to lat/long</title>
      <link>https://markhneedham.com/blog/2012/07/30/london-bus-stops-api-mapping-northingeasting-values-to-latlong/</link>
      <pubDate>Mon, 30 Jul 2012 22:28:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/30/london-bus-stops-api-mapping-northingeasting-values-to-latlong/</guid>
      <description>I started playing around with the TFL Bus stop location and routes APIand one of the annoying things about the data is that it uses easting/northingvalues to describe the location of bus stops rather than lat/longs.
The first few lines of the CSV filelook like this:
1000,91532,490000266G,WESTMINSTER STN &amp;lt;&amp;gt; / PARLIAMENT SQUARE,530171,179738,177,0K08,0 10001,72689,490013793E,TREVOR CLOSE,515781,174783,78,NB16,0 10002,48461,490000108F,HIGHBURY CORNER,531614,184603,5,C902,0 For each of the stops I wanted to convert from the easting/northing value to the equivalent lat/long value but I couldn&amp;rsquo;t find a simple way of doing it in code although I did come across an API that would do it for me.</description>
    </item>
    
    <item>
      <title>Puppet: Keeping the discipline</title>
      <link>https://markhneedham.com/blog/2012/07/29/puppet-keeping-the-discipline/</link>
      <pubDate>Sun, 29 Jul 2012 21:53:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/29/puppet-keeping-the-discipline/</guid>
      <description>For the last 5 weeks or so I&amp;rsquo;ve been working with puppetevery day to automate the configuration of various nodes in our stack and my most interesting observation so far is that you really need to keep your discipline when doing this type of work.
We can keep that discipline in three main ways when developing modules.
When it&amp;rsquo;s &amp;lsquo;just little bits&amp;rsquo; there is a massive temptation to make changes manually and then retrospectively put it into a puppet module and assume that it will workif we run from scratch.</description>
    </item>
    
    <item>
      <title>Unix: tee</title>
      <link>https://markhneedham.com/blog/2012/07/29/unix-tee/</link>
      <pubDate>Sun, 29 Jul 2012 19:11:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/29/unix-tee/</guid>
      <description>I&amp;rsquo;ve read about the Unix &amp;lsquo;tee&amp;rsquo; command before but never found a reason to use it until the last few weeks.
One of the things I repeatedly do by mistake is open /etc/hostswithout sudo and then try to make changes to it:
$ vi /etc/hosts # Editing it leads to the dreaded &amp;#39;W10: Changing a readonly file&amp;#39; I always used to close the file and then re-open it with sudo but I recently came across an approach which allows us to use &amp;lsquo;tee&amp;rsquo; to get around the problem.</description>
    </item>
    
    <item>
      <title>neo4j: Multiple starting nodes by index lookup</title>
      <link>https://markhneedham.com/blog/2012/07/28/neo4j-multiple-starting-nodes-by-index-lookup/</link>
      <pubDate>Sat, 28 Jul 2012 23:32:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/28/neo4j-multiple-starting-nodes-by-index-lookup/</guid>
      <description>I spent a bit of time this evening extracting some data from the ThoughtWorks graph for our marketing team who were interested in anything related to our three European offices in London, Manchester and Hamburg.
The most interesting things we can explore relate to the relationship between people and the offices.
The model around people and offices looks like this:
I added a &amp;lsquo;current_home_office&amp;rsquo; relationship to make it easier to quickly get to the nodes of people who are currently working in a specific office.</description>
    </item>
    
    <item>
      <title>R: Mapping a function over a collection of values</title>
      <link>https://markhneedham.com/blog/2012/07/23/r-mapping-a-function-over-a-collection-of-values/</link>
      <pubDate>Mon, 23 Jul 2012 23:25:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/23/r-mapping-a-function-over-a-collection-of-values/</guid>
      <description>I spent a bit of Sunday playing around with R and one thing I wanted to do was map a function over a collection of values and transform each value slightly.
I loaded my data set using the &amp;lsquo;Import Dataset&amp;rsquo; option in R Studio(suggested to me by Rob) which gets converted to the following function call:
&amp;gt; data &amp;lt;- read.csv(&amp;#34;~/data.csv&amp;#34;, header=T, encoding=&amp;#34;ISO-8859&amp;#34;) &amp;gt; data Column1 InterestingColumn 1 Mark 12.50 2 Dave 100.</description>
    </item>
    
    <item>
      <title>neo4j: Graph Global vs Graph Local queries</title>
      <link>https://markhneedham.com/blog/2012/07/23/neo4j-graph-global-vs-graph-local-queries/</link>
      <pubDate>Mon, 23 Jul 2012 22:23:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/23/neo4j-graph-global-vs-graph-local-queries/</guid>
      <description>A few weeks ago I did a presentation at the ThoughtWorks EU away day on the graph I&amp;rsquo;ve been developing using neo4j and I wanted to show who the most connected people in each of our European offices were.
I started with the following cypher query:
START n = node(*) MATCH n-[r:colleagues*1..2]-&amp;gt;c, n-[r2:member_of]-&amp;gt;office WHERE n.type? = &amp;#39;person&amp;#39; AND (NOT(HAS(r2.end_date))) AND office.name = &amp;#39;London - UK South&amp;#39; AND (NOT(HAS(c.thoughtquitter))) RETURN n.name, count(distinct(c)) AS connections, office.</description>
    </item>
    
    <item>
      <title>neo4j: Embracing the sub graph</title>
      <link>https://markhneedham.com/blog/2012/07/21/neo4j-embracing-the-sub-graph/</link>
      <pubDate>Sat, 21 Jul 2012 22:46:06 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/21/neo4j-embracing-the-sub-graph/</guid>
      <description>In May I wrote a blog post explaining how I&amp;rsquo;d been designing a neo4j graph by thinking about what questions I wanted to answer about the data.
In the comments Josh Adell gave me the following advice:
Keep your data model rich! Don&amp;rsquo;t be afraid to have as many relationships as you need. The power of graph databases comes from finding surprising results when you have strongly interconnected data.
At the time I didn&amp;rsquo;t really understand the advice but I&amp;rsquo;ve since updated my graph so that it includes &amp;lsquo;colleagues&amp;rsquo; relationships which can be derived by looking at the projects that people had worked together on.</description>
    </item>
    
    <item>
      <title>neo4j: Shortest Path with and without cypher</title>
      <link>https://markhneedham.com/blog/2012/07/19/neo4j-shortest-path-with-and-without-cypher/</link>
      <pubDate>Thu, 19 Jul 2012 19:57:31 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/19/neo4j-shortest-path-with-and-without-cypher/</guid>
      <description>I was looking back at some code I wrote a few months ago to query a neo4j database to find the shortest path between two people via the colleagues relationships that exist.
The initial code, written using neography, looked like this:
neo = Neography::Rest.new start_node = neo.get_node(start_node_id) destination_node = neo.get_node(destination_node_id) neo.get_paths(start_node, destination_node, { &amp;#34;type&amp;#34; =&amp;gt; &amp;#34;colleagues&amp;#34; }, depth = 3, algorithm = &amp;#34;shortestPath&amp;#34;) The neography code eventually makes a POST request to /node/{start_id}/pathsand provides a JSON payload containing the other information about the query.</description>
    </item>
    
    <item>
      <title>neo4j: java.security.NoSuchAlgorithmException: Algorithm [JKS] of type [KeyStore] from provider [org.bouncycastle.jce.provider.BouncyCastleProvider: name=BC version=1.4]</title>
      <link>https://markhneedham.com/blog/2012/07/17/neo4j-java-security-nosuchalgorithmexception-algorithm-jks-of-type-keystore-from-provider-org-bouncycastle-jce-provider-bouncycastleprovider-namebc-version1-4/</link>
      <pubDate>Tue, 17 Jul 2012 00:02:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/17/neo4j-java-security-nosuchalgorithmexception-algorithm-jks-of-type-keystore-from-provider-org-bouncycastle-jce-provider-bouncycastleprovider-namebc-version1-4/</guid>
      <description>I&amp;rsquo;ve spent the last couple of hours moving my neo4j graph from my own machine onto a vanilla CentOS VM and initially tried to run neo using a non Sun version of Java which I installed like so:
yum install java This is the version of Java that was installed:
$ java -version java version &amp;#34;1.5.0&amp;#34; gij (GNU libgcj) version 4.4.6 20120305 (Red Hat 4.4.6-4) When I tried to start neo4j:</description>
    </item>
    
    <item>
      <title>tcpdump: Learning how to read UDP packets</title>
      <link>https://markhneedham.com/blog/2012/07/15/tcpdump-learning-how-to-read-udp-packets/</link>
      <pubDate>Sun, 15 Jul 2012 13:29:05 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/15/tcpdump-learning-how-to-read-udp-packets/</guid>
      <description>Philand I spent some of Friday afternoon configuring statsd:
We configured it to listen on its default port 8125 and then used netcat to send UDP packetsto see if it was working like so:
echo -n &amp;#34;blah:36|c&amp;#34; | nc -w 1 -u -4 localhost 8125 We used tcpdump to capture any UDP packets on port 8125 like so:
tcpdump -i lo udp port 8125 -vv -X To briefly explain the options we passed to it:</description>
    </item>
    
    <item>
      <title>netcat: localhost resolution not working when sending UDP packets</title>
      <link>https://markhneedham.com/blog/2012/07/15/netcat-localhost-resolution-not-working-when-sending-udp-packets/</link>
      <pubDate>Sun, 15 Jul 2012 08:14:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/15/netcat-localhost-resolution-not-working-when-sending-udp-packets/</guid>
      <description>As part of some work we were doing last week Philand I needed to send UDP packets to a local port and check that they were being picked up.
We initially tried sending a UDP packet to localhost port 8125 using netcat like so:
echo -n &amp;#34;hello&amp;#34; | nc -w 1 -u localhost 8125 That message wasn&amp;rsquo;t being received by the application listening on the port so Phil decided to try and send the same packet from Ruby which worked fine:</description>
    </item>
    
    <item>
      <title>Racket: Wiring it up to a REPL ala SLIME/Swank</title>
      <link>https://markhneedham.com/blog/2012/07/11/racket-wiring-it-up-to-a-repl-ala-slimeswank/</link>
      <pubDate>Wed, 11 Jul 2012 19:34:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/11/racket-wiring-it-up-to-a-repl-ala-slimeswank/</guid>
      <description>One of the awesome things about working with clojure is that it&amp;rsquo;s possible to wire up clojure files in emacs to a REPL by making use of Slime/Swank.
I&amp;rsquo;ve started using Racketto work through the examples in The Little Schemerand wanted to achieve a similar thing there.
I don&amp;rsquo;t know much about configuring emacs so I made use of Phil Halgelberg&amp;rsquo;s emacs-starter-kit which is available on github.
On my travels I came across this video describing how to do exactly what I wanted.</description>
    </item>
    
    <item>
      <title>Data visualisation: Is &#39;interesting&#39; enough?</title>
      <link>https://markhneedham.com/blog/2012/07/08/data-visualisation-is-interesting-enough/</link>
      <pubDate>Sun, 08 Jul 2012 22:45:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/08/data-visualisation-is-interesting-enough/</guid>
      <description>I recently read a blog post by Julian Boot titled &amp;lsquo;visualisation without analysis is fine&amp;rsquo; where he suggests that we can learn things from visualising data in the right way - detailed statistical analysis isn&amp;rsquo;t always necessary.
I thought this was quite an interesting observation because over the past couple of months I&amp;rsquo;ve been playing around with ThoughtWorks data and looking at different ways to visualise aspects of the data.</description>
    </item>
    
    <item>
      <title>ganglia: Importing gmond Python modules</title>
      <link>https://markhneedham.com/blog/2012/07/08/ganglia-importing-gmond-python-modules/</link>
      <pubDate>Sun, 08 Jul 2012 21:55:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/08/ganglia-importing-gmond-python-modules/</guid>
      <description>My colleague Shohdanand I spent a couple of days last week wiring up various monitoring metrics into ganglia and while most of them come built in, we also found some python based modules that we wanted to use.
Unfortunately we couldn&amp;rsquo;t find any instructions on github explaining how to set them up but after a bit of trial and error we figured it out.
One of the modules that we wanted to use was diskstatwhich provides I/O wait time metrics which we couldn&amp;rsquo;t find in the built in modules.</description>
    </item>
    
    <item>
      <title>Bash Shell: Reusing parts of previous commands</title>
      <link>https://markhneedham.com/blog/2012/07/05/bash-shell-reusing-parts-of-previous-commands/</link>
      <pubDate>Thu, 05 Jul 2012 23:42:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/05/bash-shell-reusing-parts-of-previous-commands/</guid>
      <description>I&amp;rsquo;ve paired a few times with my colleague Phil Potterover the last couple of weeks and since he&amp;rsquo;s a bit of a ninja with bash shortcuts/commands I wanted to record some of the things he&amp;rsquo;s shown me so I won&amp;rsquo;t forget them!
Let&amp;rsquo;s say we&amp;rsquo;re in the &amp;lsquo;/tmp&amp;rsquo; directory and want to create a folder a few levels down but forget to pass the &amp;lsquo;-p&amp;rsquo; option to &amp;lsquo;mkdir&amp;rsquo;:
$ mkdir blah/de/blah mkdir: cannot create directory `blah/de/blah&amp;#39;: No such file or directory One way of fixing that would be to press the up arrow and navigate along the previous command and put in the &amp;lsquo;-p&amp;rsquo; flag but it&amp;rsquo;s a bit fiddly so instead we can do the following:</description>
    </item>
    
    <item>
      <title>sudo, sudo -i &amp; sudo su</title>
      <link>https://markhneedham.com/blog/2012/07/04/sudo-sudo-i-sudo-su/</link>
      <pubDate>Wed, 04 Jul 2012 19:34:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/04/sudo-sudo-i-sudo-su/</guid>
      <description>On the project I&amp;rsquo;m currently working on we&amp;rsquo;re doing quite a bit of puppet and although we&amp;rsquo;re using the puppet master approach in production &amp;amp; test environments it&amp;rsquo;s still useful to be able to run puppet headless to test changes locally.
Since several of the commands require having write access to &amp;lsquo;root&amp;rsquo; folders we need to run &amp;lsquo;puppet apply&amp;rsquo; as a super user using sudo. We also need to run it in the context of some environment variables which the root user has.</description>
    </item>
    
    <item>
      <title>Debugging: Google vs The Manual</title>
      <link>https://markhneedham.com/blog/2012/07/04/debugging-google-vs-the-manual/</link>
      <pubDate>Wed, 04 Jul 2012 00:00:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/04/debugging-google-vs-the-manual/</guid>
      <description>Over the last six months or so I&amp;rsquo;ve worked with a bunch of different people and one of the things that I&amp;rsquo;ve noticed is that when something isn&amp;rsquo;t working there tend to be two quite distinct ways that people go about trying to solve the problem.
The RTFMcrowd will go straight for the official documentation or source code if needs be in an attempt to work through the problem from first principals.</description>
    </item>
    
    <item>
      <title>Powerpoint saving movies as images</title>
      <link>https://markhneedham.com/blog/2012/06/30/powerpoint-saving-movies-as-images/</link>
      <pubDate>Sat, 30 Jun 2012 10:05:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/30/powerpoint-saving-movies-as-images/</guid>
      <description>I&amp;rsquo;ve been working on a presentation for the ThoughtWorks Europe away day over the last few days and I created some screen casts using Camtasiawhich I wanted to include.
It&amp;rsquo;s reasonably easy to insert movies into Powerpoint but I was finding that when I saved the file and then reloaded it the movies had been converted into images which wasn&amp;rsquo;t what I wanted at all!
Eventually I came across a blog post which explained that I&amp;rsquo;d been saving the file as the wrong format.</description>
    </item>
    
    <item>
      <title>neo4j: Handling optional relationships</title>
      <link>https://markhneedham.com/blog/2012/06/24/neo4j-handling-optional-relationships/</link>
      <pubDate>Sun, 24 Jun 2012 23:32:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/24/neo4j-handling-optional-relationships/</guid>
      <description>On my ThoughtWorks neo4j there are now two different types of relationships between people nodes - they can either be colleagues or one can be the sponsor of the other.
The graph looks like this:
I wanted to get a list of all the sponsor pairs but also have some indicator of whether the two people have worked together.
I started off by getting all of the sponsor pairs:
START n = node(*) MATCH n-[r:sponsor_of]-&amp;gt;n2 RETURN n.</description>
    </item>
    
    <item>
      <title>Why you shouldn&#39;t use name as a key a.k.a. I am an idiot</title>
      <link>https://markhneedham.com/blog/2012/06/24/why-you-shouldnt-use-name-as-a-key-a-k-a-i-am-an-idiot/</link>
      <pubDate>Sun, 24 Jun 2012 22:55:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/24/why-you-shouldnt-use-name-as-a-key-a-k-a-i-am-an-idiot/</guid>
      <description>I think one of the first things that I learnt about dealing with users in a data store is that you should never use name as a primary key because their might be two people with the same name.
Despite knowing that I foolishly chose to ignore this knowledge when building my neo4j graph and used name as the key for the Lucene index.
I thought I&amp;rsquo;d got away with it but NO!</description>
    </item>
    
    <item>
      <title>Brightbox Repository: GPG error: The following signatures couldn&#39;t be verified because the public key is not available</title>
      <link>https://markhneedham.com/blog/2012/06/24/brightbox-repository-gpg-error-the-following-signatures-couldnt-be-verified-because-the-public-key-is-not-available/</link>
      <pubDate>Sun, 24 Jun 2012 00:58:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/24/brightbox-repository-gpg-error-the-following-signatures-couldnt-be-verified-because-the-public-key-is-not-available/</guid>
      <description>We&amp;rsquo;re using the Brightbox Ruby repositoryto get the versions of Ruby which we install on our machines and although we eventually put the configuration for this repository into Puppet we initially tested it out on a local VM.
To start with you need to add the repository to /etc/apt/sources.list:
deb http://ppa.launchpad.net/brightbox/ruby-ng/ubuntu lucid main To get that picked up we run the following:
apt-get update Which initially threw this error because it&amp;rsquo;s a gpg signed repository and we hadn&amp;rsquo;t added the key:</description>
    </item>
    
    <item>
      <title>Creating a Samba share between Ubuntu and Mac OS X</title>
      <link>https://markhneedham.com/blog/2012/06/24/creating-a-samba-share-between-ubuntu-and-mac-os-x/</link>
      <pubDate>Sun, 24 Jun 2012 00:40:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/24/creating-a-samba-share-between-ubuntu-and-mac-os-x/</guid>
      <description>On the project I&amp;rsquo;m currently working on we have our development environment setup on a bare bones Ubuntu instance which we run via VmWare.
We wanted to be able to edit files on the VM from the host O/S so my colleague Philsuggested that we set up a Samba server on the VM and then connect to it from the Mac.
We first needed to install a couple of packages on the VM:</description>
    </item>
    
    <item>
      <title>Visualising a neo4j graph using gephi</title>
      <link>https://markhneedham.com/blog/2012/06/21/visualising-a-neo4j-graph-using-gephi/</link>
      <pubDate>Thu, 21 Jun 2012 05:02:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/21/visualising-a-neo4j-graph-using-gephi/</guid>
      <description>At ThoughtWorks we don&amp;rsquo;t have line managers but people can choose to have a sponsor - typically someone who has worked in the company for longer/has more experience in the industry than them - who can help them navigate the organisation better.
From hearing people talk about sponsors over the last 6 years it seemed like quite a few people sponsored the majority and there were probably a few people who didn&amp;rsquo;t have a sponsor.</description>
    </item>
    
    <item>
      <title>Haskell: Mixed type lists</title>
      <link>https://markhneedham.com/blog/2012/06/19/haskell-mixed-type-lists/</link>
      <pubDate>Tue, 19 Jun 2012 23:09:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/19/haskell-mixed-type-lists/</guid>
      <description>I&amp;rsquo;ve been continuing to work through the exercises in The Little Schemerand came across a problem which needed me to write a function to take a mixed list of Integers and Strings and filter out the Integers.
As I mentioned in my previous postI&amp;rsquo;ve been doing the exercises in Haskell but I thought I might struggle with that approach here because Haskell collections are homogeneous i.e. all the elements need to be of the same type.</description>
    </item>
    
    <item>
      <title>The Little Schemer: Attempt #2</title>
      <link>https://markhneedham.com/blog/2012/06/19/the-little-schemer-attempt-2/</link>
      <pubDate>Tue, 19 Jun 2012 00:21:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/19/the-little-schemer-attempt-2/</guid>
      <description>A few weeks ago I asked the twittersphere for some advice on how I could get better at writing recursive functions and one of the pieces of advice was to work through The Little Schemer.
I first heard about The Little Schemer a couple of years ago and after going through the first few pages I got bored and gave up.
I still found the first few pages a bit trivial this time around as well but my colleague Jen Smithencouraged me to keep going and once I&amp;rsquo;d got about 20 pages in it became clearer to me why the first few pages had been written the way they had.</description>
    </item>
    
    <item>
      <title>neo4j/Cypher: Finding the most connected node on the graph</title>
      <link>https://markhneedham.com/blog/2012/06/16/neo4jcypher-finding-the-most-connected-node-on-the-graph/</link>
      <pubDate>Sat, 16 Jun 2012 10:41:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/16/neo4jcypher-finding-the-most-connected-node-on-the-graph/</guid>
      <description>As I mentioned in another post about a month agoI&amp;rsquo;ve been playing around with a neo4j graph in which I have the following relationship between nodes:
One thing I wanted to do was work out which node is the most connected on the graph, which would tell me who&amp;rsquo;s worked with the most people.
I started off with the following cypher query:
query = &amp;#34; START n = node(*)&amp;#34; query &amp;lt;&amp;lt; &amp;#34; MATCH n-[r:colleagues]-&amp;gt;c&amp;#34; query &amp;lt;&amp;lt; &amp;#34; WHERE n.</description>
    </item>
    
    <item>
      <title>Functional Thinking: Separating concerns</title>
      <link>https://markhneedham.com/blog/2012/06/12/functional-thinking-separating-concerns/</link>
      <pubDate>Tue, 12 Jun 2012 23:50:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/12/functional-thinking-separating-concerns/</guid>
      <description>Over the weekend I was trying to port some of the neo4j import code for the ThoughtWorks graph I&amp;rsquo;ve been working on to make use of the REST Batch APIand I came across an interesting example of imperative vs functional thinking.
I&amp;rsquo;m using the neographygem to populate the graph and to start with I was just creating a person node and then creating an index entry for it:
people_to_load = Set.</description>
    </item>
    
    <item>
      <title>CSV parsing/UTF-8 encoding</title>
      <link>https://markhneedham.com/blog/2012/06/10/csv-parsingutf-8-encoding/</link>
      <pubDate>Sun, 10 Jun 2012 23:30:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/10/csv-parsingutf-8-encoding/</guid>
      <description>I was recently trying to parse a CSV file which I&amp;rsquo;d converted from an Excel spreadsheet but was having problems with characters beyond the standard character set.
This is an exampleof what was going wrong:
&amp;gt; require &amp;#39;csv&amp;#39; &amp;gt; people = CSV.open(&amp;#34;sponsors.csv&amp;#34;, &amp;#39;r&amp;#39;, ?,, ?\r).to_a [&amp;#34;Erik D\366rnenburg&amp;#34;, &amp;#34;N/A&amp;#34;] &amp;gt; people.each { |sponsee, sponsor| puts &amp;#34;#{sponsee}#{sponsor}&amp;#34; } Erik D?rnenburg N/A I came across a Ruby gem called chardetwhich allowed me to work out the character set of Erik&amp;rsquo;s name like so:</description>
    </item>
    
    <item>
      <title>Haskell: Writing a function that can take Ints or Doubles</title>
      <link>https://markhneedham.com/blog/2012/06/05/haskell-writing-a-function-that-can-take-ints-or-doubles/</link>
      <pubDate>Tue, 05 Jun 2012 00:10:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/05/haskell-writing-a-function-that-can-take-ints-or-doubles/</guid>
      <description>In my continued reading of SICP I wanted to recreate a &amp;lsquo;sum&amp;rsquo; function used to demonstrate a function which could take another function as one of its parameters.
In Scheme the function is defined like this:
(define (sum term a next b) (if (&amp;gt; a b) 0 (+ (term a) (sum term (next a) next b)))) And can be used like this to sum the values between two numbers:
(define (identity x) x) (define (sum-integers a b) (sum identity a inc b)) &amp;gt; (sum-integers 1 10) 55 I translated it into Haskell as the following:</description>
    </item>
    
    <item>
      <title>Haskell: Building a range of numbers from command line arguments</title>
      <link>https://markhneedham.com/blog/2012/06/03/haskell-building-a-range-of-numbers-from-command-line-arguments/</link>
      <pubDate>Sun, 03 Jun 2012 20:13:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/03/haskell-building-a-range-of-numbers-from-command-line-arguments/</guid>
      <description>I&amp;rsquo;m working through some of the SICP problemsin Haskell and for problem 1.22you need to write a function which will indicate the first 3 prime numbers above a starting value.
It is also suggested to only consider odd numbers so to find the prime numbers above 1000 the function call would look like this:
&amp;gt; searchForPrimes [1001,1003..] [1009,1013,1019] I wanted to be able to feed in the range of numbers from the command line so that I&amp;rsquo;d be able to call the function with different values and see how long it took to work it out.</description>
    </item>
    
    <item>
      <title>Google Maps without any labels/country names</title>
      <link>https://markhneedham.com/blog/2012/05/31/google-maps-without-any-labelscountry-names/</link>
      <pubDate>Thu, 31 May 2012 21:52:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/31/google-maps-without-any-labelscountry-names/</guid>
      <description>I wanted to get a blank version of Google Maps without any of the country names on for a visualisation I&amp;rsquo;m working on but I&amp;rsquo;d been led to believe that this wasn&amp;rsquo;t actually possible.
In actual fact we do have control over whether the labels are shownvia the &amp;lsquo;styles&amp;rsquo; optionwhich we can call on the map.
In my case the code looks like this:
var map = new google.maps.Map(document.getElementById(&amp;#34;map_canvas&amp;#34;), { zoom: 3, center: new google.</description>
    </item>
    
    <item>
      <title>Haskell: Using type classes to generify Project Euler #31</title>
      <link>https://markhneedham.com/blog/2012/05/30/haskell-using-type-classes-to-generify-project-euler-31/</link>
      <pubDate>Wed, 30 May 2012 12:08:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/30/haskell-using-type-classes-to-generify-project-euler-31/</guid>
      <description>As I mentioned in my previous post I&amp;rsquo;ve been working on Project Euler #31and initially wasn&amp;rsquo;t sure how to write the algorithm.
I came across a post on StackOverflow which explained it in more detailbut unfortunately the example used US coins rather than UK ones like in the Project Euler problem.
To start with I created two versions of the function - one for US coins and one for UK coins:</description>
    </item>
    
    <item>
      <title>Haskell: Java Style Enums</title>
      <link>https://markhneedham.com/blog/2012/05/30/haskell-java-style-enums/</link>
      <pubDate>Wed, 30 May 2012 11:10:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/30/haskell-java-style-enums/</guid>
      <description>I&amp;rsquo;ve been playing around with problem 31 of Project Eulerwhich is defined as follows:
1p, 2p, 5p, 10p, 20p, 50p, Â£1 (100p) and Â£2 (200p).
It is possible to make Â£2 in the following way:
1 Â£1 + 150p + 220p + 15p + 12p + 31p
How many different ways can Â£2 be made using any number of coins?
Having coded way too much in Java my first thought was that the coins could be represented as an Enum but I wasn&amp;rsquo;t sure how to do that in Haskell.</description>
    </item>
    
    <item>
      <title>Haskell: Finding the minimum &amp; maximum values of a Foldable in one pass</title>
      <link>https://markhneedham.com/blog/2012/05/28/haskell-finding-the-minimum-maximum-values-of-a-foldable-in-one-pass/</link>
      <pubDate>Mon, 28 May 2012 11:18:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/28/haskell-finding-the-minimum-maximum-values-of-a-foldable-in-one-pass/</guid>
      <description>I recently came across Dan Piponi&amp;rsquo;s blog post &amp;lsquo;Haskell Monoids &amp;amp; their Uses&amp;rsquo; and towards the end of the post he suggests creating monoids to work out the maximum and minimum values of a Foldable value in one pass.
The foldMap function applies a function to each element of our structure and then accumulates the return values of each of these applications.
A list is one example of a type which implements the Foldable type class like so:</description>
    </item>
    
    <item>
      <title>Haskell: Debugging code</title>
      <link>https://markhneedham.com/blog/2012/05/27/haskell-debugging-code/</link>
      <pubDate>Sun, 27 May 2012 22:16:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/27/haskell-debugging-code/</guid>
      <description>In my continued attempts to learn QuickCheck, one thing I&amp;rsquo;ve been doing is comparing the results of my brute forceand divide &amp;amp; conquer versionsof the closest pairs algorithm.
I started with this property:
let prop_dc_bf xs = (length xs &amp;gt; 2) ==&amp;gt; (fromJust $ bfClosest xs) == dcClosest xs And then ran it from GHCI, which resulted in the following error:
&amp;gt; quickCheck (prop_dc_bf :: [(Double, Double)] -&amp;gt; Property) *** Failed!</description>
    </item>
    
    <item>
      <title>Haskell: Using monoids when sorting by multiple parameters</title>
      <link>https://markhneedham.com/blog/2012/05/23/haskell-using-monoids-when-sorting-by-multiple-parameters/</link>
      <pubDate>Wed, 23 May 2012 06:44:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/23/haskell-using-monoids-when-sorting-by-multiple-parameters/</guid>
      <description>On the project I&amp;rsquo;ve been working on we had a requirement to sort a collection of rows by 4 different criteria such that if two items matched for the first criteria we should consider the second criteria and so on.
If we wrote that code in Haskell it would read a bit like this:
data Row = Row { shortListed :: Bool, cost :: Float, distance1 :: Int, distance2 :: Int } deriving (Show, Eq) import Data.</description>
    </item>
    
    <item>
      <title>Scala/Haskell: A simple example of type classes</title>
      <link>https://markhneedham.com/blog/2012/05/22/scalahaskell-a-simple-example-of-type-classes/</link>
      <pubDate>Tue, 22 May 2012 10:26:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/22/scalahaskell-a-simple-example-of-type-classes/</guid>
      <description>I never really understood type classes when I was working with Scala but I recently came across a video where Dan Rosen explains them pretty well.
Since the last time I worked in Scala I&amp;rsquo;ve been playing around with Haskell where type classes are much more common - for example if we want to compare two values we need to make sure that their type extends the &amp;lsquo;Eq&amp;rsquo; type class.</description>
    </item>
    
    <item>
      <title>Haskell: My first attempt with QuickCheck and HUnit</title>
      <link>https://markhneedham.com/blog/2012/05/20/haskell-my-first-attempt-with-quickcheck-and-hunit/</link>
      <pubDate>Sun, 20 May 2012 19:09:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/20/haskell-my-first-attempt-with-quickcheck-and-hunit/</guid>
      <description>As I mentioned in a blog post a few daysI&amp;rsquo;ve started learning QuickCheck with the test-frameworkpackage as suggested by David Turner.
I first needed to install test-framework and some dependencies using cabal:
&amp;gt; cabal install test-framework &amp;gt; cabal install test-framework-quickcheck &amp;gt; cabal install test-framework-hunit I thought it&amp;rsquo;d be interesting to try and write some tests around the windowed function that I wrote a few months ago:
Windowed.hsmodule Windowed (windowed) where windowed :: Int -&amp;gt; [a] -&amp;gt; [[a]] windowed size [] = [] windowed size ls@(x:xs) = if length ls &amp;gt;= size then (take size ls) : windowed size xs else windowed size x I wrote my first property like so:</description>
    </item>
    
    <item>
      <title>Building an API: Test Harness UI</title>
      <link>https://markhneedham.com/blog/2012/05/19/building-an-api-test-harness-ui/</link>
      <pubDate>Sat, 19 May 2012 20:03:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/19/building-an-api-test-harness-ui/</guid>
      <description>On the project I&amp;rsquo;ve been working on we&amp;rsquo;re building an API to be used by other applications in the organisation but when we started none of those applications were ready to integrate with us and therefore drive the API design.
Initially we tried driving the API through integration style tests but we realised that taking this approach made it quite difficult for us to imagine how an application would use it.</description>
    </item>
    
    <item>
      <title>Haskell: Writing a custom equality operator</title>
      <link>https://markhneedham.com/blog/2012/05/16/haskell-writing-a-custom-equality-operator/</link>
      <pubDate>Wed, 16 May 2012 13:16:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/16/haskell-writing-a-custom-equality-operator/</guid>
      <description>In the comments on my post about generating random numbersto test a function David Turner suggested that this was exactly the use case for which QuickCheckwas intended for so I&amp;rsquo;ve been learning a bit more about that this week.
I started with a simple property to check that the brute force (bf) and divide and conquer (dc) versions of the algorithm returned the same result, assuming that there were enough values in the list to have a closest pair:</description>
    </item>
    
    <item>
      <title>Haskell: Removing if statements</title>
      <link>https://markhneedham.com/blog/2012/05/12/haskell-removing-if-statements/</link>
      <pubDate>Sat, 12 May 2012 15:46:31 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/12/haskell-removing-if-statements/</guid>
      <description>When I was looking over my solution to the closest pairs algorithmwhich I wrote last week I realised there there were quite a few if statements, something I haven&amp;rsquo;t seen in other Haskell code I&amp;rsquo;ve read.
This is the initial version that I wrote:
dcClosest :: (Ord a, Floating a) =&amp;gt; [Point a] -&amp;gt; (Point a, Point a) dcClosest pairs if length pairs &amp;lt;= 3 then = fromJust $ bfClosest pairs else foldl (\closest (p1:p2:_) -&amp;gt; if distance (p1, p2) &amp;lt; distance closest then (p1, p2) else closest) closestPair (windowed 2 pairsWithinMinimumDelta) where sortedByX = sortBy compare pairs	(leftByX:rightByX:_) = chunk (length sortedByX `div` 2) sortedByX closestPair = if distance closestLeftPair &amp;lt; distance closestRightPair then closestLeftPair else closestRightPair where closestLeftPair = dcClosest leftByX closestRightPair = dcClosest rightByX pairsWithinMinimumDelta = sortBy (compare `on` snd) $ filter withinMinimumDelta sortedByX where withinMinimumDelta (x, _) = abs (xMidPoint - x) &amp;lt;= distance closestPair where (xMidPoint, _) = last leftByX We can remove the first if statement which checks the length of the list and replace it with pattern matching code like so:</description>
    </item>
    
    <item>
      <title>neo4j/Cypher: Finding the shortest path between two nodes while applying predicates</title>
      <link>https://markhneedham.com/blog/2012/05/12/neo4jcypher-finding-the-shortest-path-between-two-nodes-while-applying-predicates/</link>
      <pubDate>Sat, 12 May 2012 14:55:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/12/neo4jcypher-finding-the-shortest-path-between-two-nodes-while-applying-predicates/</guid>
      <description>As I mentioned in a blog post about a week agoI decided to restructure the ThoughtWorks graph I&amp;rsquo;ve modelled in neo4j so that I could explicitly model projects and clients.
As a result I had to update a traversal I&amp;rsquo;d written for finding the shortest path between two people in the graph.
The original traversal query I had was really simple because I had a direct connection between the people nodes:</description>
    </item>
    
    <item>
      <title>Haskell: Explicit type declarations in GHCI</title>
      <link>https://markhneedham.com/blog/2012/05/10/haskell-explicit-type-declarations-in-ghci/</link>
      <pubDate>Thu, 10 May 2012 07:11:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/10/haskell-explicit-type-declarations-in-ghci/</guid>
      <description>On a few occasions I&amp;rsquo;ve wanted to be able to explicitly define the type of something when trying things out in the Haskell REPL (GHCI) but I didn&amp;rsquo;t actually realise this was possible until a couple of days ago.
For example say we want to use the readfunction to parse an input string into an integer.
We could do this:
&amp;gt; read &amp;#34;1&amp;#34; :: Int 1 But if we just evaluate the function alone and try and assign the result without casting to a type we get an exception:</description>
    </item>
    
    <item>
      <title>Haskell: Closest Pairs Algorithm</title>
      <link>https://markhneedham.com/blog/2012/05/09/haskell-closest-pairs-algorithm/</link>
      <pubDate>Wed, 09 May 2012 00:05:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/09/haskell-closest-pairs-algorithm/</guid>
      <description>As I mentioned in a post a couple of days agoI&amp;rsquo;ve been writing the closest pairs algorithm in Haskell and while the brute force version works for small numbers of pairs it starts to fall apart as the number of pairs increases:
time ./closest_pairs 100 bf ./closest_pairs 100 bf 0.01s user 0.00s system 87% cpu 0.016 total time ./closest_pairs 1000 bf ./closest_pairs 1000 bf 3.59s user 0.01s system 99% cpu 3.</description>
    </item>
    
    <item>
      <title>Haskell: Generating random numbers</title>
      <link>https://markhneedham.com/blog/2012/05/08/haskell-generating-random-numbers/</link>
      <pubDate>Tue, 08 May 2012 22:09:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/08/haskell-generating-random-numbers/</guid>
      <description>As I mentioned in my last postI&amp;rsquo;ve been coding the closest pairs algorithm in Haskell and needed to create some pairs of coordinates to test it against.
I&amp;rsquo;ve tried to work out how to create lists of random numbers in Haskell before and always ended up giving up because it seemed way more difficult than it should be but this time I came across a really good explanation of how to do it by jrockway on Stack Overflow.</description>
    </item>
    
    <item>
      <title>Haskell: Maximum Int value</title>
      <link>https://markhneedham.com/blog/2012/05/07/haskell-maximum-int-value/</link>
      <pubDate>Mon, 07 May 2012 09:18:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/07/haskell-maximum-int-value/</guid>
      <description>One of the algorithms covered in Algo Classwas the closest pairs algorithm- an algorithm used to determine which pair of points on a plane are closest to each other based on their Euclidean distance.
My real interest lies in writing the divide and conquer version of the algorithm but I started with the brute force version so that I&amp;rsquo;d be able to compare my answers.
This is the algorithm:
minDist = infinity for each p in P: for each q in P: if p â‰  q and dist(p, q) &amp;lt; minDist: minDist = dist(p, q) closestPair = (p, q) return closestPair &amp;lsquo;infinity&amp;rsquo; in this case could be the maximum value that an Int could hold which on a 64 bit architecture would be 263so I hardcoded that into my implementation: o</description>
    </item>
    
    <item>
      <title>neo4j: What question do you want to answer?</title>
      <link>https://markhneedham.com/blog/2012/05/05/neo4j-what-question-do-you-want-to-answer/</link>
      <pubDate>Sat, 05 May 2012 13:20:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/05/neo4j-what-question-do-you-want-to-answer/</guid>
      <description>Over the past few weeks I&amp;rsquo;ve been modelling ThoughtWorks project data in neo4jand I realised that the way that I&amp;rsquo;ve been doing this is by considering what question I want to answerand then building a graph to answer it.
When I first started doing this the main question I wanted to answer was &amp;lsquo;how connected are people to each other&amp;rsquo; which led to me modelling the data like this:
The &amp;lsquo;colleagues with&amp;rsquo; relationship stored information about the project the two people had worked on together and how long they&amp;rsquo;d worked together.</description>
    </item>
    
    <item>
      <title>gephi: Centring a graph around an individual node</title>
      <link>https://markhneedham.com/blog/2012/04/30/gephi-centring-a-graph-around-an-individual-node/</link>
      <pubDate>Mon, 30 Apr 2012 22:20:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/30/gephi-centring-a-graph-around-an-individual-node/</guid>
      <description>I spent some time recently playing around with gephi- an open source platform for creating visualisations of graphs - to get a bit more insight into the ThoughtWorks graph which I&amp;rsquo;ve created in neo4j.
I followed Max De Marxi&amp;rsquo;s blog postto create a GEFX (Graph Exchange XML Format) file to use in gephi although I later learned that you can import directly from neo4j into gephi which I haven&amp;rsquo;t tried yet.</description>
    </item>
    
    <item>
      <title>Performance: Caching per request</title>
      <link>https://markhneedham.com/blog/2012/04/30/performance-caching-per-request/</link>
      <pubDate>Mon, 30 Apr 2012 21:45:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/30/performance-caching-per-request/</guid>
      <description>A couple of years ago I wrote a post describing an approach my then colleague Christian Blundenused to help improve the performance of an application where you try to do expensive things less or find another way to do them.
On the application I&amp;rsquo;m currently working on we load reference data from an Oracle database into memory based on configurations provided by the user.
There are multiple configurations and then multiple ways that those configurations can be priced so we have two nested for loops in which we load data and then perform calculations on it.</description>
    </item>
    
    <item>
      <title>Haskell: Colour highlighting when writing to the shell</title>
      <link>https://markhneedham.com/blog/2012/04/29/haskell-colour-highlighting-when-writing-to-the-shell/</link>
      <pubDate>Sun, 29 Apr 2012 00:01:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/29/haskell-colour-highlighting-when-writing-to-the-shell/</guid>
      <description>I spent a few hours writing a simple front end on top of the Rabin Karp algorithmso that I could show the line of the first occurrence of a pattern in a piece of text on the shell.
I thought it would be quite cool if I could highlight the appropriate text on the line like how grep doeswhen the &amp;lsquo;&amp;ndash;color=auto&amp;rsquo; flag is supplied.
We can make use of ANSI escape codesto do this.</description>
    </item>
    
    <item>
      <title>Haskell: Int and Integer</title>
      <link>https://markhneedham.com/blog/2012/04/28/haskell-int-and-integer/</link>
      <pubDate>Sat, 28 Apr 2012 17:39:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/28/haskell-int-and-integer/</guid>
      <description>In my last post about the Rabin Karp algorithmI mentioned that I was having some problems when trying to write a hash function which closely matched its English description.
This is my current version of the hash function:
hash = hash&amp;#39; globalR globalQ hash&amp;#39; r q string m = foldl (\acc x -&amp;gt; (r * acc + ord x) `mod` q) 0 $ take m string And my initial attempt to write the alternate version was this:</description>
    </item>
    
    <item>
      <title>Algorithms: Rabin Karp in Haskell</title>
      <link>https://markhneedham.com/blog/2012/04/25/algorithms-rabin-karp-in-haskell/</link>
      <pubDate>Wed, 25 Apr 2012 21:28:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/25/algorithms-rabin-karp-in-haskell/</guid>
      <description>I recently came across a blog post describing the Rabin Karp algorithm- an algorithm that uses hashing to find a pattern string in some text - and thought it would be interesting to try and write a version of it in Haskell.
This algorithm is typically used when we want to search for multiple pattern strings in a text e.g. when detecting plagiarism or a primitive way of detecting code duplication but my initial version only lets your search for one pattern.</description>
    </item>
    
    <item>
      <title>Algo Class: Start simple and build up</title>
      <link>https://markhneedham.com/blog/2012/04/24/algo-class-start-simple-and-build-up/</link>
      <pubDate>Tue, 24 Apr 2012 07:17:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/24/algo-class-start-simple-and-build-up/</guid>
      <description>Over the last six weeks I&amp;rsquo;ve been working through Stanford&amp;rsquo;s Design and Analysis of Algorithms Iclass and each week there&amp;rsquo;s been a programming assignment on a specific algorithm for which a huge data set is provided.
For the first couple of assignments I tried writing the code for the algorithm and then running it directly against the provided data set.
As you might imagine it never worked first time and this approach led to me becoming very frustrated because there&amp;rsquo;s no way of telling what went wrong.</description>
    </item>
    
    <item>
      <title>Coding: Is there a name for everything?</title>
      <link>https://markhneedham.com/blog/2012/04/23/coding-is-there-a-name-for-everything/</link>
      <pubDate>Mon, 23 Apr 2012 00:20:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/23/coding-is-there-a-name-for-everything/</guid>
      <description>A month ago I wrote a post describing an approach my team has been taking to avoid premature abstractionswhereby we leave code inline until we know enough about the domain to pull out meaningful classes or methods.
Since I wrote that post we&amp;rsquo;ve come across a couple of examples where there doesn&amp;rsquo;t seem to be a name to describe a data structure.
We are building a pricing engine where the input is a set of configurations and the output is a set of pricing rows associated with each configuration.</description>
    </item>
    
    <item>
      <title>neo4J: Searching for nodes by name</title>
      <link>https://markhneedham.com/blog/2012/04/20/neo4j-searching-for-nodes-by-name/</link>
      <pubDate>Fri, 20 Apr 2012 07:10:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/20/neo4j-searching-for-nodes-by-name/</guid>
      <description>As I mentioned in a post a few days ago I&amp;rsquo;ve been graphing connections between ThoughtWorks people using neo4j and wanted to build auto complete functionality so I can search for the names of people in the graph.
The solution I came up was to create a Lucene index with an entry for each node and a common property on each document in the index so that I&amp;rsquo;d be able to get all the index entries easily.</description>
    </item>
    
    <item>
      <title>Algorithms: Flood Fill in Haskell - Abstracting the common</title>
      <link>https://markhneedham.com/blog/2012/04/17/algorithms-flood-fill-in-haskell-abstracting-the-common/</link>
      <pubDate>Tue, 17 Apr 2012 07:22:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/17/algorithms-flood-fill-in-haskell-abstracting-the-common/</guid>
      <description>In the comments of my blog post describing the flood fill algorithm in HaskellDavid Turner pointed out that the way I was passing the grid around was quite error prone.
floodFill :: Array (Int, Int) Colour -&amp;gt; (Int, Int) -&amp;gt; Colour -&amp;gt; Colour -&amp;gt; Array (Int, Int) Colour floodFill grid point@(x, y) target replacement = if((not $ inBounds grid point) || grid ! (x,y) /= target) then grid else gridNorth where grid&amp;#39; = replace grid point replacement gridEast = floodFill grid&amp;#39; (x+1, y) target replacement gridWest = floodFill gridEast (x-1, y) target replacement gridSouth = floodFill gridWest (x, y+1) target replacement gridNorth = floodFill gridSouth (x, y-1) target replacement I actually did pass the wrong grid variable around while I was writing it and ended up quite confused as to why it wasn&amp;rsquo;t working as I expected.</description>
    </item>
    
    <item>
      <title>neography/neo4j/Lucene: Getting a list of all the nodes indexed</title>
      <link>https://markhneedham.com/blog/2012/04/17/neographyneo4jlucene-getting-a-list-of-all-the-nodes-indexed/</link>
      <pubDate>Tue, 17 Apr 2012 06:54:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/17/neographyneo4jlucene-getting-a-list-of-all-the-nodes-indexed/</guid>
      <description>I&amp;rsquo;ve been playing around with neo4j using the neographygem to create a graph of all the people in ThoughtWorks and the connections between them based on working with each other.
I created a UI where you could type in the names of two people and see when they&amp;rsquo;ve worked together or the path between the shortest path between them if they haven&amp;rsquo;t.
I thought it would be cool to have auto complete functionality when typing in a name but I couldn&amp;rsquo;t figure out how to partially query the index of people&amp;rsquo;s names that I&amp;rsquo;d created.</description>
    </item>
    
    <item>
      <title>Haskell: A simple parsing example using pattern matching</title>
      <link>https://markhneedham.com/blog/2012/04/15/haskell-a-simple-parsing-example-using-pattern-matching/</link>
      <pubDate>Sun, 15 Apr 2012 14:22:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/15/haskell-a-simple-parsing-example-using-pattern-matching/</guid>
      <description>As part of the second question in the Google Code JamI needed to be able to parse lines of data which looked like this:
3 1 5 15 13 11 where
This seemed like it should be easy to do but my initial search led me to the Parsec chapterin Real World Haskell which seemed a bit over the top for my problem.
All we really need to do is split on a space and then extract the parts of the resulting list.</description>
    </item>
    
    <item>
      <title>Haskell: Reading in multiple lines of arguments</title>
      <link>https://markhneedham.com/blog/2012/04/15/haskell-reading-in-multiple-lines-of-arguments/</link>
      <pubDate>Sun, 15 Apr 2012 13:44:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/15/haskell-reading-in-multiple-lines-of-arguments/</guid>
      <description>I&amp;rsquo;ve mostly avoided doing any I/O in Haskell but as part of the Google Code JamI needed to work out how to read a variable number of lines as specified by the user.
The input looks like this:
4 3 1 5 15 13 11 3 0 8 23 22 21 2 1 1 8 0 6 2 8 29 20 8 18 18 21 The first line indicates how many lines will follow.</description>
    </item>
    
    <item>
      <title>Ruby: neo4j gem - LoadError: no such file to load -- active_support/core_ext/class/inheritable_attributes</title>
      <link>https://markhneedham.com/blog/2012/04/14/ruby-neo4j-gem-loaderror-no-such-file-to-load-active_supportcore_extclassinheritable_attributes/</link>
      <pubDate>Sat, 14 Apr 2012 10:21:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/14/ruby-neo4j-gem-loaderror-no-such-file-to-load-active_supportcore_extclassinheritable_attributes/</guid>
      <description>I&amp;rsquo;ve been playing around with neo4j again over the past couple of days using the neo4j.rbgem to build up a graph.
I installed the gem but then ended up with the following error when I tried to &amp;lsquo;require neo4j&amp;rsquo; in &amp;lsquo;irb&amp;rsquo;:
LoadError: no such file to load -- active_support/core_ext/class/inheritable_attributes require at org/jruby/RubyKernel.java:1033 require at /Users/mneedham/.rbenv/versions/jruby-1.6.7/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:36 (root) at /Users/mneedham/.rbenv/versions/jruby-1.6.7/lib/ruby/gems/1.8/gems/neo4j-1.3.1-java/lib/neo4j.rb:9 require at org/jruby/RubyKernel.java:1033 require at /Users/mneedham/.rbenv/versions/jruby-1.6.7/lib/ruby/gems/1.8/gems/neo4j-1.3.1-java/lib/neo4j.rb:59 (root) at src/main/ruby/neo_test.rb:2 It seems a few others have come across this problem as welland the problem seems to be that ActiveSupport 3.</description>
    </item>
    
    <item>
      <title>Just Observe</title>
      <link>https://markhneedham.com/blog/2012/04/09/just-observe/</link>
      <pubDate>Mon, 09 Apr 2012 22:45:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/09/just-observe/</guid>
      <description>One of the most common instincts of a developer when starting on a new team is to look at the way the application has been designed and find ways that it can be done differently.
Most often &amp;lsquo;differently&amp;rsquo; means that a pattern used in a previous project will be favoured and while I think it&amp;rsquo;s good to make use of experience that we&amp;rsquo;ve gained, we do miss out on some learning if we write every application the same way.</description>
    </item>
    
    <item>
      <title>Haskell: Processing program arguments</title>
      <link>https://markhneedham.com/blog/2012/04/08/haskell-processing-program-arguments/</link>
      <pubDate>Sun, 08 Apr 2012 20:11:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/08/haskell-processing-program-arguments/</guid>
      <description>My Prismatic news feedrecently threw up an interesting tutorial titled &amp;lsquo;Haskell the Hard Way&amp;rsquo; which has an excellent and easy to understand section showing how to do IO in Haskell.
About half way down the page there&amp;rsquo;s an exercise to write a program which sums all its arguments which I thought I&amp;rsquo;d have a go at.
We need to use the System.getArgsfunction to get the arguments passed to the program. It has the following signature:</description>
    </item>
    
    <item>
      <title>Algorithms: Flood Fill in Haskell</title>
      <link>https://markhneedham.com/blog/2012/04/07/algorithms-flood-fill-in-haskell/</link>
      <pubDate>Sat, 07 Apr 2012 00:25:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/07/algorithms-flood-fill-in-haskell/</guid>
      <description>Flood fillis an algorithm used to work out which nodes are connected to a certain node in a multi dimensional array. In this case we&amp;rsquo;ll use a two dimensional array.
The idea is that we decide that we want to change the colour of one of the cells in the array and have its immediate neighbours who share its initial colour have their colour changed too i.e. the colour floods its way through the grid.</description>
    </item>
    
    <item>
      <title>Haskell: Print friendly representation of an Array</title>
      <link>https://markhneedham.com/blog/2012/04/03/haskell-print-friendly-representation-of-an-array/</link>
      <pubDate>Tue, 03 Apr 2012 21:52:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/03/haskell-print-friendly-representation-of-an-array/</guid>
      <description>Quite frequently I play around with 2D arrays in Haskell but I&amp;rsquo;ve never quite worked out how to print them in a way that makes it easy to see the contents.
I&amp;rsquo;m using the array from the &amp;lsquo;Data.Array&amp;rsquo; module because it seems to be easier to transform them into a new representation if I want to change a value in one of the cells.
The function to create one therefore looks like this:</description>
    </item>
    
    <item>
      <title>Haskell: Pattern matching data types with named fields</title>
      <link>https://markhneedham.com/blog/2012/03/31/haskell-pattern-matching-data-types-with-named-fields/</link>
      <pubDate>Sat, 31 Mar 2012 22:49:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/31/haskell-pattern-matching-data-types-with-named-fields/</guid>
      <description>One of my favourite things about coding in Haskell is that I often end up pattern matching against data types.
I&amp;rsquo;ve been playing around with modelling cars coming into and out from a car park and changing the state of the car park accordingly.
I started with these data type definitions:
data CarParkState = Available Bool Int Int | AlmostFull Bool Int Int | Full Bool Int deriving (Show) data Action = Entering | Leaving deriving (Show) data Sticker = Handicap | None deriving (Show) which were used in the following function:</description>
    </item>
    
    <item>
      <title>Micro Services: A simple example</title>
      <link>https://markhneedham.com/blog/2012/03/31/micro-services-a-simple-example/</link>
      <pubDate>Sat, 31 Mar 2012 09:06:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/31/micro-services-a-simple-example/</guid>
      <description>In our code base we had the concept of a &amp;lsquo;ProductSpeed&amp;rsquo; with two different constructors which initialised the object in different ways:
public class ProductSpeed { public ProductSpeed(String name) { ... } public ProductSpeed(String name, int order)) { } } In the cases where the first constructor was used the order of the product was irrelevant.
When the second constructor was used we did care about it because we wanted to be able sort the products before showing them in a drop down list to the user.</description>
    </item>
    
    <item>
      <title>IntelliJ: Find/Replace using regular expressions with capture groups</title>
      <link>https://markhneedham.com/blog/2012/03/30/intellij-findreplace-using-regular-expressions-with-capture-groups/</link>
      <pubDate>Fri, 30 Mar 2012 06:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/30/intellij-findreplace-using-regular-expressions-with-capture-groups/</guid>
      <description>Everyone now and then we end up having to write a bunch of mapping code and I quite like using IntelliJ&amp;rsquo;s &amp;lsquo;Replace&amp;rsquo; option to do it but always end up spending about 5 minutes trying to remember how to do capture groups so I thought I&amp;rsquo;d write it down this time.
Given the following text in our file:
val mark = 0 val dave = 0 val john = 0 val alex = 0 Let&amp;rsquo;s say we wanted to prefix each of those names with &amp;lsquo;cool&amp;rsquo; and had decided not to use Column mode for whatever reason.</description>
    </item>
    
    <item>
      <title>Readability/Performance</title>
      <link>https://markhneedham.com/blog/2012/03/29/readabilityperformance/</link>
      <pubDate>Thu, 29 Mar 2012 06:45:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/29/readabilityperformance/</guid>
      <description>I recently read the Graphite chapterof The Architecture of Open Source Applicationsbook which mostly tells the story of how Chris Davis incrementally built out Graphite- a pretty cool tool that can be used to do real time graphing of metrics.
The whole chapter is a very good read but I found the design reflections especially interesting:
One of the main success criteria of the application that I&amp;rsquo;m currently working on is its performance - it doesn&amp;rsquo;t have millisecond-ish latency requirements but it does need to do a lot of calculations and return within a reasonable amount of time.</description>
    </item>
    
    <item>
      <title>Testing: Trying not to overdo it</title>
      <link>https://markhneedham.com/blog/2012/03/28/testing-trying-not-to-overdo-it/</link>
      <pubDate>Wed, 28 Mar 2012 00:10:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/28/testing-trying-not-to-overdo-it/</guid>
      <description>The design of the code which contains the main logic of the application that I&amp;rsquo;m currently working on looks a bit like the diagram on the right hand side:
We load a bunch of stuff from an Oracle database, construct some objects from the data and then invoke a sequence of methods on those objects in order to execute our domain logic.
Typically we might expect to see unit level test against all the classes described in this diagram but we&amp;rsquo;ve actually been trying out an approach where we don&amp;rsquo;t test the orchestration code directly but rather only test it via the resource which makes use of it.</description>
    </item>
    
    <item>
      <title>Haskell: Memoization using the power of laziness</title>
      <link>https://markhneedham.com/blog/2012/03/24/haskell-memoization-using-the-power-of-laziness/</link>
      <pubDate>Sat, 24 Mar 2012 12:28:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/24/haskell-memoization-using-the-power-of-laziness/</guid>
      <description>I&amp;rsquo;ve been trying to solve problem 15 of Project Eulerwhich requires you to find the number of routes that can be taken to navigate from the top corner of a grid down to the bottom right corner.
For example there are six routes across a 2x2 grid:
My initial solution looked like this:
routes :: (Int, Int) -&amp;gt; Int -&amp;gt; Int routes origin size = inner origin size where inner origin@(x, y) size | x == size &amp;amp;&amp;amp; y == size = 0 | x == size || y == size = 1 | otherwise = inner (x+1, y) size + inner (x, y+1) size Which can be called like this:</description>
    </item>
    
    <item>
      <title>Saving the values of dynamically populated dropdown on back button</title>
      <link>https://markhneedham.com/blog/2012/03/24/saving-the-values-of-dynamically-populated-dropdown-on-back-button/</link>
      <pubDate>Sat, 24 Mar 2012 00:40:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/24/saving-the-values-of-dynamically-populated-dropdown-on-back-button/</guid>
      <description>We wanted to be able to retain the value of a drop down menu that was being dynamically populated (via an AJAX call) when the user hit the back button but the AJAX request re-runs when we go hit back therefore losing our selection.
Our initial thinking was that we might be able to store the value of the dropdown in a hidden field and then restore it into the dropdown using jQuery on page load but that approach didn&amp;rsquo;t work since hidden fields don&amp;rsquo;t seem to retain their values when you hit back.</description>
    </item>
    
    <item>
      <title>Oracle Spatial: Querying by a point/latitude/longitude</title>
      <link>https://markhneedham.com/blog/2012/03/23/oracle-spatial-querying-by-a-pointlatitudelongitude/</link>
      <pubDate>Fri, 23 Mar 2012 23:54:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/23/oracle-spatial-querying-by-a-pointlatitudelongitude/</guid>
      <description>We&amp;rsquo;re using Oracle Spatial on the application I&amp;rsquo;m working on and while most of the time any spatial queries we make are done from Java code we wanted to be able to run them directly from SQL as well to verify the code was working correctly.
We normally end up forgetting how to construct a query so I thought I&amp;rsquo;d document it.
Assuming we have a table table_with_shapewhich has a column shapewhich is a polygon, if we want to check whether a lat/long value interacts with that shape we can do that with the following query:</description>
    </item>
    
    <item>
      <title>Functional Programming: Handling the Options</title>
      <link>https://markhneedham.com/blog/2012/03/21/functional-programming-handling-the-options/</link>
      <pubDate>Wed, 21 Mar 2012 00:50:37 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/21/functional-programming-handling-the-options/</guid>
      <description>A couple of weeks ago Channing Walton tweeted the following:
As Channing points out in the comments he was referring to unguarded calls to &amp;lsquo;get&amp;rsquo; which would lead to an exception if the Option was empty, therefore pretty much defeating the point of using an Option in the first place!
We&amp;rsquo;re using Dan Bodart&amp;rsquo;s totallylazylibrary on the application I&amp;rsquo;m currently working on and in fact were calling &amp;lsquo;get&amp;rsquo; on an Option so I wanted to see if we could get rid of it.</description>
    </item>
    
    <item>
      <title>Haskell: Newbie currying mistake</title>
      <link>https://markhneedham.com/blog/2012/03/20/haskell-newbie-currying-mistake/</link>
      <pubDate>Tue, 20 Mar 2012 23:55:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/20/haskell-newbie-currying-mistake/</guid>
      <description>As I mentioned in my last postI&amp;rsquo;ve spent a bit of this evening writing a merge sort function and one of the mistakes I made a few times was incorrectly passing arguments to the recursive calls of &amp;lsquo;merge&amp;rsquo;.
For example, this is one of the earlier versions of the function:
middle :: [Int] -&amp;gt; Int middle = floor . (\y -&amp;gt; y / 2) . fromIntegral . length	msort :: [Int] -&amp;gt; [Int] msort unsorted = let n = middle unsorted in if n == 0 then unsorted else let (left, right) = splitAt n unsorted in merge (msort left) (msort right) where merge [] right = right merge left [] = left merge left@(x:xs) right@(y:ys) = if x &amp;lt; y then x : merge(xs, right) else y : merge (left, ys) Which doesn&amp;rsquo;t actually compile:</description>
    </item>
    
    <item>
      <title>Haskell: Chaining functions to find the middle value in a collection</title>
      <link>https://markhneedham.com/blog/2012/03/20/haskell-chaining-functions-to-find-the-middle-value-in-a-collection/</link>
      <pubDate>Tue, 20 Mar 2012 23:36:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/20/haskell-chaining-functions-to-find-the-middle-value-in-a-collection/</guid>
      <description>I&amp;rsquo;ve been playing around with writing merge sort in Haskell and eventually ended up with the following function:
msort :: [Int] -&amp;gt; [Int] msort unsorted = let n = floor (fromIntegral(length unsorted) / 2) in if n == 0 then unsorted else let (left, right) = splitAt n unsorted in merge (msort left) (msort right) where merge [] right = right merge left [] = left merge left@(x:xs) right@(y:ys) = if x &amp;lt; y then x : merge xs right else y : merge left ys The 3rd line was annoying me as it has way too many brackets on it and I was fairly sure that it should be possible to just combine the functions like I learnt to do in F# a few years ago.</description>
    </item>
    
    <item>
      <title>Scala: Counting number of inversions (via merge sort) for an unsorted collection</title>
      <link>https://markhneedham.com/blog/2012/03/20/scala-counting-number-of-inversions-via-merge-sort-for-an-unsorted-collection/</link>
      <pubDate>Tue, 20 Mar 2012 06:53:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/20/scala-counting-number-of-inversions-via-merge-sort-for-an-unsorted-collection/</guid>
      <description>The first programming questions of algo-classrequires you to calculate the number of inversions it would take using merge sort to sort a collection in ascending order.
I found quite a nice explanation here too:
e.g.
2 4 1 3 5
1 2 3 4 5
The sequence 2, 4, 1, 3, 5 has three inversions (2,1), (4,1), (4,3).
The simple/naive way of solving this problem is to iterate through the collection in two loops and compare each value and its current index with the others, looking for ones which are not in the right order.</description>
    </item>
    
    <item>
      <title>Functional Programming: One function at a time</title>
      <link>https://markhneedham.com/blog/2012/03/19/functional-programming-one-function-at-a-time/</link>
      <pubDate>Mon, 19 Mar 2012 23:25:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/19/functional-programming-one-function-at-a-time/</guid>
      <description>As I mentioned in an earlier post I got a bit stuck working out all the diagonals in the 20x20 grid of Project Euler problem 11and my colleague Uday ended up showing me how to do it.
I realised while watching him solve the problem that we&amp;rsquo;d been using quite different approaches to solving the problem and that his way worked way better than mine, at least in this context.</description>
    </item>
    
    <item>
      <title>Coding: Wait for the abstractions to emerge</title>
      <link>https://markhneedham.com/blog/2012/03/17/coding-wait-for-the-abstractions-to-emerge/</link>
      <pubDate>Sat, 17 Mar 2012 11:19:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/17/coding-wait-for-the-abstractions-to-emerge/</guid>
      <description>One of the things that I&amp;rsquo;ve learnt while developing code in an incremental way is that the way the code should be designed isn&amp;rsquo;t going to be obvious straight away so we need to be patience and wait for it to emerge.
There&amp;rsquo;s often a tendency to pull out classes or methods but more recently I&amp;rsquo;ve been trying to follow an approach where I leave the code in one class/method and play around with/study it until I see a good abstraction to make.</description>
    </item>
    
    <item>
      <title>Mercurial: hg push to Google Code</title>
      <link>https://markhneedham.com/blog/2012/03/14/mercurial-hg-push-to-google-code/</link>
      <pubDate>Wed, 14 Mar 2012 21:25:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/14/mercurial-hg-push-to-google-code/</guid>
      <description>I wanted to make a change to add flatMapto Optionin totallylazyso I had to clone the repositoryand make the change.
I thought I&amp;rsquo;d then be able to just push the change using my Google user name and password but instead ended up with the following error:
âžœ mhneedham-totally-lazy hg push pushing to https://m.h.needham@code.google.com/r/mhneedham-totally-lazy/ searching for changes 1 changesets found http authorization required realm: Google Code hg Repository user: m.h.needham password: abort: HTTP Error 403: Forbidden It turns out that you need to specifically set an option to use your Google account from the settings page:</description>
    </item>
    
    <item>
      <title>Functional Programming: Shaping the data to fit a function</title>
      <link>https://markhneedham.com/blog/2012/03/13/functional-programming-shaping-the-data-to-fit-a-function/</link>
      <pubDate>Tue, 13 Mar 2012 22:55:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/13/functional-programming-shaping-the-data-to-fit-a-function/</guid>
      <description>As I mentioned in my last post I&amp;rsquo;ve been working on Project Euler problem 11 and one thing I noticed was that I was shaping the data around a windowedfunction since it seemed to fit the problem quite well.
Problem 11is defined like so:
The product of these numbers is 26 63 78 14 = 1788696.
What is the greatest product of four adjacent numbers in any direction (up, down, left, right, or diagonally) in the 20x20 grid?</description>
    </item>
    
    <item>
      <title>Haskell: Couldn&#39;t match expected type `Int&#39; with actual type `Integer&#39;</title>
      <link>https://markhneedham.com/blog/2012/03/13/haskell-couldnt-match-expected-type-int-with-actual-type-integer/</link>
      <pubDate>Tue, 13 Mar 2012 19:42:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/13/haskell-couldnt-match-expected-type-int-with-actual-type-integer/</guid>
      <description>One of the most frequent compilation error messages that I&amp;rsquo;ve been getting while working through the Project Euler problems in Haskell is the following:
Couldn&amp;#39;t match expected type `Int&amp;#39; with actual type `Integer&amp;#39; In problem 11, for example, I define the grid of numbers like so:
grid = [[08,02,22,97,38,15,00,40,00,75,04,05,07,78,52,12,50,77,91,08], [49,49,99,40,17,81,18,57,60,87,17,40,98,43,69,48,04,56,62,00], [81,49,31,73,55,79,14,29,93,71,40,67,53,88,30,03,49,13,36,65], [52,70,95,23,04,60,11,42,69,24,68,56,01,32,56,71,37,02,36,91], [22,31,16,71,51,67,63,89,41,92,36,54,22,40,40,28,66,33,13,80], [24,47,32,60,99,03,45,02,44,75,33,53,78,36,84,20,35,17,12,50], [32,98,81,28,64,23,67,10,26,38,40,67,59,54,70,66,18,38,64,70], [67,26,20,68,02,62,12,20,95,63,94,39,63,08,40,91,66,49,94,21], [24,55,58,05,66,73,99,26,97,17,78,78,96,83,14,88,34,89,63,72], [21,36,23,09,75,00,76,44,20,45,35,14,00,61,33,97,34,31,33,95], [78,17,53,28,22,75,31,67,15,94,03,80,04,62,16,14,09,53,56,92], [16,39,05,42,96,35,31,47,55,58,88,24,00,17,54,24,36,29,85,57], [86,56,00,48,35,71,89,07,05,44,44,37,44,60,21,58,51,54,17,58], [19,80,81,68,05,94,47,69,28,73,92,13,86,52,17,77,04,89,55,40], [04,52,08,83,97,35,99,16,07,97,57,32,16,26,26,79,33,27,98,66], [88,36,68,87,57,62,20,72,03,46,33,67,46,55,12,32,63,93,53,69], [04,42,16,73,38,25,39,11,24,94,72,18,08,46,29,32,40,62,76,36], [20,69,36,41,72,30,23,88,34,62,99,69,82,67,59,85,74,04,36,16], [20,73,35,29,78,31,90,01,74,31,49,71,48,86,81,16,23,57,05,54], [01,70,54,71,83,51,54,69,16,92,33,48,61,43,52,01,89,19,67,48]] Which has the following type:</description>
    </item>
    
    <item>
      <title>Choosing where to put the complexity</title>
      <link>https://markhneedham.com/blog/2012/03/06/choosing-where-to-put-the-complexity/</link>
      <pubDate>Tue, 06 Mar 2012 01:17:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/06/choosing-where-to-put-the-complexity/</guid>
      <description>On the current application I&amp;rsquo;m working on we need to make use of some data which comes from another system so we&amp;rsquo;ve created an import script which creates a copy of that data so that we can use it in our application.
In general we&amp;rsquo;ve been trying not to do too much manipulation of the data and keeping it close to the initial structure so that if something goes wrong with the import we can more easily trace the problem back to the original data source.</description>
    </item>
    
    <item>
      <title>Haskell: Creating a sliding window over a collection</title>
      <link>https://markhneedham.com/blog/2012/02/28/haskell-creating-a-sliding-window-over-a-collection/</link>
      <pubDate>Tue, 28 Feb 2012 00:21:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/28/haskell-creating-a-sliding-window-over-a-collection/</guid>
      <description>A couple of years ago when I was playing around with F# I came across the Seq.windowedfunction which allows you to create a sliding window of a specific size over a collection.
Taking an example from the F# documentation page:
let seqNumbers = [ 1.0; 1.5; 2.0; 1.5; 1.0; 1.5 ] :&amp;gt; seq&amp;lt;float&amp;gt; let seqWindows = Seq.windowed 3 seqNumbers We end up with this:
Initial sequence: 1.0 1.5 2.0 1.5 1.</description>
    </item>
    
    <item>
      <title>Haskell: Getting the nth element in a list</title>
      <link>https://markhneedham.com/blog/2012/02/28/haskell-getting-the-nth-element-in-a-list/</link>
      <pubDate>Tue, 28 Feb 2012 00:02:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/28/haskell-getting-the-nth-element-in-a-list/</guid>
      <description>I started trying to solve some of the Project Euler problemsas a way to learn a bit of Haskell and problem 7is defined like so:
What is the 10 001st prime number?
I read that the Sieve of Eratosthenesis a useful algorithm for working out all the prime numbers and there&amp;rsquo;s a page on the Literate Programs wiki explaining how to derive them using it.
The most naive implementation of all the primes ends up reading like this:</description>
    </item>
    
    <item>
      <title>Java: Faking a closure with a factory to create a domain object</title>
      <link>https://markhneedham.com/blog/2012/02/26/java-faking-a-closure-with-a-factory-to-create-a-domain-object/</link>
      <pubDate>Sun, 26 Feb 2012 00:09:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/26/java-faking-a-closure-with-a-factory-to-create-a-domain-object/</guid>
      <description>Recently we wanted to create a domain object which needed to have an external dependency in order to do a calculation and we wanted to be able to stub out that dependency in our tests.
Originally we were just new&amp;rsquo;ing up the dependency inside the domain class but that makes it impossible to control it&amp;rsquo;s value in a test.
Equally it didn&amp;rsquo;t seem like we should be passing that dependency into the constructor of the domain object since it&amp;rsquo;s not a piece of state which defines the object, just something that it uses.</description>
    </item>
    
    <item>
      <title>Haskell: Viewing the steps of a reduce</title>
      <link>https://markhneedham.com/blog/2012/02/25/haskell-viewing-the-steps-of-a-reduce/</link>
      <pubDate>Sat, 25 Feb 2012 23:40:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/25/haskell-viewing-the-steps-of-a-reduce/</guid>
      <description>I&amp;rsquo;ve been playing around with Haskell a bit over the last week and in the bit of code I was working on I wanted to fold over a collection but see the state of the fold after each step.
I remembered Don Syme showing me how to do something similar during the F# Exchange last year while we were writing some code to score a tennis gameby using Seq.scan.
I didn&amp;rsquo;t realise there was also a scan function in Haskell which could be defined in terms of foldlif we wanted to:</description>
    </item>
    
    <item>
      <title>Thou shalt storm</title>
      <link>https://markhneedham.com/blog/2012/02/24/thou-shalt-storm/</link>
      <pubDate>Fri, 24 Feb 2012 02:03:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/24/thou-shalt-storm/</guid>
      <description>On the majority of the teams that I&amp;rsquo;ve worked on there&amp;rsquo;s been a time where everyone seems to be disagreeing with each other about almost everything and the whole situation becomes pretty tense for all involved.
The first time I came across this it seemed quite dysfunctional but I was introduced to Bruce Tuckman&amp;rsquo;s model of group developmentwhich helps to explain what&amp;rsquo;s going on.
Tuckman outlines four stages which teams tend to go through - forming, storming, norming and performing.</description>
    </item>
    
    <item>
      <title>Optimising for typing</title>
      <link>https://markhneedham.com/blog/2012/02/21/optimising-for-typing/</link>
      <pubDate>Tue, 21 Feb 2012 22:21:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/21/optimising-for-typing/</guid>
      <description>My colleague Ola Bini recently wrote a post describing his thoughts on the syntax of programming languagesand while the post in general is interesting the bit that most resonates with me at the moment is the following:
On the application I&amp;rsquo;m currently working on we have a full time DBA on the team who favours a much more concise style of naming in tables than most developers would be used to.</description>
    </item>
    
    <item>
      <title>Coding: Packaging by vertical slice</title>
      <link>https://markhneedham.com/blog/2012/02/20/coding-packaging-by-vertical-slice/</link>
      <pubDate>Mon, 20 Feb 2012 21:54:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/20/coding-packaging-by-vertical-slice/</guid>
      <description>On most of the applications I&amp;rsquo;ve worked on we&amp;rsquo;ve tended to organise/package classes by the function that they have or the layer that they fit in.
A typical package structure might therefore end up looking like this:
This works reasonably well and allows you to find code which is similar in function but I find that more often than not a lot of the code that lives immediately around where you currently are isn&amp;rsquo;t actually relevant at the time.</description>
    </item>
    
    <item>
      <title>Tech Leads &amp; The Progress Principle</title>
      <link>https://markhneedham.com/blog/2012/02/18/tech-leads-the-progress-principle/</link>
      <pubDate>Sat, 18 Feb 2012 01:31:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/18/tech-leads-the-progress-principle/</guid>
      <description>I&amp;rsquo;ve been reading The Progress Principleon and off for the last couple of months and one of my favourite quotes from the book is the following:
While a tech lead might not like to be referred to as a manager I think part of the role does involve helping developers to make progressand the best ones I&amp;rsquo;ve worked with seem to do that instinctively.
They&amp;rsquo;re able to see when someone has got very stuck with what they&amp;rsquo;re doing and can then work out whether they just need to provide some advice on how they can move forward or if that&amp;rsquo;s not working they can come and work together on the problem.</description>
    </item>
    
    <item>
      <title>Reading Code: boilerpipe</title>
      <link>https://markhneedham.com/blog/2012/02/13/reading-code-boilerpipe/</link>
      <pubDate>Mon, 13 Feb 2012 21:16:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/13/reading-code-boilerpipe/</guid>
      <description>I&amp;rsquo;m a big fan of the iPad application Flipboard, especially it&amp;rsquo;s ability to filter out the non important content on web pages and just show me the main content so I&amp;rsquo;ve been looking around at open source libraries which provide that facility.
I came across a quora page where someone had asked how this was doneand the suggested libraries were readability, Gooseand boilerpipe.
boilerpipe was written by Christian KohlschÃ¼tter and has a corresponding paperand videoas well.</description>
    </item>
    
    <item>
      <title>Oracle Spatial: java.sql.SQLRecoverableException: No more data to read from socket</title>
      <link>https://markhneedham.com/blog/2012/02/11/oracle-spatial-java-sql-sqlrecoverableexception-no-more-data-to-read-from-socket/</link>
      <pubDate>Sat, 11 Feb 2012 10:55:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/11/oracle-spatial-java-sql-sqlrecoverableexception-no-more-data-to-read-from-socket/</guid>
      <description>We&amp;rsquo;re using Oracle Spatial on my current project so that we can locate points within geographical regions and decided earlier in the week to rename the table where we store the SDO_GEOMETRYobjects for each region.
We did that by using a normal table alter statement but then started seeing the following error when we tried to insert test data in that column which takes an SDO_GEOMETRY object:
org.hibernate.exception.JDBCConnectionException: could not execute native bulk manipulation query at org.</description>
    </item>
    
    <item>
      <title>Java: Fooled by java.util.Arrays.asList</title>
      <link>https://markhneedham.com/blog/2012/02/11/java-fooled-by-java-util-arrays-aslist/</link>
      <pubDate>Sat, 11 Feb 2012 10:29:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/11/java-fooled-by-java-util-arrays-aslist/</guid>
      <description>I&amp;rsquo;ve been playing around with the boilerpipecode base by writing some tests around it to check my understanding but ran into an interesting problem using java.util.Arrays.asListto pass a list into one of the functions.
I was testing the BlockProximityFusionclass which is used to merge together adjacent text blocks.
I started off calling that class like this:
import static java.util.Arrays.asList; @Test public void willCallBlockProximityFustion() throws Exception { TextDocument document = new TextDocument(asList(contentBlock(&amp;#34;some words&amp;#34;), contentBlock(&amp;#34;followed by more words&amp;#34;))); BlockProximityFusion.</description>
    </item>
    
    <item>
      <title>Downloading the JDK 6 source code</title>
      <link>https://markhneedham.com/blog/2012/02/11/downloading-the-jdk-6-source-code/</link>
      <pubDate>Sat, 11 Feb 2012 10:02:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/11/downloading-the-jdk-6-source-code/</guid>
      <description>Every now and then I want to get the JDK source code onto a new machine and it always seems to take me longer than I expect it to so this post is an attempt to help future me!
Googling for this takes me to this pageand I always think I&amp;rsquo;ll just checkout the SVN repositoryand hook that up but it doesn&amp;rsquo;t seem to be available.
$ wget -S http://java.net/projects/jdk-jrl-sources/ --2012-02-11 09:51:34-- http://java.</description>
    </item>
    
    <item>
      <title>Delivery approach and constraints</title>
      <link>https://markhneedham.com/blog/2012/02/08/delivery-approach-and-constraints/</link>
      <pubDate>Wed, 08 Feb 2012 22:34:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/08/delivery-approach-and-constraints/</guid>
      <description>In my latest post I described an approach we&amp;rsquo;d been taking when analysing how to rewrite part of an existing system so that we could build the new version in an incremental way.
Towards the end I pointed out that we weren&amp;rsquo;t actually going to be using an incremental approach as we&amp;rsquo;d initially thought which was due to a couple of constraints that we have to work under.
Unfortunately we later on came to learn that it takes around 6-9 months to provision production hardware.</description>
    </item>
    
    <item>
      <title>Looking for the seam</title>
      <link>https://markhneedham.com/blog/2012/02/06/looking-for-the-seam/</link>
      <pubDate>Mon, 06 Feb 2012 22:22:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/06/looking-for-the-seam/</guid>
      <description>During December/early January we spent some time analysing an existing system which we were looking to rewrite and our approach was to look for how we could do this in an incremental way.
In order to do that we needed to look for what Michael Feathers refers to as a seam:
On previous times when I&amp;rsquo;ve been thinking about seams it&amp;rsquo;s been at a code level inside a single application but this time there were more than one pieces interacting.</description>
    </item>
    
    <item>
      <title>Scala: Converting a scala collection to java.util.List</title>
      <link>https://markhneedham.com/blog/2012/02/05/scala-converting-a-scala-collection-to-java-util-list/</link>
      <pubDate>Sun, 05 Feb 2012 21:40:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/05/scala-converting-a-scala-collection-to-java-util-list/</guid>
      <description>I&amp;rsquo;ve been playing around a little with Goose- a library for extracting the main body of text from web pages - and I thought I&amp;rsquo;d try converting some of the code to be more scala-esque in style.
The API of the various classes/methods is designed so it&amp;rsquo;s interoperable with Java code but in order to use functions like map/filter we need the collection to be a Scala one.
That&amp;rsquo;s achieved by importing &amp;lsquo;scala.</description>
    </item>
    
    <item>
      <title>Oracle: dbstart - ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener</title>
      <link>https://markhneedham.com/blog/2012/01/26/oracle-dbstart-oracle_home_listner-is-not-set-unable-to-auto-start-oracle-net-listener/</link>
      <pubDate>Thu, 26 Jan 2012 21:58:27 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/26/oracle-dbstart-oracle_home_listner-is-not-set-unable-to-auto-start-oracle-net-listener/</guid>
      <description>We ran into an interesting problem when trying to start up an Oracle instance using dbstartwhereby we were getting the following error:
-bash-3.2$ dbstart ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener Usage: /u01/app/oracle/product/11.2.0/dbhome_1/bin/dbstart ORACLE_HOME Processing Database instance &amp;#34;orcl&amp;#34;: log file /u01/app/oracle/product/11.2.0/dbhome_1/startup.log Ignoring the usage message we thought that setting the environment variable was what we needed to do, but&amp;hellip;
-bash-3.2$ export ORACLE_HOME_LISTNER=$ORACLE_HOME -bash-3.2$ dbstart ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener Usage: /u01/app/oracle/product/11.</description>
    </item>
    
    <item>
      <title>Developer machine automation: Dependencies</title>
      <link>https://markhneedham.com/blog/2012/01/24/developer-machine-automation-dependencies/</link>
      <pubDate>Tue, 24 Jan 2012 23:16:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/24/developer-machine-automation-dependencies/</guid>
      <description>As I mentioned in a post last weekwe&amp;rsquo;ve been automating the setup of our developer machines with puppet over the last week and one thing that we&amp;rsquo;ve learnt is that you need to be careful about how you define dependencies.
The aim is to get your scripts to the point where the outcome is reasonably deterministic so that we can have confidence they&amp;rsquo;re going to work the next we run them.</description>
    </item>
    
    <item>
      <title>Playing around with pomodoros</title>
      <link>https://markhneedham.com/blog/2012/01/22/playing-around-with-pomodoros/</link>
      <pubDate>Sun, 22 Jan 2012 21:25:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/22/playing-around-with-pomodoros/</guid>
      <description>Over the last 3/4 months I&amp;rsquo;ve been playing around with the idea of using pomodorosto track all coding/software related stuff that I do outside of work.
I originally started using this technique while I was doing the programming assignments for ml-classbecause I wanted to know how much time I was spending on it each week and make sure I didn&amp;rsquo;t run down rabbit holes too often.
One interesting observation that I noticed from keeping the data of these pomodoros was that while during the early programming assignments it would take me 7 or 8 pomodoros to finish, by the end it was down to around 4.</description>
    </item>
    
    <item>
      <title>Installing Puppet on Oracle Linux</title>
      <link>https://markhneedham.com/blog/2012/01/18/installing-puppet-on-oracle-linux/</link>
      <pubDate>Wed, 18 Jan 2012 00:30:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/18/installing-puppet-on-oracle-linux/</guid>
      <description>We&amp;rsquo;ve been spending some time trying to setup our developer environment on a Oracle Linux 5.7 build and one of the first steps was to install Puppet as we&amp;rsquo;ve already created scripts which automate the installation of most things.
Unfortunately Oracle Linux builds don&amp;rsquo;t come with any yum repos configured so when you run the following command&amp;hellip;
ls -alh /etc/yum.repos.d/ &amp;hellip;you don&amp;rsquo;t see anything :(
We eventually realised that there are a list of public yum repositories on the Oracle website, of which we needed to download the definition for Oracle Linux 5 like so:</description>
    </item>
    
    <item>
      <title>Application footprint</title>
      <link>https://markhneedham.com/blog/2012/01/16/application-footprint/</link>
      <pubDate>Mon, 16 Jan 2012 01:40:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/16/application-footprint/</guid>
      <description>I recently came across Carl Erickson&amp;rsquo;s &amp;lsquo;small teams are dramatically more efficient than large teams&amp;rsquo; blog post which reminded me of something which my colleague Ashoksuggested as a useful way for determining team size - the application footprint.
As I understand it the application footprint is applicable for an application at a given point in time and determines how many parallel tasks/streams of work we have.
In the case of the project that I&amp;rsquo;m currently working on there are 3 separate components which need to interact with each other via an API but otherwise are independent.</description>
    </item>
    
    <item>
      <title>Focused Retrospectives: things to watch for</title>
      <link>https://markhneedham.com/blog/2012/01/16/focused-retrospectives-things-to-watch-for/</link>
      <pubDate>Mon, 16 Jan 2012 01:01:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/16/focused-retrospectives-things-to-watch-for/</guid>
      <description>A few weeks ago a slide deck from an Esther Derby presentation on retrospectiveswas doing the rounds on twitter and one thing that I found interesting in the deck was the suggestion that a retrospective needs to be focused in some way.
I&amp;rsquo;ve participated in a few focused retrospectives over the past 7/8 months and I think there are some things to be careful about when we decide to focus on something specific rather than just looking back at a time period in general.</description>
    </item>
    
    <item>
      <title>Wireshark: Following HTTP requests/responses</title>
      <link>https://markhneedham.com/blog/2012/01/14/wireshark-following-http-requestsresponses/</link>
      <pubDate>Sat, 14 Jan 2012 23:20:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/14/wireshark-following-http-requestsresponses/</guid>
      <description>I like using Wiresharkto have a look at the traffic going across different interfaces but because it shows what&amp;rsquo;s happening across the wire by the packet it&amp;rsquo;s quite difficult to tell what a request/response looked like.
I&amp;rsquo;ve been playing around with restfulie/Vraptortoday so I wanted to be able to see the request/response pair when something wasn&amp;rsquo;t working.
I didn&amp;rsquo;t know it was actually possible but this post on StackOverflow describes how.</description>
    </item>
    
    <item>
      <title>Oracle: exp -  EXP-00008: ORACLE error 904 encountered/ORA-00904: &#34;POLTYP&#34;: invalid identifier</title>
      <link>https://markhneedham.com/blog/2012/01/13/oracle-exp-exp-00008-oracle-error-904-encounteredora-00904-poltyp-invalid-identifier/</link>
      <pubDate>Fri, 13 Jan 2012 21:46:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/13/oracle-exp-exp-00008-oracle-error-904-encounteredora-00904-poltyp-invalid-identifier/</guid>
      <description>I spent a bit of time this afternoon trying to export an Oracle test database so that we could use it locally using the exptool.
I had to connect to exp like this:
exp user/password@remote_address And then filled in the other parameters interactively.
Unfortunately when I tried to actually export the specified tables I got the following error message:
EXP-00008: ORACLE error 904 encountered ORA-00904: &amp;#34;POLTYP&amp;#34;: invalid identifier EXP-00000: Export terminated unsuccessfully I eventually came across Oyvind Isene&amp;rsquo;s blog post which pointed out that you&amp;rsquo;d get this problem if you tried to export a 10g database using an 11g clientwhich is exactly what I was trying to do!</description>
    </item>
    
    <item>
      <title>Learning Android: Roboguice - Injecting context into PreferenceManager</title>
      <link>https://markhneedham.com/blog/2012/01/12/learning-android-roboguice-injecting-context-into-preferencemanager/</link>
      <pubDate>Thu, 12 Jan 2012 17:24:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/12/learning-android-roboguice-injecting-context-into-preferencemanager/</guid>
      <description>In my last post I showed how I&amp;rsquo;d been able to write a test around saved preferences in my app by making use of a ShadowPreferenceManagerbut it seemed a bit hacky.
I didn&amp;rsquo;t want to have to do that for every test where I dealt with preferences - I thought it&amp;rsquo;d be better if I could wrap the preferences in an object of my own and then inject it where necessary.</description>
    </item>
    
    <item>
      <title>Learning Android: Robolectric - Testing details got saved to SharedPreferences</title>
      <link>https://markhneedham.com/blog/2012/01/10/learning-android-testing-details-got-saved-to-sharedpreferences/</link>
      <pubDate>Tue, 10 Jan 2012 09:53:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/10/learning-android-testing-details-got-saved-to-sharedpreferences/</guid>
      <description>I&amp;rsquo;ve been writing some tests around an app I&amp;rsquo;ve been working on using the Robolectrictesting framework and one thing I wanted to do was check that an OAuth token/secret were being saved to the user&amp;rsquo;s preferences.
The code that saved the preferences looked like this:
public class AuthoriseWithTwitterActivity extends RoboActivity { @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(intent); ... save(&amp;#34;fakeToken&amp;#34;, &amp;#34;fakeSecret&amp;#34;); ... } private void save(String userKey, String userSecret) { SharedPreferences settings = PreferenceManager.</description>
    </item>
    
    <item>
      <title>Learning Android: Getting android-support jar/compatability package as a Maven dependency</title>
      <link>https://markhneedham.com/blog/2012/01/08/learning-android-getting-android-support-jarcompatability-package-as-a-maven-dependency/</link>
      <pubDate>Sun, 08 Jan 2012 20:56:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/08/learning-android-getting-android-support-jarcompatability-package-as-a-maven-dependency/</guid>
      <description>In the app I&amp;rsquo;m working on I make use of the ViewPager classwhich is only available in the compatibility package from revisions 3 upwards.
Initially I followed the instructions on the developer guideto get hold of the jar but now that I&amp;rsquo;m trying to adapt my code to fit the RobolectricSample, as I mentioned in my previous post, I needed to hook it up as a Maven dependency.
I added the dependency to my pom.</description>
    </item>
    
    <item>
      <title>Learning Android: java.lang.OutOfMemoryError: Java heap space with android-maven-plugin</title>
      <link>https://markhneedham.com/blog/2012/01/07/learning-android-java-lang-outofmemoryerror-java-heap-space-with-android-maven-plugin/</link>
      <pubDate>Sat, 07 Jan 2012 17:14:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/07/learning-android-java-lang-outofmemoryerror-java-heap-space-with-android-maven-plugin/</guid>
      <description>I&amp;rsquo;ve been trying to adapt my Android application to fit into the structure of the RobolectricSampleso that I can add some tests around my code but I was running into a problem when trying to deploy the application.
To deploy the application you need to run the following command:
mvn package android:deploy Which was resulting in the following error:
[INFO] UNEXPECTED TOP-LEVEL ERROR: [INFO] java.lang.OutOfMemoryError: Java heap space [INFO] at com.</description>
    </item>
    
    <item>
      <title>Learning Android: Freezing the UI with a BroadcastReceiver</title>
      <link>https://markhneedham.com/blog/2012/01/06/learning-android-freezing-the-ui-with-a-broadcastreceiver/</link>
      <pubDate>Fri, 06 Jan 2012 23:40:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/06/learning-android-freezing-the-ui-with-a-broadcastreceiver/</guid>
      <description>As I mentioned in a previous postI recently wrote some code in my Android app to inform a BroadcastReceiverwhenever a service processed a tweet with a link in it but in implementing this I managed to freeze the UI every time that happened.
I made the stupid (in hindsight) mistake of not realising that I shouldn&amp;rsquo;t be doing a lot of logic in BroadcastReceiver.onReceivesince that bit of code gets executed on the UI thread.</description>
    </item>
    
    <item>
      <title>Learning Android: Getting a service to communicate with an activity</title>
      <link>https://markhneedham.com/blog/2012/01/05/learning-android-getting-a-service-to-communicate-with-an-activity/</link>
      <pubDate>Thu, 05 Jan 2012 01:41:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/05/learning-android-getting-a-service-to-communicate-with-an-activity/</guid>
      <description>In the app I&amp;rsquo;m working on I created a service which runs in the background away from the main UI thread consuming the Twitter streaming API using twitter4j.
It looks like this:
public class TweetService extends IntentService { String consumerKey = &amp;#34;TwitterConsumerKey&amp;#34;; String consumerSecret = &amp;#34;TwitterConsumerSecret&amp;#34;; public TweetService() { super(&amp;#34;Tweet Service&amp;#34;); } @Override protected void onHandleIntent(Intent intent) { AccessToken accessToken = createAccessToken(); StatusListener listener = new UserStreamListener() { // override a whole load of methods - removed for brevity  public void onStatus(Status status) { String theTweet = status.</description>
    </item>
    
    <item>
      <title>My Software Development journey: 2011</title>
      <link>https://markhneedham.com/blog/2012/01/03/my-software-development-journey-2011/</link>
      <pubDate>Tue, 03 Jan 2012 01:48:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/03/my-software-development-journey-2011/</guid>
      <description>A couple of years agoI used to write a blog postreflecting on what I&amp;rsquo;d worked on in the preceding year and what I&amp;rsquo;d learned and having read 2011 reviews by a coupleof otherpeopleI thought I&amp;rsquo;d have a go.
Often I&amp;rsquo;d work on something and know exactly how it should be designed and where we could go wrong since I&amp;rsquo;d done the same thing several times before and the challenge of not knowing what to do had disappeared somewhat.</description>
    </item>
    
    <item>
      <title>Learning Android: Authenticating with Twitter using OAuth</title>
      <link>https://markhneedham.com/blog/2012/01/02/learning-android-authenticating-with-twitter-using-oauth/</link>
      <pubDate>Mon, 02 Jan 2012 02:39:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/02/learning-android-authenticating-with-twitter-using-oauth/</guid>
      <description>I want to be able to get the tweets from my timeline into my app which means I need to authorise the app with Twitter using OAuth.
The last time I tried to authenticate using OAuth a couple of years ago was a bit of a failure but luckily this time Honza Pokorny has written a blog post explaining what to do.
I had to adjust the code a little bit from what&amp;rsquo;s written on his post so I thought I&amp;rsquo;d document what I&amp;rsquo;ve done.</description>
    </item>
    
    <item>
      <title>Learning Android: &#39;Unable to start service Intent not found&#39;</title>
      <link>https://markhneedham.com/blog/2012/01/01/learning-android-unable-to-start-service-intent-not-found/</link>
      <pubDate>Sun, 01 Jan 2012 03:22:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/01/learning-android-unable-to-start-service-intent-not-found/</guid>
      <description>In the Android application that I&amp;rsquo;ve been playing around with I wrote a service which consumes the Twitter streaming API which I trigger from the app&amp;rsquo;s main activity like so:
public class MyActivity extends Activity { ... @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); Intent intent = new Intent(this, TweetService.class); startService(intent); ... } } Where TweetServiceis defined roughly like this:
public class TweetService extends IntentService { @Override protected void onHandleIntent(Intent intent) { // Twitter streaming API stuff goes here  } } Unfortunately when I tried to deploy the app the service wasn&amp;rsquo;t starting and I got this message in the log:</description>
    </item>
    
  </channel>
</rss>