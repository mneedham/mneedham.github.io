<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Software Development on Mark Needham</title>
    <link>https://markhneedham.com/blog/category/software-development/</link>
    <description>Recent content in Software Development on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Mar 2018 21:57:14 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/category/software-development/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Running asciidoctor-pdf on TeamCity</title>
      <link>https://markhneedham.com/blog/2018/03/13/running-asciidoctor-pdf-teamcity/</link>
      <pubDate>Tue, 13 Mar 2018 21:57:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/03/13/running-asciidoctor-pdf-teamcity/</guid>
      <description>I&amp;#8217;ve been using asciidoctor-pdf to generate PDF and while I was initially running the tool locally I eventually decided to setup a build on TeamCity.
 It was a bit trickier than I expected, mostly because I&amp;#8217;m not that familiar with deploying Ruby applications, but I thought I&amp;#8217;d capture what I&amp;#8217;ve done for future me.
 I have the following Gemfile that installs asciidoctor-pdf and its dependencies:
 Gemfile
 source &#39;https://rubygems.</description>
    </item>
    
    <item>
      <title>Asciidoctor: Creating a macro</title>
      <link>https://markhneedham.com/blog/2018/02/19/asciidoctor-creating-macro/</link>
      <pubDate>Mon, 19 Feb 2018 20:51:31 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/02/19/asciidoctor-creating-macro/</guid>
      <description>I&amp;#8217;ve been writing the TWIN4j blog for almost a year now and during that time I&amp;#8217;ve written a few different asciidoc macros to avoid repetition.
 The most recent one I wrote does the formatting around the Featured Community Member of the Week. I call it like this from the asciidoc, passing in the name of the person and a link to an image:
 featured::https://s3.amazonaws.com/dev.assets.neo4j.com/wp-content/uploads/20180202004247/this-week-in-neo4j-3-february-2018.jpg[name=&#34;Suellen Stringer-Hye&#34;]   The code for the macro has two parts.</description>
    </item>
    
    <item>
      <title>Asciidoc to Asciidoc: Exploding includes</title>
      <link>https://markhneedham.com/blog/2018/01/23/asciidoc-asciidoc-exploding-includes/</link>
      <pubDate>Tue, 23 Jan 2018 21:11:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/01/23/asciidoc-asciidoc-exploding-includes/</guid>
      <description>One of my favourite features in AsciiDoc is the ability to include other files, but when using lots of includes is that it becomes difficult to read the whole document unless you convert it to one of the supported backends.
 $ asciidoctor --help Usage: asciidoctor [OPTION]... FILE... Translate the AsciiDoc source FILE or FILE(s) into the backend output format (e.g., HTML 5, DocBook 4.5, etc.) By default, the output is written to a file with the basename of the source file and the appropriate extension.</description>
    </item>
    
    <item>
      <title>Strava: Calculating the similarity of two runs</title>
      <link>https://markhneedham.com/blog/2018/01/18/strava-calculating-similarity-two-runs/</link>
      <pubDate>Thu, 18 Jan 2018 23:35:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/01/18/strava-calculating-similarity-two-runs/</guid>
      <description>I go running several times a week and wanted to compare my runs against each other to see how similar they are.
 I record my runs with the Strava app and it has an API that returns lat/long coordinates for each run in the Google encoded polyline algorithm format.
 We can use the polyline library to decode these values into a list of lat/long tuples. For example:
 import polyline polyline.</description>
    </item>
    
    <item>
      <title>Morning Pages: What should I write about?</title>
      <link>https://markhneedham.com/blog/2017/12/27/morning-pages-write/</link>
      <pubDate>Wed, 27 Dec 2017 23:28:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/12/27/morning-pages-write/</guid>
      <description>I&amp;#8217;ve been journalling for almost 2 years now but some days I get stuck and can&amp;#8217;t think of anything to write about.
 I did a bit of searching to see if anybody had advice on solving this problem and found a few different articles:
   The Productive Benefits of Journaling (plus 11 ideas for making the habit stick)
  Read This If You Want To Keep A Journal But Don&amp;#8217;t Know How</description>
    </item>
    
    <item>
      <title>Serverless: Building a mini producer/consumer data pipeline with AWS SNS</title>
      <link>https://markhneedham.com/blog/2017/09/30/serverless-building-mini-producerconsumer-data-pipeline-aws-sns/</link>
      <pubDate>Sat, 30 Sep 2017 07:51:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/09/30/serverless-building-mini-producerconsumer-data-pipeline-aws-sns/</guid>
      <description>I wanted to create a little data pipeline with Serverless whose main use would be to run once a day, call an API, and load that data into a database.
 It&amp;#8217;s mostly used to pull in recent data from that API, but I also wanted to be able to invoke it manually and specify a date range.
 I created the following pair of lambdas that communicate with each other via an SNS topic.</description>
    </item>
    
    <item>
      <title>Serverless: S3 - S3BucketPermissions - Action does not apply to any resource(s) in statement</title>
      <link>https://markhneedham.com/blog/2017/09/29/serverless-s3-s3bucketpermissions-action-does-not-apply-to-any-resources-in-statement/</link>
      <pubDate>Fri, 29 Sep 2017 06:09:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/09/29/serverless-s3-s3bucketpermissions-action-does-not-apply-to-any-resources-in-statement/</guid>
      <description>I&amp;#8217;ve been playing around with S3 buckets with Serverless, and recently wrote the following code to create an S3 bucket and put a file into that bucket:
 const AWS = require(&#34;aws-sdk&#34;); let regionParams = { &#39;region&#39;: &#39;us-east-1&#39; } let s3 = new AWS.S3(regionParams); let s3BucketName = &#34;marks-blog-bucket&#34;; console.log(&#34;Creating bucket: &#34; + s3BucketName); let bucketParams = { Bucket: s3BucketName, ACL: &#34;public-read&#34; }; s3.createBucket(bucketParams).promise() .then(console.log) .catch(console.error); var putObjectParams = { Body: &#34;</description>
    </item>
    
    <item>
      <title>Serverless: AWS HTTP Gateway - 502 Bad Gateway</title>
      <link>https://markhneedham.com/blog/2017/08/11/serverless-aws-http-gateway-502-bad-gateway/</link>
      <pubDate>Fri, 11 Aug 2017 16:01:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/08/11/serverless-aws-http-gateway-502-bad-gateway/</guid>
      <description>In my continued work with Serverless and AWS Lambda I ran into a problem when trying to call a HTTP gateway.
 My project looked like this:
 serverless.yaml
 service: http-gateway frameworkVersion: &#34;&amp;gt;=1.2.0 &amp;lt;2.0.0&#34; provider: name: aws runtime: python3.6 timeout: 180 functions: no-op: name: NoOp handler: handler.noop events: - http: POST noOp   handler.py
 def noop(event, context): return &#34;hello&#34;   Let&amp;#8217;s deploy to AWS:
 $ serverless deploy Serverless: Packaging service.</description>
    </item>
    
    <item>
      <title>Serverless: Python - virtualenv - { &#34;errorMessage&#34;: &#34;Unable to import module &#39;handler&#39;&#34; }</title>
      <link>https://markhneedham.com/blog/2017/08/06/serverless-python-virtualenv-errormessage-unable-import-module-handler/</link>
      <pubDate>Sun, 06 Aug 2017 19:03:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/08/06/serverless-python-virtualenv-errormessage-unable-import-module-handler/</guid>
      <description>I&amp;#8217;ve been using the Serverless library to deploy and run some Python functions on AWS lambda recently and was initially confused about how to handle my dependencies.
 I tend to create a new virtualenv for each of my project so let&amp;#8217;s get that setup first:
 Prerequisites $ npm install serverless   $ virtualenv -p python3 a $ . a/bin/activate   Now let&amp;#8217;s create our Serverless project. I&amp;#8217;m going to install the requests library so that I can use it in my function.</description>
    </item>
    
    <item>
      <title>AWS Lambda: /lib/ld-linux.so.2: bad ELF interpreter: No such file or directory&#39;</title>
      <link>https://markhneedham.com/blog/2017/08/03/aws-lambda-libld-linux-2-bad-elf-interpreter-no-file-directory/</link>
      <pubDate>Thu, 03 Aug 2017 17:24:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/08/03/aws-lambda-libld-linux-2-bad-elf-interpreter-no-file-directory/</guid>
      <description>I&amp;#8217;ve been working on an AWS lambda job to convert a HTML page to PDF using a Python wrapper around the wkhtmltopdf library but ended up with the following error when I tried to execute it:
 b&#39;/bin/sh: ./binary/wkhtmltopdf: /lib/ld-linux.so.2: bad ELF interpreter: No such file or directory\n&#39;: Exception Traceback (most recent call last): File &#34;/var/task/handler.py&#34;, line 33, in generate_certificate wkhtmltopdf(local_html_file_name, local_pdf_file_name) File &#34;/var/task/lib/wkhtmltopdf.py&#34;, line 64, in wkhtmltopdf wkhp.render() File &#34;</description>
    </item>
    
    <item>
      <title>AWS Lambda: Programmatically scheduling a CloudWatchEvent</title>
      <link>https://markhneedham.com/blog/2017/04/05/aws-lambda-programatically-scheduling-a-cloudwatchevent/</link>
      <pubDate>Wed, 05 Apr 2017 23:49:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/04/05/aws-lambda-programatically-scheduling-a-cloudwatchevent/</guid>
      <description>I recently wrote a blog post showing how to create a Python &#39;Hello World&#39; AWS lambda function and manually invoke it, but what I really wanted to do was have it run automatically every hour.
 To achieve that in AWS Lambda land we need to create a CloudWatch Event. The documentation describes them as follows:
  Using simple rules that you can quickly set up, you can match events and route them to one or more target functions or streams.</description>
    </item>
    
    <item>
      <title>AWS Lambda: Encrypted environment variables</title>
      <link>https://markhneedham.com/blog/2017/04/03/aws-lambda-encrypted-environment-variables/</link>
      <pubDate>Mon, 03 Apr 2017 05:49:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/04/03/aws-lambda-encrypted-environment-variables/</guid>
      <description>Continuing on from my post showing how to create a &#39;Hello World&#39; AWS lambda function I wanted to pass encrypted environment variables to my function.
 The following function takes in both an encrypted and unencrypted variable and prints them out.
 Don&amp;#8217;t print out encrypted variables in a real function, this is just so we can see the example working!
 import boto3 import os from base64 import b64decode def lambda_handler(event, context): encrypted = os.</description>
    </item>
    
    <item>
      <title>AWS Lambda: Programatically create a Python &#39;Hello World&#39; function</title>
      <link>https://markhneedham.com/blog/2017/04/02/aws-lambda-programatically-create-a-python-hello-world-function/</link>
      <pubDate>Sun, 02 Apr 2017 22:11:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/04/02/aws-lambda-programatically-create-a-python-hello-world-function/</guid>
      <description>I&amp;#8217;ve been playing around with AWS Lambda over the last couple of weeks and I wanted to automate the creation of these functions and all their surrounding config.
 Let&amp;#8217;s say we have the following Hello World function: ~python def lambda_handler(event, context): print(&#34;Hello world&#34;) ~
 To upload it to AWS we need to put it inside a zip file so let&amp;#8217;s do that: ~bash $ zip HelloWorld.zip HelloWorld.py ~ ~bash $ unzip -l HelloWorld.</description>
    </item>
    
    <item>
      <title>My top 10 technology podcasts</title>
      <link>https://markhneedham.com/blog/2017/03/30/top-10-technology-podcasts/</link>
      <pubDate>Thu, 30 Mar 2017 22:38:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/03/30/top-10-technology-podcasts/</guid>
      <description>For the last six months I&amp;#8217;ve been listening to 2 or 3 technology podcasts every day while out running and on my commute and I thought it&amp;#8217;d be cool to share some of my favourites.
 I listen to all of these on the Podbean android app which seems pretty good. It can&amp;#8217;t read the RSS feeds of some podcasts but other than that it&amp;#8217;s worked well.
 Anyway, on with the podcasts:</description>
    </item>
    
    <item>
      <title>Kubernetes: Writing hostname to a file</title>
      <link>https://markhneedham.com/blog/2016/11/22/kubernetes-writing-hostname-to-a-file/</link>
      <pubDate>Tue, 22 Nov 2016 19:56:31 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/11/22/kubernetes-writing-hostname-to-a-file/</guid>
      <description>Over the weekend I spent a bit of time playing around with Kubernetes and to get the hang of the technology I set myself the task of writing the hostname of the machine to a file.
 I&amp;#8217;m using the excellent minikube tool to create a local Kubernetes cluster for my experiments so the first step is to spin that up:
 $ minikube start Starting local Kubernetes cluster... Kubectl is now configured to use the cluster.</description>
    </item>
    
    <item>
      <title>Study until your mind wanders</title>
      <link>https://markhneedham.com/blog/2015/12/31/study-until-your-mind-wanders/</link>
      <pubDate>Thu, 31 Dec 2015 10:47:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/31/study-until-your-mind-wanders/</guid>
      <description>I&amp;#8217;ve previously found it very difficult to read math heavy content which has made it challenging to read Distributed Computing which I bought last May.
 After several false starts where I gave up after getting frustrated that I couldn&amp;#8217;t understand things the first time around and forgot everything if I left it a couple of days I decided to try again with a different approach.
 I&amp;#8217;ve been trying a technique I learned from Mini Habits where every day I have a (very small) goal of reading one page of the book.</description>
    </item>
    
    <item>
      <title>jq: Cannot iterate over number / string and number cannot be added</title>
      <link>https://markhneedham.com/blog/2015/11/24/jq-cannot-iterate-over-number-string-and-number-cannot-be-added/</link>
      <pubDate>Tue, 24 Nov 2015 00:12:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/24/jq-cannot-iterate-over-number-string-and-number-cannot-be-added/</guid>
      <description>In my continued parsing of meetup.com&amp;#8217;s JSON API I wanted to extract some information from the following JSON file:
 $ head -n40 data/members/18313232.json [ { &#34;status&#34;: &#34;active&#34;, &#34;city&#34;: &#34;London&#34;, &#34;name&#34;: &#34;. .&#34;, &#34;other_services&#34;: {}, &#34;country&#34;: &#34;gb&#34;, &#34;topics&#34;: [], &#34;lon&#34;: -0.13, &#34;joined&#34;: 1438866605000, &#34;id&#34;: 92951932, &#34;state&#34;: &#34;17&#34;, &#34;link&#34;: &#34;http://www.meetup.com/members/92951932&#34;, &#34;photo&#34;: { &#34;thumb_link&#34;: &#34;http://photos1.meetupstatic.com/photos/member/8/d/6/b/thumb_250896203.jpeg&#34;, &#34;photo_id&#34;: 250896203, &#34;highres_link&#34;: &#34;http://photos1.meetupstatic.com/photos/member/8/d/6/b/highres_250896203.jpeg&#34;, &#34;photo_link&#34;: &#34;http://photos1.meetupstatic.com/photos/member/8/d/6/b/member_250896203.jpeg&#34; }, &#34;lat&#34;: 51.49, &#34;visited&#34;: 1446745707000, &#34;self&#34;: { &#34;common&#34;: {} } }, { &#34;</description>
    </item>
    
    <item>
      <title>jq: Filtering missing keys</title>
      <link>https://markhneedham.com/blog/2015/11/14/jq-filtering-missing-keys/</link>
      <pubDate>Sat, 14 Nov 2015 22:51:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/14/jq-filtering-missing-keys/</guid>
      <description>I&amp;#8217;ve been playing around with the meetup.com API again over the last few days and having saved a set of events to disk I wanted to extract the venues using jq.
 This is what a single event record looks like:
 $ jq -r &#34;.[0]&#34; data/events/0.json { &#34;status&#34;: &#34;past&#34;, &#34;rating&#34;: { &#34;count&#34;: 1, &#34;average&#34;: 1 }, &#34;utc_offset&#34;: 3600000, &#34;event_url&#34;: &#34;http://www.meetup.com/londonweb/events/3261890/&#34;, &#34;group&#34;: { &#34;who&#34;: &#34;Web Peeps&#34;, &#34;name&#34;: &#34;London Web&#34;, &#34;group_lat&#34;: 51.</description>
    </item>
    
    <item>
      <title>Docker 1.9: Port forwarding on Mac OS X</title>
      <link>https://markhneedham.com/blog/2015/11/08/docker-1-9-port-forwarding-on-mac-os-x/</link>
      <pubDate>Sun, 08 Nov 2015 20:58:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/08/docker-1-9-port-forwarding-on-mac-os-x/</guid>
      <description>Since the Neo4j 2.3.0 release there&amp;#8217;s been an official docker image which I thought I&amp;#8217;d give a try this afternoon.
 The last time I used docker about a year ago I had to install boot2docker which has now been deprecated in place of Docker Machine and the Docker Toolbox.
 I created a container with the following command:
 docker run --detach --publish=7474:7474 neo4j/neo4j   And then tried to access the Neo4j server locally:</description>
    </item>
    
    <item>
      <title>IntelliJ &#39;java: cannot find JDK 1.8&#39;</title>
      <link>https://markhneedham.com/blog/2015/11/08/intellij-java-cannot-find-jdk-1-8/</link>
      <pubDate>Sun, 08 Nov 2015 11:47:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/08/intellij-java-cannot-find-jdk-1-8/</guid>
      <description>I upgraded to IntelliJ 15.0 a few days ago and was initially seeing the following exception when trying to compile:
 module-name java: cannot find JDK 1.8   I&amp;#8217;ve been compiling against JDK 1.8 for a while now using IntelliJ 14 so I wasn&amp;#8217;t sure what was going on.
 I checked my project settings and they seemed fine:
   The error message suggested I look in the logs to find more information but I wasn&amp;#8217;t sure where those live!</description>
    </item>
    
    <item>
      <title>Hadoop: HDFS - java.lang.NoSuchMethodError: org.apache.hadoop.fs.FSOutputSummer.&lt;init&gt;(Ljava/util/zip/Checksum;II)V</title>
      <link>https://markhneedham.com/blog/2015/10/31/hadoop-hdfs-ava-lang-nosuchmethoderror-org-apache-hadoop-fs-fsoutputsummer-ljavautilzipchecksumiiv/</link>
      <pubDate>Sat, 31 Oct 2015 23:58:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/31/hadoop-hdfs-ava-lang-nosuchmethoderror-org-apache-hadoop-fs-fsoutputsummer-ljavautilzipchecksumiiv/</guid>
      <description>I wanted to write a little program to check that one machine could communicate a HDFS server running on the other and adapted some code from the Hadoop wiki as follows:
 package org.playground; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.FSDataInputStream; import org.apache.hadoop.fs.FSDataOutputStream; import org.apache.hadoop.fs.FileSystem; import org.apache.hadoop.fs.Path; import java.io.IOException; public class HadoopDFSFileReadWrite { static void printAndExit(String str) { System.err.println( str ); System.exit(1); } public static void main (String[] argv) throws IOException { Configuration conf = new Configuration(); conf.</description>
    </item>
    
    <item>
      <title>jq: error - Cannot iterate over null (null)</title>
      <link>https://markhneedham.com/blog/2015/10/09/jq-error-cannot-iterate-over-null-null/</link>
      <pubDate>Fri, 09 Oct 2015 06:34:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/09/jq-error-cannot-iterate-over-null-null/</guid>
      <description>I&amp;#8217;ve been playing around with the jq library again over the past couple of days to convert the JSON from the Stack Overflow API into CSV and found myself needing to deal with an optional field.
 I&amp;#8217;ve downloaded 100 or so questions and stored them as an array in a JSON array like so:
 $ head -n 100 so.json [ { &#34;has_more&#34;: true, &#34;items&#34;: [ { &#34;is_answered&#34;: false, &#34;</description>
    </item>
    
    <item>
      <title>Mac OS X: Installing the PROJ.4 - Cartographic Projections Library</title>
      <link>https://markhneedham.com/blog/2015/10/05/mac-os-x-installing-the-proj-4-cartographic-projections-library/</link>
      <pubDate>Mon, 05 Oct 2015 22:41:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/05/mac-os-x-installing-the-proj-4-cartographic-projections-library/</guid>
      <description>I&amp;#8217;ve been following Scott Barnham&amp;#8217;s guide to transforming UK postcodes into (lat, long) coordinates and needed to install the PROJ.4 Cartographic Projections library which I initially struggled with.
 The first step is to download a tar.gz version which is linked from the wiki page:
 $ wget http://download.osgeo.org/proj/proj-4.9.1.tar.gz   Next we&amp;#8217;ll unpack the file and then build the binaries:
 $ tar -xvf proj-4.9.1.tar.gz $ cd proj-4.9.1 $ .</description>
    </item>
    
    <item>
      <title>Record Linkage: Playing around with Duke</title>
      <link>https://markhneedham.com/blog/2015/08/08/record-linkage-playing-around-with-duke/</link>
      <pubDate>Sat, 08 Aug 2015 22:50:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/08/record-linkage-playing-around-with-duke/</guid>
      <description>I&amp;#8217;ve become quite interesting in record linkage recently and came across the Duke project which provides some tools to help solve this problem. I thought I&amp;#8217;d give it a try.
 The typical problem when doing record linkage is that we have two records from different data sets which represent the same entity but don&amp;#8217;t have a common key that we can use to merge them together. We therefore need to come up with a heuristic that will allow us to do so.</description>
    </item>
    
    <item>
      <title>The Willpower Instinct: Reducing time spent mindlessly scrolling for things to read</title>
      <link>https://markhneedham.com/blog/2015/06/12/the-willpower-instinct-reducing-time-spent-mindlessly-scrolling-for-things-to-read/</link>
      <pubDate>Fri, 12 Jun 2015 23:12:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/12/the-willpower-instinct-reducing-time-spent-mindlessly-scrolling-for-things-to-read/</guid>
      <description>I recently finished reading Kelly McGonigal&amp;#8217;s excellent book &#39;http://www.amazon.co.uk/The-Willpower-Instinct-Kelly-McGonigal/dp/1583335080[The Willpower Instinct]&#39; having previously watched her Google talk of the same title
 My main takeaway from the book is that there are things that we want to do (or not do) but doing them (or not as the case may be) isn&amp;#8217;t necessarily instinctive and so we need to develop some strategies to help ourselves out.
 In one of the early chapters she suggests picking a habit that you want to do less off and write down on a piece of paper every time you want to do it and how you&amp;#8217;re feeling at that point.</description>
    </item>
    
    <item>
      <title>Deliberate Practice: Building confidence vs practicing</title>
      <link>https://markhneedham.com/blog/2015/04/30/deliberate-practice-building-confidence-vs-practicing/</link>
      <pubDate>Thu, 30 Apr 2015 07:48:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/30/deliberate-practice-building-confidence-vs-practicing/</guid>
      <description>A few weeks ago I wrote about the learning to cycle dependency graph which described some of the skills required to become proficient at riding a bike.
   While we&amp;#8217;ve been practicing various skills/sub skills I&amp;#8217;ve often found myself saying the following:
  if it&amp;#8217;s not hard you&amp;#8217;re not practicing me, April 2015
   i.e. you should find the skill you&amp;#8217;re currently practicing difficult otherwise you&amp;#8217;re not stretching yourself and therefore aren&amp;#8217;t getting better.</description>
    </item>
    
    <item>
      <title>Deliberate Practice: Watching yourself fail</title>
      <link>https://markhneedham.com/blog/2015/04/25/deliberate-practice-watching-yourself-fail/</link>
      <pubDate>Sat, 25 Apr 2015 22:26:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/25/deliberate-practice-watching-yourself-fail/</guid>
      <description>I&amp;#8217;ve recently been reading the literature written by K. Anders Eriksson and co on Deliberate Practice and one of the suggestions for increasing our competence at a skill is to put ourselves in a situation where we can fail.
 I&amp;#8217;ve been reading Think Bayes - an introductory text on Bayesian statistics, something I know nothing about - and each chapter concludes with a set of exercises to practice, a potentially perfect exercise in failure!</description>
    </item>
    
    <item>
      <title>InetAddressImpl#lookupAllHostAddr slow/hangs</title>
      <link>https://markhneedham.com/blog/2015/03/29/inetaddressimpllookupallhostaddr-slowhangs/</link>
      <pubDate>Sun, 29 Mar 2015 00:31:37 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/29/inetaddressimpllookupallhostaddr-slowhangs/</guid>
      <description>Since I upgraded to Yosemite I&amp;#8217;ve noticed that attempts to resolve localhost on my home network have been taking ages (sometimes over a minute) so I thought I&amp;#8217;d try and work out why.
 This is what my initial /etc/hosts file looked like based on the assumption that my machine&amp;#8217;s hostname was teetotal:
 $ cat /etc/hosts ## # Host Database # # localhost is used to configure the loopback interface # when the system is booting.</description>
    </item>
    
    <item>
      <title>One month of mini habits</title>
      <link>https://markhneedham.com/blog/2015/03/17/one-month-of-mini-habits/</link>
      <pubDate>Tue, 17 Mar 2015 01:32:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/17/one-month-of-mini-habits/</guid>
      <description>I recently read a book in the &#39;getting things done&#39; genre written by Stephen Guise titled &#39;http://www.amazon.co.uk/Mini-Habits-Smaller-Bigger-Results-ebook/dp/B00HGKNBDK[Mini Habits]&#39; and although I generally don&amp;#8217;t like those types of books I quite enjoyed this one and decided to give his system a try.
 The underlying idea is that there are two parts of actually doing stuff:
   Planning what to do
  Doing it
   We often get stuck in between the first and second steps because what we&amp;#8217;ve planned to do is too big and overwhelming.</description>
    </item>
    
    <item>
      <title>Docker/Neo4j: Port forwarding on Mac OS X not working</title>
      <link>https://markhneedham.com/blog/2014/11/27/dockerneo4j-port-forwarding-on-mac-os-x-not-working/</link>
      <pubDate>Thu, 27 Nov 2014 12:28:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/11/27/dockerneo4j-port-forwarding-on-mac-os-x-not-working/</guid>
      <description>Prompted by Ognjen Bubalo&amp;#8217;s excellent blog post I thought it was about time I tried running Neo4j on a docker container on my Mac Book Pro to make it easier to play around with different data sets.
 I got the container up and running by following Ognien&amp;#8217;s instructions and had the following ports forwarded to my host machine:
 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c62f8601e557 tpires/neo4j:latest &#34;</description>
    </item>
    
    <item>
      <title>hdiutil: could not access / create failed - Operation canceled</title>
      <link>https://markhneedham.com/blog/2014/10/31/hdiutil-could-not-access-create-failed-operation-canceled/</link>
      <pubDate>Fri, 31 Oct 2014 09:45:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/10/31/hdiutil-could-not-access-create-failed-operation-canceled/</guid>
      <description>Earlier in the year I wrote a blog post showing how to build a Mac OS X DMG file for a Java application and I recently revisited this script to update it to a new version and ran into a frustrating error message.
 I tried to run the following command to create a new DMG file from a source folder...
 $ hdiutil create -volname &#34;DemoBench&#34; -size 100m -srcfolder dmg/ -ov -format UDZO pack.</description>
    </item>
    
    <item>
      <title>Data Modelling: The Thin Model</title>
      <link>https://markhneedham.com/blog/2014/10/27/data-modelling-the-thin-model/</link>
      <pubDate>Mon, 27 Oct 2014 06:55:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/10/27/data-modelling-the-thin-model/</guid>
      <description>About a third of the way through Mastering Data Modeling the authors describe common data modelling mistakes and one in particular resonated with me - &#39;Thin LDS, Lost Users&#39;.
 LDS stands for &#39;Logical Data Structure&#39; which is a diagram depicting what kinds of data some person or group wants to remember. In other words, a tool to help derive the conceptual model for our domain.
 They describe the problem that a thin model can cause as follows:</description>
    </item>
    
    <item>
      <title>Neo4j: LOAD CSV - The sneaky null character</title>
      <link>https://markhneedham.com/blog/2014/10/18/neo4j-load-csv-the-sneaky-null-character/</link>
      <pubDate>Sat, 18 Oct 2014 10:49:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/10/18/neo4j-load-csv-the-sneaky-null-character/</guid>
      <description>I spent some time earlier in the week trying to import a CSV file extracted from Hadoop into Neo4j using Cypher&amp;#8217;s LOAD CSV command and initially struggled due to some rogue characters.
 The CSV file looked like this:
 $ cat foo.csv foo,bar,baz 1,2,3   I wrote the following LOAD CSV query to extract some of the fields and compare others:
 load csv with headers from &#34;file:/Users/markneedham/Downloads/foo.csv&#34; AS line RETURN line.</description>
    </item>
    
    <item>
      <title>PostgreSQL: ERROR:  column does not exist</title>
      <link>https://markhneedham.com/blog/2014/09/29/postgresql-error-column-does-not-exist/</link>
      <pubDate>Mon, 29 Sep 2014 22:40:31 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/09/29/postgresql-error-column-does-not-exist/</guid>
      <description>I&amp;#8217;ve been playing around with PostgreSQL recently and in particular the Northwind dataset typically used as an introductory data set for relational databases.
 Having imported the data I wanted to take a quick look at the employees table:
 postgres=# select * from employees limit 1; EmployeeID | LastName | FirstName | Title | TitleOfCourtesy | BirthDate | HireDate | Address | City | Region | PostalCode | Country | HomePhone | Extension | Photo | Notes | ReportsTo | PhotoPath ------------+----------+-----------+----------------------+-----------------+------------+------------+-----------------------------+---------+--------+------------+---------+----------------+-----------+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+-------------------------------------- 1 | Davolio | Nancy | Sales Representative | Ms.</description>
    </item>
    
    <item>
      <title>4 types of user</title>
      <link>https://markhneedham.com/blog/2014/07/29/4-types-of-user/</link>
      <pubDate>Tue, 29 Jul 2014 19:07:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/07/29/4-types-of-user/</guid>
      <description>I&amp;#8217;ve been working with Neo4j full time for slightly more than a year now and from interacting with the community I&amp;#8217;ve noticed that while using different features of the product people fall into 4 categories.
 These are as follows:
   On one axis we have &#39;loudness&#39; i.e. how vocal somebody is either on twitter, StackOverflow or by email and on the other we have &#39;success&#39; which is how well a product feature is working for them.</description>
    </item>
    
    <item>
      <title>Thoughts on meetups</title>
      <link>https://markhneedham.com/blog/2014/05/31/thoughts-on-meetups/</link>
      <pubDate>Sat, 31 May 2014 19:50:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/05/31/thoughts-on-meetups/</guid>
      <description>I recently came across an interesting blog post by Zach Tellman in which he explains a new approach that he&amp;#8217;s been trialling at The Bay Area Clojure User Group.
 Zach explains that a lecture based approach isn&amp;#8217;t necessarily the most effective way for people to learn and that half of the people attending the meetup are likely to be novices and would struggle to follow more advanced content.
 He then goes on to explain an alternative approach:</description>
    </item>
    
    <item>
      <title>install4j and AppleScript: Creating a Mac OS X Application Bundle for a Java application</title>
      <link>https://markhneedham.com/blog/2014/04/07/install4j-and-applescript-creating-a-mac-os-x-application-bundle-for-a-java-application/</link>
      <pubDate>Mon, 07 Apr 2014 00:04:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/04/07/install4j-and-applescript-creating-a-mac-os-x-application-bundle-for-a-java-application/</guid>
      <description>We have a few internal applications at Neo which can be launched using &#39;java -jar &#39; and I always forget where the jars are so I thought I&amp;#8217;d wrap a Mac OS X application bundle around it to make life easier.&amp;lt;/p&amp;gt;
 My favourite installation pattern is the one where when you double click the dmg it shows you a window where you can drag the application into the &#39;Applications&#39; folder, like this:</description>
    </item>
    
    <item>
      <title>Soulver: For all your random calculations</title>
      <link>https://markhneedham.com/blog/2014/03/30/soulver-for-all-your-random-calculations/</link>
      <pubDate>Sun, 30 Mar 2014 14:48:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/03/30/soulver-for-all-your-random-calculations/</guid>
      <description>I often find myself doing random calculations and I used to do so part manually and part using Alfred&#39;s calculator until Alistair pointed me at Soulver, a desktop/iPhone/iPad app, which is even better.
 I thought I&amp;#8217;d write some examples of calculations I use it for, partly so I&amp;#8217;ll remember the syntax in future!
 Calculating how much memory Neo4j memory mapping will take up
 800 mb + 2660mb + 6600mb + 9500mb + 40mb in GB = 19.</description>
    </item>
    
    <item>
      <title>Automating Skype&#39;s &#39;This message has been removed&#39;</title>
      <link>https://markhneedham.com/blog/2014/02/20/automating-skypes-this-message-has-been-removed/</link>
      <pubDate>Thu, 20 Feb 2014 23:16:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/02/20/automating-skypes-this-message-has-been-removed/</guid>
      <description>One of the stranger features of Skype is that that it allows you to delete the contents of a message that you&amp;#8217;ve already sent to someone - something I haven&amp;#8217;t seen on any other messaging system I&amp;#8217;ve used.
 For example if I wrote a message in Skype and wanted to edit it I would press the &#39;up&#39; arrow:
   Once I&amp;#8217;ve deleted the message I&amp;#8217;d see this in the space where the message used to be:</description>
    </item>
    
    <item>
      <title>Learning about bitmaps</title>
      <link>https://markhneedham.com/blog/2014/01/12/learning-about-bitmaps/</link>
      <pubDate>Sun, 12 Jan 2014 17:44:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/01/12/learning-about-bitmaps/</guid>
      <description>A few weeks ago Alistair and I were working on the code used to model the labels that a node has attached to it in a Neo4j database.
 The way this works is that chunks of 32 nodes ids are represented as a 32 bit bitmap for each label where a 1 for a bit means that a node has the label and a 0 means that it doesn&amp;#8217;t.</description>
    </item>
    
    <item>
      <title>Supporting production code: Start with the simple things</title>
      <link>https://markhneedham.com/blog/2013/12/20/supporting-production-code-start-with-the-simple-things/</link>
      <pubDate>Fri, 20 Dec 2013 18:07:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/12/20/supporting-production-code-start-with-the-simple-things/</guid>
      <description>A few months ago I wrote about my experiences supporting production code while working at uSwitch.
 Since then I&amp;#8217;ve been working on support for Neo4j customers and I&amp;#8217;ve realised that there are a couple of other things to keep in mind while debugging production problems that I missed from the initial list.
 Keep a clear head / Hold back your assumptions The first is that it&amp;#8217;s very helpful to completely clear your head of any assumptions when looking at a problem.</description>
    </item>
    
    <item>
      <title>Neo4j&#39;s Graph Café London - 28th August 2013</title>
      <link>https://markhneedham.com/blog/2013/08/31/neo4js-graph-cafe-london-28th-august-2013/</link>
      <pubDate>Sat, 31 Aug 2013 10:52:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/31/neo4js-graph-cafe-london-28th-august-2013/</guid>
      <description>On Wednesday evening I attended an interesting spin on the monthly Neo4j meetup, where instead of the usual &#39;talk then go to the pub afterwards&#39; format my colleagues Rik and Arturas organised Graph Café in the Doggetts Coat and Badge pub in Blackfriars.
 The format was changed as well - the evening consisted of ~10 lightening talks which were spread out over about 3 hours, an approach Rik has used at similar events in Belgium and Holland earlier in the year.</description>
    </item>
    
    <item>
      <title>Ranking Systems: What I&#39;ve learnt so far</title>
      <link>https://markhneedham.com/blog/2013/08/24/ranking-systems-what-ive-learnt-so-far/</link>
      <pubDate>Sat, 24 Aug 2013 11:05:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/24/ranking-systems-what-ive-learnt-so-far/</guid>
      <description>I often go off on massive tangents reading all about a new topic but don&amp;#8217;t record what I&amp;#8217;ve read so if I go back to the topic again in the future I have to start from scratch which is quite frustrating.
 In this instance after playing around with calculating the eigenvector centrality of a sub graph I learnt that this algorithm can also be used in ranking systems.
 I started off by reading a paper written by James Keener about the Perron-Frobenius Theorem and the ranking of American football teams.</description>
    </item>
    
    <item>
      <title>Products &amp; Infinite configurability</title>
      <link>https://markhneedham.com/blog/2013/08/22/products-infinite-configurability/</link>
      <pubDate>Thu, 22 Aug 2013 22:11:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/22/products-infinite-configurability/</guid>
      <description>One of the common feature requests on the ThoughtWorks projects that I worked on was that the application we were working on should be almost infinitely configurable to cover potential future use cases.
 My experience of attempting to do this was that you ended up with an extremely complicated code base and those future use cases often didn&amp;#8217;t come to fruition.
 It therefore made more sense to solve the problem at hand and then make the code more configurable if/when the need arose.</description>
    </item>
    
    <item>
      <title>Model to answer your questions rather than modelling reality</title>
      <link>https://markhneedham.com/blog/2013/08/22/model-to-answer-your-questions-rather-than-modelling-reality/</link>
      <pubDate>Thu, 22 Aug 2013 21:26:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/22/model-to-answer-your-questions-rather-than-modelling-reality/</guid>
      <description>On the recommendation of Ian Robinson I&amp;#8217;ve been reading the 2nd edition of William&amp;#8217;s Kent&amp;#8217;s &#39;http://www.waterstones.com/waterstonesweb/products/william+kent/data+and+reality/5270709/[Data and Reality]&#39; and the author makes an interesting observation at the end of the first chapter which resonated with me:
  Once more: we are not modelling reality, but the way information about reality is processed, by people.
   It reminds me of similar advice in Eric Evans&#39; Domain Driven Design and it&amp;#8217;s advice which I believe is helpful when designing a model in a graph database.</description>
    </item>
    
    <item>
      <title>BT Internet: Non existent hosts mapping to 92.242.132.15</title>
      <link>https://markhneedham.com/blog/2013/08/17/bt-internet-non-existent-hosts-mapping-to-92-242-132-15/</link>
      <pubDate>Sat, 17 Aug 2013 21:13:27 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/17/bt-internet-non-existent-hosts-mapping-to-92-242-132-15/</guid>
      <description>We have a test in our code which checks for unresolvable hosts and it started failing for me because instead of throwing an UnknownHostException from the following call:
 InetAddress.getByName( &#34;host.that.is.invalid&#34; )   I was getting back a valid although unreachable host. When I called ping it was easier to see what was going on:
 $ ping host.that.is.invalid PING host.that.is.invalid (92.242.132.15): 56 data bytes Request timeout for icmp_seq 0 Request timeout for icmp_seq 1 Request timeout for icmp_seq 2   As you can see, that hostname is resolving to &#39;92.</description>
    </item>
    
    <item>
      <title>AWS: Attaching an EBS volume on an EC2 instance and making it available for use</title>
      <link>https://markhneedham.com/blog/2013/07/31/aws-attaching-an-ebs-volume-on-an-ec2-instance-and-making-it-available-for-use/</link>
      <pubDate>Wed, 31 Jul 2013 06:21:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/31/aws-attaching-an-ebs-volume-on-an-ec2-instance-and-making-it-available-for-use/</guid>
      <description>I recently wanted to attach an EBS volume to an existing EC2 instance that I had running and since it was for a one off tasks (famous last words) I decided to configure it manually.
 I created the EBS volume through the AWS console and one thing that initially caught me out is that the EC2 instance and EBS volume need to be in the same region and zone.</description>
    </item>
    
    <item>
      <title>Getting started with screen</title>
      <link>https://markhneedham.com/blog/2013/07/31/getting-started-with-screen/</link>
      <pubDate>Wed, 31 Jul 2013 05:41:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/31/getting-started-with-screen/</guid>
      <description>Last week I had a ~10GB file I wanted to download to my machine but Chrome&amp;#8217;s initial estimate was that it would take 10+ hours to do so which meant I&amp;#8217;d have probably shutdown my machine before it had completed.
 It seemed to make more sense to spin up an EC2 instance and download it onto there instead but I didn&amp;#8217;t want to have to keep an SSH session open to that machine either.</description>
    </item>
    
    <item>
      <title>s3cmd: put fails with &#34;`Connection reset by peer`&#34; for large files</title>
      <link>https://markhneedham.com/blog/2013/07/30/s3cmd-put-fails-with-connection-reset-by-peer-for-large-files/</link>
      <pubDate>Tue, 30 Jul 2013 16:20:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/30/s3cmd-put-fails-with-connection-reset-by-peer-for-large-files/</guid>
      <description>I recently wanted to copy some large files from an AWS instance into an S3 bucket using s3cmd but ended up with the following error when trying to use the &#39;put&#39; command:
 $ s3cmd put /mnt/ebs/myfile.tar s3://mybucket.somewhere.com /mnt/ebs/myfile.tar -&amp;gt; s3://mybucket.somewhere.com/myfile.tar [1 of 1] 1077248 of 12185313280 0% in 1s 937.09 kB/s failed WARNING: Upload failed: /myfile.tar ([Errno 104] Connection reset by peer) WARNING: Retrying on lower speed (throttle=0.00) WARNING: Waiting 3 sec.</description>
    </item>
    
    <item>
      <title>On &#34;The fear of blogging about technical topics&#34;</title>
      <link>https://markhneedham.com/blog/2013/07/22/on-the-fear-of-blogging-about-technical-topics/</link>
      <pubDate>Mon, 22 Jul 2013 23:47:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/22/on-the-fear-of-blogging-about-technical-topics/</guid>
      <description>My former colleague Anne Simmons recently wrote an interesting post in which she describes some of the reasons that she finds herself not wanting to write about technical topics..
 I wrote a post at the end of 2012 in which I explained some of the reasons why I think writing about what you learn is a good idea but Anne brought up some things I hadn&amp;#8217;t thought of which I think are worth addressing.</description>
    </item>
    
    <item>
      <title>Lessons from supporting production code</title>
      <link>https://markhneedham.com/blog/2013/07/22/lessons-from-supporting-production-code/</link>
      <pubDate>Mon, 22 Jul 2013 22:37:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/22/lessons-from-supporting-production-code/</guid>
      <description>Until I started working on the uSwitch energy website around 8 months ago I had not really done any support of a production system so I learnt some interesting lessons in my time there.
 Look at the new code first We had our application wired up to Airbrake so whenever a user did anything which resulted in an exception being thrown we received a report with the stack trace, environment variables and which page they were on.</description>
    </item>
    
    <item>
      <title>Graph Processing: Calculating betweenness centrality for an undirected graph using graphstream</title>
      <link>https://markhneedham.com/blog/2013/07/19/graph-processing-calculating-betweenness-centrality-for-an-undirected-graph-using-graphstream/</link>
      <pubDate>Fri, 19 Jul 2013 00:37:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/19/graph-processing-calculating-betweenness-centrality-for-an-undirected-graph-using-graphstream/</guid>
      <description>Since I now spend most of my time surrounded by graphs I thought it&amp;#8217;d be interesting to learn a bit more about graph processing, a topic my colleague Jim wrote about a couple of years ago.
 I like to think of the types of queries you&amp;#8217;d do with a graph processing engine as being similar in style graph global queries where you take most of the nodes in a graph into account and do some sort of calculation.</description>
    </item>
    
    <item>
      <title>JAX RS: Streaming a Response using StreamingOutput</title>
      <link>https://markhneedham.com/blog/2013/07/08/jax-rs-streaming-a-response-using-streamingoutput/</link>
      <pubDate>Mon, 08 Jul 2013 23:19:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/08/jax-rs-streaming-a-response-using-streamingoutput/</guid>
      <description>A couple of weeks ago Jim and I were building out a neo4j unmanaged extension from which we wanted to return the results of a traversal which had a lot of paths.
 Our code initially looked a bit like this:
 package com.markandjim @Path(&#34;/subgraph&#34;) public class ExtractSubGraphResource { private final GraphDatabaseService database; public ExtractSubGraphResource(@Context GraphDatabaseService database) { this.database = database; } @GET @Produces(MediaType.TEXT_PLAIN) @Path(&#34;/{nodeId}/{depth}&#34;) public Response hello(@PathParam(&#34;nodeId&#34;) long nodeId, @PathParam(&#34;</description>
    </item>
    
    <item>
      <title>Survivorship Bias and Product Development</title>
      <link>https://markhneedham.com/blog/2013/07/08/survivorship-bias-and-product-development/</link>
      <pubDate>Mon, 08 Jul 2013 22:14:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/07/08/survivorship-bias-and-product-development/</guid>
      <description>A couple of months ago I came across an interesting article by the author of &#39;http://www.amazon.co.uk/You-are-Not-Smart-Yourself/dp/1851689397/ref=sr_1_1?ie=UTF8&amp;amp;qid=1373320231&amp;amp;sr=8-1&amp;amp;keywords=you+are+not+so+smart[You Are Not So Smart]&#39; about a fallacy known as &#39;http://youarenotsosmart.com/2013/05/23/survivorship-bias/[Survivorship Bias]&#39; which Wikipedia defines as:
  The logical error of concentrating on the people or things that &#34;survived&#34; some process and inadvertently overlooking those that didn&amp;#8217;t because of their lack of visibility.
   I particularly liked the story describing how Abraham Wald helped the US military overcome an instance of this error when trying to work out where to place armour on their bomber planes:</description>
    </item>
    
    <item>
      <title>Vagrant: Multi (virtual) machine with Puppet roles</title>
      <link>https://markhneedham.com/blog/2013/06/30/vagrant-multi-virtual-machine-with-puppet-roles/</link>
      <pubDate>Sun, 30 Jun 2013 13:13:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/30/vagrant-multi-virtual-machine-with-puppet-roles/</guid>
      <description>I&amp;#8217;ve been playing around with setting up a neo4j cluster using Vagrant and HAProxy and one thing I wanted to do was define two different roles for the HAProxy and neo4j machines.
 When I was working at uSwitch Nathan had solved a similar problem, but with AWS VMs, by defining the role in an environment variable in the VM&amp;#8217;s spin up script.
 In retrospect I think I might have been able to do that by using the shell provisioner and calling that before the puppet provisioner but Nathan, Gareth Rushgrove and Gregor Russbuelt suggested that using facter might be better.</description>
    </item>
    
    <item>
      <title>Vagrant 1.2.2: `[]&#39;: can&#39;t convert Symbol into Integer (TypeError)/The following settings don&#39;t exist</title>
      <link>https://markhneedham.com/blog/2013/06/29/vagrant-1-2-2-cant-convert-symbol-into-integer-typeerrorthe-following-settings-dont-exist/</link>
      <pubDate>Sat, 29 Jun 2013 08:44:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/29/vagrant-1-2-2-cant-convert-symbol-into-integer-typeerrorthe-following-settings-dont-exist/</guid>
      <description>As I mentioned in my previous post I&amp;#8217;ve been playing around with Vagrant for the past couple of days and I was trying to adapt a Vagrantfile that Nathan created a few months ago to do what I wanted.
 I&amp;#8217;m using Vagrant 1.2.2 and I started out with the following Vagrantfile:
 Vagrant.configure(&#34;2&#34;) do |config| config.vm.box = &#34;precise64&#34; config.vm.box_url = &#34;http://files.vagrantup.com/precise64.box&#34; config.vm.define :neo01 do |neo| neo.vm.network :hostonly, &#34;192.168.33.101&#34; neo.vm.forward_port 8080, 4569 end end   Unfortunately a &#39;vagrant up&#39; doesn&amp;#8217;t quite work as expected:</description>
    </item>
    
    <item>
      <title>Vagrant/Virtual Box: There was an error executing the following command with VBoxManage - Progress object failure: NS_ERROR_CALL_FAILED</title>
      <link>https://markhneedham.com/blog/2013/06/29/vagrantvirtual-box-there-was-an-error-executing-the-following-command-with-vboxmanage-progress-object-failure-ns_error_call_failed/</link>
      <pubDate>Sat, 29 Jun 2013 07:38:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/29/vagrantvirtual-box-there-was-an-error-executing-the-following-command-with-vboxmanage-progress-object-failure-ns_error_call_failed/</guid>
      <description>I&amp;#8217;ve been playing around with Vagrant a bit again lately and having installed it on a new machine was running into the following exception when I tried to run &#39;vagrant up&#39; on a new virtual machine:
 ERROR vagrant: /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/plugins/providers/virtualbox/driver/base.rb:292:in `block in execute&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/util/retryable.rb:17:in `retryable&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/plugins/providers/virtualbox/driver/base.rb:282:in `execute&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/plugins/providers/virtualbox/driver/version_4_2.rb:165:in `import&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/plugins/providers/virtualbox/action/import.rb:15:in `call&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/action/warden.rb:34:in `call&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/action/builtin/handle_box_url.rb:38:in `call&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/action/warden.rb:34:in `call&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/plugins/providers/virtualbox/action/check_accessible.rb:18:in `call&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/action/warden.rb:34:in `call&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/action/runner.rb:61:in `block in run&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/util/busy.rb:19:in `busy&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/action/runner.rb:61:in `run&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.1.2/lib/vagrant/action/builtin/call.rb:51:in `call&#39; /Applications/Vagrant/embedded/gems/gems/vagrant-1.</description>
    </item>
    
    <item>
      <title>The Affect Heuristic</title>
      <link>https://markhneedham.com/blog/2013/06/06/the-affect-heuristic/</link>
      <pubDate>Thu, 06 Jun 2013 22:36:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/06/the-affect-heuristic/</guid>
      <description>In my continued reading of Daniel Kahneman&amp;#8217;s Thinking Fast and Slow I&amp;#8217;ve reached the section which talks about the affect heuristic which seems particularly applicable to the technical decisions that we make.
  The dominance of conclusions over arguments is most pronounced where emotions are involved. The psychologist Paul Slovic has proposed an affect heuristic in which people let their likes and dislikes determine their beliefs about the world.</description>
    </item>
    
    <item>
      <title>Ego Depletion</title>
      <link>https://markhneedham.com/blog/2013/06/04/ego-depletion/</link>
      <pubDate>Tue, 04 Jun 2013 23:16:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/04/ego-depletion/</guid>
      <description>On the recommendation of Mike Jones I&amp;#8217;ve been reading through Daniel Kahneman&amp;#8217;s Thinking Fast and Slow in which the first part of the book covers our two styles of thinking:
   System 1 - operates automatically and quickly, with little or no effort and no sense of voluntary control.
  System 2 - allocates attention to the effortful mental activities that demand it, including complex computations. The operations of System 2 are often associated with the subjective experience of agency, choice, and concentration.</description>
    </item>
    
    <item>
      <title>Viewing the contents of an archive</title>
      <link>https://markhneedham.com/blog/2013/05/29/viewing-the-contents-of-an-archive/</link>
      <pubDate>Wed, 29 May 2013 11:22:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/29/viewing-the-contents-of-an-archive/</guid>
      <description>Everyone now and then I want to check the contents of an archive without unpacking it and I tend to use http://linux.about.com/od/commands/l/blcmdl1_unzip.htm to do so:
 $ unzip -l batch-import-jar-with-dependencies.jar | tail -n 10 1645 02-17-13 01:03 org/neo4j/batchimport/StdOutReport.class 3089 02-17-13 01:03 org/neo4j/batchimport/structs/NodeStruct.class 1244 02-17-13 01:03 org/neo4j/batchimport/structs/Property.class 1732 02-17-13 01:03 org/neo4j/batchimport/structs/PropertyHolder.class 1635 02-17-13 01:03 org/neo4j/batchimport/structs/Relationship.class 905 02-17-13 01:03 org/neo4j/batchimport/utils/Chunker.class 1884 02-17-13 01:03 org/neo4j/batchimport/utils/Params.class 4445 02-17-13 01:03 org/neo4j/batchimport/Utils.class -------- ------- 49947859 16447 files   It does the job although it does print out some information that we&amp;#8217;re not really interested in so I was intrigued to see that Alistair used http://linux.</description>
    </item>
    
    <item>
      <title>Pomodoros: Just start the timer</title>
      <link>https://markhneedham.com/blog/2013/05/27/pomodoros-just-start-the-timer/</link>
      <pubDate>Mon, 27 May 2013 13:23:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/27/pomodoros-just-start-the-timer/</guid>
      <description>I wrote earlier in the year about my use of pomodoros to track what I&amp;#8217;m doing outside of work and having done this for 6 months I noticed that I&amp;#8217;m now procrastinating over picking something off the list to work on.
 (I know&amp;#8230;&amp;#8203;I am awesome!)
 I&amp;#8217;m not sure whether this is because I don&amp;#8217;t have anything really appealing on the list of things to work on or whether having so many things listed (I have 8-10 items) is causing the paralysis.</description>
    </item>
    
    <item>
      <title>A/B Testing: Being pragmatic with statistical significance</title>
      <link>https://markhneedham.com/blog/2013/05/27/ab-testing-pragmatica-statistical-significance/</link>
      <pubDate>Mon, 27 May 2013 13:13:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/27/ab-testing-pragmatica-statistical-significance/</guid>
      <description>One of the first things that we did before starting any of the A/B tests that I&amp;#8217;ve previously written about was to work out how many users we needed to go through before we could be sure that the results we saw were statistically significant.
 We used the prop.test function from R to do this and based on our traffic at the time worked out that we&amp;#8217;d need to run a test for 6 weeks to achieve statistical significance.</description>
    </item>
    
    <item>
      <title>Polyglot Persistence: Embrace the ETL</title>
      <link>https://markhneedham.com/blog/2013/05/27/polyglot-persistence-embrace-the-etl/</link>
      <pubDate>Mon, 27 May 2013 00:11:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/27/polyglot-persistence-embrace-the-etl/</guid>
      <description>Over the past few years I&amp;#8217;ve seen the emergence of polyglot persistence i.e. using different data storage technologies for different data and in most situations we work that out up front.
   For example we might use MongoDB to store data about a customer journey through our website but we might simultaneously write page view data through to something like Hadoop or Redshift:
 This works reasonably well but sometimes it might not be immediately obvious how we want to query our data when we first start collecting it and our storage choice might not be the best for writing these queries.</description>
    </item>
    
    <item>
      <title>Polyglot Persistence: The &#39;boring&#39; relational option</title>
      <link>https://markhneedham.com/blog/2013/05/26/polyglot-persistence-the-boring-relational-option/</link>
      <pubDate>Sun, 26 May 2013 23:29:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/26/polyglot-persistence-the-boring-relational-option/</guid>
      <description>I was chatting with Brian Blignaut last week after the Equal Experts NoSQL event and he made an interesting observation that in this age of Polyglot Persistence we often rule out the relational database.
 I think it&amp;#8217;s definitely better that we now have many different options for where we store our data - be it as key/value pairs, documents or as a network/graph.
 Having these options forces us to think more about how we&amp;#8217;re going to read/write data in our application whereas previously our effort was focused around which tables we were going to pull out.</description>
    </item>
    
    <item>
      <title>A/B Testing: User Experience vs Conversion</title>
      <link>https://markhneedham.com/blog/2013/05/18/ab-testing-user-experience-vs-conversion/</link>
      <pubDate>Sat, 18 May 2013 20:18:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/18/ab-testing-user-experience-vs-conversion/</guid>
      <description>I&amp;#8217;ve written a couple of posts over the last few months about my experiences with A/B testing and one conversation we often used to have was around user experience vs conversion rate.
 Once you start running an A/B test it encourages you to focus more on the conversion rate of users in different parts of the flow and your inclination is to make changes that increase that conversion rate.</description>
    </item>
    
    <item>
      <title>Sublime: Overriding default file type/Assigning specific files to a file type</title>
      <link>https://markhneedham.com/blog/2013/05/05/sublime-overriding-default-file-typeassigning-specific-files-to-a-file-type/</link>
      <pubDate>Sun, 05 May 2013 00:03:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/05/sublime-overriding-default-file-typeassigning-specific-files-to-a-file-type/</guid>
      <description>I&amp;#8217;ve been using Sublime a bit recently and one thing I wanted to do was put neo4j cypher queries into files with arbitrary extensions and have them recognised as cypher files every time I open them.
 I&amp;#8217;m using the cypher Sublime plugin to get the syntax highlighting but since I&amp;#8217;ve got my cypher in a .haml file it only remembers that it should have cypher highlighting as long as the file is open.</description>
    </item>
    
    <item>
      <title>Mac OS X: A couple of neat tools</title>
      <link>https://markhneedham.com/blog/2013/04/30/mac-os-x-a-couple-of-neat-tools/</link>
      <pubDate>Tue, 30 Apr 2013 20:07:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/30/mac-os-x-a-couple-of-neat-tools/</guid>
      <description>When I first started working at uSwitch Sid installed a couple of &#39;productivity applications&#39; on my Mac which I&amp;#8217;ve found pretty useful but from talking to others I realised they aren&amp;#8217;t known/being used by everyone.
 Alfred Alfred is a Quick Silver replacement which allows you to quickly open applications, find files, search Google and more. Even though we&amp;#8217;re not using half of its features it&amp;#8217;s still proved to be useful.</description>
    </item>
    
    <item>
      <title>A/B Testing: Reporting</title>
      <link>https://markhneedham.com/blog/2013/04/28/ab-testing-reporting/</link>
      <pubDate>Sun, 28 Apr 2013 22:32:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/28/ab-testing-reporting/</guid>
      <description>A few months ago I wrote about my initial experiences with A/B testing and since then we&amp;#8217;ve been working on another one and learnt some things around reporting on these types of tests that I thought was interesting.
 Reporting as a first class concern One thing we changed from our previous test after a suggestion by Mike was to start treating the reporting of data related to the test as a first class citizen.</description>
    </item>
    
    <item>
      <title>No downtime deploy with capistrano, Thin and nginx</title>
      <link>https://markhneedham.com/blog/2013/04/23/no-downtime-deploy-with-capistrano-thin-and-nginx/</link>
      <pubDate>Tue, 23 Apr 2013 23:25:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/23/no-downtime-deploy-with-capistrano-thin-and-nginx/</guid>
      <description>As I mentioned a couple of weeks ago I&amp;#8217;ve been working on a tutorial about thinking through problems in graphs and since it&amp;#8217;s a Sinatra application I thought thin would be a decent choice for web server.
 In my initial setup I had the following nginx config file which was used to proxy requests on to thin:
 /etc/nginx/sites-available/thinkingingraphs.conf
 upstream thin { server 127.0.0.1:3000; } server { listen 80 default; server_name _; charset utf-8; rewrite ^\/status(.</description>
    </item>
    
    <item>
      <title>Sublime: Getting Textmate&#39;s Reveal/Select in Side Bar (Cmd &#43; Ctrl &#43; R)</title>
      <link>https://markhneedham.com/blog/2013/04/07/sublime-getting-textmates-revealselect-in-side-bar-cmd-ctrl-r/</link>
      <pubDate>Sun, 07 Apr 2013 01:00:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/07/sublime-getting-textmates-revealselect-in-side-bar-cmd-ctrl-r/</guid>
      <description>After coming across this post about why you should use Sublime Text I decided to try using it a bit more and one of the things that I missed from Textmate was the way you can select the current file on the sidebar.
 In Textmate the shortcut to do that is &#39;Cmd + Ctrl + R&#39; so I wanted to be able to do something similar or configure Sublime so it responded to the same shortcut.</description>
    </item>
    
    <item>
      <title>MySQL: Repairing broken tables/indices</title>
      <link>https://markhneedham.com/blog/2013/04/06/mysql-repairing-broken-tablesindices/</link>
      <pubDate>Sat, 06 Apr 2013 17:26:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/06/mysql-repairing-broken-tablesindices/</guid>
      <description>I part time administrate a football forum that I used to run when I was at university and one problem we had recently was that some of the tables/indices had got corrupted when MySQL crashed due to a lack of disc space.
 We weren&amp;#8217;t seeing any visible sign of a problem in any of the logs but whenever you tried to query one of the topics it wasn&amp;#8217;t returning any posts.</description>
    </item>
    
    <item>
      <title>Embracing the logs</title>
      <link>https://markhneedham.com/blog/2013/03/31/embracing-the-logs/</link>
      <pubDate>Sun, 31 Mar 2013 21:44:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/03/31/embracing-the-logs/</guid>
      <description>Despite the fact that I&amp;#8217;ve been working full time in software for almost 8 years now every now and then I still need a reminder of how useful reading logs can be in helping solve problems.
 I had a couple of such instances recently which I thought I&amp;#8217;d document.
 The first was a couple of weeks ago when Tim and I were pairing on moving some applications from Passenger to Unicorn and were testing whether or not we&amp;#8217;d done so successfully.</description>
    </item>
    
    <item>
      <title>Editing config files on a server &amp; Ctrl-Z</title>
      <link>https://markhneedham.com/blog/2013/03/29/editing-config-files-on-a-server-ctrl-z/</link>
      <pubDate>Fri, 29 Mar 2013 10:51:37 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/03/29/editing-config-files-on-a-server-ctrl-z/</guid>
      <description>A couple of weeks ago Tim and I were spinning up a new service on a machine which wasn&amp;#8217;t quite working so we were manually making changes to the /etc/nginx/nginx.conf file and restarting nginx to try and sort it out.
 This process is generally not that interesting - you open the file in vi, make some changes, close it, then restart nginx and see if it works. If not then you open the file again and repeat.</description>
    </item>
    
    <item>
      <title>When nokogiri fails with &#39;Nokogiri::XML::SyntaxError: Element script embeds close tag&#39; Web Driver to the rescue</title>
      <link>https://markhneedham.com/blog/2013/03/24/when-nokogiri-fails-with-nokogirixmlsyntaxerror-element-script-embeds-close-tag-web-driver-to-the-rescue/</link>
      <pubDate>Sun, 24 Mar 2013 21:20:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/03/24/when-nokogiri-fails-with-nokogirixmlsyntaxerror-element-script-embeds-close-tag-web-driver-to-the-rescue/</guid>
      <description>As I mentioned in my previous post I wanted to add televised games to my football graph and the Premier League website seemed like the best case to find out which games those were.
 I initially tried to use Nokogiri to grab the data that I wanted...
 &amp;gt; require &#39;nokogiri&#39; &amp;gt; require &#39;open-air&#39; &amp;gt; tv_times = Nokogiri::HTML(open(&#39;http://www.premierleague.com/en-gb/matchday/broadcast-schedules.tv.html?rangeType=.dateSeason&amp;amp;country=GB&amp;amp;clubId=ALL&amp;amp;season=2012-2013&amp;amp;isLive=true&#39;))   ...but when I tried to query by CSS selector for all the matches nothing came back:</description>
    </item>
    
    <item>
      <title>beanstalkd: Getting the status of the queue</title>
      <link>https://markhneedham.com/blog/2013/03/21/beanstalkd-getting-the-status-of-the-queue/</link>
      <pubDate>Thu, 21 Mar 2013 23:25:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/03/21/beanstalkd-getting-the-status-of-the-queue/</guid>
      <description>For the last few days Jason and I have been porting a few of our applications across to a new puppet setup and one thing we needed to do was check that messages were passing through beanstalkd correctly.
 We initially had the idea that it wasn&amp;#8217;t configured correctly so Paul showed us a way of checking whether that was the case by connecting to the port it runs on like so:</description>
    </item>
    
    <item>
      <title>Wiring up an Amazon S3 bucket to a CNAME entry - The specified bucket does not exist</title>
      <link>https://markhneedham.com/blog/2013/03/21/wiring-up-an-amazon-s3-bucket-to-a-cname-entry-the-specified-bucket-does-not-exist/</link>
      <pubDate>Thu, 21 Mar 2013 22:39:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/03/21/wiring-up-an-amazon-s3-bucket-to-a-cname-entry-the-specified-bucket-does-not-exist/</guid>
      <description>Jason and I were setting up an internal static website using an S3 bucket a couple of days ago and wanted to point a more friendly domain name at it.
 We initially called our bucket &#39;static-site&#39; and then created a CNAME entry using zerigo to point our sub domain at the bucket.
 The mapping was something like this:
 our-subdomain.somedomain.com -&amp;gt; static-site.s3-website-eu-west-1.amazonaws.com   When we tried to access the site through our-subdomain.</description>
    </item>
    
    <item>
      <title>A quick and dirty way of testing the performance of a service</title>
      <link>https://markhneedham.com/blog/2013/03/16/a-quick-and-dirty-way-of-testing-the-performance-of-a-service/</link>
      <pubDate>Sat, 16 Mar 2013 11:58:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/03/16/a-quick-and-dirty-way-of-testing-the-performance-of-a-service/</guid>
      <description>We had a power outage in our data centre yesterday and once it had recovered Jason and I wanted to do a quick check that one of our backend services was still responding in an acceptable amount of time.
 Since this particular service only serves HTTP GET requests it was reasonably easy to setup a cURL command to do this:
 while true; do curl -k -s -w %{time_total} https://serviceurl/whatever/something; -o /dev/null; printf &#34;</description>
    </item>
    
    <item>
      <title>Vertical/Horizontal Slicing</title>
      <link>https://markhneedham.com/blog/2013/02/28/verticalhorizontal-slicing/</link>
      <pubDate>Thu, 28 Feb 2013 22:23:27 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/02/28/verticalhorizontal-slicing/</guid>
      <description>A few years ago I wrote a bunch of posts exploring my experiences of outside in development eventually coming to the conclusion that it seemed to make sense to drive out functionality from the UI and work back from there.
 i.e. we take a vertical slice of functionality and then drive it end to end.
 On the team I&amp;#8217;m working on there&amp;#8217;s been success using an approach where the functionality is still split vertically but we work across a horizontal layer for all the cards before moving onto the next layer.</description>
    </item>
    
    <item>
      <title>Compatible Opinions &amp; Confirmation Bias</title>
      <link>https://markhneedham.com/blog/2013/02/28/compatible-opinions-confirmation-bias/</link>
      <pubDate>Thu, 28 Feb 2013 21:57:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/02/28/compatible-opinions-confirmation-bias/</guid>
      <description>In 2011 Jay Fields wrote a blog post in which he suggested that it&amp;#8217;s better to build teams in which people have a similar opinion on the way software should be built at a high level rather than having people whose opinions are in conflict.
 He referred to this as having &#39;compatible opinions on software&#39; and since I read the post I&amp;#8217;ve become much more aware of this myself on the teams that I&amp;#8217;ve worked on.</description>
    </item>
    
    <item>
      <title>Pomodoros and the To-Do list</title>
      <link>https://markhneedham.com/blog/2013/02/25/pomodoros-and-the-to-do-list/</link>
      <pubDate>Mon, 25 Feb 2013 23:33:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/02/25/pomodoros-and-the-to-do-list/</guid>
      <description>Anna and I were recently discussing the way that we get things done outside of work and since December I&amp;#8217;ve been fairly religiously working through various &#39;to-do&#39; lists with a pomodoro timer.
 So far I&amp;#8217;ve done 308 30 minute pomodoros in about 8 weeks which is just under 20 hours a week which is not bad but still leaves time for a ridiculous amount of procrastination.
 These are some of the things that I&amp;#8217;ve noticed from only doing things when it&amp;#8217;s explicitly on a timer:</description>
    </item>
    
    <item>
      <title>Regular Expressions: Non greedy matching</title>
      <link>https://markhneedham.com/blog/2013/02/16/regular-expressions-non-greedy-matching/</link>
      <pubDate>Sat, 16 Feb 2013 12:17:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/02/16/regular-expressions-non-greedy-matching/</guid>
      <description>I was playing around with some football data earlier in the week and I wanted to try and extract just the name &#39;Rooney&#39; from the following bit of text:
 Rooney 8′, 27′   My initial regular expression was the following which annoyingly captures the time of the first goal:
 &amp;gt; &#34;Rooney 8′, 27′&#34;.match(/(.*)\s\d(.*)/)[1] =&amp;gt; &#34;Rooney 8,&#34;   It works fine if the player has only scored one goal&amp;#8230;&amp;#8203;</description>
    </item>
    
    <item>
      <title>Onboarding: Sketch the landscape</title>
      <link>https://markhneedham.com/blog/2013/02/15/onboarding-sketch-the-landscape/</link>
      <pubDate>Fri, 15 Feb 2013 07:36:06 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/02/15/onboarding-sketch-the-landscape/</guid>
      <description>For four months during 2012 I was working on the GDS infrastructure team and one of the first tasks that Gareth suggested I do was update a diagram showing how all the different applications and databases worked together.
 I thought this was quite a strange thing to ask the &#39;new guy&#39; to do since I obviously knew nothing at all about how anything worked but he told me that was partly why he wanted me to do it.</description>
    </item>
    
    <item>
      <title>Levels of automation</title>
      <link>https://markhneedham.com/blog/2013/01/31/levels-of-automation/</link>
      <pubDate>Thu, 31 Jan 2013 22:36:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/31/levels-of-automation/</guid>
      <description>Over the last 18 months or so I&amp;#8217;ve worked on a variety of different projects in different organisations and seen some patterns around the way that automation was done which I thought would be interesting to document.
 The approaches tend to fall into roughly three categories:
 Predominantly Manual This tends to be less frequent these days as most developers have at some stage flicked through The Pragmatic Programmer and been persuaded that automating away boring and repetitive tasks is probably a good idea.</description>
    </item>
    
    <item>
      <title>A/B Testing: Thoughts so far</title>
      <link>https://markhneedham.com/blog/2013/01/27/ab-testing-thoughts-so-far/</link>
      <pubDate>Sun, 27 Jan 2013 13:27:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/27/ab-testing-thoughts-so-far/</guid>
      <description>I&amp;#8217;ve been working at uSwitch for about two months now and for the majority of that time have been working on an A/B test we were running to try and make it easier for users to go through the energy comparison process.
 I found the &#39;http://www.exp-platform.com/Documents/GuideControlledExperiments.pdf[Practical Guide to Controlled Experiments on the Web]&#39; paper useful for explaining how to go about doing an A/B test and there&amp;#8217;s also an interesting presentation by Dan McKinley about how etsy do A/B testing.</description>
    </item>
    
    <item>
      <title>telnet/netcat: Waiting for a port to be open</title>
      <link>https://markhneedham.com/blog/2013/01/20/waiting-for-a-port-to-be-open/</link>
      <pubDate>Sun, 20 Jan 2013 15:53:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/20/waiting-for-a-port-to-be-open/</guid>
      <description>On Friday Nathan and I were setting up a new virtual machine and we needed a firewall rule to be created to allow us to connect to another machine which had some JAR files we wanted to download.
 We wanted to know when it had been done by one of our operations team and I initially thought we might be able to do that using telnet:
 $ telnet 10.</description>
    </item>
    
    <item>
      <title>A new year&#39;s idea: Share what you learn</title>
      <link>https://markhneedham.com/blog/2013/01/05/a-new-years-idea-share-what-you-learn/</link>
      <pubDate>Sat, 05 Jan 2013 00:25:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/05/a-new-years-idea-share-what-you-learn/</guid>
      <description>Apologies in advance for how meta this post is.
 About 4 1/2 years ago Jay Fields wrote a blog post where he encouraged people to write, present and contribute and outlined the advantages he&amp;#8217;d seen in his career from doing so.
 In hindsight the bit which stood out the most for me was the following paragraph:
  Don&amp;#8217;t know what to write about? The answers are all around you.</description>
    </item>
    
    <item>
      <title>TextMate Bundles location on Mountain Lion</title>
      <link>https://markhneedham.com/blog/2012/12/31/textmate-bundles-location-on-mountain-lion/</link>
      <pubDate>Mon, 31 Dec 2012 23:59:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/textmate-bundles-location-on-mountain-lion/</guid>
      <description>Something that I&amp;#8217;ve noticed when trying to install various different bundles is that the installation instructions which worked flawlessly on Snow Leopard don&amp;#8217;t seem to do the job on Mountain Lion.
 For example, the Clojure bundle assumes that the installation directory is &#39;~/Library/Application\ Support/TextMate/Bundles&#39; but for some reason the &#39;Bundles&#39; folder doesn&amp;#8217;t exist.
 We therefore have two choices:
   mkdir -p ~/Library/Application\ Support/TextMate/Bundles and then continue as normal</description>
    </item>
    
    <item>
      <title>Gamification and Software: Some thoughts</title>
      <link>https://markhneedham.com/blog/2012/12/31/gamification-and-software-some-thoughts/</link>
      <pubDate>Mon, 31 Dec 2012 10:57:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/31/gamification-and-software-some-thoughts/</guid>
      <description>On the recommendation of J.B. Rainsberger I&amp;#8217;ve been reading &#39;http://www.amazon.co.uk/Reality-Broken-Games-Better-Change/dp/0224089250/ref=sr_1_1?ie=UTF8&amp;amp;qid=1356692858&amp;amp;sr=8-1[Reality is Broken]&#39; - a book which talks about how we can apply some of the things games designers have learned about getting people engaged to real life.
 The author, Jane McGonigal, also has a TED talk on the topic which will help you get a flavour for the topic.
 I was particularly interested in trying to see how her ideas could be applied in a software context and indeed how they are already being applied.</description>
    </item>
    
    <item>
      <title>rsyncing to an AWS instance</title>
      <link>https://markhneedham.com/blog/2012/12/11/rsyncing-to-an-aws-instance/</link>
      <pubDate>Tue, 11 Dec 2012 23:44:05 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/11/rsyncing-to-an-aws-instance/</guid>
      <description>I wanted to try running some of the machine learning algorithms that Jen and I have been playing around with on a beefier machine so I thought spinning up an AWS instance would be the best way to do that.
 I built the JAR with the appropriate algorithms on my machine and then wanted to copy it up onto an AWS instance.
 I could have used scp but I quite like the progress bar that you can get with rsync and since the JAR had somehow drifted to a size of 47MB the progress bar was useful.</description>
    </item>
    
    <item>
      <title>apt-get update: 416 Requested Range Not Satisfiable</title>
      <link>https://markhneedham.com/blog/2012/12/10/apt-get-update-416-requested-range-not-satisfiable/</link>
      <pubDate>Mon, 10 Dec 2012 00:39:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/10/apt-get-update-416-requested-range-not-satisfiable/</guid>
      <description>We were trying to run a puppet update on some machines last week and one of the first things it does is run &#39;apt-get update&#39; which was working on all but one node for which it was returning the following exception:
 Err http://us-west-1.ec2.archive.ubuntu.com/ubuntu/ i386 Packages 416 Requested Range Not Satisfiable Fetched 5,079B in 2s (2,296B/s) W: Failed to fetch http://us-west-1.ec2.archive.ubuntu.com/ubuntu/dists/maverick-updates/main/binary-i386/Packages.gz 416 Requested Range Not Satisfiable   It turns out one way that exception can manifest is if you&amp;#8217;ve got a partial copy of the index files from the repository and in this case the solution was as simple as deleting those and trying again:</description>
    </item>
    
    <item>
      <title>IntelliJ Debug Mode: Viewing beyond 100 frames/items in an array</title>
      <link>https://markhneedham.com/blog/2012/11/26/intellij-debug-mode-viewing-beyond-100-framesitems-in-an-array/</link>
      <pubDate>Mon, 26 Nov 2012 04:28:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/26/intellij-debug-mode-viewing-beyond-100-framesitems-in-an-array/</guid>
      <description>In my continued attempts at the Kaggle Digit Recognizer problem I&amp;#8217;ve been playing around with the encog library to try and build a neural networks solution to the problem.
 Unfortunately it&amp;#8217;s not quite working at the moment so I wanted to debug the code and see whether the input parameters were being correctly translated from the CSV file.
 Each input is an array containing 784 values but by default IntelliJ restricts you to seeing 100 elements which wasn&amp;#8217;t helpful in my case since the early values tend to all be 0 and it&amp;#8217;s not until you get half way through that you see different values:</description>
    </item>
    
    <item>
      <title>Core Competency</title>
      <link>https://markhneedham.com/blog/2012/11/24/core-competency/</link>
      <pubDate>Sat, 24 Nov 2012 12:44:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/24/core-competency/</guid>
      <description>For at least the last few years I&amp;#8217;ve heard colleagues talk about working out the core competency of our clients businesses and I&amp;#8217;d confused myself into thinking that the software we helped them build was the core competency.
 I think Martin Fowler best explains how technology and business core competences work in his post about utility and strategic projects where he describes the difference between these like so:
  So what is the distinguishing factor between utility and strategic projects?</description>
    </item>
    
    <item>
      <title>Windows line endings: Exception in thread &#39;main&#39; java.io.FileNotFoundException /opt/app/config.yml{caret}M (no such file or directory)</title>
      <link>https://markhneedham.com/blog/2012/11/24/windows-line-endings-exception-in-thread-main-java-io-filenotfoundexception-optappconfig-ymlm-no-such-file-or-directory/</link>
      <pubDate>Sat, 24 Nov 2012 09:04:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/24/windows-line-endings-exception-in-thread-main-java-io-filenotfoundexception-optappconfig-ymlm-no-such-file-or-directory/</guid>
      <description>As I mentioned in my previous post we&amp;#8217;ve been making it possible to deploy our application to a new environment and as part of this we defined an upstart script which would run the JAR.
 We tend to edit code on Windows and then test it out on the vagrant VM afterwards.
 The end of our upstart script looked a bit like this:
 script cd /opt/app java -jar /opt/app/app.</description>
    </item>
    
    <item>
      <title>Looking inside the black box</title>
      <link>https://markhneedham.com/blog/2012/11/21/looking-inside-the-black-box/</link>
      <pubDate>Wed, 21 Nov 2012 19:42:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/21/looking-inside-the-black-box/</guid>
      <description>I recently came across a really interesting post about black box abstraction by Angeleah where she talks about developers desire to know how things work and the need to understand when and when not to follow that instinct.
 Angeleah defines black box abstraction like so:
  It is a technique for controlling complexity and abstracting detail. The point of doing this is to allow you to to build bigger things.</description>
    </item>
    
    <item>
      <title>Incremental/iterative development: Breaking down work</title>
      <link>https://markhneedham.com/blog/2012/11/19/incrementaliterative-development-breaking-down-work/</link>
      <pubDate>Mon, 19 Nov 2012 08:50:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/19/incrementaliterative-development-breaking-down-work/</guid>
      <description>Over the past couple of years I&amp;#8217;ve worked on several different applications and one thing they had in common was that they had a huge feature which would take a few months to complete and initially seemed difficult to break down.
 Since we favoured an incremental/iterative approach to building these features and wanted to add value in short feedback cycles we needed to find a way to break them down.</description>
    </item>
    
    <item>
      <title>Buy vs Build: Driving from the problem</title>
      <link>https://markhneedham.com/blog/2012/11/17/buy-vs-build-driving-from-the-problem/</link>
      <pubDate>Sat, 17 Nov 2012 16:56:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/17/buy-vs-build-driving-from-the-problem/</guid>
      <description>My colleague Erik Doernenburg has written a couple of articles recently discussing the reasons why people buy and build IT solutions and one part in particular resonated with me:
  it is also possible, and not uncommon, that the software package does not do exactly what the business needs, leading to decreased productivity and lost opportunities.
   I feel like there&amp;#8217;s a mindset change once you start thinking which package you could buy to solve your problem whereby you stop solving the problem you actually have and focus instead on what features the package offers.</description>
    </item>
    
    <item>
      <title>Do the simple thing</title>
      <link>https://markhneedham.com/blog/2012/10/21/do-the-simple-thing/</link>
      <pubDate>Sun, 21 Oct 2012 21:35:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/21/do-the-simple-thing/</guid>
      <description>One of the most unexpected things that I picked up while pairing with Ashok for a few days in August/September is his ability to pick the simplest solution when confronted with a problem.
 On numerous occasions we&amp;#8217;d be trying to do something and I&amp;#8217;d end up on a yak shaving mission trying to get a complicated approach to work while he watched on with bemusement.
 I thought I&amp;#8217;d actually learnt this lesson from working with Ashok but on a couple of occasions over the last week I&amp;#8217;ve caught myself doing the same thing again!</description>
    </item>
    
    <item>
      <title>Environment agnostic machines and applications</title>
      <link>https://markhneedham.com/blog/2012/10/14/environment-agnostic-machines-and-applications/</link>
      <pubDate>Sun, 14 Oct 2012 18:49:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/14/environment-agnostic-machines-and-applications/</guid>
      <description>On my current project we&amp;#8217;ve been setting up production and staging environments and Shodhan came up with the idea of making staging and production identical to the point that a machine wouldn&amp;#8217;t even know what environment it was in.
 Identical in this sense means:
   Puppet doesn&amp;#8217;t know which environment the machine is in. Our factor variables suggest the environment is production.
  We set the RACK_ENV variable to production so applications don&amp;#8217;t know what environment they&amp;#8217;re in.</description>
    </item>
    
    <item>
      <title>Play Framework 2.0: Rendering JSON data in the view</title>
      <link>https://markhneedham.com/blog/2012/10/14/play-framework-2-0-rendering-json-data-in-the-view/</link>
      <pubDate>Sun, 14 Oct 2012 09:28:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/14/play-framework-2-0-rendering-json-data-in-the-view/</guid>
      <description>I&amp;#8217;ve been playing around with the Play Framework which we&amp;#8217;re using to front a bunch of visualisations and one thing I wanted to do is send a data structure to a view and then convert that into JSON.
 I&amp;#8217;ve got a simple controller which looks like this:
 package controllers; import play.mvc.Controller; import play.mvc.Result; import views.html.*; public class SalesByCategory extends Controller { public static Result index() { ArrayList&amp;lt;Map&amp;lt;String, Object&amp;gt;&amp;gt; series = new ArrayList&amp;lt;Map&amp;lt;String, Object&amp;gt;&amp;gt;(); Map&amp;lt;String, Object&amp;gt; oneSeries = new HashMap&amp;lt;String, Object&amp;gt;(); oneSeries.</description>
    </item>
    
    <item>
      <title>Varnish: Purging the cache</title>
      <link>https://markhneedham.com/blog/2012/10/10/varnish-purging-the-cache/</link>
      <pubDate>Wed, 10 Oct 2012 23:28:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/10/varnish-purging-the-cache/</guid>
      <description>We&amp;#8217;re using varnish to cache all the requests that come through our web servers and especially in our pre-production environments we deploy quite frequently and want to see the changes that we&amp;#8217;ve made.
 This means that we need to purge the pages we&amp;#8217;re accessing from varnish so that it will actually pass the request through to the application server and serve up the latest version of the page.
 For some reason my google-fu when trying to remember/work out how to do this has always been weak but my colleague Shodhan helped me understand how to do this today so I thought I better record it so I don&amp;#8217;t forget!</description>
    </item>
    
    <item>
      <title>Mac OS X: Removing Byte Order Mark with an editor</title>
      <link>https://markhneedham.com/blog/2012/10/07/mac-os-x-removing-byte-order-mark-with-an-editor/</link>
      <pubDate>Sun, 07 Oct 2012 10:43:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/10/07/mac-os-x-removing-byte-order-mark-with-an-editor/</guid>
      <description>About a month ago I wrote about some problems I was having working with Windows generated CSV files which had a Byte Order Mark (BOM) at the beginning of the file and I described a way to get rid of it using awk.
 It&amp;#8217;s a bit of a long winded process though and I always forget what the parameters I need to pass to awk are so I thought it would probably be quicker if I could just work out a way to get rid of the BOM using an editor.</description>
    </item>
    
    <item>
      <title>logstash not picking up some files</title>
      <link>https://markhneedham.com/blog/2012/09/07/logstash-not-picking-up-some-files/</link>
      <pubDate>Fri, 07 Sep 2012 23:49:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/07/logstash-not-picking-up-some-files/</guid>
      <description>We&amp;#8217;re using logstash to collect all the logs across the different machines that we use in various environments and had noticed that on some of the nodes log files which we&amp;#8217;d told the logstash-client to track weren&amp;#8217;t being collected.
 We wanted to check what the open file descriptors of logstash-client were so we first had to grab its process id:
 $ ps aux | grep logstash logstash 19896 134 9.</description>
    </item>
    
    <item>
      <title>Apt-Cacher-Server: Extra junk at end of file</title>
      <link>https://markhneedham.com/blog/2012/09/07/apt-cacher-server-extra-junk-at-end-of-file/</link>
      <pubDate>Fri, 07 Sep 2012 15:45:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/07/apt-cacher-server-extra-junk-at-end-of-file/</guid>
      <description>We&amp;#8217;ve been installing Apt-Cache-Server so that we can cache some of the packages that we&amp;#8217;re installing using apt-get on our own network.
 (Almost) Following the instructions from the home page we added the following to /etc/apt/apt.conf.d/01proxy:
 Acquire::http::Proxy &#34;http://apt-cache-server:3142&#34;   And when we ran &#39;apt-get update&#39; we were getting the following error:
 E: Syntax error /etc/apt/apt.conf.d/01proxy:2: Extra junk at end of file   We initially thought it must be a problem with having an extra space or line ending but it turns out we had just left off the semi colon.</description>
    </item>
    
    <item>
      <title>A rogue &#34;\357\273\277&#34; (UTF-8 byte order mark)</title>
      <link>https://markhneedham.com/blog/2012/09/03/a-rogue-357273277-utf-8-byte-order-mark/</link>
      <pubDate>Mon, 03 Sep 2012 06:31:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/03/a-rogue-357273277-utf-8-byte-order-mark/</guid>
      <description>We&amp;#8217;ve been loading some data into neo4j from a CSV file - creating one node per row and using the value in the first column as the index lookup for the node.
 Unfortunately the index lookup wasn&amp;#8217;t working for the first row but was for every other row.
 By coincidence we started saving each row into a hash map and were then able to see what was going wrong:</description>
    </item>
    
    <item>
      <title>The Curse Of Knowledge</title>
      <link>https://markhneedham.com/blog/2012/08/28/the-curse-of-knowledge/</link>
      <pubDate>Tue, 28 Aug 2012 21:22:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/28/the-curse-of-knowledge/</guid>
      <description>My colleague Anand Vishwanath recently recommended the book &#39;http://www.amazon.co.uk/Made-Stick-ideas-others-unstuck/dp/009950569X/ref=sr_1_1?ie=UTF8&amp;amp;qid=1346108348&amp;amp;sr=8-1[Made To Stick]&#39; and one thing that has really stood out for me while reading it is the idea of the &#39;The Curse Of Knowledge&#39; which is described like so:
  Once we know something, we find it hard to imagine what it was like not to know it. Our knowledge has &#34;cursed&#34; us. And it becomes difficult for us to share out knowledge with others, because can&amp;#8217;t readily re-create our listeners&#39; state of mind.</description>
    </item>
    
    <item>
      <title>puppetdb: Failed to submit &#39;replace catalog&#39; command for client to PuppetDB at puppetmaster:8081: [500 Server Error]</title>
      <link>https://markhneedham.com/blog/2012/08/16/puppetdb-failed-to-submit-replace-catalog-command-for-client-to-puppetdb-at-puppetmaster8081-500-server-error/</link>
      <pubDate>Thu, 16 Aug 2012 23:31:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/16/puppetdb-failed-to-submit-replace-catalog-command-for-client-to-puppetdb-at-puppetmaster8081-500-server-error/</guid>
      <description>I&amp;#8217;m still getting used to the idea of following the logs when working out what&amp;#8217;s going wrong with distributed systems but it worked well when trying to work out why our puppet client which was throwing this error when we ran &#39;puppet agent -tdv&#39;:
 err: Could not retrieve catalog from remote server: Error 400 on SERVER: Failed to submit &#39;replace catalog&#39; command for client to PuppetDB at puppetmaster:8081: [500 Server Error]   We were seeing the same error in /var/log/syslog on the puppet master and a quick look at the process list didn&amp;#8217;t show that the puppet master or puppetdb services were under a particularly heavy load.</description>
    </item>
    
    <item>
      <title>London Bus Stops API: Mapping northing/easting values to lat/long</title>
      <link>https://markhneedham.com/blog/2012/07/30/london-bus-stops-api-mapping-northingeasting-values-to-latlong/</link>
      <pubDate>Mon, 30 Jul 2012 22:28:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/30/london-bus-stops-api-mapping-northingeasting-values-to-latlong/</guid>
      <description>I started playing around with the TFL Bus stop location and routes API and one of the annoying things about the data is that it uses easting/northing values to describe the location of bus stops rather than lat/longs.
 The first few lines of the CSV file look like this:
 1000,91532,490000266G,WESTMINSTER STN &amp;lt;&amp;gt; / PARLIAMENT SQUARE,530171,179738,177,0K08,0 10001,72689,490013793E,TREVOR CLOSE,515781,174783,78,NB16,0 10002,48461,490000108F,HIGHBURY CORNER,531614,184603,5,C902,0   For each of the stops I wanted to convert from the easting/northing value to the equivalent lat/long value but I couldn&amp;#8217;t find a simple way of doing it in code although I did come across an API that would do it for me.</description>
    </item>
    
    <item>
      <title>Puppet: Keeping the discipline</title>
      <link>https://markhneedham.com/blog/2012/07/29/puppet-keeping-the-discipline/</link>
      <pubDate>Sun, 29 Jul 2012 21:53:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/29/puppet-keeping-the-discipline/</guid>
      <description>For the last 5 weeks or so I&amp;#8217;ve been working with puppet every day to automate the configuration of various nodes in our stack and my most interesting observation so far is that you really need to keep your discipline when doing this type of work.
 We can keep that discipline in three main ways when developing modules.
 Running from scratch Configuring various bits of software seems to follow the 80/20 rule and we get very close to having each thing working quite quickly but then end up spending a disproportionate amount of time tweaking the last little bits.</description>
    </item>
    
    <item>
      <title>Racket: Wiring it up to a REPL ala SLIME/Swank</title>
      <link>https://markhneedham.com/blog/2012/07/11/racket-wiring-it-up-to-a-repl-ala-slimeswank/</link>
      <pubDate>Wed, 11 Jul 2012 19:34:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/11/racket-wiring-it-up-to-a-repl-ala-slimeswank/</guid>
      <description>One of the awesome things about working with clojure is that it&amp;#8217;s possible to wire up clojure files in emacs to a REPL by making use of Slime/https://github.com/technomancy/swank-clojure[Swank].
 I&amp;#8217;ve started using Racket to work through the examples in The Little Schemer and wanted to achieve a similar thing there.
  Racket is a modern programming language in the Lisp/Scheme family, suitable for a wide range of applications
   I don&amp;#8217;t know much about configuring emacs so I made use of Phil Halgelberg&amp;#8217;s emacs-starter-kit which is available on github.</description>
    </item>
    
    <item>
      <title>Data visualisation: Is &#39;interesting&#39; enough?</title>
      <link>https://markhneedham.com/blog/2012/07/08/data-visualisation-is-interesting-enough/</link>
      <pubDate>Sun, 08 Jul 2012 22:45:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/08/data-visualisation-is-interesting-enough/</guid>
      <description>I recently read a blog post by Julian Boot titled &#39;http://julianboot.com/2012/07/visualisation-without-analysis/[visualisation without analysis is fine]&#39; where he suggests that we can learn things from visualising data in the right way - detailed statistical analysis isn&amp;#8217;t always necessary.
 I thought this was quite an interesting observation because over the past couple of months I&amp;#8217;ve been playing around with ThoughtWorks data and looking at different ways to visualise aspects of the data.</description>
    </item>
    
    <item>
      <title>ganglia: Importing gmond Python modules</title>
      <link>https://markhneedham.com/blog/2012/07/08/ganglia-importing-gmond-python-modules/</link>
      <pubDate>Sun, 08 Jul 2012 21:55:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/08/ganglia-importing-gmond-python-modules/</guid>
      <description>My colleague Shohdan and I spent a couple of days last week wiring up various monitoring metrics into ganglia and while most of them come built in, we also found some python based modules that we wanted to use.
 Unfortunately we couldn&amp;#8217;t find any instructions on github explaining how to set them up but after a bit of trial and error we figured it out.
 One of the modules that we wanted to use was diskstat which provides I/O wait time metrics which we couldn&amp;#8217;t find in the built in modules.</description>
    </item>
    
    <item>
      <title>sudo, sudo -i &amp; sudo su</title>
      <link>https://markhneedham.com/blog/2012/07/04/sudo-sudo-i-sudo-su/</link>
      <pubDate>Wed, 04 Jul 2012 19:34:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/04/sudo-sudo-i-sudo-su/</guid>
      <description>On the project I&amp;#8217;m currently working on we&amp;#8217;re doing quite a bit of puppet and although we&amp;#8217;re using the puppet master approach in production &amp;amp; test environments it&amp;#8217;s still useful to be able to run puppet headless to test changes locally.
 Since several of the commands require having write access to &#39;root&#39; folders we need to run &#39;puppet apply&#39; as a super user using sudo. We also need to run it in the context of some environment variables which the root user has.</description>
    </item>
    
    <item>
      <title>Debugging: Google vs The Manual</title>
      <link>https://markhneedham.com/blog/2012/07/04/debugging-google-vs-the-manual/</link>
      <pubDate>Wed, 04 Jul 2012 00:00:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/04/debugging-google-vs-the-manual/</guid>
      <description>Over the last six months or so I&amp;#8217;ve worked with a bunch of different people and one of the things that I&amp;#8217;ve noticed is that when something isn&amp;#8217;t working there tend to be two quite distinct ways that people go about trying to solve the problem.
 The Manual The RTFM crowd will go straight for the official documentation or source code if needs be in an attempt to work through the problem from first principals.</description>
    </item>
    
    <item>
      <title>Powerpoint saving movies as images</title>
      <link>https://markhneedham.com/blog/2012/06/30/powerpoint-saving-movies-as-images/</link>
      <pubDate>Sat, 30 Jun 2012 10:05:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/30/powerpoint-saving-movies-as-images/</guid>
      <description>I&amp;#8217;ve been working on a presentation for the ThoughtWorks Europe away day over the last few days and I created some screen casts using Camtasia which I wanted to include.
 It&amp;#8217;s reasonably easy to insert movies into Powerpoint but I was finding that when I saved the file and then reloaded it the movies had been converted into images which wasn&amp;#8217;t what I wanted at all!
 Eventually I came across a blog post which explained that I&amp;#8217;d been saving the file as the wrong format.</description>
    </item>
    
    <item>
      <title>Why you shouldn&#39;t use name as a key a.k.a. I am an idiot</title>
      <link>https://markhneedham.com/blog/2012/06/24/why-you-shouldnt-use-name-as-a-key-a-k-a-i-am-an-idiot/</link>
      <pubDate>Sun, 24 Jun 2012 22:55:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/24/why-you-shouldnt-use-name-as-a-key-a-k-a-i-am-an-idiot/</guid>
      <description>I think one of the first things that I learnt about dealing with users in a data store is that you should never use name as a primary key because their might be two people with the same name.
 Despite knowing that I foolishly chose to ignore this knowledge when building my neo4j graph and used name as the key for the Lucene index.
 I thought I&amp;#8217;d got away with it but NO!</description>
    </item>
    
    <item>
      <title>Brightbox Repository: GPG error: The following signatures couldn&#39;t be verified because the public key is not available</title>
      <link>https://markhneedham.com/blog/2012/06/24/brightbox-repository-gpg-error-the-following-signatures-couldnt-be-verified-because-the-public-key-is-not-available/</link>
      <pubDate>Sun, 24 Jun 2012 00:58:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/24/brightbox-repository-gpg-error-the-following-signatures-couldnt-be-verified-because-the-public-key-is-not-available/</guid>
      <description>We&amp;#8217;re using the Brightbox Ruby repository to get the versions of Ruby which we install on our machines and although we eventually put the configuration for this repository into Puppet we initially tested it out on a local VM.
 To start with you need to add the repository to /etc/apt/sources.list:
 deb http://ppa.launchpad.net/brightbox/ruby-ng/ubuntu lucid main   To get that picked up we run the following:
 apt-get update   Which initially threw this error because it&amp;#8217;s a gpg signed repository and we hadn&amp;#8217;t added the key:</description>
    </item>
    
    <item>
      <title>Creating a Samba share between Ubuntu and Mac OS X</title>
      <link>https://markhneedham.com/blog/2012/06/24/creating-a-samba-share-between-ubuntu-and-mac-os-x/</link>
      <pubDate>Sun, 24 Jun 2012 00:40:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/24/creating-a-samba-share-between-ubuntu-and-mac-os-x/</guid>
      <description>On the project I&amp;#8217;m currently working on we have our development environment setup on a bare bones Ubuntu instance which we run via VmWare.
 We wanted to be able to edit files on the VM from the host O/S so my colleague Phil suggested that we set up a Samba server on the VM and then connect to it from the Mac.
 We first needed to install a couple of packages on the VM:</description>
    </item>
    
    <item>
      <title>The Little Schemer: Attempt #2</title>
      <link>https://markhneedham.com/blog/2012/06/19/the-little-schemer-attempt-2/</link>
      <pubDate>Tue, 19 Jun 2012 00:21:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/19/the-little-schemer-attempt-2/</guid>
      <description>A few weeks ago I asked the twittersphere for some advice on how I could get better at writing recursive functions and one of the pieces of advice was to work through The Little Schemer.
 I first heard about The Little Schemer a couple of years ago and after going through the first few pages I got bored and gave up.
 I still found the first few pages a bit trivial this time around as well but my colleague Jen Smith encouraged me to keep going and once I&amp;#8217;d got about 20 pages in it became clearer to me why the first few pages had been written the way they had.</description>
    </item>
    
    <item>
      <title>Functional Thinking: Separating concerns</title>
      <link>https://markhneedham.com/blog/2012/06/12/functional-thinking-separating-concerns/</link>
      <pubDate>Tue, 12 Jun 2012 23:50:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/12/functional-thinking-separating-concerns/</guid>
      <description>Over the weekend I was trying to port some of the neo4j import code for the ThoughtWorks graph I&amp;#8217;ve been working on to make use of the REST Batch API and I came across an interesting example of imperative vs functional thinking.
 I&amp;#8217;m using the neography gem to populate the graph and to start with I was just creating a person node and then creating an index entry for it:</description>
    </item>
    
    <item>
      <title>CSV parsing/UTF-8 encoding</title>
      <link>https://markhneedham.com/blog/2012/06/10/csv-parsingutf-8-encoding/</link>
      <pubDate>Sun, 10 Jun 2012 23:30:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/06/10/csv-parsingutf-8-encoding/</guid>
      <description>I was recently trying to parse a CSV file which I&amp;#8217;d converted from an Excel spreadsheet but was having problems with characters beyond the standard character set.
 This is an example of what was going wrong:
 &amp;gt; require &#39;csv&#39; &amp;gt; people = CSV.open(&#34;sponsors.csv&#34;, &#39;r&#39;, ?,, ?\r).to_a [&#34;Erik D\366rnenburg&#34;, &#34;N/A&#34;] &amp;gt; people.each { |sponsee, sponsor| puts &#34;#{sponsee} #{sponsor}&#34; } Erik D?rnenburg N/A   I came across a Ruby gem called http://snippets.</description>
    </item>
    
    <item>
      <title>Google Maps without any labels/country names</title>
      <link>https://markhneedham.com/blog/2012/05/31/google-maps-without-any-labelscountry-names/</link>
      <pubDate>Thu, 31 May 2012 21:52:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/31/google-maps-without-any-labelscountry-names/</guid>
      <description>I wanted to get a blank version of Google Maps without any of the country names on for a visualisation I&amp;#8217;m working on but I&amp;#8217;d been led to believe that this wasn&amp;#8217;t actually possible.
 In actual fact we do have control over whether the labels are shown via the &#39;styles&#39; option which we can call on the map.
 In my case the code looks like this:
 var map = new google.</description>
    </item>
    
    <item>
      <title>Building an API: Test Harness UI</title>
      <link>https://markhneedham.com/blog/2012/05/19/building-an-api-test-harness-ui/</link>
      <pubDate>Sat, 19 May 2012 20:03:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/05/19/building-an-api-test-harness-ui/</guid>
      <description>On the project I&amp;#8217;ve been working on we&amp;#8217;re building an API to be used by other applications in the organisation but when we started none of those applications were ready to integrate with us and therefore drive the API design.
 Initially we tried driving the API through integration style tests but we realised that taking this approach made it quite difficult for us to imagine how an application would use it.</description>
    </item>
    
    <item>
      <title>gephi: Centring a graph around an individual node</title>
      <link>https://markhneedham.com/blog/2012/04/30/gephi-centring-a-graph-around-an-individual-node/</link>
      <pubDate>Mon, 30 Apr 2012 22:20:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/30/gephi-centring-a-graph-around-an-individual-node/</guid>
      <description>I spent some time recently playing around with gephi - an open source platform for creating visualisations of graphs - to get a bit more insight into the ThoughtWorks graph which I&amp;#8217;ve created in neo4j.
 I followed Max De Marxi&amp;#8217;s blog post to create a GEFX (Graph Exchange XML Format) file to use in gephi although I later learned that you can import directly from neo4j into gephi which I haven&amp;#8217;t tried yet.</description>
    </item>
    
    <item>
      <title>Performance: Caching per request</title>
      <link>https://markhneedham.com/blog/2012/04/30/performance-caching-per-request/</link>
      <pubDate>Mon, 30 Apr 2012 21:45:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/30/performance-caching-per-request/</guid>
      <description>A couple of years ago I wrote a post describing an approach my then colleague Christian Blunden used to help improve the performance of an application where you try to do expensive things less or find another way to do them.
 On the application I&amp;#8217;m currently working on we load reference data from an Oracle database into memory based on configurations provided by the user.
 There are multiple configurations and then multiple ways that those configurations can be priced so we have two nested for loops in which we load data and then perform calculations on it.</description>
    </item>
    
    <item>
      <title>Algo Class: Start simple and build up</title>
      <link>https://markhneedham.com/blog/2012/04/24/algo-class-start-simple-and-build-up/</link>
      <pubDate>Tue, 24 Apr 2012 07:17:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/24/algo-class-start-simple-and-build-up/</guid>
      <description>Over the last six weeks I&amp;#8217;ve been working through Stanford&amp;#8217;s Design and Analysis of Algorithms I class and each week there&amp;#8217;s been a programming assignment on a specific algorithm for which a huge data set is provided.
 For the first couple of assignments I tried writing the code for the algorithm and then running it directly against the provided data set.
 As you might imagine it never worked first time and this approach led to me becoming very frustrated because there&amp;#8217;s no way of telling what went wrong.</description>
    </item>
    
    <item>
      <title>neo4J: Searching for nodes by name</title>
      <link>https://markhneedham.com/blog/2012/04/20/neo4j-searching-for-nodes-by-name/</link>
      <pubDate>Fri, 20 Apr 2012 07:10:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/20/neo4j-searching-for-nodes-by-name/</guid>
      <description>As I mentioned in a post a few days ago I&amp;#8217;ve been graphing connections between ThoughtWorks people using neo4j and wanted to build auto complete functionality so I can search for the names of people in the graph.
 The solution I came up was to create a Lucene index with an entry for each node and a common property on each document in the index so that I&amp;#8217;d be able to get all the index entries easily.</description>
    </item>
    
    <item>
      <title>neography/neo4j/Lucene: Getting a list of all the nodes indexed</title>
      <link>https://markhneedham.com/blog/2012/04/17/neographyneo4jlucene-getting-a-list-of-all-the-nodes-indexed/</link>
      <pubDate>Tue, 17 Apr 2012 06:54:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/17/neographyneo4jlucene-getting-a-list-of-all-the-nodes-indexed/</guid>
      <description>I&amp;#8217;ve been playing around with neo4j using the neography gem to create a graph of all the people in ThoughtWorks and the connections between them based on working with each other.
 I created a UI where you could type in the names of two people and see when they&amp;#8217;ve worked together or the path between the shortest path between them if they haven&amp;#8217;t.
 I thought it would be cool to have auto complete functionality when typing in a name but I couldn&amp;#8217;t figure out how to partially query the index of people&amp;#8217;s names that I&amp;#8217;d created.</description>
    </item>
    
    <item>
      <title>Just Observe</title>
      <link>https://markhneedham.com/blog/2012/04/09/just-observe/</link>
      <pubDate>Mon, 09 Apr 2012 22:45:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/04/09/just-observe/</guid>
      <description>One of the most common instincts of a developer when starting on a new team is to look at the way the application has been designed and find ways that it can be done differently.
 Most often &#39;differently&#39; means that a pattern used in a previous project will be favoured and while I think it&amp;#8217;s good to make use of experience that we&amp;#8217;ve gained, we do miss out on some learning if we write every application the same way.</description>
    </item>
    
    <item>
      <title>IntelliJ: Find/Replace using regular expressions with capture groups</title>
      <link>https://markhneedham.com/blog/2012/03/30/intellij-findreplace-using-regular-expressions-with-capture-groups/</link>
      <pubDate>Fri, 30 Mar 2012 06:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/30/intellij-findreplace-using-regular-expressions-with-capture-groups/</guid>
      <description>Everyone now and then we end up having to write a bunch of mapping code and I quite like using IntelliJ&amp;#8217;s &#39;Replace&#39; option to do it but always end up spending about 5 minutes trying to remember how to do capture groups so I thought I&amp;#8217;d write it down this time.
 Given the following text in our file:
 val mark = 0 val dave = 0 val john = 0 val alex = 0   Let&amp;#8217;s say we wanted to prefix each of those names with &#39;cool&#39; and had decided not to use Column mode for whatever reason.</description>
    </item>
    
    <item>
      <title>Readability/Performance</title>
      <link>https://markhneedham.com/blog/2012/03/29/readabilityperformance/</link>
      <pubDate>Thu, 29 Mar 2012 06:45:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/29/readabilityperformance/</guid>
      <description>I recently read the Graphite chapter of The Architecture of Open Source Applications book which mostly tells the story of how Chris Davis incrementally built out Graphite - a pretty cool tool that can be used to do real time graphing of metrics.
 The whole chapter is a very good read but I found the design reflections especially interesting:
  One of Graphite&amp;#8217;s greatest strengths and greatest weaknesses is the fact that very little of it was actually &#34;</description>
    </item>
    
    <item>
      <title>Saving the values of dynamically populated dropdown on back button</title>
      <link>https://markhneedham.com/blog/2012/03/24/saving-the-values-of-dynamically-populated-dropdown-on-back-button/</link>
      <pubDate>Sat, 24 Mar 2012 00:40:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/24/saving-the-values-of-dynamically-populated-dropdown-on-back-button/</guid>
      <description>We wanted to be able to retain the value of a drop down menu that was being dynamically populated (via an AJAX call) when the user hit the back button but the AJAX request re-runs when we go hit back therefore losing our selection.
 Our initial thinking was that we might be able to store the value of the dropdown in a hidden field and then restore it into the dropdown using jQuery on page load but that approach didn&amp;#8217;t work since hidden fields don&amp;#8217;t seem to retain their values when you hit back.</description>
    </item>
    
    <item>
      <title>Oracle Spatial: Querying by a point/latitude/longitude</title>
      <link>https://markhneedham.com/blog/2012/03/23/oracle-spatial-querying-by-a-pointlatitudelongitude/</link>
      <pubDate>Fri, 23 Mar 2012 23:54:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/23/oracle-spatial-querying-by-a-pointlatitudelongitude/</guid>
      <description>We&amp;#8217;re using Oracle Spatial on the application I&amp;#8217;m working on and while most of the time any spatial queries we make are done from Java code we wanted to be able to run them directly from SQL as well to verify the code was working correctly.
 We normally end up forgetting how to construct a query so I thought I&amp;#8217;d document it.
 Assuming we have a table table_with_shape which has a column shape which is a polygon, if we want to check whether a lat/long value interacts with that shape we can do that with the following query:</description>
    </item>
    
    <item>
      <title>Coding: Wait for the abstractions to emerge</title>
      <link>https://markhneedham.com/blog/2012/03/17/coding-wait-for-the-abstractions-to-emerge/</link>
      <pubDate>Sat, 17 Mar 2012 11:19:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/17/coding-wait-for-the-abstractions-to-emerge/</guid>
      <description>One of the things that I&amp;#8217;ve learnt while developing code in an incremental way is that the way the code should be designed isn&amp;#8217;t going to be obvious straight away so we need to be patience and wait for it to emerge.
 There&amp;#8217;s often a tendency to pull out classes or methods but more recently I&amp;#8217;ve been trying to follow an approach where I leave the code in one class/method and play around with/study it until I see a good abstraction to make.</description>
    </item>
    
    <item>
      <title>Choosing where to put the complexity</title>
      <link>https://markhneedham.com/blog/2012/03/06/choosing-where-to-put-the-complexity/</link>
      <pubDate>Tue, 06 Mar 2012 01:17:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/03/06/choosing-where-to-put-the-complexity/</guid>
      <description>On the current application I&amp;#8217;m working on we need to make use of some data which comes from another system so we&amp;#8217;ve created an import script which creates a copy of that data so that we can use it in our application.
 In general we&amp;#8217;ve been trying not to do too much manipulation of the data and keeping it close to the initial structure so that if something goes wrong with the import we can more easily trace the problem back to the original data source.</description>
    </item>
    
    <item>
      <title>Thou shalt storm</title>
      <link>https://markhneedham.com/blog/2012/02/24/thou-shalt-storm/</link>
      <pubDate>Fri, 24 Feb 2012 02:03:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/24/thou-shalt-storm/</guid>
      <description>On the majority of the teams that I&amp;#8217;ve worked on there&amp;#8217;s been a time where everyone seems to be disagreeing with each other about almost everything and the whole situation becomes pretty tense for all involved.
 The first time I came across this it seemed quite dysfunctional but I was introduced to Bruce Tuckman&amp;#8217;s model of group development which helps to explain what&amp;#8217;s going on.
 Tuckman outlines four stages which teams tend to go through - forming, storming, norming and performing.</description>
    </item>
    
    <item>
      <title>Optimising for typing</title>
      <link>https://markhneedham.com/blog/2012/02/21/optimising-for-typing/</link>
      <pubDate>Tue, 21 Feb 2012 22:21:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/21/optimising-for-typing/</guid>
      <description>My colleague Ola Bini recently wrote a post describing his thoughts on the syntax of programming languages and while the post in general is interesting the bit that most resonates with me at the moment is the following:
  Typing fewer characters doesn&amp;#8217;t actually optimize for writing either - the intuition behind that statement is quite easy: imagine you had to write a book. However, instead of writing it in English, you just wrote the gzipped version of the book directly.</description>
    </item>
    
    <item>
      <title>Tech Leads &amp; The Progress Principle</title>
      <link>https://markhneedham.com/blog/2012/02/18/tech-leads-the-progress-principle/</link>
      <pubDate>Sat, 18 Feb 2012 01:31:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/18/tech-leads-the-progress-principle/</guid>
      <description>I&amp;#8217;ve been reading The Progress Principle on and off for the last couple of months and one of my favourite quotes from the book is the following:
  Truly effective video game designers know how to create a sense of progress for players within all stages of a game. Truly effective managers know how to do the same for their subordinates.
   While a tech lead might not like to be referred to as a manager I think part of the role does involve helping developers to make progress and the best ones I&amp;#8217;ve worked with seem to do that instinctively.</description>
    </item>
    
    <item>
      <title>Oracle Spatial: java.sql.SQLRecoverableException: No more data to read from socket</title>
      <link>https://markhneedham.com/blog/2012/02/11/oracle-spatial-java-sql-sqlrecoverableexception-no-more-data-to-read-from-socket/</link>
      <pubDate>Sat, 11 Feb 2012 10:55:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/11/oracle-spatial-java-sql-sqlrecoverableexception-no-more-data-to-read-from-socket/</guid>
      <description>We&amp;#8217;re using Oracle Spatial on my current project so that we can locate points within geographical regions and decided earlier in the week to rename the table where we store the SDO_GEOMETRY objects for each region.
 We did that by using a normal table alter statement but then started seeing the following error when we tried to insert test data in that column which takes an SDO_GEOMETRY object:
 org.</description>
    </item>
    
    <item>
      <title>Downloading the JDK 6 source code</title>
      <link>https://markhneedham.com/blog/2012/02/11/downloading-the-jdk-6-source-code/</link>
      <pubDate>Sat, 11 Feb 2012 10:02:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/11/downloading-the-jdk-6-source-code/</guid>
      <description>Every now and then I want to get the JDK source code onto a new machine and it always seems to take me longer than I expect it to so this post is an attempt to help future me!
 Googling for this takes me to this page and I always think I&amp;#8217;ll just checkout the SVN repository and hook that up but it doesn&amp;#8217;t seem to be available.
 $ wget -S http://java.</description>
    </item>
    
    <item>
      <title>Delivery approach and constraints</title>
      <link>https://markhneedham.com/blog/2012/02/08/delivery-approach-and-constraints/</link>
      <pubDate>Wed, 08 Feb 2012 22:34:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/08/delivery-approach-and-constraints/</guid>
      <description>In my latest post I described an approach we&amp;#8217;d been taking when analysing how to rewrite part of an existing system so that we could build the new version in an incremental way.
 Towards the end I pointed out that we weren&amp;#8217;t actually going to be using an incremental approach as we&amp;#8217;d initially thought which was due to a couple of constraints that we have to work under.
 Hardware provisioning One of the main reasons that we favoured an incremental approach is that we&amp;#8217;d be able to deploy to production early which would allow us to show a quicker return on investment.</description>
    </item>
    
    <item>
      <title>Looking for the seam</title>
      <link>https://markhneedham.com/blog/2012/02/06/looking-for-the-seam/</link>
      <pubDate>Mon, 06 Feb 2012 22:22:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/02/06/looking-for-the-seam/</guid>
      <description>During December/early January we spent some time analysing an existing system which we were looking to rewrite and our approach was to look for how we could do this in an incremental way.
 In order to do that we needed to look for what Michael Feathers refers to as a seam:
  A seam is a place where you can alter behaviour in your program without editing in that place</description>
    </item>
    
    <item>
      <title>Oracle: dbstart - ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener</title>
      <link>https://markhneedham.com/blog/2012/01/26/oracle-dbstart-oracle_home_listner-is-not-set-unable-to-auto-start-oracle-net-listener/</link>
      <pubDate>Thu, 26 Jan 2012 21:58:27 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/26/oracle-dbstart-oracle_home_listner-is-not-set-unable-to-auto-start-oracle-net-listener/</guid>
      <description>We ran into an interesting problem when trying to start up an Oracle instance using dbstart whereby we were getting the following error:
 -bash-3.2$ dbstart ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener Usage: /u01/app/oracle/product/11.2.0/dbhome_1/bin/dbstart ORACLE_HOME Processing Database instance &#34;orcl&#34;: log file /u01/app/oracle/product/11.2.0/dbhome_1/startup.log   Ignoring the usage message we thought that setting the environment variable was what we needed to do, but&amp;#8230;&amp;#8203;
 -bash-3.2$ export ORACLE_HOME_LISTNER=$ORACLE_HOME -bash-3.</description>
    </item>
    
    <item>
      <title>Developer machine automation: Dependencies</title>
      <link>https://markhneedham.com/blog/2012/01/24/developer-machine-automation-dependencies/</link>
      <pubDate>Tue, 24 Jan 2012 23:16:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/24/developer-machine-automation-dependencies/</guid>
      <description>As I mentioned in a post last week we&amp;#8217;ve been automating the setup of our developer machines with puppet over the last week and one thing that we&amp;#8217;ve learnt is that you need to be careful about how you define dependencies.
 The aim is to get your scripts to the point where the outcome is reasonably deterministic so that we can have confidence they&amp;#8217;re going to work the next we run them.</description>
    </item>
    
    <item>
      <title>Playing around with pomodoros</title>
      <link>https://markhneedham.com/blog/2012/01/22/playing-around-with-pomodoros/</link>
      <pubDate>Sun, 22 Jan 2012 21:25:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/22/playing-around-with-pomodoros/</guid>
      <description>Over the last 3/4 months I&amp;#8217;ve been playing around with the idea of using pomodoros to track all coding/software related stuff that I do outside of work.
 I originally started using this technique while I was doing the programming assignments for ml-class because I wanted to know how much time I was spending on it each week and make sure I didn&amp;#8217;t run down rabbit holes too often.
 One interesting observation that I noticed from keeping the data of these pomodoros was that while during the early programming assignments it would take me 7 or 8 pomodoros to finish, by the end it was down to around 4.</description>
    </item>
    
    <item>
      <title>Installing Puppet on Oracle Linux</title>
      <link>https://markhneedham.com/blog/2012/01/18/installing-puppet-on-oracle-linux/</link>
      <pubDate>Wed, 18 Jan 2012 00:30:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/18/installing-puppet-on-oracle-linux/</guid>
      <description>We&amp;#8217;ve been spending some time trying to setup our developer environment on a Oracle Linux 5.7 build and one of the first steps was to install Puppet as we&amp;#8217;ve already created scripts which automate the installation of most things.
 Unfortunately Oracle Linux builds don&amp;#8217;t come with any yum repos configured so when you run the following command&amp;#8230;&amp;#8203;
 ls -alh /etc/yum.repos.d/   &amp;#8230;&amp;#8203;you don&amp;#8217;t see anything :(
 We eventually realised that there are a list of public yum repositories on the Oracle website, of which we needed to download the definition for Oracle Linux 5 like so:</description>
    </item>
    
    <item>
      <title>Application footprint</title>
      <link>https://markhneedham.com/blog/2012/01/16/application-footprint/</link>
      <pubDate>Mon, 16 Jan 2012 01:40:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/16/application-footprint/</guid>
      <description>I recently came across Carl Erickson&amp;#8217;s &#39;http://spin.atomicobject.com/2012/01/11/small-teams-are-dramatically-more-efficient-than-large-teams/[small teams are dramatically more efficient than large teams]&#39; blog post which reminded me of something which my colleague Ashok suggested as a useful way for determining team size - the application footprint.
 As I understand it the application footprint is applicable for an application at a given point in time and determines how many parallel tasks/streams of work we have.
 In the case of the project that I&amp;#8217;m currently working on there are 3 separate components which need to interact with each other via an API but otherwise are independent.</description>
    </item>
    
    <item>
      <title>Wireshark: Following HTTP requests/responses</title>
      <link>https://markhneedham.com/blog/2012/01/14/wireshark-following-http-requestsresponses/</link>
      <pubDate>Sat, 14 Jan 2012 23:20:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/14/wireshark-following-http-requestsresponses/</guid>
      <description>I like using Wireshark to have a look at the traffic going across different interfaces but because it shows what&amp;#8217;s happening across the wire by the packet it&amp;#8217;s quite difficult to tell what a request/response looked like.
 I&amp;#8217;ve been playing around with restfulie/http://vraptor.caelum.com.br/[Vraptor] today so I wanted to be able to see the request/response pair when something wasn&amp;#8217;t working.
 I didn&amp;#8217;t know it was actually possible but this post on StackOverflow describes how.</description>
    </item>
    
    <item>
      <title>Oracle: exp -  EXP-00008: ORACLE error 904 encountered/ORA-00904: &#34;POLTYP&#34;: invalid identifier</title>
      <link>https://markhneedham.com/blog/2012/01/13/oracle-exp-exp-00008-oracle-error-904-encounteredora-00904-poltyp-invalid-identifier/</link>
      <pubDate>Fri, 13 Jan 2012 21:46:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/13/oracle-exp-exp-00008-oracle-error-904-encounteredora-00904-poltyp-invalid-identifier/</guid>
      <description>I spent a bit of time this afternoon trying to export an Oracle test database so that we could use it locally using the http://www.orafaq.com/wiki/Import_Export_FAQ#How_does_one_use_the_import.2Fexport_utilities.3F tool.
 I had to connect to exp like this:
 exp user/password@remote_address   And then filled in the other parameters interactively.
 Unfortunately when I tried to actually export the specified tables I got the following error message:
 EXP-00008: ORACLE error 904 encountered ORA-00904: &#34;</description>
    </item>
    
    <item>
      <title>My Software Development journey: 2011</title>
      <link>https://markhneedham.com/blog/2012/01/03/my-software-development-journey-2011/</link>
      <pubDate>Tue, 03 Jan 2012 01:48:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/01/03/my-software-development-journey-2011/</guid>
      <description>A couple of years ago I used to write a blog post reflecting on what I&amp;#8217;d worked on in the preceding year and what I&amp;#8217;d learned and having read 2011 reviews by a couple of other people I thought I&amp;#8217;d have a go.
 Am I actually learning anything? A thought I had many times in 2011 was &#39;am I actually learning anything?&#39; as, although I was working with languages that I hadn&amp;#8217;t used professionally before, the applications that we I worked on were very similar to ones that I&amp;#8217;ve worked on previously.</description>
    </item>
    
    <item>
      <title>Yak Shaving: Tracking the yak stack</title>
      <link>https://markhneedham.com/blog/2011/12/31/yak-shaving-tracking-the-yak-stack/</link>
      <pubDate>Sat, 31 Dec 2011 03:54:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/12/31/yak-shaving-tracking-the-yak-stack/</guid>
      <description>While I&amp;#8217;ve been learning how to write an android application there&amp;#8217;s been plenty of opportunities for me to go off shaving yaks, it&amp;#8217;s pretty much Yakville Central.
 Typically I&amp;#8217;d end up spending hours trying to work out some obscure thing which I didn&amp;#8217;t really need to know so I wanted to try and avoid that this time.
 I started keeping a track of the &#39;yak stack&#39; which I was currently following and mentally noting exactly where I was up to.</description>
    </item>
    
    <item>
      <title>The supposed black box</title>
      <link>https://markhneedham.com/blog/2011/12/20/the-supposed-black-box/</link>
      <pubDate>Tue, 20 Dec 2011 23:57:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/12/20/the-supposed-black-box/</guid>
      <description>On a reasonable number of the systems that I&amp;#8217;ve worked on over the past few years there&amp;#8217;s been a &#39;black box&#39; component which the team I&amp;#8217;ve been on has needed to integrate with.
 I&amp;#8217;ve always found it a little strange that you wouldn&amp;#8217;t need to/want to know how that part of the system worked or that you could actually believe that it was truly a black box.
 If it doesn&amp;#8217;t work then you have no way of diagnosing the problem - did you do something wrong, was there something wrong inside the black box or was it something else.</description>
    </item>
    
    <item>
      <title>WebDriver: Getting it to play nicely with Xvfb</title>
      <link>https://markhneedham.com/blog/2011/12/15/webdriver-getting-it-to-play-nicely-with-xvfb/</link>
      <pubDate>Thu, 15 Dec 2011 23:19:31 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/12/15/webdriver-getting-it-to-play-nicely-with-xvfb/</guid>
      <description>Another thing we&amp;#8217;ve been doing with WebDriver is having it run with the FirefoxDriver while redirecting the display output into the Xvfb framebuffer so that we can run it on our continuous integration agents which don&amp;#8217;t have a display attached.
 The first thing we needed to do was set the environment property &#39;webdriver.firefox.bin&#39; to our own script which would point the display to Xvfb before starting Firefox:
 import java.</description>
    </item>
    
    <item>
      <title>WebDriver: Getting it to play nicely with jQuery ColorBox</title>
      <link>https://markhneedham.com/blog/2011/12/13/webdriver-getting-it-to-play-nicely-with-jquery-colorbox/</link>
      <pubDate>Tue, 13 Dec 2011 23:31:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/12/13/webdriver-getting-it-to-play-nicely-with-jquery-colorbox/</guid>
      <description>As I mentioned in an earlier post about removing manual test scenarios we&amp;#8217;ve been trying to automate some parts of our application where a user action leads to a jQuery ColorBox powered overlay appearing.
 With this type of feature there tends to be some sort of animation which accompanies the overlay so we have to wait for an element inside the overlay to become visible on the screen before trying to do any assertions on the overlay.</description>
    </item>
    
    <item>
      <title>The 5 Whys/Root cause analysis - Douglas Squirrel</title>
      <link>https://markhneedham.com/blog/2011/12/10/the-5-whysroot-cause-analysis-douglas-squirrel/</link>
      <pubDate>Sat, 10 Dec 2011 14:11:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/12/10/the-5-whysroot-cause-analysis-douglas-squirrel/</guid>
      <description>At XP Day I was chatting to Benjamin Mitchell about the 5 whys exercises that we&amp;#8217;d tried on my team and I suggested that beyond Eric Ries&#39; post on the subject I hadn&amp;#8217;t come across an article/video which explained how to do it.
 Benjamin mentioned that Douglas Squirrel had recently done a talk on this very subject at Skillsmatter and as with most Skillsmatter talks there&amp;#8217;s a video of the presentation online.</description>
    </item>
    
    <item>
      <title>Continuous Delivery: Removing manual scenarios</title>
      <link>https://markhneedham.com/blog/2011/12/05/continuous-delivery-removing-manual-scenarios/</link>
      <pubDate>Mon, 05 Dec 2011 23:13:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/12/05/continuous-delivery-removing-manual-scenarios/</guid>
      <description>On the project that I&amp;#8217;m currently working on we&amp;#8217;re trying to move to the stage where we&amp;#8217;d be able to deploy multiple times a week while still having a reasonable degree of confidence that the application still works.
 One of the (perhaps obvious) things that we&amp;#8217;ve had to do as a result of wanting to do this is reduce the number of manual scenarios that our QAs need to run through.</description>
    </item>
    
    <item>
      <title>The 5 whys: Another attempt</title>
      <link>https://markhneedham.com/blog/2011/11/13/the-5-whys-another-attempt/</link>
      <pubDate>Sun, 13 Nov 2011 23:08:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/11/13/the-5-whys-another-attempt/</guid>
      <description>Towards the end of the week before last and the beginning of last week we&amp;#8217;d been having quite a few problems with our QA environment to the point where we were unable to deploy anything to it for 3 days.
 A few weeks ago I wrote about a 5 whys exercise that we did in a retrospective and in our weekly code review we decided to give it a go and see what we could learn.</description>
    </item>
    
    <item>
      <title>fgrep: Searching for a list of identifiers</title>
      <link>https://markhneedham.com/blog/2011/11/10/fgrep-searching-for-a-list-of-identifiers/</link>
      <pubDate>Thu, 10 Nov 2011 23:37:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/11/10/fgrep-searching-for-a-list-of-identifiers/</guid>
      <description>We had a problem to solve earlier in the week where we wanted to try and find out which files we had ingested into our database based on a unique identifier.
 We had a few hundred thousand files to search through to try and find the ones where around 50,000 identifiers were mentioned so that we could re-ingest them.
 Running a normal grep for each identifier individually took a ridiculously long time so we needed to find a way to search for all of the identifiers at the same time to speed up the process.</description>
    </item>
    
    <item>
      <title>Working with external identifiers</title>
      <link>https://markhneedham.com/blog/2011/10/31/working-with-external-identifiers/</link>
      <pubDate>Mon, 31 Oct 2011 22:58:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/31/working-with-external-identifiers/</guid>
      <description>As part of the ingestion process for our application we import XML documents and corresponding PDFs into a database and onto the file system respectively.
   Since the user needs to be able to search for documents by the userFacingId we reference it by that identifier in the database and the web application.
 Each document also has an external identifier and we use this to identify the PDFs on the file system.</description>
    </item>
    
    <item>
      <title>Canonical Identifiers</title>
      <link>https://markhneedham.com/blog/2011/10/30/canonical-identifiers/</link>
      <pubDate>Sun, 30 Oct 2011 22:32:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/30/canonical-identifiers/</guid>
      <description>Duncan and I had an interesting problem recently where we had to make it possible to search within an &#39;item&#39; to find possible sub items that exist inside it.
 The URI for the item was something like this:
 /items/234   Let&amp;#8217;s say Item 234 contains the following sub items:
   Mark
  duncan
   We have a search box on the page which allows us to type in the name of a sub item and go the sub item&amp;#8217;s page if it exists or see an error message if it doesn&amp;#8217;t.</description>
    </item>
    
    <item>
      <title>Unix: Some useful tools</title>
      <link>https://markhneedham.com/blog/2011/10/17/unix-some-useful-tools/</link>
      <pubDate>Mon, 17 Oct 2011 22:58:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/17/unix-some-useful-tools/</guid>
      <description>On my current project we regularly use a few Unix tools which aren&amp;#8217;t on the standard installation so I thought I&amp;#8217;d collate them here so I don&amp;#8217;t forget about them in the future.
 ghex We suspected we&amp;#8217;d ended up with some rogue characters in a file that we weren&amp;#8217;t able to detect in our normal text editor recently and wanted to view the byte by byte representation of the file to check it out.</description>
    </item>
    
    <item>
      <title>The &#39;window fixing&#39; wall</title>
      <link>https://markhneedham.com/blog/2011/09/20/the-window-fixing-wall/</link>
      <pubDate>Tue, 20 Sep 2011 06:49:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/09/20/the-window-fixing-wall/</guid>
      <description>On my current project we have a wall where we keep track of &#39;window fixing&#39; tasks - things that people want to fix in the code base but chose to defer until a later date.
 Every now and then we take what&amp;#8217;s on the wall and prioritise it according to Fabio Pereira&amp;#8217;s effort/pain matrix so that we know which clean up tasks will provide the greatest value to the team.</description>
    </item>
    
    <item>
      <title>gawk: Getting story numbers from git commit messages</title>
      <link>https://markhneedham.com/blog/2011/09/12/gawk-getting-story-numbers-from-git-commit-messages/</link>
      <pubDate>Mon, 12 Sep 2011 07:05:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/09/12/gawk-getting-story-numbers-from-git-commit-messages/</guid>
      <description>As I mentioned in my previous post I&amp;#8217;ve been writing a little application to create graphs based on our git repository history and in one of them we wanted to try and create a graph showing which people had been working on which stories.
 I needed a way to extract a story number from the git commit message and then store them all in a text file.
 A typical commit with a story number in might look like this:</description>
    </item>
    
    <item>
      <title>Learning Regular Expressions: Non capturing match</title>
      <link>https://markhneedham.com/blog/2011/09/07/learning-regular-expressions-non-capturing-match/</link>
      <pubDate>Wed, 07 Sep 2011 20:47:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/09/07/learning-regular-expressions-non-capturing-match/</guid>
      <description>I&amp;#8217;ve been working my way slowly through the O&amp;#8217;Reilly &#39;http://www.amazon.co.uk/Mastering-Regular-Expressions-Jeffrey-Friedl/dp/0596528124/ref=sr_1_2?ie=UTF8&amp;amp;qid=1315428243&amp;amp;sr=8-2[Mastering Regular Expressions]&#39; book and recently read about the non capturing match operator which came in useful for some Git log parsing I&amp;#8217;ve been doing.
 On the project I&amp;#8217;m working on we all commit as the same user and then put our names at the beginning of the commit message.
 We wanted to try and find out the statistics of who&amp;#8217;d been pairing with each other and therefore needed to extract the pairs from commits.</description>
    </item>
    
    <item>
      <title>Parsing XML from the unix terminal/shell</title>
      <link>https://markhneedham.com/blog/2011/09/03/parsing-xml-from-the-unix-terminalshell/</link>
      <pubDate>Sat, 03 Sep 2011 23:42:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/09/03/parsing-xml-from-the-unix-terminalshell/</guid>
      <description>I spent a bit of time today trying to put together a quick script which would allow me to grab story numbers from the commits in our Git repository and then work out which functional areas those stories were in by querying mingle.
 Therefore I wanted to make a curl request to the mingle and then pipe that result somewhere and run an xpath expression to get my element.</description>
    </item>
    
    <item>
      <title>The read-only database</title>
      <link>https://markhneedham.com/blog/2011/08/29/the-read-only-database/</link>
      <pubDate>Mon, 29 Aug 2011 23:32:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/08/29/the-read-only-database/</guid>
      <description>The last couple of applications I&amp;#8217;ve worked on have had almost completely read only databases where we had to populate the database in an offline process and then provide various ways for users to access the data.
 This creates an interesting situation with respect to how we should setup our development environment.
 Our normal setup would probably have an individual version of that database on every development machine and we would populate and then truncate the database during various test scenarios.</description>
    </item>
    
    <item>
      <title>Pain Driven Development</title>
      <link>https://markhneedham.com/blog/2011/08/21/pain-driven-development/</link>
      <pubDate>Sun, 21 Aug 2011 17:33:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/08/21/pain-driven-development/</guid>
      <description>My colleague Pat Fornasier has been using an interesting spin on the idea of making decisions at the last responsible moment by encouraging our team to &#39;feel the pain&#39; before introducing any constraint in our application.
 These are some of the decisions which we&amp;#8217;ve been delaying/are still delaying:
 Dependency Injection Everyone in our team comes from a Java/C# background and one of the first technical decisions that gets made on applications in those languages is which dependency injection container to use.</description>
    </item>
    
    <item>
      <title>Performance tuning our data import: Gather precise data</title>
      <link>https://markhneedham.com/blog/2011/07/29/performance-tuning-our-data-import-gather-precise-data/</link>
      <pubDate>Fri, 29 Jul 2011 01:34:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/07/29/performance-tuning-our-data-import-gather-precise-data/</guid>
      <description>One of the interesting problems that we have to solve on my current project is working out how to import a few million XML documents into our database in a reasonable amount of time.
 The stages of the import process are as follows:
  Extract a bunch of ZIP files to the disc
  Processing only the XML documents...
  Load the XML document and determine whether the document is valid to import</description>
    </item>
    
    <item>
      <title>A crude way of telling if a remote machine is a VM</title>
      <link>https://markhneedham.com/blog/2011/07/27/a-crude-way-of-telling-if-a-remote-machine-is-a-vm/</link>
      <pubDate>Wed, 27 Jul 2011 22:31:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/07/27/a-crude-way-of-telling-if-a-remote-machine-is-a-vm/</guid>
      <description>We were doing a bit of profiling of a data importing process we&amp;#8217;ve been running across various environments and wanted to check whether or not one of the environments was a physical machine or a VM.
 A bit of googling first led me to the following site where you can fill a MAC address and it will tell you which vendor it belongs to.
 macvendorlookup.com is even better though because it&amp;#8217;s more easily scriptable!</description>
    </item>
    
    <item>
      <title>Emacs: Re-mapping the Control and Meta Keys on Mac OS X</title>
      <link>https://markhneedham.com/blog/2011/07/17/emacs-re-mapping-the-control-and-meta-keys-on-mac-os-x/</link>
      <pubDate>Sun, 17 Jul 2011 10:24:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/07/17/emacs-re-mapping-the-control-and-meta-keys-on-mac-os-x/</guid>
      <description>Since I&amp;#8217;ve started playing around with Clojure again I thought it&amp;#8217;d make sense to use emacs as my editor and therefore needed to work out how to remap the Ctrl and Meta to keys which are more accessible on the MBP&amp;#8217;s keyboard.
 I&amp;#8217;ve found that I like using the Caps Lock for Ctrl and that&amp;#8217;s reasonably easy to change by navigating to &#39;System Preferences &amp;gt; Keyboard &amp;gt; Modifier Keys&#39;:</description>
    </item>
    
    <item>
      <title>Tech Leading: Keeping the passion</title>
      <link>https://markhneedham.com/blog/2011/06/22/tech-leading-keeping-the-passion/</link>
      <pubDate>Wed, 22 Jun 2011 23:48:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/06/22/tech-leading-keeping-the-passion/</guid>
      <description>As I mentioned a couple of months ago, while I was in India I was acting as the Tech Lead on the project the TWU grads were working on and one thing I learnt from doing that is the importance of trying to keep the passion of the developers on the team.
 When we started off I was more focused on trying to encourage the team to try and develop as many of the stories as possible.</description>
    </item>
    
    <item>
      <title>Fedora: Recovering from the IntelliJ &#39;Ctrl-Alt-F7&#39;</title>
      <link>https://markhneedham.com/blog/2011/06/16/fedora-recovering-from-the-intellij-ctrl-alt-f7/</link>
      <pubDate>Thu, 16 Jun 2011 07:27:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/06/16/fedora-recovering-from-the-intellij-ctrl-alt-f7/</guid>
      <description>We&amp;#8217;re using Fedora on our local developer work stations and some of the default key bindings of the operating system seem to conflict with ones provided by IntelliJ IDEA.
 One particular amusing one is &#39;Ctrl-Alt-F7&#39; which you use in IntelliJ to see the usages of a piece of code.
 In Fedora that seems to switch into a different X Server session and you just see a blank screen with seemingly no way out!</description>
    </item>
    
    <item>
      <title>IntelliJ: Adding resources with unusual extensions onto the classpath</title>
      <link>https://markhneedham.com/blog/2011/06/09/intellij-adding-resources-with-unusual-extensions-onto-the-classpath/</link>
      <pubDate>Thu, 09 Jun 2011 23:10:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/06/09/intellij-adding-resources-with-unusual-extensions-onto-the-classpath/</guid>
      <description>We&amp;#8217;re making use of MarkLogic and therefore xquery on the project I&amp;#8217;m currently working on and recently wanted to add our xquery setup files onto the classpath so they could be used in a test.
 We added them into &#39;src/main/resources&#39; and set that as a source path in IntelliJ assuming that was all we needed to do.
 Despite doing that our test kept failing because it couldn&amp;#8217;t locate the files on the classpath.</description>
    </item>
    
    <item>
      <title>Developer Experience (#devexp) and the 5 minute experience</title>
      <link>https://markhneedham.com/blog/2011/05/31/developer-experience-devexp-and-the-5-minute-experience/</link>
      <pubDate>Tue, 31 May 2011 21:29:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/05/31/developer-experience-devexp-and-the-5-minute-experience/</guid>
      <description>My former colleague Ade Oshineye recently linked me to a post he&amp;#8217;s written about Developer Experience (#devexp) which is described as:
  [...] an aspirational movement that seeks to apply the techniques of User Experience (UX) professionals to the tools and services that we offer to developers.&#34;
   I think it&amp;#8217;s quite an interesting idea and I particularly like two of the ideas suggested:
  2. Focus on the &#39;5 minute Out Of Box experience&#39; The idea here is that if you provide a library, developers should be able to go from downloading to &#34;</description>
    </item>
    
    <item>
      <title>The sunk cost fallacy</title>
      <link>https://markhneedham.com/blog/2011/04/17/the-sunk-cost-fallacy/</link>
      <pubDate>Sun, 17 Apr 2011 12:05:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/04/17/the-sunk-cost-fallacy/</guid>
      <description>I recently came across David McRaney&amp;#8217;s post about the sunk cost fallacy with reference to Farmville, a fallacy that is very applicable to software.
 David starts off with the following statements which describe the fallacy pretty well:
  The Misconception: You make rational decisions based on the future value of objects, investments and experiences. The Truth: Your decisions are tainted by the emotional investments you accumulate, and the more you invest in something the harder it becomes to abandon it.</description>
    </item>
    
    <item>
      <title>Tech Leading: Initial Thoughts</title>
      <link>https://markhneedham.com/blog/2011/04/17/tech-leading-initial-thoughts/</link>
      <pubDate>Sun, 17 Apr 2011 11:27:31 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/04/17/tech-leading-initial-thoughts/</guid>
      <description>As I mentioned in an earlier post I&amp;#8217;ve been playing the role of tech lead on the project that we&amp;#8217;ve been doing at ThoughtWorks University so I thought it&amp;#8217;d be interesting to note down some of my observations so far.
 Out of the tech leads that I&amp;#8217;ve had I liked the style of Dave Cameron the best.
 He viewed himself more as a technical facilitator rather than as a person who should make every single decision about how a system got built which meant that others also got a chance to take some responsibility.</description>
    </item>
    
    <item>
      <title>HTML encoding/escaping with StringTemplate and Spring MVC</title>
      <link>https://markhneedham.com/blog/2011/04/09/html-encodingescaping-with-stringtemplate-and-spring-mvc/</link>
      <pubDate>Sat, 09 Apr 2011 10:54:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/04/09/html-encodingescaping-with-stringtemplate-and-spring-mvc/</guid>
      <description>Last week my colleague T.C. and I had to work out how to HTML encode the values entered by the user when redisplaying those onto the page to prevent a cross site scripting attack on the website.
 I wrote a blog post a couple of years ago describing how to do this in ASP.NET MVC and the general idea is that we need to have a custom renderer which HTML encodes any strings that pass through it.</description>
    </item>
    
    <item>
      <title>Unix: Getting the sound from &#39;say&#39; as a wav file</title>
      <link>https://markhneedham.com/blog/2011/04/07/unix-getting-the-sound-from-say-as-a-wav-file/</link>
      <pubDate>Thu, 07 Apr 2011 19:18:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/04/07/unix-getting-the-sound-from-say-as-a-wav-file/</guid>
      <description>I spent a bit of time yesterday afternoon working out how to get the output from the Unix command &#39;say&#39; to be played whenever our build breaks.
 We&amp;#8217;re using cctray on a Windows box for that purpose which means that we need to have the file in the &#39;wav&#39; format.
 Unfortunately &#39;say&#39; doesn&amp;#8217;t seem to be able to output a file in that format:
 &amp;gt; say &#34;WARNING! Drainage has occurred, please fix it.</description>
    </item>
    
    <item>
      <title>The working long hours culture</title>
      <link>https://markhneedham.com/blog/2011/03/29/the-working-long-hours-culture/</link>
      <pubDate>Tue, 29 Mar 2011 17:25:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/03/29/the-working-long-hours-culture/</guid>
      <description>One of the aspects of software development that I&amp;#8217;ve thankfully seen relatively infrequently over the last few years is that of some people in teams working long hours on a consistent basis.
 I have seen it happen on a few occasions and I think it can have a detrimental effect on a team rather than the good which is presumably intended.
 The biggest disadvantage is that it makes other people in the team feel guilty that they aren&amp;#8217;t working long hours and they may feel peer pressured into matching the hours of their colleagues.</description>
    </item>
    
    <item>
      <title>Pomodoro: Observations from giving it a go</title>
      <link>https://markhneedham.com/blog/2011/02/20/pomodoro-observations-from-giving-it-a-go/</link>
      <pubDate>Sun, 20 Feb 2011 19:26:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/02/20/pomodoro-observations-from-giving-it-a-go/</guid>
      <description>I learnt about the pomodoro technique a couple of years ago and while I did try it out sporadically back then, it&amp;#8217;s only recently that I thought I&amp;#8217;d properly give it a try when managing my spare time.
 My approach without the pomodoro technique is to have a long list of things that I could do and then not really doing any of them because I feel bad about not doing one of the other things instead.</description>
    </item>
    
    <item>
      <title>Vim: Copying to and retrieving from the clipboard</title>
      <link>https://markhneedham.com/blog/2011/02/14/vim-copying-to-and-retrieving-from-the-clipboard/</link>
      <pubDate>Mon, 14 Feb 2011 14:13:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/02/14/vim-copying-to-and-retrieving-from-the-clipboard/</guid>
      <description>My memory when it comes to remembering how to get text to and from Vim via the clipboard is pretty bad so I thought I&amp;#8217;d try summarising what I know and see if that works out any better.
 We can access the system clipboard via the &#39;+&#39; buffer so the commands revolve around that.
 Copying to the clipboard To copy the whole file to the clipboard we can use this command:</description>
    </item>
    
    <item>
      <title>Sed: Extended regular expressions</title>
      <link>https://markhneedham.com/blog/2011/02/11/sed-extended-regular-expressions/</link>
      <pubDate>Fri, 11 Feb 2011 20:34:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/02/11/sed-extended-regular-expressions/</guid>
      <description>Irfan and I were looking at how to do some text substitution in a text file this afternoon and turned to sed to help us in our quest.
 He had originally used grep to find what he wanted to replace on each line, using a grep regular expression to match one or more numbers:
 cat the_file.txt | grep &#34;[0-9]\+&#34;   That works pretty well but since I knew how to do the substitution in sed we needed to convert the regular expression to work with sed.</description>
    </item>
    
    <item>
      <title>University coding</title>
      <link>https://markhneedham.com/blog/2011/02/06/university-coding/</link>
      <pubDate>Sun, 06 Feb 2011 16:57:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/02/06/university-coding/</guid>
      <description>We went to do some university recruitment recently and pairing with some of the students reminded me of some things that I&amp;#8217;ve started doing better since I started working professionally.
 I wanted to note them down so that I&amp;#8217;m more aware that these might be common areas to improve on for university graduates that I work with in the future.
 Naming of things I don&amp;#8217;t remember there being that much focus on naming variables/methods/classes in any of the programming courses that I studied.</description>
    </item>
    
    <item>
      <title>The Five Orders of Ignorance - Phillip G. Armour</title>
      <link>https://markhneedham.com/blog/2011/01/26/the-five-orders-of-ignorance-phillip-g-armour/</link>
      <pubDate>Wed, 26 Jan 2011 18:08:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/26/the-five-orders-of-ignorance-phillip-g-armour/</guid>
      <description>While trawling the comments of Dan North&amp;#8217;s &#39;http://dannorth.net/2010/08/30/introducing-deliberate-discovery/[Deliberate Discovery]&#39; post I came across an interesting article written by Phillip G. Armour titled &#39;http://www-plan.cs.colorado.edu/diwan/3308-07/p17-armour.pdf[The Five Orders of Ignorance]&#39;.
 The main thing I took from the article is that the author uses the metaphor of software as a &#39;knowledge acquisition activity&#39; for which he then defines five orders of ignorance that we can have in our attempts to acquire that knowledge.</description>
    </item>
    
    <item>
      <title>Deliberate Discovery: The stuff I don&#39;t know list</title>
      <link>https://markhneedham.com/blog/2011/01/26/deliberate-discovery-the-stuff-i-dont-know-list/</link>
      <pubDate>Wed, 26 Jan 2011 18:07:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/26/deliberate-discovery-the-stuff-i-dont-know-list/</guid>
      <description>Towards the end of Dan North&amp;#8217;s post on Deliberate Discovery he makes the following suggestion:
  There is much more to say about deliberate discovery. Think about applying the principle to learning a new language, or picking up a new technology, or a new domain. What could you do to identify and reduce your ignorance most rapidly?
   This reminded me a lot of what I used to do when I came across things that I didn&amp;#8217;t know how to do a few years ago.</description>
    </item>
    
    <item>
      <title>MySQL: The used command is not allowed with this MySQL version</title>
      <link>https://markhneedham.com/blog/2011/01/18/mysql-the-used-command-is-not-allowed-with-this-mysql-version/</link>
      <pubDate>Tue, 18 Jan 2011 18:58:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/18/mysql-the-used-command-is-not-allowed-with-this-mysql-version/</guid>
      <description>For my own reference more than anything else, on my version of MySQL on Mac OS X, which is:
  mysql5 Ver 14.14 Distrib 5.1.48, for apple-darwin10.4.0 (i386) using readline 6.1
   When I try to use the &#39;LOAD DATA LOCAL&#39; option to load data into tables I get the following error message:
 ERROR 1148 (42000) at line 4: The used command is not allowed with this MySQL version   Which we can get around by using the following flag as described in the comments of the documentation:</description>
    </item>
    
    <item>
      <title>Installing git-svn on Mac OS X</title>
      <link>https://markhneedham.com/blog/2011/01/15/installing-git-svn-on-mac-os-x/</link>
      <pubDate>Sat, 15 Jan 2011 19:05:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/15/installing-git-svn-on-mac-os-x/</guid>
      <description>I somehow managed to uninstall git-svn on my machine and Emmanuel Bernard&amp;#8217;s blog post suggested it could be installed using ports:
 sudo port install git-core +svn   I tried that and was ending up with the following error:
 ---&amp;gt; Computing dependencies for git-core ---&amp;gt; Dependencies to be installed: p5-svn-simple subversion-perlbindings apr-util db46 cyrus-sasl2 neon serf subversion p5-term-readkey ---&amp;gt; Verifying checksum(s) for db46 Error: Checksum (md5) mismatch for patch.</description>
    </item>
    
    <item>
      <title>Jet Airways: Lacking conceptual integrity and the power of twitter</title>
      <link>https://markhneedham.com/blog/2011/01/10/jet-airways-lacking-conceptual-integrity-and-the-power-of-twitter/</link>
      <pubDate>Mon, 10 Jan 2011 18:08:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/10/jet-airways-lacking-conceptual-integrity-and-the-power-of-twitter/</guid>
      <description>I recently travelled to London and back for Christmas using Jet Airways and the whole journey got off to an &#39;interesting&#39; start.
 I originally booked two Jet Airways flights - one from Pune to Delhi and another from Delhi to London.
 A couple of weeks later I was sent an email cancelling my Pune to Delhi flight and informing me that I should contact their customer support centre.</description>
    </item>
    
    <item>
      <title>Failure of integration point doesn&#39;t have to stop the user: A real life example</title>
      <link>https://markhneedham.com/blog/2011/01/10/failure-of-integration-point-doesnt-have-to-stop-the-user-a-real-life-example/</link>
      <pubDate>Mon, 10 Jan 2011 15:28:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/10/failure-of-integration-point-doesnt-have-to-stop-the-user-a-real-life-example/</guid>
      <description>Ashwin and I were recently discussing integration points in software systems and in particular how many systems are designed in such a way that they will stop the user from going any further if one of those integration points is down.
 The main point in favour of designing systems in this way is that it&amp;#8217;s logically very simple - all operations are synchronous and we don&amp;#8217;t have to worry about any offline processing.</description>
    </item>
    
    <item>
      <title>Vim: Learnings so far</title>
      <link>https://markhneedham.com/blog/2010/12/27/vim-learnings-so-far/</link>
      <pubDate>Mon, 27 Dec 2010 19:15:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/12/27/vim-learnings-so-far/</guid>
      <description>I&amp;#8217;ve been using Vim instead of RubyMine for the last month or so and it&amp;#8217;s been interesting observing the way that I browse code as I add plugins to make my life easier.
 Between files I generally don&amp;#8217;t know exactly where in the folder structure different files live since I&amp;#8217;m used to being able to search by just the name i.e. RubyMine&amp;#8217;s Ctrl-N
 Yahuda Katz wrote a blog post earlier in the year where he listed some of the plugins he&amp;#8217;s been using - one of which is called Command-T and allows exactly this functionality.</description>
    </item>
    
    <item>
      <title>Theory of Constraints: Blaming the bottleneck</title>
      <link>https://markhneedham.com/blog/2010/12/26/theory-of-constraints-blaming-the-bottleneck/</link>
      <pubDate>Sun, 26 Dec 2010 00:04:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/12/26/theory-of-constraints-blaming-the-bottleneck/</guid>
      <description>I&amp;#8217;ve been reading The Goal over the last week or so where Eliyahu Goldratt describes the theory of constraints as a philosophy for allowing organisations to continually achieve their goal.
 Goldratt goes on to describe bottlenecks - resources which have a capacity less than the capacity being demanded of the system.
 The capacity of the system cannot be higher than that of the bottleneck which means that we need to find a way to optimise the bottlenecks in any system.</description>
    </item>
    
    <item>
      <title>Communication when it&#39;s not going your way</title>
      <link>https://markhneedham.com/blog/2010/12/22/communication-when-its-not-going-your-way/</link>
      <pubDate>Wed, 22 Dec 2010 23:32:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/12/22/communication-when-its-not-going-your-way/</guid>
      <description>I&amp;#8217;ve been reading some of the articles written about the disruption caused by the snow across Europe and I found one quote in The Daily Telegraph by Phillip Hammond particularly interesting
  &#34;I think whilst people are obviously deeply upset about the inconvenience, particularly at this time of year, of having their travel plans disrupted, most of what I am hearing is a sense of outrage about the way they were then treated when they were stranded at Heathrow airport.</description>
    </item>
    
    <item>
      <title>Ask someone vs work it out yourself</title>
      <link>https://markhneedham.com/blog/2010/12/14/ask-someone-vs-work-it-out-yourself/</link>
      <pubDate>Tue, 14 Dec 2010 18:04:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/12/14/ask-someone-vs-work-it-out-yourself/</guid>
      <description>Back in 2007/2008 when I worked on my first couple of projects at ThoughtWorks I always found it strange how frequently my colleagues would try and figure something out themselves rather than asking someone else (who already knew how to do it) how to do it.
 Fast forward to 2010 and I find myself being the one encouraging people to figure things out themselves.
 There&amp;#8217;s still merit in communicating with colleagues when we&amp;#8217;ve tried to work out how to do something and haven&amp;#8217;t managed to figure it out but it&amp;#8217;s also useful to not have this as our default mode.</description>
    </item>
    
    <item>
      <title>Bugs: Prioritising by bucket</title>
      <link>https://markhneedham.com/blog/2010/12/12/bugs-prioritising-by-bucket/</link>
      <pubDate>Sun, 12 Dec 2010 07:59:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/12/12/bugs-prioritising-by-bucket/</guid>
      <description>At a lot of organisations that I&amp;#8217;ve worked there is a tendency to prioritise bugs by a priority bucket.
 We might therefore have priority buckets 1-4 where the bucket number indicates how important the bug is to fix and then any buckets ranked below 4 would not be fixed but would be logged anyway.
 From what I&amp;#8217;ve noticed this isn&amp;#8217;t a particularly effective way of managing bugs.
 To start with there tend to be a lot of discussions around what the priority of each bug should be where a QA will argue that it should be a higher priority while a developer disagrees.</description>
    </item>
    
    <item>
      <title>Why am I working in India?</title>
      <link>https://markhneedham.com/blog/2010/12/10/why-am-i-working-in-india/</link>
      <pubDate>Fri, 10 Dec 2010 03:47:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/12/10/why-am-i-working-in-india/</guid>
      <description>A few colleagues have asked me why I chose to work in India so I thought it would be interesting to explore what it is that appealed to me about working here.
 I&amp;#8217;ve come to the conclusion that there were 2 main drivers for me:
 The buzz of the ThoughtWorks office I was in Bangalore in 2006 when I attended ThoughtWorks University and one of the things that stood out for me was the atmosphere in the Diamond District office.</description>
    </item>
    
    <item>
      <title>Noone wants your stupid process - Jeff Patton</title>
      <link>https://markhneedham.com/blog/2010/11/30/noone-wants-your-stupid-process-jeff-patton/</link>
      <pubDate>Tue, 30 Nov 2010 20:35:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/30/noone-wants-your-stupid-process-jeff-patton/</guid>
      <description>My former colleague Alexandre Martins recently pointed me to a presentation given by Jeff Patton at Agile Roots titled &#39;http://confreaks.net/videos/44-agileroots2010-keynote-no-one-wants-your-stupid-process[Noone wants your stupid process]&#39; and it&amp;#8217;s one of the most interesting talks I&amp;#8217;ve watched recently.
 In the talk Jeff cites globo.com as a case study of a company which is using an agile approach to development of their website but are starting to doubt whether it&amp;#8217;s the best way to go about things.</description>
    </item>
    
    <item>
      <title>Consulting is like inception</title>
      <link>https://markhneedham.com/blog/2010/11/30/consulting-is-like-inception/</link>
      <pubDate>Tue, 30 Nov 2010 19:25:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/30/consulting-is-like-inception/</guid>
      <description>My colleague Jason Yip recently tweeted the following&amp;#8230;&amp;#8203;
  Sometimes consulting reminds me of the movie Inception
   &amp;#8230;&amp;#8203;which reminded me of a conversation I was having with a colleague here who&amp;#8217;s been working on consulting engagements here for the last few months.
 I was describing some of the things that I wanted to change on my team and she pointed out that I always described each change as something that I wanted to change rather than something which I wanted to see change.</description>
    </item>
    
    <item>
      <title>Local port forwarding</title>
      <link>https://markhneedham.com/blog/2010/11/29/local-port-forwarding/</link>
      <pubDate>Mon, 29 Nov 2010 19:42:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/29/local-port-forwarding/</guid>
      <description>A colleague and I ran into an interesting problem today which we wanted to use local port forwarding to solve.
 In our environment.rb file we have a Solr instance url defined like so:
 SOLR_CONFIG = { :service_url =&amp;gt; &#34;http://some.internal.address:9983/solr/sco_slave_1&#34; }   It&amp;#8217;s defined like that because our colleagues in Chicago have setup a Solr instance on a test environment and all the developers hit the same box.</description>
    </item>
    
    <item>
      <title>Systems Thinking: Individuals and the environment</title>
      <link>https://markhneedham.com/blog/2010/11/23/systems-thinking-individuals-and-the-environment/</link>
      <pubDate>Tue, 23 Nov 2010 20:20:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/23/systems-thinking-individuals-and-the-environment/</guid>
      <description>Something which I&amp;#8217;ve become fairly convinced about recently is that the environment that someone works in has far more impact on their perceived performance than their own individual skills.
 Given that belief I&amp;#8217;ve often got stuck answering why some people are better able to handle a difficult environment than others - in terms of accepting the situation and finding a way of being productive regardless.
 Does this mean that they&amp;#8217;re better than people who can&amp;#8217;t work in that environment as effectively?</description>
    </item>
    
    <item>
      <title>Make it interesting for yourself</title>
      <link>https://markhneedham.com/blog/2010/11/22/make-it-interesting-for-yourself/</link>
      <pubDate>Mon, 22 Nov 2010 19:58:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/22/make-it-interesting-for-yourself/</guid>
      <description>Just over a year ago I wrote a post about learning one thing each day and since I&amp;#8217;ve been struggling to do this lately I thought I&amp;#8217;d come back to this topic again.
 My general thinking at the time I wrote that post was that sometimes it would be really difficult to find a way to learn anything on the project I was working on and the only way to learn would be to play around with something outside work.</description>
    </item>
    
    <item>
      <title>From unconsciously incompetent to consciously incompetent</title>
      <link>https://markhneedham.com/blog/2010/11/19/from-unconsciously-incompetent-to-consciously-incompetent/</link>
      <pubDate>Fri, 19 Nov 2010 20:20:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/19/from-unconsciously-incompetent-to-consciously-incompetent/</guid>
      <description>One of the cool things about software development is that despite writing code for 5 years professionally and just under 10 altogether, there are still a phenomenal number of things that I don&amp;#8217;t know how to do.
 The learning opportunities are vast!
 One of the areas which I&amp;#8217;ve known I don&amp;#8217;t know that much about is Unix command line tools such as awk and sed.
 Since the majority of projects that I&amp;#8217;ve worked on have involved using Windows as the development environment I&amp;#8217;ve never had extended exposure to the types of problems we get on a project which require their use.</description>
    </item>
    
    <item>
      <title>Experiments in not using the mouse</title>
      <link>https://markhneedham.com/blog/2010/11/12/experiments-in-not-using-the-mouse/</link>
      <pubDate>Fri, 12 Nov 2010 15:43:37 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/12/experiments-in-not-using-the-mouse/</guid>
      <description>Priyank and I have been pairing a bit lately and we thought it&amp;#8217;d be interesting to try and not use the mouse for anything that we had to do while pairing.
 Editor Priyank uses GVim (Yehuda Katz recommends MacVim if you&amp;#8217;re using Mac OS) so we already don&amp;#8217;t need to use the mouse at all when we&amp;#8217;re inside the editor.
 One annoying thing we found is that sometimes we wanted to copy stuff from the terminal into GVim and couldn&amp;#8217;t think of a good way to do that without selecting the text on the terminal with a mouse and then &#39;Ctrl-C&amp;#8217;ing.</description>
    </item>
    
    <item>
      <title>Flow in software teams</title>
      <link>https://markhneedham.com/blog/2010/09/05/flow-in-software-teams/</link>
      <pubDate>Sun, 05 Sep 2010 17:34:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/09/05/flow-in-software-teams/</guid>
      <description>My former colleague Greg Gigon has written an interesting blog post where he talks about the pain that we cause ourselves by multi-tasking, a point which Kevin Fox also makes on the Theory of Constraints blog.
 I think the overall point that he makes is very true:
  We can switch our attention quickly from one task to another. But &amp;#8230;&amp;#8203; is it good for our brain? Is it good for the work we are doing?</description>
    </item>
    
    <item>
      <title>Design Simplicity: Partially updating an object</title>
      <link>https://markhneedham.com/blog/2010/09/05/design-simplicity-partially-updating-an-object/</link>
      <pubDate>Sun, 05 Sep 2010 17:32:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/09/05/design-simplicity-partially-updating-an-object/</guid>
      <description>One of the most common discussions that I have with my colleagues is around designing bits of code in the simplest way possible.
 I&amp;#8217;ve never quite been able to put my finger on exactly what makes a design simple and there is frequently disagreement about what is even considered simple.
 On the last project I worked on we had an interesting problem where we wanted to partially update different parts of an object from different pages of the application.</description>
    </item>
    
    <item>
      <title>Ultimate configurability</title>
      <link>https://markhneedham.com/blog/2010/08/21/ultimate-configurability/</link>
      <pubDate>Sat, 21 Aug 2010 11:04:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/08/21/ultimate-configurability/</guid>
      <description>In Continuous Delivery the authors talk about the danger of ultimate configurability&amp;#8230;&amp;#8203;
  Configurable software is not always the cheaper solution it appears to be. It&amp;#8217;s almost always better to focus on delivering the high-value functionality with little configuration and then add configuration options later when necessary
   &amp;#8230;&amp;#8203;and from my experience when you take this over configurability to its logical conclusion you end up developing a framework that can hopefully just be &#39;configured&#39; for any number of &#39;front ends&#39;.</description>
    </item>
    
    <item>
      <title>The fear tax</title>
      <link>https://markhneedham.com/blog/2010/08/20/the-fear-tax/</link>
      <pubDate>Fri, 20 Aug 2010 14:14:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/08/20/the-fear-tax/</guid>
      <description>Seth Godin recently wrote a post about &#39;http://sethgodin.typepad.com/seths_blog/2010/08/the-fear-tax.html[the fear tax]&#39; which he describes as a &#39;tax&#39; that we pay when we do something in order to try and calm our fear about something else but don&amp;#8217;t necessarily end up calming those fears.
  We pay the fear tax every time we spend time or money seeking reassurance. We pay it twice when the act of seeking that reassurance actually makes us more anxious, not less.</description>
    </item>
    
    <item>
      <title>Creativity - John Cleese</title>
      <link>https://markhneedham.com/blog/2010/08/16/creativity-john-cleese/</link>
      <pubDate>Mon, 16 Aug 2010 05:42:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/08/16/creativity-john-cleese/</guid>
      <description>Jonas Boner recently linked to a really cool (and short) presentation by John Cleese about creativity which I think is very applicable to software development.&amp;lt;/param&amp;gt;&amp;lt;/param&amp;gt;&amp;lt;/param&amp;gt;&amp;lt;/embed&amp;gt;
 Cleese describes some observations he&amp;#8217;s made about creativity from his experiences working in comedy. These were some of the key ideas:
 Plan to throw one away? Cleese describes a situation where he wrote a script for Fawlty Towers and then lost it. He decided to rewrite it from memory and after he&amp;#8217;d done that he found the original.</description>
    </item>
    
    <item>
      <title>Rules of thumb vs Exercise your judgement</title>
      <link>https://markhneedham.com/blog/2010/08/13/rules-of-thumb-vs-exercise-your-judgement/</link>
      <pubDate>Fri, 13 Aug 2010 10:05:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/08/13/rules-of-thumb-vs-exercise-your-judgement/</guid>
      <description>I spent a bit of time working through the first Micro Testing album of the Industrial Logic eLearning suite a few weeks ago and there&amp;#8217;s an interesting piece of advice towards the end of the album:
  Microtesting is not a formula. It&amp;#8217;s a technique. When microtesting rigorously, you will be called constantly to make judgments like these, between one set of names and another, and their corresponding approaches. Remember the judgment premise.</description>
    </item>
    
    <item>
      <title>The value of naming things</title>
      <link>https://markhneedham.com/blog/2010/07/31/the-value-of-naming-things/</link>
      <pubDate>Sat, 31 Jul 2010 07:05:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/07/31/the-value-of-naming-things/</guid>
      <description>Nikhil and I were discussing some of the ideas around Test Driven Development earlier in the week and at one stage I pointed out that I quite liked Bryan Liles&#39; idea of &#39;http://aac2009.confreaks.com/07-feb-2009-13-30-tatft-the-laymans-guide-bryan-liles.html[make it pass or change the message]&#39;.
 Bryan suggests that when we have a failing test our next step should be to make that test pass or at least write some code which results in us getting a different error message and hopefully one step closer to making the test pass.</description>
    </item>
    
    <item>
      <title>Drive - Dan Pink</title>
      <link>https://markhneedham.com/blog/2010/07/15/drive-dan-pink/</link>
      <pubDate>Thu, 15 Jul 2010 00:21:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/07/15/drive-dan-pink/</guid>
      <description>One of the more interesting presentations doing the rounds on twitter and on our internal mailing lists is the following one by Dan Pink titled &#39;http://www.youtube.com/watch?v=u6XAPnuFjJc[Drive - The surprising truth about what motivates us]&#39;.&amp;lt;/param&amp;gt;&amp;lt;/param&amp;gt;&amp;lt;/param&amp;gt;&amp;lt;/embed&amp;gt;
 This topic generally interests me anyway but it&amp;#8217;s quite intriguing that the research Dan has gathered support for what I imagine many people intrinsically knew.
 Incentives The presentation dispels the myth that money always works as a motivator for getting people to do what we want them to do.</description>
    </item>
    
    <item>
      <title>The Internet Explorer 6 dilemma</title>
      <link>https://markhneedham.com/blog/2010/07/11/the-internet-explorer-6-dilemma/</link>
      <pubDate>Sun, 11 Jul 2010 19:31:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/07/11/the-internet-explorer-6-dilemma/</guid>
      <description>A couple of weeks ago Dermot and I showcased a piece of functionality that we&amp;#8217;d been working on - notably hiding some options in a drop down list.
 We showcased this piece of functionality to the rest of the team in Firefox and it all worked correctly.
 Our business analyst, who was also acting as QA, then had a look at the story in Internet Explorer 6 and we promptly realised that the way we&amp;#8217;d solved the problem didn&amp;#8217;t actually work in IE6.</description>
    </item>
    
    <item>
      <title>Performance: Do it less or find another way</title>
      <link>https://markhneedham.com/blog/2010/07/10/performance-do-it-less-or-find-another-way/</link>
      <pubDate>Sat, 10 Jul 2010 22:49:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/07/10/performance-do-it-less-or-find-another-way/</guid>
      <description>One thing that we tried to avoid on the project that I&amp;#8217;ve been working on is making use of C# expressions trees in production code.
 We found that the areas of the code where we compiled these expressions trees frequently showed up as being the least performant areas of the code base when run through a performance profiler.
 In a discussion about the ways to improve the performance of an application Christian pointed out that once we&amp;#8217;ve identified the area for improvement there are two ways to do this:</description>
    </item>
    
    <item>
      <title>The Limited Red Society - Joshua Kerievsky</title>
      <link>https://markhneedham.com/blog/2010/07/05/the-limited-red-society-joshua-kerievsky/</link>
      <pubDate>Mon, 05 Jul 2010 15:02:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/07/05/the-limited-red-society-joshua-kerievsky/</guid>
      <description>I recently watched a presentation given by Joshua Kerievsky from the Lean Software &amp;amp; Systems conference titled &#39;http://www.infoq.com/presentations/The-Limited-Red-Society[The Limited Red Society]&#39; in which describes an approach to refactoring where we try to minimise the amount of time that the code is in a &#39;red&#39; state.
 This means that the code should be compiling and the tests green for as much of this time as possible .
 I think it&amp;#8217;s very important to follow these principles in order to successfully refactor code on a project team and it&amp;#8217;s an approach that my colleague Dave Cameron first introduced me to when we worked together last year.</description>
    </item>
    
    <item>
      <title>Intuition and &#39;quit thinking and look&#39;</title>
      <link>https://markhneedham.com/blog/2010/06/28/intuition-and-quit-thinking-and-look/</link>
      <pubDate>Mon, 28 Jun 2010 08:39:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/06/28/intuition-and-quit-thinking-and-look/</guid>
      <description>Something which Dermot, Christian and I noticed last week is that on our project we&amp;#8217;ve reached the stage where we intuitively know what the underlying problem is for any given error message in the application we&amp;#8217;re working on.
 We&amp;#8217;re pretty much at the stage where we&amp;#8217;re effectively pattern matching what&amp;#8217;s going on without needing to think that much anymore.
 This is a good thing because it saves a lot of time analysing every single message to try and work out what&amp;#8217;s going on - I think this means that we&amp;#8217;ve reached a higher level of the Dreyfus model when it comes to this particular situation.</description>
    </item>
    
    <item>
      <title>Leadership and software teams: Some thoughts</title>
      <link>https://markhneedham.com/blog/2010/06/22/leadership-and-software-teams-some-thoughts/</link>
      <pubDate>Tue, 22 Jun 2010 22:51:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/06/22/leadership-and-software-teams-some-thoughts/</guid>
      <description>Roy Osherove wrote a post about a month ago describing the different maturity levels of software teams and the strategies that he uses when leading each of these which I found quite interesting.
 He describes the following states of maturity for a team:
   Chaotic Stage&amp;#8201;&amp;#8212;&amp;#8201;the state where a team does not possess the skills, motives or ambition to become a mature self managing team.
  Mid-Life stage&amp;#8201;&amp;#8212;&amp;#8201;where a team possesses some skills for self management and decision making , and can make some of its own decisions without needing a team lead.</description>
    </item>
    
    <item>
      <title>iPad: First thoughts</title>
      <link>https://markhneedham.com/blog/2010/06/21/ipad-first-thoughts/</link>
      <pubDate>Mon, 21 Jun 2010 21:30:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/06/21/ipad-first-thoughts/</guid>
      <description>I&amp;#8217;ve had the iPad for about a month now and since my colleagues Martin Fowler, Neal Ford and Chris Stevenson have already previously written about their experiences with it I thought I&amp;#8217;d share the way I&amp;#8217;m using it as well.
 Twitter I follow a lot of people involved in software development on twitter and come across a lot of interesting articles/blogs that people link to or write. A lot of the time I don&amp;#8217;t really want to read those posts when I come across them - it would be much better if I could just save them to read later on.</description>
    </item>
    
    <item>
      <title>Slack time</title>
      <link>https://markhneedham.com/blog/2010/06/18/slack-time/</link>
      <pubDate>Fri, 18 Jun 2010 17:36:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/06/18/slack-time/</guid>
      <description>Ken Schwaber recently wrote a blog post where he compared the differences between the kanban, lean and scrum approaches to software development and although I haven&amp;#8217;t had the same experiences as he has with the first two, one interesting thing he implies is that with a scrum approach we have slack time built in.
  God help us. People found ways to have slack in waterfall, to rest and be creative.</description>
    </item>
    
    <item>
      <title>Using real life metaphors</title>
      <link>https://markhneedham.com/blog/2010/06/17/using-real-life-metaphors/</link>
      <pubDate>Thu, 17 Jun 2010 07:00:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/06/17/using-real-life-metaphors/</guid>
      <description>My colleague Dermot Kilroy attended the DDD 2010 Exchange in London last week and one of the ideas that he&amp;#8217;s been sharing with us from that is that of thinking how the user would solve a given problem without a technological solution i.e. how was something done before computers existed.
 This encourages us to take a bigger picture view and can actually lead to a much simpler solution than we&amp;#8217;d otherwise come up with.</description>
    </item>
    
    <item>
      <title>XP2010: General thoughts</title>
      <link>https://markhneedham.com/blog/2010/06/09/xp2010-general-thoughts/</link>
      <pubDate>Wed, 09 Jun 2010 15:29:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/06/09/xp2010-general-thoughts/</guid>
      <description>I had the chance to attend the XP2010 conference in Trondheim, Norway for a couple of days last week as I was presenting a lightening talk based on a blog post I wrote last year titled &#39;http://www.markhneedham.com/blog/2009/08/13/challenging-projects-and-the-five-stages-of-grief/[Tough projects and the Kubler Ross Grief Cycle]&#39;.
 It was interesting to see the way another conference was organised as the only other conference I&amp;#8217;ve attended was QCon which is a much more technical conference.</description>
    </item>
    
    <item>
      <title>Ask for forgiveness, not for permission</title>
      <link>https://markhneedham.com/blog/2010/06/04/ask-for-forgiveness-not-for-permission/</link>
      <pubDate>Fri, 04 Jun 2010 21:03:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/06/04/ask-for-forgiveness-not-for-permission/</guid>
      <description>I gave a presentation at our ThoughtWorks Brazil office in Porto Alegre last way on some of the things that I&amp;#8217;ve learned while working at ThoughtWorks and the first point I made was that it was better to &#39;ask for forgiveness, not for permission&#39;.
 This was something that was taught to me a few years ago and the idea behind this is that if there&amp;#8217;s some idea we want to try out it makes much more sense to start trying it now and then we can always apologise later on if someone has a problem with us doing that.</description>
    </item>
    
    <item>
      <title>Evolving a design: Some thoughts</title>
      <link>https://markhneedham.com/blog/2010/05/13/evolving-a-design-some-thoughts/</link>
      <pubDate>Thu, 13 May 2010 07:00:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/05/13/evolving-a-design-some-thoughts/</guid>
      <description>Phil wrote an interesting post recently about the Ubuntu decision making process with respect to design and suggested that we should look to follow something similar on agile software development teams.
 The Ubuntu design process basically comes down to this:
  This is not a democracy. Good feedback, good data, are welcome. But we are not voting on design decisions.
   Phil suggests the following:
  That doesn&amp;#8217;t mean that there is an Architect (capital A, please), designing the system for the less-skilled developers to write.</description>
    </item>
    
    <item>
      <title>Learnings from my first project of 2010</title>
      <link>https://markhneedham.com/blog/2010/05/09/learnings-from-my-first-project-of-2010/</link>
      <pubDate>Sun, 09 May 2010 22:17:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/05/09/learnings-from-my-first-project-of-2010/</guid>
      <description>Pat Kua recently wrote a retrospective of his time working at ThoughtWorks and since I recently finished the first project I&amp;#8217;ve worked on in 2010 I thought it would be interesting to have a look at what I&amp;#8217;d learned and observed while working on it.
 &#34;Perfect&#34; code I&amp;#8217;ve previously believed that driving for the cleanest code with the least duplication and best structured object oriented design was the way to go but on this project we favoured a simpler design which felt quite procedural in comparison to some of the code bases I&amp;#8217;ve worked on.</description>
    </item>
    
    <item>
      <title>Lured in by the complexity</title>
      <link>https://markhneedham.com/blog/2010/04/21/lured-in-by-the-complexity/</link>
      <pubDate>Wed, 21 Apr 2010 07:21:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/04/21/lured-in-by-the-complexity/</guid>
      <description>We recently ran into an interesting problem when running the website we&amp;#8217;re building on our &#39;user replica machine&#39; where you can access the application via a web browser running on Citrix.
 The problem we were having was that the result of a post redirect get request that we were making via the jQuery Form plugin was failing to update the fragment of the page correctly. It looked like it was replacing it with the original HTML.</description>
    </item>
    
    <item>
      <title>Late integration: Some thoughts</title>
      <link>https://markhneedham.com/blog/2010/04/18/late-integration-some-thoughts/</link>
      <pubDate>Sun, 18 Apr 2010 21:19:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/04/18/late-integration-some-thoughts/</guid>
      <description>John Daniels has an interesting post summarising GOOSgaggle, an event run a few weeks ago where people met up to talk about the ideas in &#39;http://www.amazon.co.uk/Growing-Object-Oriented-Software-Guided-Signature/dp/0321503627/ref=sr_1_1?ie=UTF8&amp;amp;s=books&amp;amp;qid=1271313406&amp;amp;sr=8-1[Growing Object Oriented Software, Guided by Tests]&#39;.
 It&amp;#8217;s an interesting post and towards the end he states the following:
  Given these two compelling justifications for starting with end-to-end tests, why is it that many people apparently don&amp;#8217;t start there? We came up with two possibilities, although there may be many others:</description>
    </item>
    
    <item>
      <title>LDNUG: Mixing functional and object oriented approaches to programming in C#</title>
      <link>https://markhneedham.com/blog/2010/04/02/ldnug-mixing-functional-and-object-oriented-approaches-to-programming-in-c/</link>
      <pubDate>Fri, 02 Apr 2010 23:11:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/04/02/ldnug-mixing-functional-and-object-oriented-approaches-to-programming-in-c/</guid>
      <description>On Wednesday evening my colleague Mike Wagg and I presented a variation of a talk I originally presented at Developer Developer Developer 8 titled &#39;Mixing functional and object oriented approaches to programming in C#&#39; to the London .NET User Group at Skillsmatter.
 The slides from the talk are below and there is a video of the talk on the Skillsmatter website.
 Mixing functional and object oriented approaches to programming in C#</description>
    </item>
    
    <item>
      <title>How I Learned to Let My Workers Lead</title>
      <link>https://markhneedham.com/blog/2010/04/01/how-i-learned-to-let-my-workers-lead/</link>
      <pubDate>Thu, 01 Apr 2010 09:38:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/04/01/how-i-learned-to-let-my-workers-lead/</guid>
      <description>I recently came across a really interesting article written by Ralph Stayer titled &#39;http://people.wku.edu/rich.patterson/CFS-452/Readings/stayer.htm[How I Learned to Let My Workers Lead]&#39; about his experiences at Johnsonville Foods.
 It describes the way that he was able to help change the company culture from one where he made all the decisions and took all responsibility to one where everyone in the company was involved in decision making, resulting in a more successful organisation.</description>
    </item>
    
    <item>
      <title>Saved from an episode of bear shaving</title>
      <link>https://markhneedham.com/blog/2010/03/30/saved-from-an-episode-of-bear-shaving/</link>
      <pubDate>Tue, 30 Mar 2010 06:57:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/03/30/saved-from-an-episode-of-bear-shaving/</guid>
      <description>As part of our continuous integration build we have a step in the build which tears down a Windows service, uninstalls it and then reinstalls it later on from the latest files checked into the repository.
 One problem we&amp;#8217;ve been having recently is that despite the fact it should already have been uninstalled a lock has been kept on the log4net dll in our build directory, a directory that we tear down as one of the next steps.</description>
    </item>
    
    <item>
      <title>Defensive Programming and the UI</title>
      <link>https://markhneedham.com/blog/2010/03/22/defensive-programming-and-the-ui/</link>
      <pubDate>Mon, 22 Mar 2010 23:42:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/03/22/defensive-programming-and-the-ui/</guid>
      <description>A few weeks ago I was looking at quite an interesting bug in our system which initially didn&amp;#8217;t seem possible.
 On one of our screens we have some questions that the user fills in which read a bit like this:
   Do you have a foo?
  Is your foo an approved foo?
  Is your foo special?
      i.e. you would only see the 2nd and 3rd questions on the screen if you answered yes to the first question.</description>
    </item>
    
    <item>
      <title>Essential and accidental complexity</title>
      <link>https://markhneedham.com/blog/2010/03/18/essential-and-accidental-complexity/</link>
      <pubDate>Thu, 18 Mar 2010 23:21:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/03/18/essential-and-accidental-complexity/</guid>
      <description>I&amp;#8217;ve been reading Neal Ford&amp;#8217;s series of articles on Evolutionary architecture and emergent design and in the one about &#39;http://www.ibm.com/developerworks/java/library/j-eaed1/index.html[Investigating architecture and design]&#39; he discusses Essential and accidental complexity which I&amp;#8217;ve previously read about in Neal&amp;#8217;s book, &#39;http://www.markhneedham.com/blog/2008/09/05/the-productive-programmer-book-review/[The Productive Programmer]&#39;.
 Neal defines these terms like so:
  Essential complexity is the core of the problem we have to solve, and it consists of the parts of the software that are legitimately difficult problems.</description>
    </item>
    
    <item>
      <title>A reminder of the usefulness of Git</title>
      <link>https://markhneedham.com/blog/2010/03/14/a-reminder-of-the-usefulness-of-git/</link>
      <pubDate>Sun, 14 Mar 2010 00:45:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/03/14/a-reminder-of-the-usefulness-of-git/</guid>
      <description>Despite the fact that none of the projects that I&amp;#8217;ve worked on have used Git or Mercurial as the team&amp;#8217;s main repository I keep forgetting how useful those tools can be even if they&amp;#8217;re just being used locally.
 I ran into a problem when trying to work out why a Rhino Mocks expectation wasn&amp;#8217;t working as I expected last week having refactored a bit of code to include a constructor.</description>
    </item>
    
    <item>
      <title>Does an organisation need to be fully committed to agile/lean/scrum?</title>
      <link>https://markhneedham.com/blog/2010/03/11/does-an-organisation-need-to-be-fully-committed-to-agileleanscrum/</link>
      <pubDate>Thu, 11 Mar 2010 08:05:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/03/11/does-an-organisation-need-to-be-fully-committed-to-agileleanscrum/</guid>
      <description>Alan Atlas has a recent blog post where he discusses agile, lean and scrum and suggests that you can&amp;#8217;t truly achieve agility unless your company is fully committed to it which differs slightly from my experiences.
 Alan makes a valid point that we&amp;#8217;re not really following an approach just because we use all the practices:
  Many people make the mistake of viewing Scrum and Agile and Lean as sets of practices.</description>
    </item>
    
    <item>
      <title>Getting real: Book review</title>
      <link>https://markhneedham.com/blog/2010/03/08/getting-real-book-review/</link>
      <pubDate>Mon, 08 Mar 2010 21:56:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/03/08/getting-real-book-review/</guid>
      <description>I recently came across 37 Signals &#39;http://gettingreal.37signals.com[Getting Real]&#39; book where they go through their approach to building web applications and there have certainly been some good reminders and ideas on the best way to do this.
 These are some of my favourite parts:
   Ship it!
 If there are minor bugs, ship it as soon you have the core scenarios nailed and ship the bug ﬁxes to web gradually after that.</description>
    </item>
    
    <item>
      <title>Riskiest thing first vs Outside in development</title>
      <link>https://markhneedham.com/blog/2010/03/02/riskiest-thing-first-vs-outside-in-development/</link>
      <pubDate>Tue, 02 Mar 2010 22:49:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/03/02/riskiest-thing-first-vs-outside-in-development/</guid>
      <description>I had an interesting conversation with my colleague David Santoro last week where I described the way that I often pick out the riskiest parts of a story or task and do those first and David pointed out that this approach didn&amp;#8217;t seem to fit in with the idea of outside in development.
 The idea with outside in development as I understand it is that we would look to drive any new functionality from the UI i.</description>
    </item>
    
    <item>
      <title>Strategic Design (Responsibility Traps) - Eric Evans</title>
      <link>https://markhneedham.com/blog/2010/01/18/strategic-design-responsibility-traps-eric-evans/</link>
      <pubDate>Mon, 18 Jan 2010 22:52:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/01/18/strategic-design-responsibility-traps-eric-evans/</guid>
      <description>Reading through some of Simon Harris&#39; blog entries I came across his thoughts on a presentation Eric Evans did at QCon titled &#39;http://www.infoq.com/presentations/design-strategic-eric-evans[Strategic Design - Responsibility Traps]&#39; which seems to cover a lot of the ground from the second half of Domain Driven Design and more.
 In the presentation Evans make some really insightful comments and points out a lot of mistakes that I&amp;#8217;ve made on projects. It certainly serves as a reminder to go back and read part 4 of the book again and really understand the material from that section.</description>
    </item>
    
    <item>
      <title>Duke Nukem Forever &amp; Reworking code</title>
      <link>https://markhneedham.com/blog/2009/12/23/duke-nukem-forever-reworking-code/</link>
      <pubDate>Wed, 23 Dec 2009 07:27:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/12/23/duke-nukem-forever-reworking-code/</guid>
      <description>Cosmin Stejerean linked to a really interesting article on wired.com which tells the story of how Duke Nukem failed over 12 years to ship their latest game, eventually giving up.
 Phil has written a post about the article from the angle of his experience working with these types of companies and working out how to get something into production but as I read this article it seemed to have some relation to reworking code and why/how we approach this.</description>
    </item>
    
    <item>
      <title>One change at a time</title>
      <link>https://markhneedham.com/blog/2009/12/22/one-change-at-a-time/</link>
      <pubDate>Tue, 22 Dec 2009 06:01:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/12/22/one-change-at-a-time/</guid>
      <description>I&amp;#8217;m reading through Paul Butcher&amp;#8217;s &#39;http://www.amazon.com/gp/product/193435628X?ie=UTF8&amp;amp;tag=marneesblo-20&amp;amp;linkCode=as2&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=193435628X[Debug It]&#39; book and one of his suggestions when trying to diagnose a problem in our code is to only change one thing at a time.
 In a way this might seem fairly obvious but I&amp;#8217;ve certainly fallen into the trap of making multiple changes at the same time in the misled belief that it&amp;#8217;ll lead to the problem being solved more quickly.
 When making changes to code Butcher has the following piece of advice which I quite like:</description>
    </item>
    
    <item>
      <title>You and Your Research - Richard Hamming</title>
      <link>https://markhneedham.com/blog/2009/12/19/you-and-your-research-richard-hamming/</link>
      <pubDate>Sat, 19 Dec 2009 02:52:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/12/19/you-and-your-research-richard-hamming/</guid>
      <description>Another paper that I read on my Sydney to London flight was one titled &#39;http://www.cs.virginia.edu/~robins/YouAndYourResearch.html[You and Your Research]&#39; by Richard Hamming.
 It&amp;#8217;s a transcript of a talk that Richard Hamming gave to Bellcore employees at the Morris Research and Engineering Centre in 1986.
 The talk is aimed at computer science researchers and Hamming describes ways for them to do the best research that they can. I think several of the ideas in the talk relate to software development as well.</description>
    </item>
    
    <item>
      <title>The Computer Scientist as Toolsmith - Fred Brooks</title>
      <link>https://markhneedham.com/blog/2009/12/16/the-computer-scientist-as-toolsmith-fred-brooks/</link>
      <pubDate>Wed, 16 Dec 2009 06:15:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/12/16/the-computer-scientist-as-toolsmith-fred-brooks/</guid>
      <description>I&amp;#8217;ve come across a couple of posts recently talking about the gender specificness of the term &#39;Software Craftsman&#39; and Victoria suggests that the term &#39;Codesmith&#39; would be a more appropriate name to use.
 I&amp;#8217;m not that bothered what the name is but I was reading the transcript of Fred Brooks&#39; acceptance speech for winning the ACM Allen Newell Award in 1994 titled &#39;http://www.cs.unc.edu/~brooks/Toolsmith-CACM.pdf[The Computer Scientist as Toolsmith]&#39; which has some interesting ideas about what our role should be.</description>
    </item>
    
    <item>
      <title>Our obsession with efficiency - Dan North</title>
      <link>https://markhneedham.com/blog/2009/12/07/our-obsession-with-efficiency-dan-north/</link>
      <pubDate>Mon, 07 Dec 2009 17:05:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/12/07/our-obsession-with-efficiency-dan-north/</guid>
      <description>Oredev have put some of the videos from the conference on Vimeo and one of my favourites is &#39;http://www.vimeo.com/7849591[Our obsession with efficiency]&#39; by my colleague Dan North.
 The slides for the talk are available on SlideShare.
 In this talk Dan leads from the following statement about efficiency:
  So here&amp;#8217;s the thing, I don&amp;#8217;t believe in efficiency. It&amp;#8217;s our obsession with efficiency that has got us into the current technology mess, and which has led almost directly to heavy waterfall processes.</description>
    </item>
    
    <item>
      <title>A reminder to talk to the rubber duck</title>
      <link>https://markhneedham.com/blog/2009/11/15/a-reminder-to-talk-to-the-rubber-duck/</link>
      <pubDate>Sun, 15 Nov 2009 21:06:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/11/15/a-reminder-to-talk-to-the-rubber-duck/</guid>
      <description>Alongside taking a break from it perhaps one of the most effective ways to solve a tricky problem is to describe it to someone else.
 When pairing This typically isn&amp;#8217;t a problem when pair programming although it can still happen if a pair stays together too long and both start making the same possibly incorrect assumptions when trying to solve a problem.
 In this case it makes sense to call someone else over who can lend a fresh perspective to the problem.</description>
    </item>
    
    <item>
      <title>Adapting our approach for the context</title>
      <link>https://markhneedham.com/blog/2009/11/13/adapting-our-approach-for-the-context/</link>
      <pubDate>Fri, 13 Nov 2009 06:34:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/11/13/adapting-our-approach-for-the-context/</guid>
      <description>Amongst the many posts written recently about unit testing one which I quite liked was written by fallenrogue where he describes how in different contexts/cultures a different approach is favoured which means a technique like TDD might not work so well.
 cashto, the guy who wrote the original post, agrees with this in the comments on that post:
  Absolutely right. I write apps on mobile devices in C++.</description>
    </item>
    
    <item>
      <title>Knowing when to persevere and when to change approach</title>
      <link>https://markhneedham.com/blog/2009/11/08/knowing-when-to-persevere-and-when-to-change-approach/</link>
      <pubDate>Sun, 08 Nov 2009 09:57:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/11/08/knowing-when-to-persevere-and-when-to-change-approach/</guid>
      <description>It strikes me that one of the most important skills to develop in software development is knowing when to keep going with an approach to a problem and when we should stop and try something else.
 This situation doesn&amp;#8217;t always happen because if we have two people available and realise before we start on the task that there is some doubt as to which solution is the most appropriate then we can adopt a set based approach whereby we try out multiple potential solutions in parallel.</description>
    </item>
    
    <item>
      <title>The effect of adding new people to project teams</title>
      <link>https://markhneedham.com/blog/2009/10/21/the-effect-of-adding-new-people-to-project-teams/</link>
      <pubDate>Wed, 21 Oct 2009 18:06:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/10/21/the-effect-of-adding-new-people-to-project-teams/</guid>
      <description>I&amp;#8217;ve read quite frequently about the challenges we will experience when adding new people onto teams, including Fred Brooks&#39; &#39;http://www.markhneedham.com/blog/2009/04/11/the-mythical-man-month-book-review/[The Mythical Man Month]&#39;, but having seen quite a few new people join the project that I&amp;#8217;ve been working on over the last few months I think there are actually some significant benefits they can provide.
 I think the impact new people provide is particularly useful on a challenging project where they may be able to have a much more immediate impact.</description>
    </item>
    
    <item>
      <title>Software Development Apprenticeship: Some thoughts</title>
      <link>https://markhneedham.com/blog/2009/10/07/software-development-apprenticeship-some-thoughts/</link>
      <pubDate>Wed, 07 Oct 2009 20:32:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/10/07/software-development-apprenticeship-some-thoughts/</guid>
      <description>I recently came across a interview with Dave Hoover where he talks through the idea of working as an apprentice software developer and suggests some ways to do this more effectively.
 I think the easiest thing to get wrong in software development is to over estimate our ability and there is even a study that proves that theory. Hoover refers to this as &#39;having an accurate self assessment&#39;.
 If we work on the same project for a while then we&amp;#8217;re going to get pretty good at navigating that code base and we&amp;#8217;ll probably be able to solve any problem and add any piece of functionality fairly easily which only helps fuel the belief.</description>
    </item>
    
    <item>
      <title>My Software Development journey: Year 3-4</title>
      <link>https://markhneedham.com/blog/2009/10/05/my-software-development-journey-year-3-4/</link>
      <pubDate>Mon, 05 Oct 2009 18:52:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/10/05/my-software-development-journey-year-3-4/</guid>
      <description>Just over a year ago I wrote a blog post about my software development journey up to that point and I thought it&amp;#8217;d be interesting to write a new version for the 13 months or so since then to see what the main things I&amp;#8217;ve learned are.
 Functional programming I started playing around with F# about 11 months ago after becoming intrigued about this approach to programming following some conversations with my colleague Phil Calcado.</description>
    </item>
    
    <item>
      <title>The Duct Tape Programmer: Some thoughts</title>
      <link>https://markhneedham.com/blog/2009/09/26/the-duct-tape-programmer-some-thoughts/</link>
      <pubDate>Sat, 26 Sep 2009 17:16:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/09/26/the-duct-tape-programmer-some-thoughts/</guid>
      <description>I just came across quite an insightful post by Jak Charlton titled &#39;http://devlicio.us/blogs/casey/archive/2009/09/25/ship-it-or-ship-out.aspx[Ship it or Ship out]&#39; in which he talks about the importance of shipping the software we work on, referring to Joel&amp;#8217;s recent post &#39;http://www.joelonsoftware.com/items/2009/09/23.html[The Duct Tape Programmer]&#39;.
 Unit testing When I first read Joel&amp;#8217;s post I didn&amp;#8217;t really like it because it seems to downplay the role of unit testing when coding, something which I believe is quite important from my experience of software development so far.</description>
    </item>
    
    <item>
      <title>A reminder that sometimes it&#39;s best just to ask</title>
      <link>https://markhneedham.com/blog/2009/09/07/a-reminder-that-sometimes-its-best-just-to-ask/</link>
      <pubDate>Mon, 07 Sep 2009 22:27:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/09/07/a-reminder-that-sometimes-its-best-just-to-ask/</guid>
      <description>Recently my pair and I were trying to merge some changes into our code that we had just picked up fron updating from the trunk and realised that we weren&amp;#8217;t actually sure how to resolve that merge since it seemed to conflict with what we&amp;#8217;d been working on.
 We hadn&amp;#8217;t checked in for longer than we would have liked to due to a bit of a checkin pile up which had happened because the build on the CI server had been failing for a few hours due to a temporary problem we were having with an external dependency.</description>
    </item>
    
    <item>
      <title>Fiddler: Trying to work out how it all hooks together</title>
      <link>https://markhneedham.com/blog/2009/09/06/fiddler-trying-to-work-out-how-it-all-hooks-together/</link>
      <pubDate>Sun, 06 Sep 2009 23:25:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/09/06/fiddler-trying-to-work-out-how-it-all-hooks-together/</guid>
      <description>I mentioned previously that we&amp;#8217;re making use of Fiddler quite a lot on my current project, mainly to check the traffic going to and from the service layer, and I&amp;#8217;m quite curious how it actually works.
 In particular I wanted to know:
   How we&amp;#8217;re able to route requests through Fiddler and then through the corporate proxy
  How proxy settings work differently for Firefox and Internet Explorer</description>
    </item>
    
    <item>
      <title>Challenging projects and the five stages of grief</title>
      <link>https://markhneedham.com/blog/2009/08/13/challenging-projects-and-the-five-stages-of-grief/</link>
      <pubDate>Thu, 13 Aug 2009 17:20:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/08/13/challenging-projects-and-the-five-stages-of-grief/</guid>
      <description>One of the things that I&amp;#8217;ve noticed over the past few years of working on software delivery projects is that the most challenging projects, the ones that most people hate working on, tend to last the longest yet teach you the most although maybe not immediately.
 The problem is that a lot of the time we are in a state of frustration with all the things that are wrong about the project and therefore don&amp;#8217;t focus on the things that we can do to make our situation better and improve the chances of the project to deliver.</description>
    </item>
    
    <item>
      <title>Bear Shaving</title>
      <link>https://markhneedham.com/blog/2009/08/06/bear-shaving/</link>
      <pubDate>Thu, 06 Aug 2009 18:58:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/08/06/bear-shaving/</guid>
      <description>I recently came across a blog post by Seth Godin where he coins the term &#39;bear shaving&#39; which is where we address the symptoms of a problem instead of addressing the problem.
 The main example he gives is the idea of shaving a bear so that it can deal with the increased temperature caused by global warming instead of addressing the underlying problem which has led to this happening in the first place.</description>
    </item>
    
    <item>
      <title>Think a little, code a little</title>
      <link>https://markhneedham.com/blog/2009/08/05/think-a-little-code-a-little/</link>
      <pubDate>Wed, 05 Aug 2009 00:13:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/08/05/think-a-little-code-a-little/</guid>
      <description>I recently came across an interesting post by Frans Bauma entitled &#39;http://weblogs.asp.net/fbouma/archive/2009/07/26/think-first-doing-is-for-later.aspx[Think first, doing is for later]&#39; which was linked to from Jeremy Miller&amp;#8217;s blog entry about incremental delivery and continuous design.
 Right now I find myself in favour of Jeremy&amp;#8217;s approach which is more about writing some code and then getting some feedback on it and then writing some more code instead of spending a lot of time thinking before we write any code.</description>
    </item>
    
    <item>
      <title>Strong opinions, weakly held</title>
      <link>https://markhneedham.com/blog/2009/08/03/strong-opinions-weakly-held/</link>
      <pubDate>Mon, 03 Aug 2009 00:46:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/08/03/strong-opinions-weakly-held/</guid>
      <description>I find one of the most applicable mantras in software development is Bob Sutton&amp;#8217;s idea that we should have strong opinions weakly held.
 The idea as I understand it is that we shouldn&amp;#8217;t sit on the fence but instead have an opinion that we research thoroughly and are prepared to back up. However, we shouldn&amp;#8217;t become too attached to those opinions but instead be prepared to listen to alternative points of view and take those on where they prove more useful than our previous opinions.</description>
    </item>
    
    <item>
      <title>Good Lazy and Bad Lazy</title>
      <link>https://markhneedham.com/blog/2009/07/21/good-lazy-and-bad-lazy/</link>
      <pubDate>Tue, 21 Jul 2009 23:10:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/07/21/good-lazy-and-bad-lazy/</guid>
      <description>One of the things I remember picking up from reading The Pragmatic Programmer is that developers need to be lazy in order to find better ways to solve problems and I came across a post by Philipp Lensson from a few years ago where he also suggests good developers are lazy and dumb.
 Something which I&amp;#8217;ve come to realise more recently is that it&amp;#8217;s not necessarily true that being lazy as a developer is always a good thing - it depends in what way you are being lazy because there are certainly good and bad ways in which you can express your laziness!</description>
    </item>
    
    <item>
      <title>Continuous Integration: Community College Discussion</title>
      <link>https://markhneedham.com/blog/2009/07/11/continuous-integration-community-college-discussion/</link>
      <pubDate>Sat, 11 Jul 2009 14:13:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/07/11/continuous-integration-community-college-discussion/</guid>
      <description>We ran a session on Continuous Integration at the most recent Community College in the ThoughtWorks Sydney office.
 It was roughly based around a CI Maturity Model which I recently came across although the intention was to find out what other teams were doing CI wise.
 I became a bit more aware of how little I know about CI after listening to a Software Engineering Radio interview with my colleague Chris Read so I was keen to see how other teams are approaching this problem.</description>
    </item>
    
    <item>
      <title>QTB: Agile Adoption - How to stuff it up</title>
      <link>https://markhneedham.com/blog/2009/06/24/qtb-agile-adoption-how-to-stuff-it-up/</link>
      <pubDate>Wed, 24 Jun 2009 23:58:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/06/24/qtb-agile-adoption-how-to-stuff-it-up/</guid>
      <description>I attended the most recent ThoughtWorks Quarterly Technology briefing on Tuesday which was titled &#39;http://www.thoughtworks.com/pdfs/aus-qtb-june09.pdf[Agile Adoption - How to stuff it up]&#39; and presented by my colleagues Andy Marks and Martin Fowler.
 There seems to be quite a few books out at the moment about how to introduce a more agile approach into your organisation - I&amp;#8217;ve been reading Lean-Agile Software Development and Becoming Agile and there is also a book called Scaling Lean and Agile Development - so I was intrigued to see whether the messages from this talk would be similar to those in these books.</description>
    </item>
    
    <item>
      <title>Visual Studio/Resharper: Changing the order of arguments</title>
      <link>https://markhneedham.com/blog/2009/06/23/visual-studioresharper-changing-the-order-of-arguments/</link>
      <pubDate>Tue, 23 Jun 2009 19:31:37 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/06/23/visual-studioresharper-changing-the-order-of-arguments/</guid>
      <description>We&amp;#8217;ve recently run into some places in our tests where the expectation and actual values passed into NUnit&#39;s &#39;Assert.AreEqual&#39; are the wrong way round, therefore meaning that the error messages we get when tests fail are somewhat confusing!
 Assert.AreEqual(theActualValue, &#34;the expectation&#34;);   We can change the arguments around using Resharper by using the key combination &#39;Ctrl-Alt-Shift-ArrowKey&#39; but you can only do this one line at a time which was a bit annoying as there were about 20 to change.</description>
    </item>
    
    <item>
      <title>Seams: Some thoughts</title>
      <link>https://markhneedham.com/blog/2009/06/21/seams-some-thoughts/</link>
      <pubDate>Sun, 21 Jun 2009 17:21:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/06/21/seams-some-thoughts/</guid>
      <description>I pick up Michael Feathers&#39; Working Effectively with Legacy Code book from time to time and one of my favourite parts of the book is the chapter where he talks about &#39;Seams&#39;.
 To quote the book:
  A seam is a place where you can alter behaviour in your program without editing in that place
   Seams in the book are generally discussed in terms of how we can get tests around legacy code which was written without easy testability in mind but I&amp;#8217;ve noticed that the ideas behind seams seem to be more widely applicable than this.</description>
    </item>
    
    <item>
      <title>VMware: Accessing host server</title>
      <link>https://markhneedham.com/blog/2009/06/02/vmware-accessing-host-server/</link>
      <pubDate>Tue, 02 Jun 2009 21:36:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/06/02/vmware-accessing-host-server/</guid>
      <description>I&amp;#8217;ve been doing all my spare time .NET development from within VMWare for about the last year or so and now and then it&amp;#8217;s quite useful to be able to access the host machine either to get some files from there or to access a server that&amp;#8217;s running on the host.
 The former problem is solved by going to &#39;Virtual Machines -&amp;gt; Shared Folders&#39; and clicking on the + button on the bottom left of the menu to add a folder that you want to share.</description>
    </item>
    
    <item>
      <title>The value of a fresh mind</title>
      <link>https://markhneedham.com/blog/2009/05/26/the-value-of-a-fresh-mind/</link>
      <pubDate>Tue, 26 May 2009 00:51:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/05/26/the-value-of-a-fresh-mind/</guid>
      <description>I recently read a post by my colleague Sai Venkatakrishnan where he talks about some of the disadvantages of over working on a project and it reminded me of something I&amp;#8217;ve noticed a lot recently - notably that after taking a break from solving a problem, either by looking at it again the next day or after lunch or any kind of break I end up solving it significantly more quickly than if I&amp;#8217;d kept on trying to solve it without doing so.</description>
    </item>
    
    <item>
      <title>Debugging: Get to a stage where it works</title>
      <link>https://markhneedham.com/blog/2009/05/12/debugging-get-to-a-stage-where-it-works/</link>
      <pubDate>Tue, 12 May 2009 09:21:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/05/12/debugging-get-to-a-stage-where-it-works/</guid>
      <description>When debugging a problem I&amp;#8217;ve learnt far too many times that where possible the most effective approach is to try and get the application back into a state where it does work and then analyse the changes that have resulted in it no longer working as expected.
 About 7 or 8 years ago when I used to code PHP at school and university that pretty much was my default approach - I didn&amp;#8217;t really know how to program well enough to work out how to fix something that was broken so I would always just revert back all the steps I&amp;#8217;d done until it worked.</description>
    </item>
    
    <item>
      <title>Tackling the risk early on at a task level</title>
      <link>https://markhneedham.com/blog/2009/05/11/tackling-the-risk-early-on-at-a-task-level/</link>
      <pubDate>Mon, 11 May 2009 23:54:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/05/11/tackling-the-risk-early-on-at-a-task-level/</guid>
      <description>I wrote previously about the idea of tackling the risky tasks in a project early on - an idea that I learnt about when reading Alistair Cockburn&amp;#8217;s Crystal Clear.
 Towards the end of the post I wondered whether we could apply this idea at a story level whereby we would identify the potentially risky parts of a story and make sure that we addressed those risks before they became problematic to us.</description>
    </item>
    
    <item>
      <title>Pimp my architecture - Dan North</title>
      <link>https://markhneedham.com/blog/2009/04/25/pimp-my-architecture-dan-north/</link>
      <pubDate>Sat, 25 Apr 2009 01:26:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/04/25/pimp-my-architecture-dan-north/</guid>
      <description>My colleague Dan North presented a version of a talk he first did at QCon London titled &#39;http://qconlondon.com/london-2009/presentation/Pimp+my+architecture[Pimp my architecture]&#39; at the ThoughtWorks Sydney community college on Wednesday night. He&amp;#8217;ll also be presenting it at JAOO in Sydney and Brisbane in a couple of weeks time.
 The slides for the talk are here and it&amp;#8217;s also available on InfoQ.
 What did I learn?   I quite liked the way the talk was laid out - Dan laid out a series of problems that he&amp;#8217;s seen on some projects he&amp;#8217;s worked on and then showed on the next slide where he planned to take the architecture.</description>
    </item>
    
    <item>
      <title>QTB: Lean Times Require Lean Thinking</title>
      <link>https://markhneedham.com/blog/2009/03/25/qtb-lean-times-require-lean-thinking/</link>
      <pubDate>Wed, 25 Mar 2009 00:36:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/03/25/qtb-lean-times-require-lean-thinking/</guid>
      <description>I went to watch the latest ThoughtWorks Quarterly Technology Briefing on Tuesday, which was presented by my colleague Jason Yip and Paul Heaton, titled &#39;http://www.thoughtworks.com/pdfs/aus-qtb-mar09.pdf[Lean Times Require Lean Thinking]&#39;
 I&amp;#8217;ve been reading quite a bit of lean related material lately but I thought it would be interesting to hear about it directly from the perspective of two people who have been involved with applying the concepts in organisations.
 What did I learn?</description>
    </item>
    
    <item>
      <title>Re-reading books</title>
      <link>https://markhneedham.com/blog/2009/03/19/re-reading-books/</link>
      <pubDate>Thu, 19 Mar 2009 10:49:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/03/19/re-reading-books/</guid>
      <description>An interesting thing that I&amp;#8217;ve started to notice recently with regards to software development books is that I get a lot more from reading the book the second time compared to what I did reading the book the first time.
 I&amp;#8217;ve noticed this for several books, including The Pragmatic Programmer, Code Complete and Domain Driven Design, so my first thought was that perhaps I had read this books too early when I didn&amp;#8217;t have the necessary context or experience to gain value from reading them.</description>
    </item>
    
    <item>
      <title>Trade Offs: Some Thoughts</title>
      <link>https://markhneedham.com/blog/2009/03/02/trade-offs-some-thoughts/</link>
      <pubDate>Mon, 02 Mar 2009 23:01:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/03/02/trade-offs-some-thoughts/</guid>
      <description>As we know with software development with pretty much every decision we make or technology we choose there is a trade off that goes with making this choice as compared with choosing an alternative.
 I first learnt this when working with Ade a couple of years ago and while I know it to be true, I had come to believe that some practices are just non-negotiable and we should look to apply them judiciously wherever possible.</description>
    </item>
    
    <item>
      <title>Encoding user entered data</title>
      <link>https://markhneedham.com/blog/2009/02/15/encoding-user-entered-data/</link>
      <pubDate>Sun, 15 Feb 2009 01:46:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/02/15/encoding-user-entered-data/</guid>
      <description>I previously wrote about protecting websites from cross site scripting in the ASP.NET MVC framework by encoding user input when we are going to display it in the browser.
 We can either choose to encode data like this or we can encode it straight away when we get it.
 There did not seem to be a consensus on the best approach in a discussion on the ASP.NET forums but we believe it is far better to encode the data when it is outgoing rather than incoming.</description>
    </item>
    
    <item>
      <title>Quality is what I work for</title>
      <link>https://markhneedham.com/blog/2009/02/09/quality-is-what-i-work-for/</link>
      <pubDate>Mon, 09 Feb 2009 16:51:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/02/09/quality-is-what-i-work-for/</guid>
      <description>I&amp;#8217;ve been reading the transcript of Joel Spolsky/Jeff Atwood&amp;#8217;s podcast discussion on TDD/Quality and related posts on the subject by Uncle Bob and Ron Jeffries and while I guess it&amp;#8217;s fairly inevitable that I&amp;#8217;m likely to side with the latter two, what I&amp;#8217;ve realised is that I get the greatest enjoyment from my job when we are writing high quality software.
 Certainly delivering value to customers in a timely manner is important but if we&amp;#8217;re not producing something that we&amp;#8217;re proud to have written then I think we&amp;#8217;re doing ourselves and our customer a disservice.</description>
    </item>
    
    <item>
      <title>Finding the value in fixing technical debt</title>
      <link>https://markhneedham.com/blog/2009/01/10/finding-the-value-in-fixing-technical-debt/</link>
      <pubDate>Sat, 10 Jan 2009 14:04:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2009/01/10/finding-the-value-in-fixing-technical-debt/</guid>
      <description>Technical debt is a term coined by Martin Fowler which we tend to use on our projects to describe a number of different situations on projects as Ian Cartwright points out in his post on the subject.
 Ian covers it in more detail, but to summarise my understanding of what technical debt actually is:
  Technical debt is where we know that something we choose not to take care of now is going to affect us in the future.</description>
    </item>
    
    <item>
      <title>Try it and see what happens</title>
      <link>https://markhneedham.com/blog/2008/12/21/try-it-and-see-what-happens/</link>
      <pubDate>Sun, 21 Dec 2008 17:43:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/12/21/try-it-and-see-what-happens/</guid>
      <description>Another of the ideas I have picked up from my lean reading is that of trying things out without understanding exactly what is happening.
 Or as The Toyota Way puts it&amp;#8230;&amp;#8203;
  There are many things one doesn&amp;#8217;t understand and therefore, we ask them why don&amp;#8217;t you just go ahead and take action; try to do something?
   This is an approach which several colleagues I have worked with recently have been encouraging me to follow.</description>
    </item>
    
    <item>
      <title>Javascript: Creating quick feedback loops</title>
      <link>https://markhneedham.com/blog/2008/12/09/javascript-creating-quick-feedback-loops/</link>
      <pubDate>Tue, 09 Dec 2008 21:13:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/12/09/javascript-creating-quick-feedback-loops/</guid>
      <description>I&amp;#8217;ve been working quite a lot with Javascript and in particular jQuery recently and since I haven&amp;#8217;t done much in this area before all the tips and tricks are new to me.
 One thing which is always useful no matter the programming language is to use it in a way that you can get rapid feedback on what you are doing.
 Fortunately there are quite a few tools that allow us to do this with Javascript:</description>
    </item>
    
    <item>
      <title>Twitter as a learning tool</title>
      <link>https://markhneedham.com/blog/2008/12/07/twitter-as-a-learning-tool/</link>
      <pubDate>Sun, 07 Dec 2008 22:30:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/12/07/twitter-as-a-learning-tool/</guid>
      <description>About 8 or 9 months ago I remember having a conversation with a colleague where I asked him where he had got his almost encyclopedic knowledge of all things software development.
 His reply at the time was that he read a lot of blogs and that this was where he had picked up a lot of the information.
 While subscribing to different blogs remains a useful way of learning about different aspects of software development, I think Twitter is now becoming a very useful complementary tool to use alongside the RSS reader.</description>
    </item>
    
    <item>
      <title>Dave Thomas on Managing Lean and Agile In Large Software Development</title>
      <link>https://markhneedham.com/blog/2008/12/05/dave-thomas-on-managing-lean-and-agile-in-large-software-development/</link>
      <pubDate>Fri, 05 Dec 2008 00:00:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/12/05/dave-thomas-on-managing-lean-and-agile-in-large-software-development/</guid>
      <description>No coding dojo update this week as Dave Thomas was in the ThoughtWorks Sydney office to talk about Managing Lean and Agile in Large Software Development.
 It was actually a talk to the Geek Girls Sydney group but I sneaked in to hear his other talk after listening to the cloud computing one last week.
 It was a much toned down presentation compared to the cloud computing one although still amusing in places.</description>
    </item>
    
    <item>
      <title>What are your personal practices?</title>
      <link>https://markhneedham.com/blog/2008/12/02/what-are-your-personal-practices/</link>
      <pubDate>Tue, 02 Dec 2008 21:18:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/12/02/what-are-your-personal-practices/</guid>
      <description>I&amp;#8217;ve been reviewing Apprenticeship Patterns over the last week or so and one of the cool ideas I came across is that of creating a Personal Practices Map.
 The idea is that you draw up a list of your 10 most important practices for coding and design and draw out any relationships between them.
 This is mine as of now:
   I wouldn&amp;#8217;t say I follow all of these all the time, but they are the practices that I try to follow whenever possible.</description>
    </item>
    
    <item>
      <title>Dave Thomas on Cloud Computing</title>
      <link>https://markhneedham.com/blog/2008/11/26/dave-thomas-on-cloud-computing/</link>
      <pubDate>Wed, 26 Nov 2008 20:46:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/11/26/dave-thomas-on-cloud-computing/</guid>
      <description>I went to see Object Mentor&amp;#8217;s Dave Thomas give a talk about cloud computing on Tuesday evening in a combined meeting of the Sydney Alt.NET user group and several others.
 I&amp;#8217;d not seen him speak before but several colleagues had seen him at JAOO earlier this year so he came highly recommended.
 We started off with a plug for the JAOO Australia 2009 conference which will again be in Brisbane and Sydney at the beginning of May.</description>
    </item>
    
    <item>
      <title>Debugging 3rd party libraries more effectively</title>
      <link>https://markhneedham.com/blog/2008/11/09/debugging-3rd-party-libraries-more-effectively/</link>
      <pubDate>Sun, 09 Nov 2008 21:55:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/11/09/debugging-3rd-party-libraries-more-effectively/</guid>
      <description>Debugging 3rd party library code quickly and effectively is one of the skills which most obviously separates Senior and Junior developers from my experience.
 From observation over the last couple of years there are some patterns in the approaches which the best debuggers take.
 Get more information Sometimes it&amp;#8217;s difficult to understand exactly how to solve a problem without getting more information.
 Verbose logging mode is available on the majority of libraries and provides the information showing how everything fits together which is normally enough information to work out how to solve the problem.</description>
    </item>
    
    <item>
      <title>File system equivalent of commenting code</title>
      <link>https://markhneedham.com/blog/2008/11/06/file-system-equivalent-of-commenting-code/</link>
      <pubDate>Thu, 06 Nov 2008 21:51:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/11/06/file-system-equivalent-of-commenting-code/</guid>
      <description>Last week I came across what I have decided is the file system equivalent of commenting out code - not deleting directories when we are no longer using them.
 The specific situation we ran into was while trying to make some Tomcat configuration changes but everything we changed was having no effect on what we were seeing on the web site.
 Eventually we realised that we were actually changing the configuration in the wrong place - we actually had two Tomcat folder lying around.</description>
    </item>
    
    <item>
      <title>Object Calisthenics: First thoughts</title>
      <link>https://markhneedham.com/blog/2008/11/06/object-calisthenics-first-thoughts/</link>
      <pubDate>Thu, 06 Nov 2008 21:30:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/11/06/object-calisthenics-first-thoughts/</guid>
      <description>We ran an Object Calisthenics variation of Coding Dojo on Wednesday night as part of ThoughtWorks Geek Night in Sydney.
 Object Calisthenics is an idea suggest by Jeff Bay in The ThoughtWorks Anthology , and lists 9 rules to writing better Object Oriented code. For those who haven&amp;#8217;t seen the book, the 9 rules are:
  Use only one level of indentation per method
  Don&amp;#8217;t use the else keyword</description>
    </item>
    
    <item>
      <title>CSS in Internet Explorer - Some lessons learned</title>
      <link>https://markhneedham.com/blog/2008/11/01/css-in-internet-explorer-some-lessons-learned/</link>
      <pubDate>Sat, 01 Nov 2008 01:24:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/11/01/css-in-internet-explorer-some-lessons-learned/</guid>
      <description>I&amp;#8217;ve spent the last few days working with CSS, and in particular trying to make a layout which works perfectly fine in Firefox work properly in Internet Explorer 6.
 I&amp;#8217;m far from an expert when it comes to this but I&amp;#8217;ve picked up a few lessons from our attempts to get identical layouts in both browsers.
   Internet Explorer seems to do some crazy stuff when it comes to padding and margins - we were often ending up with huge margins where we hadn&amp;#8217;t even specified any.</description>
    </item>
    
    <item>
      <title>Don&#39;t shave the yak, ask &#39;Why are we doing this?&#39;</title>
      <link>https://markhneedham.com/blog/2008/10/25/dont-shave-the-yak-ask-why-are-we-doing-this/</link>
      <pubDate>Sat, 25 Oct 2008 01:34:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/10/25/dont-shave-the-yak-ask-why-are-we-doing-this/</guid>
      <description>One of the very common pitfalls I make when working on things is to get so engrossed in the technical details of the problem that I completely forget the reason for doing it in the first place.
 Over the last week or so I have noticed myself trying to solve some ridiculous problems without considering whether I am solving the right problem in the first place.
 To give an example, I was working with Hibernate earlier in the week trying to setup a new mapping between two entities which involved creating a composite key on one of the entities, which led to us having to work out how to do that on the database, then editing our migration script, then trawling Google to work out why our mapping wasn&amp;#8217;t working, before a colleague overheard our pain and pointed out that we had over complicated matters.</description>
    </item>
    
    <item>
      <title>Easily misused language features</title>
      <link>https://markhneedham.com/blog/2008/09/25/easily-misused-language-features/</link>
      <pubDate>Thu, 25 Sep 2008 23:18:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/09/25/easily-misused-language-features/</guid>
      <description>In the comments of my previous post about my bad experiences with Java&amp;#8217;s import static my colleague Carlos and several others pointed out that it is actually a useful feature when used properly.
 The code base where I initially came across the feature misused it quite severely but it got me thinking about other language features I have come across which can add great value when used effectively but lead to horrific problems when misused.</description>
    </item>
    
    <item>
      <title>Onshore or Offshore - The concepts are the same?</title>
      <link>https://markhneedham.com/blog/2008/09/24/onshore-or-offshore-the-concepts-are-the-same/</link>
      <pubDate>Wed, 24 Sep 2008 07:08:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/09/24/onshore-or-offshore-the-concepts-are-the-same/</guid>
      <description>I&amp;#8217;ve never worked on a distributed or offshore project before, but intrigued having read about Jay Fields&#39; experiences I attended the &#39;OffShoring: The Current State of Play&#39; Quarterly Technology Briefing held this morning in Sydney to hear the other side of the argument.
 The underlying message for me was that a lot of the concepts we apply for onshore projects are equally important for offshore projects.
 Forrester&amp;#8217;s Tim Sheedy started off by providing some research data on the state of IT offshoring, some reasons he had identified around which type of work should be offshored before closing on some reasons that it might fail if not done correctly.</description>
    </item>
    
    <item>
      <title>Where are we now? Where do we want to be?</title>
      <link>https://markhneedham.com/blog/2008/09/20/where-are-we-now-where-do-we-want-to-be/</link>
      <pubDate>Sat, 20 Sep 2008 17:32:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/09/20/where-are-we-now-where-do-we-want-to-be/</guid>
      <description>Listening to Dan North speaking last week I was reminded of one of my favourite NLP[*] techniques for making improvements on projects.
 The technique is the http://en.wikipedia.org/wiki/T.O.T.E.[TOTE] (Test, Operate, Test, Exit) and it is a technique designed to help us get from where we are now to where we want to be via short feedback loops.
 On my previous project we had a situation where we needed to build and deploy our application in order to show it to the client in a show case.</description>
    </item>
    
    <item>
      <title>What makes a good developer?</title>
      <link>https://markhneedham.com/blog/2008/09/16/what-make-a-good-developer/</link>
      <pubDate>Tue, 16 Sep 2008 10:07:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/09/16/what-make-a-good-developer/</guid>
      <description>Early last year I became very curious about what it was that made the best developers in the industry so good at what they do.
 Jay Fields points out some things that he believes indicate that a developer is good at the end of this post but a former colleague and I tried to come up with a list of areas that any Developer needed to be skilled in to justifiably consider themselves good.</description>
    </item>
    
    <item>
      <title>My Software Development journey so far</title>
      <link>https://markhneedham.com/blog/2008/09/01/my-software-development-journey-so-far/</link>
      <pubDate>Mon, 01 Sep 2008 01:01:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/09/01/my-software-development-journey-so-far/</guid>
      <description>While reading some of the rough drafts of Apprenticeship Patterns online I started thinking about the stages I have gone through on my Software Development journey so far.
 I have worked in the industry for just over 3 years; 1 year at Reed Business and 2 years at ThoughtWorks. Over that time my thoughts, opinions and ways of doing things have changed, and no doubt these will continue to evolve as I learn more and more.</description>
    </item>
    
    <item>
      <title>Handling balances in systems</title>
      <link>https://markhneedham.com/blog/2008/08/27/handling-balances-in-systems/</link>
      <pubDate>Wed, 27 Aug 2008 21:47:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/08/27/handling-balances-in-systems/</guid>
      <description>On one of my previous projects one of the problems that we had to solve was how to handle balances - we were working on a cash service for a financial services company.
 The main discussion often centres around how often the balance should be updated. From my experience there are two main ways that we can go about this:
 Real time update after every transaction This is perhaps the most obvious approach and the implementation is fairly simple.</description>
    </item>
    
    <item>
      <title>From Prototype to Delivery</title>
      <link>https://markhneedham.com/blog/2008/08/18/from-prototype-to-delivery/</link>
      <pubDate>Mon, 18 Aug 2008 22:39:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/08/18/from-prototype-to-delivery/</guid>
      <description>Projects often reach the interesting point where the prototyping and development phases intersect and there are some interesting decisions to make.
 From a development point of view the biggest decision is what to do with the code that has been developed.
 When developing prototypes the focus tends to be on getting something to work quick and dirty. Not a lot of time is put into considering edge cases or error conditions or any of the other niceties that are needed for software to be usable in an enterprise environment.</description>
    </item>
    
    <item>
      <title>Dependency Tasks</title>
      <link>https://markhneedham.com/blog/2008/08/12/dependency-tasks/</link>
      <pubDate>Tue, 12 Aug 2008 23:48:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/08/12/dependency-tasks/</guid>
      <description>I am a big fan of Pat Kua&amp;#8217;s tiny tasks and to see my desk would be to believe that there had been an invasion of yellow stickies on the planet.
 Pat explains the idea on his website but to summarise; the idea is that given a story, you break it down into the individual tasks that need to be done in order for it to be complete, write each tasks on a sticky and then when that task is finished throw the sticky away.</description>
    </item>
    
    <item>
      <title>Does generalising specialist mean you can&#39;t be the best?</title>
      <link>https://markhneedham.com/blog/2008/08/11/does-generalising-specialist-mean-you-cant-be-the-best/</link>
      <pubDate>Mon, 11 Aug 2008 05:31:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/08/11/does-generalising-specialist-mean-you-cant-be-the-best/</guid>
      <description>It&amp;#8217;s often said that people who are really good at what they do are so good at it because they have narrowed their focus in their area of specialty until they are only doing the thing that they are good at.
 To use a football analogy, Manchester United&amp;#8217;s Cristiano Ronaldo - widely acknowledged as the best footballer in the world at the moment - is absolutely brilliant when he has the ball at his feet, taking on defenders, getting in shots around the opposition penalty area.</description>
    </item>
    
  </channel>
</rss>