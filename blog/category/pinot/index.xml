<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pinot on Mark Needham</title>
    <link>https://www.markhneedham.com/blog/category/pinot/</link>
    <description>Recent content in Pinot on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Jan 2022 02:44:37 +0000</lastBuildDate>
    
	<atom:link href="https://www.markhneedham.com/blog/category/pinot/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Apache Pinot: Resetting a segment after an invalid JSON Transformation</title>
      <link>https://www.markhneedham.com/blog/2022/01/31/pinot-resetting-segment-invalid-json-transformation/</link>
      <pubDate>Mon, 31 Jan 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/31/pinot-resetting-segment-invalid-json-transformation/</guid>
      <description>I recently had a typo in a Pinot ingestion transformation function and wanted to have Pinot re-process the Kafka stream without having to restart all the things. In this blog post we&amp;#8217;ll learn how to do that.
  Figure 1. Apache Pinot: Resetting a segment after an invalid JSON Transformation  Setup We&amp;#8217;re going to spin up a local instance of Pinot and Kafka using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Sorted indexes on real-time tables</title>
      <link>https://www.markhneedham.com/blog/2022/01/20/apache-pinot-sorted-indexes-realtime-tables/</link>
      <pubDate>Thu, 20 Jan 2022 02:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/20/apache-pinot-sorted-indexes-realtime-tables/</guid>
      <description>I&amp;#8217;ve recently been learning all about Apache Pinot&amp;#8217;s sorted forward indexes, and in my first blog post I explained how they work for offline tables. In this blog post we&amp;#8217;ll learn how sorted indexes work with real-time tables.
  Figure 1. Apache Pinot: Sorted indexes on real-time tables  Launch Components We&amp;#8217;re going to spin up a local instance of Pinot and Kafka using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Sorted indexes on offline tables</title>
      <link>https://www.markhneedham.com/blog/2022/01/19/apache-pinot-sorted-indexes-offline-tables/</link>
      <pubDate>Wed, 19 Jan 2022 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/19/apache-pinot-sorted-indexes-offline-tables/</guid>
      <description>I&amp;#8217;ve recently been learning all about Apache Pinot&amp;#8217;s sorted forward indexes. I was initially going to explain how they work for offline and real-time tables, but the post got a bit long, so instead we&amp;#8217;ll have two blog posts. In this one we&amp;#8217;ll learn how sorted indexes are applied for offline tables.
  Figure 1. Apache Pinot: Sorted indexes on offline tables  Launch Components We&amp;#8217;re going to spin up a local instance of Pinot using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Checking which indexes are defined</title>
      <link>https://www.markhneedham.com/blog/2022/01/13/apache-pinot-which-indexes-are-defined/</link>
      <pubDate>Thu, 13 Jan 2022 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2022/01/13/apache-pinot-which-indexes-are-defined/</guid>
      <description>One of the most common questions in the Apache Pinot community Slack is how to work out which indexes are defined on columns in Pinot segments. This blog post will attempt to answer that question.
  Figure 1. Apache Pinot: Checking which indexes are defined  Setup First, we&amp;#8217;re going to spin up a local instance of Pinot using the following Docker compose config:
 docker-compose.yml version: &#39;3.7&#39; services: zookeeper: image: zookeeper:3.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Exploring range queries</title>
      <link>https://www.markhneedham.com/blog/2021/12/07/apache-pinot-exploring-range-queries/</link>
      <pubDate>Tue, 07 Dec 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/12/07/apache-pinot-exploring-range-queries/</guid>
      <description>In our last post about the Chicago Crimes dataset and Apache Pinot, we learnt how to use various indexes to filter columns by exact values. In this post we&amp;#8217;re going to learn how to write range queries against the dataset.
  Figure 1. Apache Pinot - Range Queries  Recap To recap, the Chicago Crimes dataset contains more than 7 million crimes committed in Chicago from 2001 until today. For each crime we have various identifiers, a timestamp, location, and codes reprsenting the type of crime that&amp;#8217;s been committed.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Copying a segment to a new table</title>
      <link>https://www.markhneedham.com/blog/2021/12/06/apache-pinot-copy-segment-new-table/</link>
      <pubDate>Mon, 06 Dec 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/12/06/apache-pinot-copy-segment-new-table/</guid>
      <description>In this post we&amp;#8217;ll learn how to use the same Pinot segment in multiple tables.
  Figure 1. Apache Pinot - Copy segment to another table  Setup First, we&amp;#8217;re going to spin up a local instance of Pinot using the following Docker compose config:
 docker-compose.yml version: &#39;3.7&#39; services: zookeeper: image: zookeeper:3.5.6 hostname: zookeeper container_name: manual-zookeeper ports: - &#34;2181:2181&#34; environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 pinot-controller: image: apachepinot/pinot:0.9.0 command: &#34;</description>
    </item>
    
    <item>
      <title>Apache Pinot: Convert DateTime string to Timestamp - IllegalArgumentException: Invalid timestamp</title>
      <link>https://www.markhneedham.com/blog/2021/12/03/apache-pinot-convert-datetime-string-timestamp-invalid-timestamp/</link>
      <pubDate>Fri, 03 Dec 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/12/03/apache-pinot-convert-datetime-string-timestamp-invalid-timestamp/</guid>
      <description>In this post we&amp;#8217;ll learn how to deal with a field that contains DateTime strings when importing a CSV file into Apache Pinot. We&amp;#8217;ll also cover some of the error messages that you&amp;#8217;ll see if you do it the wrong way.
  Figure 1. Apache Pinot - Convert DateTime string to Timestamp  Setup We&amp;#8217;re going to spin up a local instance of Pinot using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Exploring indexing techniques on Chicago Crimes</title>
      <link>https://www.markhneedham.com/blog/2021/11/30/apache-pinot-exploring-index-chicago-crimes/</link>
      <pubDate>Tue, 30 Nov 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/11/30/apache-pinot-exploring-index-chicago-crimes/</guid>
      <description>In Neha Pawar&amp;#8217;s recent blog post, What Makes Apache Pinot fast?, she summarises it with the following sentence:
  At the heart of the system, Pinot is a columnar store with several smart optimizations that can be applied at various stages of the query by the different Pinot components. Some of the most commonly used and impactful optimizations are data partitioning strategies, segment assignment strategies, smart query routing techniques, a rich set of indexes for filter optimizations, and aggregation optimization techniques.</description>
    </item>
    
    <item>
      <title>Apache Pinot: Importing CSV files with columns containing spaces</title>
      <link>https://www.markhneedham.com/blog/2021/11/25/apache-pinot-csv-columns-spaces/</link>
      <pubDate>Thu, 25 Nov 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/11/25/apache-pinot-csv-columns-spaces/</guid>
      <description>I&amp;#8217;ve been playing around with one of my favourite datasets from the Chicago Data Portal and spent a while figuring out how to import columns that contain spaces into Apache Pinot. In this blog post we&amp;#8217;ll learn how to do that using a subset of the data.
 Setup We&amp;#8217;re going to spin up a local instance of Pinot using the following Docker compose config:
 docker-compose.yml version: &#39;3.7&#39; services: zookeeper: image: zookeeper:3.</description>
    </item>
    
    <item>
      <title>Apache Pinot: org.apache.helix.HelixException: Cluster structure is not set up for cluster: PinotCluster</title>
      <link>https://www.markhneedham.com/blog/2021/11/23/apache-pinot-helix-exception-cluster-structure-not-set-up/</link>
      <pubDate>Tue, 23 Nov 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/11/23/apache-pinot-helix-exception-cluster-structure-not-set-up/</guid>
      <description>In my continued exploration of Apache Pinot, I wanted to spin up all the components individually rather than relying on one of the QuickStarts that takes care of that for me. In doing so I came across an interesting error that we&amp;#8217;ll explore in this post.
 Setup We&amp;#8217;re going to spin up a local instance of Pinot using the following Docker compose config:
 version: &#39;3.7&#39; services: zookeeper: image: zookeeper:3.</description>
    </item>
    
    <item>
      <title>Apache Pinot: BadQueryRequestException - Cannot convert value to type: LONG</title>
      <link>https://www.markhneedham.com/blog/2021/07/16/pinot-bad-query-request-exception-cannot-convert-value-long/</link>
      <pubDate>Fri, 16 Jul 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/07/16/pinot-bad-query-request-exception-cannot-convert-value-long/</guid>
      <description>In my continued exploration of Apache Pinot I&amp;#8217;ve been trying out the GitHub events recipe , which imports data from the GitHub events stream into Pinot. In this blog post I want to show how I worked around an exception I was getting when trying to filter the data by one of the timestamp&amp;#8217;s column.
 Setup We&amp;#8217;re going to spin up a local instance of Pinot using the following Docker compose config:</description>
    </item>
    
    <item>
      <title>Apache Pinot: Analysing England&#39;s Covid case data</title>
      <link>https://www.markhneedham.com/blog/2021/06/22/pinot-analysing-england-covid-cases/</link>
      <pubDate>Tue, 22 Jun 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/06/22/pinot-analysing-england-covid-cases/</guid>
      <description>As I mentioned in my last blog post, I&amp;#8217;ve been playing around with Apache Pinot, a data store that&amp;#8217;s optimised for user facing analytical workloads.
   My understanding is that Pinot is a really good fit for datasets where:
  The query patterns are of an analytical nature e.g. slicing and dicing on any columns.
  We&amp;#8217;re ingesting the data in real time from a stream of events.</description>
    </item>
    
    <item>
      <title>Apache Pinot: {&#39;errorCode&#39;: 410, &#39;message&#39;: &#39;BrokerResourceMissingError&#39;}</title>
      <link>https://www.markhneedham.com/blog/2021/06/21/pinot-broker-resource-missing/</link>
      <pubDate>Mon, 21 Jun 2021 00:44:37 +0000</pubDate>
      
      <guid>https://www.markhneedham.com/blog/2021/06/21/pinot-broker-resource-missing/</guid>
      <description>I&amp;#8217;ve recently been playing around with Apache Pinot, a realtime analytical data store that&amp;#8217;s used for user facing analytics use cases. In this blog post I want to walk through some challenges I had connecting to Pinot using the Python driver and how I got things working.
 I&amp;#8217;m running Pinot locally using the Docker image, which I setup in a Docker compose file:
 docker-compose.yml version: &#39;3.7&#39; services: pinot: image: apachepinot/pinot:0.</description>
    </item>
    
  </channel>
</rss>