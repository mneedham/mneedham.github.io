<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shell Scripting on Mark Needham</title>
    <link>https://markhneedham.com/blog/category/shell-scripting/</link>
    <description>Recent content in Shell Scripting on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Jun 2017 12:26:49 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/category/shell-scripting/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Shell: Create a comma separated string</title>
      <link>https://markhneedham.com/blog/2017/06/23/shell-create-comma-separated-string/</link>
      <pubDate>Fri, 23 Jun 2017 12:26:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/06/23/shell-create-comma-separated-string/</guid>
      <description>foo-0,foo-1,foo-2 n=3 for i in $(seq 0 $(($n &amp;gt; 0? $n-1: 0))); do echo &amp;#34;foo-$i&amp;#34; done foo-0 foo-1 foo-2 n=3 combined=&amp;#34;&amp;#34; for i in $(seq 0 $(($n &amp;gt; 0? $n-1: 0))); do token=&amp;#34;foo-$i&amp;#34; combined=&amp;#34;${combined}${combined:+,}$token&amp;#34; done echo $combined foo-0,foo-1,foo-2 n=3 combined=&amp;#34;&amp;#34; for i in $(seq 0 $(($n &amp;gt; 0 ? $n-1: 0))); do token=&amp;#34;foo-$i&amp;#34; combined=&amp;#34;${combined}${combined:+,}$token&amp;#34; echo $combined done foo-0 foo-0,foo-1 foo-0,foo-1,foo-2 </description>
    </item>
    
    <item>
      <title>Unix: Find files greater than date</title>
      <link>https://markhneedham.com/blog/2016/06/24/unix-find-files-greater-than-date/</link>
      <pubDate>Fri, 24 Jun 2016 16:56:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/24/unix-find-files-greater-than-date/</guid>
      <description>$ ls -alh foo/database-agent-* -rw-r--r-- 1 markneedham wheel 2.5K 23 Jun 14:00 foo/database-agent-mac17f73-1-logs-archive-201606231300176.tar.gz -rw-r--r-- 1 markneedham wheel 8.6K 23 Jun 11:49 foo/database-agent-mac19b6b-1-logs-archive-201606231049507.tar.gz -rw-r--r-- 1 markneedham wheel 8.6K 23 Jun 11:49 foo/database-agent-mac1f427-1-logs-archive-201606231049507.tar.gz -rw-r--r-- 1 markneedham wheel 2.5K 23 Jun 14:00 foo/database-agent-mac29389-1-logs-archive-201606231300176.tar.gz -rw-r--r-- 1 markneedham wheel 11K 23 Jun 13:44 foo/database-agent-mac3533f-1-logs-archive-201606231244152.tar.gz -rw-r--r-- 1 markneedham wheel 4.8K 23 Jun 14:00 foo/database-agent-mac35563-1-logs-archive-201606231300176.tar.gz -rw-r--r-- 1 markneedham wheel 3.8K 23 Jun 13:44 foo/database-agent-mac35f7e-1-logs-archive-201606231244165.tar.gz -rw-r--r-- 1 markneedham wheel 4.</description>
    </item>
    
    <item>
      <title>Unix: Find all text below string in a file</title>
      <link>https://markhneedham.com/blog/2016/06/19/unix-find-all-text-below-string-in-a-file/</link>
      <pubDate>Sun, 19 Jun 2016 08:36:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/19/unix-find-all-text-below-string-in-a-file/</guid>
      <description># text I don&amp;#39;t care about = Heading of the bit I care about # text I care about $ cat /tmp/foo.txt # text I don&amp;#39;t care about = Heading of the bit I care about # text I care about $ cat /tmp/foo.txt | sed &amp;#39;1,/Heading of the bit I care about/d&amp;#39; # text I care about $ cat /tmp/foo.txt | sed -e &amp;#39;1,/Heading of the bit I care about/d&amp;#39; -e &amp;#39;/^\s*$/d&amp;#39; # text I care about </description>
    </item>
    
    <item>
      <title>Unix: Split string using separator</title>
      <link>https://markhneedham.com/blog/2016/06/19/unix-split-string-using-separator/</link>
      <pubDate>Sun, 19 Jun 2016 07:22:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/19/unix-split-string-using-separator/</guid>
      <description>A/B/C $ string=&amp;#34;A/B/C&amp;#34; $ echo ${string} | cut -d&amp;#34;/&amp;#34; -f3 C $ echo ${string} | awk -F&amp;#34;/&amp;#34; &amp;#39;{ print $3}&amp;#39; C $ IFS=&amp;#34;/&amp;#34; read -ra ADDR &amp;lt;&amp;lt;&amp;lt; &amp;#34;${string}&amp;#34;; echo ${ADDR[2]} C $ IFS=&amp;#34;/&amp;#34; read -ra ADDR &amp;lt;&amp;lt;&amp;lt; &amp;#34;${string}&amp;#34;; echo ${ADDR[-1]} C $ echo ${string##*/} C </description>
    </item>
    
    <item>
      <title>Unix parallel: Populating all the USB sticks</title>
      <link>https://markhneedham.com/blog/2016/06/01/unix-parallel-populating-all-the-usb-sticks/</link>
      <pubDate>Wed, 01 Jun 2016 05:53:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/01/unix-parallel-populating-all-the-usb-sticks/</guid>
      <description>for i in 1 2 3 4 5 6 7; do diskutil renameVolume &amp;#34;USB DISK&amp;#34; NEO4J${i}; done function duplicate() { i=${1} echo ${i} time rsync -avP --size-only --delete --exclude &amp;#39;.*&amp;#39; --omit-dir-times /Users/markneedham/Downloads/graph-connect-europe-2016/ /Volumes/NEO4J${i}/ } seq 1 7 | parallel duplicate </description>
    </item>
    
    <item>
      <title>Unix: Stripping first n bytes in a file / Byte Order Mark (BOM)</title>
      <link>https://markhneedham.com/blog/2015/08/19/unix-stripping-first-n-bytes-in-a-file-byte-order-mark-bom/</link>
      <pubDate>Wed, 19 Aug 2015 23:27:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/19/unix-stripping-first-n-bytes-in-a-file-byte-order-mark-bom/</guid>
      <description>$ time tail -c +4 Casualty7904.csv &amp;gt; Casualty7904_stripped.csv real	0m31.945s user	0m31.370s sys	0m0.518s -c number The location is number bytes. </description>
    </item>
    
    <item>
      <title>Unix: Redirecting stderr to stdout</title>
      <link>https://markhneedham.com/blog/2015/08/15/unix-redirecting-stderr-to-stdout/</link>
      <pubDate>Sat, 15 Aug 2015 15:55:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/15/unix-redirecting-stderr-to-stdout/</guid>
      <description>#!/bin/sh ./neo4j-community-2.2.3/bin/neo4j start $ ./foo.sh &amp;gt; /tmp/output.txt Unable to find any JVMs matching version &amp;#34;1.7&amp;#34;. $ cat /tmp/output.txt Starting Neo4j Server...WARNING: not changing user process [48230]... waiting for server to be ready.... OK. http://localhost:7474/ is ready. #!/bin/sh ./neo4j-community-2.2.3/bin/neo4j start 2&amp;gt;&amp;amp;1 $ ./foo.sh &amp;gt; /tmp/output.txt $ cat /tmp/output.txt Unable to find any JVMs matching version &amp;#34;1.7&amp;#34;. Starting Neo4j Server...WARNING: not changing user process [47989]... waiting for server to be ready.... OK. http://localhost:7474/ is ready.</description>
    </item>
    
    <item>
      <title>Sed: Using environment variables</title>
      <link>https://markhneedham.com/blog/2015/08/13/sed-using-environment-variables/</link>
      <pubDate>Thu, 13 Aug 2015 19:30:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/13/sed-using-environment-variables/</guid>
      <description>LOAD CSV WITH HEADERS FROM &amp;#34;https://raw.githubusercontent.com/mneedham/neo4j-bbc/master/data/matches.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;file:///Users/markneedham/repos/neo4j-bbc/data/matches.csv&amp;#34; AS row $ echo $PWD /Users/markneedham/repos/neo4j-bbc $ sed &amp;#39;s_https://raw.githubusercontent.com/mneedham/neo4j-bbc/master__&amp;#39; import.cql $ sed &amp;#39;s_https://raw.githubusercontent.com/mneedham/neo4j-bbc/master__&amp;#39; import.cql | grep LOAD LOAD CSV WITH HEADERS FROM &amp;#34;/data/matches.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/players.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/players.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/fouls.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/attempts.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/attempts.</description>
    </item>
    
    <item>
      <title>Neo4j: Using LOAD CSV to help explore CSV files</title>
      <link>https://markhneedham.com/blog/2015/06/11/neo4j-using-load-csv-to-help-explore-csv-files/</link>
      <pubDate>Thu, 11 Jun 2015 23:15:06 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/11/neo4j-using-load-csv-to-help-explore-csv-files/</guid>
      <description>$ head -n 5 data/import/references.csv ReferencedEpisodeId,ReferencingEpisodeId,ReferenceText 168,184,&amp;#34;Marshall will eventually hear back from the New York State Judicatory Committee in Something New, which will become a main plot point of Season 9.&amp;#34; 168,169,Barney proclaiming to be done with Robin will be the focal point of Lobster Crawl. 58,57,&amp;#34;Barney finally confronts his saboteur (Abby, whom he slept with in Ten Sessions) in Everything Must Go.&amp;#34; 58,63,&amp;#34;Barney finally confronts his saboteur (Abby, whom he slept with in Ten Sessions) in Everything Must Go.</description>
    </item>
    
    <item>
      <title>Mac OS X: GNU sed -  Hex string replacement / replacing new line characters</title>
      <link>https://markhneedham.com/blog/2015/06/11/mac-os-x-gnu-sed-hex-string-replacement-replacing-new-line-characters/</link>
      <pubDate>Thu, 11 Jun 2015 21:38:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/11/mac-os-x-gnu-sed-hex-string-replacement-replacing-new-line-characters/</guid>
      <description>brew install coreutils brew install gnu-sed --with-default-names $ echo -e &amp;#34;Hello\x0AMark\x0A\x0D&amp;#34; Hello Mark $ echo -e &amp;#34;Hello\x0AMark\x0A\x0D&amp;#34; | \  sed &amp;#39;N;/\x0A[^\x0D]/s/\n/ /&amp;#39; Hello Mark $ echo -e &amp;#34;Hello\x0AMark\x0A\x0DHello\x0AMichael\x0A\x0D&amp;#34; Hello Mark Hello Michael $ echo -e &amp;#34;Hello\x0AMark\x0A\x0DHello\x0AMichael\x0A\x0D&amp;#34; | \  sed &amp;#39;N;/\x0A[^\x0D]/s/\n/ /&amp;#39; Hello Mark Hello Michael </description>
    </item>
    
    <item>
      <title>Unix: Converting a file of values into a comma separated list</title>
      <link>https://markhneedham.com/blog/2015/06/08/unix-converting-a-file-of-values-into-a-comma-separated-list/</link>
      <pubDate>Mon, 08 Jun 2015 22:23:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/08/unix-converting-a-file-of-values-into-a-comma-separated-list/</guid>
      <description>$ cat foo2.txt | head -n 5 1.0 1.0 1.0 1.0 1.0 &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34; $ sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt | head -n 5 &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; $ sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt | tr &amp;#39;\n&amp;#39; &amp;#39;,&amp;#39; &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;, $ paste -s -d &amp;#39;,&amp;#39; &amp;lt;(sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt) &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34; $ paste -s -d &amp;#39;,&amp;#39; &amp;lt;(sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt) | pbcopy </description>
    </item>
    
    <item>
      <title>cURL: POST/Upload multi part form</title>
      <link>https://markhneedham.com/blog/2013/09/23/curl-postupload-multi-part-form/</link>
      <pubDate>Mon, 23 Sep 2013 22:16:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/09/23/curl-postupload-multi-part-form/</guid>
      <description>&amp;lt;form action=&amp;#34;http://foobar.com&amp;#34; method=&amp;#34;POST&amp;#34; enctype=&amp;#34;multipart/form-data&amp;#34;&amp;gt; &amp;lt;p&amp;gt; &amp;lt;label for=&amp;#34;nodes&amp;#34;&amp;gt;File 1:&amp;lt;/label&amp;gt; &amp;lt;input type=&amp;#34;file&amp;#34; name=&amp;#34;file1&amp;#34; id=&amp;#34;file1&amp;#34;&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;p&amp;gt; &amp;lt;label for=&amp;#34;relationships&amp;#34;&amp;gt;File 2:&amp;lt;/label&amp;gt; &amp;lt;input type=&amp;#34;file&amp;#34; name=&amp;#34;file2&amp;#34; id=&amp;#34;file2&amp;#34;&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;input type=&amp;#34;submit&amp;#34; name=&amp;#34;submit&amp;#34; value=&amp;#34;Submit&amp;#34;&amp;gt; &amp;lt;/form&amp;gt; curl &amp;#39;http://foobar.com&amp;#39; -H &amp;#39;Origin: null&amp;#39; -H &amp;#39;Accept-Encoding: gzip,deflate,sdch&amp;#39; -H &amp;#39;Host: foobar.com:7474&amp;#39; -H &amp;#39;Accept-Language: en-US,en;q=0.8&amp;#39; -H &amp;#39;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.95 Safari/537.36&amp;#39; -H &amp;#39;Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryMxYFIg6GFEIPAe6V&amp;#39; -H &amp;#39;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&amp;#39; -H &amp;#39;Cache-Control: max-age=0&amp;#39; -H &amp;#39;Cookie: splashShown1.6=1; undefined=0; _mkto_trk=id:773-GON-065&amp;amp;token:_mch-localhost-1373821432078-37666; JSESSIONID=123cbkxby1rtcj3dwipqzs7yu&amp;#39; -H &amp;#39;Connection: keep-alive&amp;#39; --data-binary $&amp;#39;------WebKitFormBoundaryMxYFIg6GFEIPAe6V\r\nContent-Disposition: form-data; name=&amp;#34;file1&amp;#34;; filename=&amp;#34;file1.</description>
    </item>
    
    <item>
      <title>Unix: tar - Extracting, creating and viewing archives</title>
      <link>https://markhneedham.com/blog/2013/08/22/unix-tar-extracting-creating-and-viewing-archives/</link>
      <pubDate>Thu, 22 Aug 2013 22:56:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/22/unix-tar-extracting-creating-and-viewing-archives/</guid>
      <description>$ wget http://dist.neo4j.org/neo4j-community-1.9.2-unix.tar.gz $ tar -xvf neo4j-community-1.9.2-unix.tar.gz $ wget http://dist.neo4j.org/neo4j-community-1.9.2-unix.tar.gz -o - | tar -xv $ tar -cvzpf neo4j-football.tar.gz neo4j-football/ $ ls -alh neo4j-football.tar.gz -rw-r--r-- 1 markhneedham staff 526M 22 Aug 23:38 neo4j-football.tar.gz $ tar --exclude &amp;#34;data*&amp;#34; --exclude &amp;#34;neo4j-community*&amp;#34; --exclude &amp;#34;.git&amp;#34; -cvzpf neo4j-football.tar.gz neo4j-football/ $ ls -alh neo4j-football.tar.gz -rw-r--r-- 1 markhneedham staff 138M 22 Aug 23:36 neo4j-football.tar.gz $ tar -tvf neo4j-football.tar.gz </description>
    </item>
    
    <item>
      <title>Unix/awk: Extracting substring using a regular expression with capture groups</title>
      <link>https://markhneedham.com/blog/2013/06/26/unixawk-extracting-substring-using-a-regular-expression-with-capture-groups/</link>
      <pubDate>Wed, 26 Jun 2013 15:23:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/26/unixawk-extracting-substring-using-a-regular-expression-with-capture-groups/</guid>
      <description>$ echo &amp;#34;mark #1000&amp;#34; | gawk &amp;#39;{ match($0, /#([0-9]+)/, arr); if(arr[1] != &amp;#34;&amp;#34;) print arr[1] }&amp;#39; 1000 $ echo &amp;#34;mark #1000&amp;#34; | awk &amp;#39;match($0, /#[0-9]+/) { print substr( $0, RSTART, RLENGTH )}&amp;#39; #1000 $ head -n 5 log.txt Command[27716, Node[7825340,used=true,rel=14547348,prop=31734662]] Command[27716, Node[7825341,used=true,rel=14547349,prop=31734665]] Command[27716, Node[7825342,used=true,rel=14547350,prop=31734668]] Command[27716, Node[7825343,used=true,rel=14547351,prop=31734671]] $ head -n 5 log.txt | awk &amp;#39;match($0, /Node\[([^,]+)/) { print substr( $0, RSTART, RLENGTH )}&amp;#39; Node[7825340 Node[7825341 Node[7825342 Node[7825343 Node[7825336 $ head -n 5 log.</description>
    </item>
    
    <item>
      <title>Unix: find, xargs, zipinfo and the &#39;caution: filename not matched:&#39; error</title>
      <link>https://markhneedham.com/blog/2013/06/09/unix-find-xargs-zipinfo-and-the-caution-filename-not-matched-error/</link>
      <pubDate>Sun, 09 Jun 2013 23:10:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/06/09/unix-find-xargs-zipinfo-and-the-caution-filename-not-matched-error/</guid>
      <description>$ bundle show neo4j-enterprise /Users/markhneedham/.rbenv/versions/jruby-1.7.1/lib/ruby/gems/shared/gems/neo4j-enterprise-1.8.2-java $ cd /Users/markhneedham/.rbenv/versions/jruby-1.7.1/lib/ruby/gems/shared/gems/neo4j-enterprise-1.8.2-java/lib/neo4j-enterprise/jars/ $ find . -iname &amp;#34;*.jar&amp;#34; | xargs zipinfo caution: filename not matched: ./lib/neo4j-enterprise/jars/logback-classic-0.9.30.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/logback-core-0.9.30.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-backup-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-com-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-consistency-check-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-ha-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/neo4j-udc-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/org.apache.servicemix.bundles.netty-3.2.5.Final_1.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/server-api-1.8.2.jar caution: filename not matched: ./lib/neo4j-enterprise/jars/slf4j-api-1.6.2.jar caution: filename not matched: .</description>
    </item>
    
    <item>
      <title>Unix: Working with parts of large files</title>
      <link>https://markhneedham.com/blog/2013/05/19/unix-working-with-parts-of-large-files/</link>
      <pubDate>Sun, 19 May 2013 21:44:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/19/unix-working-with-parts-of-large-files/</guid>
      <description>$ sed -n &amp;#39;10,15p&amp;#39; data/log/neo4j.0.0.log INFO: Enabling HTTPS on port [7473] May 19, 2013 11:11:52 AM org.neo4j.server.logging.Logger log INFO: No SSL certificate found, generating a self-signed certificate.. May 19, 2013 11:11:53 AM org.neo4j.server.logging.Logger log INFO: Mounted discovery module at [/] May 19, 2013 11:11:53 AM org.neo4j.server.logging.Logger log </description>
    </item>
    
    <item>
      <title>Unix: Checking for open sockets on nginx</title>
      <link>https://markhneedham.com/blog/2013/04/23/unix-checking-for-open-sockets-on-nginx/</link>
      <pubDate>Tue, 23 Apr 2013 23:59:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/23/unix-checking-for-open-sockets-on-nginx/</guid>
      <description>$ ulimit -n 1024 $ ps aux | grep nginx | grep -v grep root 1089 0.0 0.7 105152 2736 ? Ss 17:34 0:00 nginx: master process /usr/sbin/nginx www-data 17474 0.0 0.6 105300 2296 ? S 21:49 0:04 nginx: worker process www-data 17475 0.0 0.7 105300 2856 ? S 21:49 0:04 nginx: worker process www-data 17476 0.0 0.7 105300 2792 ? S 21:49 0:03 nginx: worker process www-data 17477 0.0 0.</description>
    </item>
    
    <item>
      <title>awk: Parsing &#39;free -m&#39; output to get memory usage/consumption</title>
      <link>https://markhneedham.com/blog/2013/04/10/awk-parsing-free-m-output-to-get-memory-usageconsumption/</link>
      <pubDate>Wed, 10 Apr 2013 07:03:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/10/awk-parsing-free-m-output-to-get-memory-usageconsumption/</guid>
      <description>$ free -m total used free shared buffers cached Mem: 365 360 5 0 59 97 -/+ buffers/cache: 203 161 Swap: 767 13 754 $ free -m | awk &amp;#39;/Mem:/ { print $2 } /buffers\/cache/ { print $3 }&amp;#39; 365 203 $ free -m | awk &amp;#39;/Mem:/ { print $2 } /buffers\/cache/ { print $3 }&amp;#39; | awk &amp;#39;BEGIN { RS = &amp;#34;&amp;#34; ; FS = &amp;#34;\n&amp;#34; } { print $2 / $1 }&amp;#39; 0.</description>
    </item>
    
    <item>
      <title>Sed: Replacing characters with a new line</title>
      <link>https://markhneedham.com/blog/2012/12/29/sed-replacing-characters-with-a-new-line/</link>
      <pubDate>Sat, 29 Dec 2012 17:49:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/12/29/sed-replacing-characters-with-a-new-line/</guid>
      <description>[(1,2), (3,4)…] sed -E -e &amp;#39;s/, \(/\\n(/g&amp;#39; ruby_union.txt sed -E -e &amp;#34;s/,\(/\ /g&amp;#34; ruby_union.txt $ echo &amp;#34;mark\r\nneedham&amp;#34; mark\r\nneedham $ echo -e &amp;#34;mark\r\nneedham&amp;#34; mark needham sed -E -e &amp;#34;s/, \(/\\`echo -e &amp;#39;\n\r&amp;#39;`/g&amp;#34; ruby_union.txt $ echo &amp;#34;[(1,2), (3,4), (5,6)]&amp;#34; | sed -E -e &amp;#34;s/, \(/\\`echo -e &amp;#39;\n\r&amp;#39;`/g&amp;#34; -e &amp;#39;s/\[|]|\)|\(//g&amp;#39; 1,2 3,4 5,6 </description>
    </item>
    
    <item>
      <title>Unix: Counting the number of commas on a line</title>
      <link>https://markhneedham.com/blog/2012/11/10/unix-counting-the-number-of-commas-on-a-line/</link>
      <pubDate>Sat, 10 Nov 2012 16:30:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/11/10/unix-counting-the-number-of-commas-on-a-line/</guid>
      <description>A few weeks ago I was playing around with some data stored in a CSV file and wanted to do a simple check on the quality of the data by making sure that each line had the same number of fields.
One way this can be done is with awk:
awk -F &amp;#34;,&amp;#34; &amp;#39; { print NF-1 } &amp;#39; file.csv Here we&amp;rsquo;re specifying the file separator -Fas &amp;lsquo;,&amp;rsquo; and then using the NF(number of fields) variable to print how many commas there are on the line.</description>
    </item>
    
    <item>
      <title>Upstart: Job getting stuck in the start/killed state</title>
      <link>https://markhneedham.com/blog/2012/09/29/upstart-job-getting-stuck-in-the-startkilled-state/</link>
      <pubDate>Sat, 29 Sep 2012 09:56:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/29/upstart-job-getting-stuck-in-the-startkilled-state/</guid>
      <description>We&amp;rsquo;re using upstartto handle the processes running on our machines and since the haproxypackage only came package with an init.d script we wanted to make it upstartified.
When defining an upstart script you need to specify an expectstanza in which you specify whether or not the process which you&amp;rsquo;re launching is going to fork.
However, most Unix services will &amp;ldquo;daemonize&amp;rdquo;, meaning that they will create a new process (using fork(2)) which is a child of the initial process.</description>
    </item>
    
    <item>
      <title>Finding ways to use bash command line history shortcuts</title>
      <link>https://markhneedham.com/blog/2012/09/19/finding-ways-to-use-bash-command-line-history-shortcuts/</link>
      <pubDate>Wed, 19 Sep 2012 07:00:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/19/finding-ways-to-use-bash-command-line-history-shortcuts/</guid>
      <description>A couple of months ago I wrote about a bunch of command line history shortcutsthat Philhad taught me and after recently coming across Peteris Krumins&amp;rsquo; bash history cheat sheetI thought it&amp;rsquo;d be interesting to find some real ways to use them.
A few weeks ago I wrote about a UTF-8 byte order mark (BOM) that I wanted to remove from a fileI was working on and I realised this evening that there were some other files with the same problem.</description>
    </item>
    
    <item>
      <title>zsh: Don&#39;t verify substituted history expansion a.k.a.  disabling histverify</title>
      <link>https://markhneedham.com/blog/2012/09/16/zsh-dont-verify-substituted-history-expansion-a-k-a-disabling-histverify/</link>
      <pubDate>Sun, 16 Sep 2012 13:35:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/16/zsh-dont-verify-substituted-history-expansion-a-k-a-disabling-histverify/</guid>
      <description>I use zshon my Mac terminal and in general I prefer it to bash but it has an annoying default setting whereby when you try to repeat a command via substituted history expansion it asks you to verify that.
For example let&amp;rsquo;s say by mistake I try to vi into a directory rather than cd&amp;rsquo;ing into it:
vi ~/.oh-my-zsh If I try to cd into the directory by using &amp;lsquo;!$&amp;rsquo; to grab the last argument from the previous command it will make me confirm that I want to do this:</description>
    </item>
    
    <item>
      <title>cURL and the case of the carriage return</title>
      <link>https://markhneedham.com/blog/2012/09/15/curl-and-the-case-of-the-carriage-return/</link>
      <pubDate>Sat, 15 Sep 2012 09:06:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/15/curl-and-the-case-of-the-carriage-return/</guid>
      <description>We were doing some work this week where we needed to make a couple of calls to an API via a shell script and in the first call we wanted to capture one of the lines of the HTTP response headers and use that as in input to the second call.
The way we were doing this was something like the following:
#!/bin/bash # We were actually grabbing a different header but for the sake # of this post we&amp;#39;ll say it was &amp;#39;Set-Cookie&amp;#39; AUTH_HEADER=`curl -I http://www.</description>
    </item>
    
    <item>
      <title>Bash: Piping data into a command using heredocs</title>
      <link>https://markhneedham.com/blog/2012/09/15/bash-piping-data-into-a-command-using-heredocs/</link>
      <pubDate>Sat, 15 Sep 2012 07:54:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/15/bash-piping-data-into-a-command-using-heredocs/</guid>
      <description>I&amp;rsquo;ve been playing around with some data modelled in neo4j recently and one thing I wanted to do is run an adhoc query in the neo4j-shelland grab the results and do some text manipulation on them.
For example I wrote a query which outputted the following to the screen and I wanted to sum together all the values in the 3rd column:
| [&amp;#34;1&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;3&amp;#34;] | &amp;#34;3&amp;#34; | 1234567 | | [&amp;#34;4&amp;#34;,&amp;#34;5&amp;#34;,&amp;#34;6&amp;#34;] | &amp;#34;6&amp;#34; | 8910112 | Initially I was pasting the output into a text file and then running the following sequence of commands to work it out:</description>
    </item>
    
    <item>
      <title>Unix: Caught out by shell significant characters</title>
      <link>https://markhneedham.com/blog/2012/09/13/unix-caught-out-by-shell-significant-characters/</link>
      <pubDate>Thu, 13 Sep 2012 00:17:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/13/unix-caught-out-by-shell-significant-characters/</guid>
      <description>One of the applications that Philand I were deploying today needed a MySQL server and part of our puppet code to provision that node type runs a command to setup the privileges for a database user.
The unevaluated puppet code reads like this:
/usr/bin/mysql -h ${host} -uroot ${rootpassarg} -e &amp;#34;grant all on ${name}.* to ${user}@&amp;#39;${remote_host}&amp;#39; identified by &amp;#39;$password&amp;#39;; flush privileges;&amp;#34; In the application we were deploying that expanded into something like this:</description>
    </item>
    
    <item>
      <title>While waiting for VMs to provision...</title>
      <link>https://markhneedham.com/blog/2012/09/12/while-waiting-for-vms-to-provision/</link>
      <pubDate>Wed, 12 Sep 2012 22:53:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/09/12/while-waiting-for-vms-to-provision/</guid>
      <description>Philand I spent part of the day provisioning new virtual machines for some applications that we need to deploy which involves running a provisioning script and then opening another terminal and repeatedly trying to ssh into the box until it succeeds.
Eventually we got bored of doing that so we figured out a nice little one liner to use instead:
while :; do ssh 10.0.0.2; done The &amp;lsquo;:&amp;rsquo; is a bash noopand is defined like so:</description>
    </item>
    
    <item>
      <title>SSHing onto machines via a jumpbox</title>
      <link>https://markhneedham.com/blog/2012/08/10/sshing-onto-machines-via-a-jumpbox/</link>
      <pubDate>Fri, 10 Aug 2012 00:58:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/10/sshing-onto-machines-via-a-jumpbox/</guid>
      <description>We wanted to be able to ssh into some machines which were behind a firewall so we set up a jumpboxwhich our firewall directed any traffic on port 22 towards.
Initially if we wanted to SSH onto a machine inside the network we&amp;rsquo;d have to do a two step process:
$ ssh jumpbox # now on the jumpbx $ ssh internal-network-machine That got a bit annoying after a while so Samshowed us a neat way of proxying the second ssh command through the first one by making use of netcat.</description>
    </item>
    
    <item>
      <title>VCloud Guest Customization Script : [: postcustomization: unexpected operator</title>
      <link>https://markhneedham.com/blog/2012/08/06/vcloud-guest-customization-script-postcustomization-unexpected-operator/</link>
      <pubDate>Mon, 06 Aug 2012 21:50:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/08/06/vcloud-guest-customization-script-postcustomization-unexpected-operator/</guid>
      <description>We have been doing some work to automatically provision machines using the VCloud API via fog and one of the things we wanted to do was run a custom script the first time that a node powers on.
The following explains how customization scripts work:
We wanted the script to run only when passed the &amp;lsquo;postcustomization&amp;rsquo; flag because our script relied on some networking configuration which hadn&amp;rsquo;t yet been done in the &amp;lsquo;precustomization&amp;rsquo; state.</description>
    </item>
    
    <item>
      <title>Unix: tee</title>
      <link>https://markhneedham.com/blog/2012/07/29/unix-tee/</link>
      <pubDate>Sun, 29 Jul 2012 19:11:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/29/unix-tee/</guid>
      <description>I&amp;rsquo;ve read about the Unix &amp;lsquo;tee&amp;rsquo; command before but never found a reason to use it until the last few weeks.
One of the things I repeatedly do by mistake is open /etc/hostswithout sudo and then try to make changes to it:
$ vi /etc/hosts # Editing it leads to the dreaded &amp;#39;W10: Changing a readonly file&amp;#39; I always used to close the file and then re-open it with sudo but I recently came across an approach which allows us to use &amp;lsquo;tee&amp;rsquo; to get around the problem.</description>
    </item>
    
    <item>
      <title>Bash Shell: Reusing parts of previous commands</title>
      <link>https://markhneedham.com/blog/2012/07/05/bash-shell-reusing-parts-of-previous-commands/</link>
      <pubDate>Thu, 05 Jul 2012 23:42:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2012/07/05/bash-shell-reusing-parts-of-previous-commands/</guid>
      <description>I&amp;rsquo;ve paired a few times with my colleague Phil Potterover the last couple of weeks and since he&amp;rsquo;s a bit of a ninja with bash shortcuts/commands I wanted to record some of the things he&amp;rsquo;s shown me so I won&amp;rsquo;t forget them!
Let&amp;rsquo;s say we&amp;rsquo;re in the &amp;lsquo;/tmp&amp;rsquo; directory and want to create a folder a few levels down but forget to pass the &amp;lsquo;-p&amp;rsquo; option to &amp;lsquo;mkdir&amp;rsquo;:
$ mkdir blah/de/blah mkdir: cannot create directory `blah/de/blah&amp;#39;: No such file or directory One way of fixing that would be to press the up arrow and navigate along the previous command and put in the &amp;lsquo;-p&amp;rsquo; flag but it&amp;rsquo;s a bit fiddly so instead we can do the following:</description>
    </item>
    
    <item>
      <title>Learning Unix find: Searching in/Excluding certain folders</title>
      <link>https://markhneedham.com/blog/2011/10/21/learning-unix-find-searching-inexcluding-certain-folders/</link>
      <pubDate>Fri, 21 Oct 2011 21:25:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/21/learning-unix-find-searching-inexcluding-certain-folders/</guid>
      <description>I love playing around with commands on the Unix shell but one of the ones that I&amp;rsquo;ve found the most difficult to learn beyond the very basics is find.
I think this is partially because I find the find man page quite difficult to read and partially because it&amp;rsquo;s usually quicker to work out how to solve my problem with a command I already know than to learn another one.</description>
    </item>
    
    <item>
      <title>Bash: Reusing previous commands</title>
      <link>https://markhneedham.com/blog/2011/10/13/bash-reusing-previous-commands/</link>
      <pubDate>Thu, 13 Oct 2011 19:46:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/13/bash-reusing-previous-commands/</guid>
      <description>A lot of the time when I&amp;rsquo;m using the bash shell I want to re-use commands that I&amp;rsquo;ve previously entered and I&amp;rsquo;ve recently learnt some neat ways to do this from my colleagues Tomand Kief.
If we want to list the history of all the commands we&amp;rsquo;ve entered in a shell session then the following command does the trick:
&amp;gt; history ... 761 sudo port search pdfinfo 762 to_ipad andersen-phd-thesis.pdf 763 vi ~/.</description>
    </item>
    
    <item>
      <title>Unix: Getting the page count of a linearized PDF</title>
      <link>https://markhneedham.com/blog/2011/10/09/unix-getting-the-page-count-of-a-linearized-pdf/</link>
      <pubDate>Sun, 09 Oct 2011 11:34:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/10/09/unix-getting-the-page-count-of-a-linearized-pdf/</guid>
      <description>We were doing some work last week to rasterize a PDF document into a sequence of images and wanted to get a rough idea of how many pages we&amp;rsquo;d be dealing with if we created an image per page.
The PDFs we&amp;rsquo;re dealing with are linearizedsince they&amp;rsquo;re available for viewing on the web:
The ﬁle is valid PDF in all respects, and is compatible with all existing viewers and other PDF applications.</description>
    </item>
    
    <item>
      <title>Unix: Summing the total time from a log file</title>
      <link>https://markhneedham.com/blog/2011/07/27/unix-summing-the-total-time-from-a-log-file/</link>
      <pubDate>Wed, 27 Jul 2011 23:02:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/07/27/unix-summing-the-total-time-from-a-log-file/</guid>
      <description>As I mentioned in my last postwe&amp;rsquo;ve been doing some profiling of a data ingestion job and as a result have been putting some logging into our code to try and work out where we need to work on.
We end up with a log file peppered with different statements which looks a bit like the following:
18:50:08.086 [akka:event-driven:dispatcher:global-5] DEBUG - Imported document. /Users/mneedham/foo.xml in: 1298 18:50:09.064 [akka:event-driven:dispatcher:global-1] DEBUG - Imported document.</description>
    </item>
    
    <item>
      <title>mount_smbfs: mount error..File exists</title>
      <link>https://markhneedham.com/blog/2011/01/15/mount_smbfs-mount-error-file-exists/</link>
      <pubDate>Sat, 15 Jan 2011 18:31:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/15/mount_smbfs-mount-error-file-exists/</guid>
      <description>I&amp;rsquo;ve been playing around with mounting a Windows file share onto my machine via the terminal because I&amp;rsquo;m getting bored of constantly having to go to Finder and manually mounting it each time!
After a couple of times of mounting and unmounting the drive I ended up with this error:
&amp;gt; mount_smbfs //mneedham@punedc02/shared punedc02_shared/ mount_smbfs: mount error: /Volumes/punedc02_shared: File exists I originally thought the &amp;lsquo;file exists&amp;rsquo; part of the message was suggesting that I&amp;rsquo;d already mounted a share on &amp;lsquo;punedc02_shared&amp;rsquo; but calling the &amp;lsquo;umount&amp;rsquo; command led to the following error:</description>
    </item>
    
    <item>
      <title>Sed: &#39;sed: 1: invalid command code R&#39; on Mac OS X</title>
      <link>https://markhneedham.com/blog/2011/01/14/sed-sed-1-invalid-command-code-r-on-mac-os-x/</link>
      <pubDate>Fri, 14 Jan 2011 14:15:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/14/sed-sed-1-invalid-command-code-r-on-mac-os-x/</guid>
      <description>A few days ago I wrote about how we&amp;rsquo;d been using Sed to edit multiple filesand while those examples were derived from what we&amp;rsquo;d been using on Ubuntu I realised that they didn&amp;rsquo;t actually work on Mac OS X.
For example, the following command:
sed -i &amp;#39;s/require/include/&amp;#39; Rakefile Throws this error:
sed: 1: &amp;#34;Rakefile&amp;#34;: invalid command code R What I hadn&amp;rsquo;t realised is that on the Mac version of sed the &amp;lsquo;-i&amp;rsquo; flag has a mandatory suffix, as described in this post.</description>
    </item>
    
    <item>
      <title>Sed across multiple files</title>
      <link>https://markhneedham.com/blog/2011/01/11/sed-across-multiple-files/</link>
      <pubDate>Tue, 11 Jan 2011 16:43:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2011/01/11/sed-across-multiple-files/</guid>
      <description>Pankhuriand I needed to rename a method and change all the places where it was used and decided to see if we could work out how to do it using sed.
We needed to change a method call roughly like this:
home_link(current_user) To instead read:
homepage_path For which we need the following sed expression:
sed -i &amp;#39;s/home_link([^)]*)/homepage_path/&amp;#39; [file_name] Which works pretty well if you know which file you want to change but we wanted to run it over the whole code base.</description>
    </item>
    
    <item>
      <title>A dirty hack to get around aliases not working in a shell script</title>
      <link>https://markhneedham.com/blog/2010/11/24/a-dirty-hack-to-get-around-aliases-not-working-in-a-shell-script/</link>
      <pubDate>Wed, 24 Nov 2010 18:48:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2010/11/24/a-dirty-hack-to-get-around-aliases-not-working-in-a-shell-script/</guid>
      <description>In another script I&amp;rsquo;ve been working on lately I wanted to call &amp;lsquo;mysql&amp;rsquo; but unfortunately on my machine it&amp;rsquo;s &amp;lsquo;mysql5&amp;rsquo; rather than &amp;lsquo;mysql&amp;rsquo;.
I have an alias defined in &amp;lsquo;~/.bash_profile&amp;rsquo; so I can call &amp;lsquo;mysql&amp;rsquo; from the terminal whenever I want to.
alias mysql=mysql5 Unfortunately shell scripts don&amp;rsquo;t seem to have access to this alias and the only suggestionI&amp;rsquo;ve come across while googling this is to source &amp;lsquo;~/.bash_profile&amp;rsquo; inside the script.</description>
    </item>
    
    <item>
      <title>Browsing around the Unix shell more easily</title>
      <link>https://markhneedham.com/blog/2008/10/15/browsing-around-the-unix-shell-more-easily/</link>
      <pubDate>Wed, 15 Oct 2008 22:31:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/10/15/browsing-around-the-unix-shell-more-easily/</guid>
      <description>Following on from my post about getting the pwd to display on the bash prompt all the timeI have learnt a couple of other tricks to make the shell experience more productive.
Aliasesare the first new concept I came across and several members of my current team and I now have these setup.
We are primarily using them to provide a shortcut command to get to various locations in the file system.</description>
    </item>
    
    <item>
      <title>Show pwd all the time</title>
      <link>https://markhneedham.com/blog/2008/09/28/show-pwd-all-the-time/</link>
      <pubDate>Sun, 28 Sep 2008 22:50:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2008/09/28/show-pwd-all-the-time/</guid>
      <description>Finally back in the world of the shell last week I was constantly typing &amp;lsquo;pwd&amp;rsquo; to work out where exactly I was in the file system until my colleague pointed out that you can adjust your settings to get this to show up automatically for you on the left hand side of the prompt.
To do this you need to create or edit your .bash_profile file by entering the following command:</description>
    </item>
    
  </channel>
</rss>