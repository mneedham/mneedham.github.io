<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Mark Needham</title>
    <link>https://markhneedham.com/blog/category/python/</link>
    <description>Recent content in Python on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Aug 2020 00:21:00 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/category/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>pipenv: ImportError: No module named &#39;virtualenv.seed.via_app_data&#39;</title>
      <link>https://markhneedham.com/blog/2020/08/07/pipenv-import-file-no-module-named-virtualenv/</link>
      <pubDate>Fri, 07 Aug 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/08/07/pipenv-import-file-no-module-named-virtualenv/</guid>
      <description>I&amp;#8217;ve been trying to install pipenv on a new computer and ran into a frustrating issue. After installing pipenv using pip, I tried to run the command below:
 $ /home/markhneedham/.local/bin/pipenv shell Creating a virtualenv for this project… Pipfile: /tmp/Pipfile Using /usr/bin/python3.8 (3.8.2) to create virtualenv… ⠙ Creating virtual environment...ModuleNotFoundError: No module named &#39;virtualenv.seed.via_app_data&#39; ✘ Failed creating virtual environment [pipenv.exceptions.VirtualenvCreationException]: Failed to create virtual environment.   Hmmm, for some reason it&amp;#8217;s unable to find one of the virtualenv modules.</description>
    </item>
    
    <item>
      <title>Python: Select keys from map/dictionary</title>
      <link>https://markhneedham.com/blog/2020/04/27/python-select-keys-from-map-dictionary/</link>
      <pubDate>Mon, 27 Apr 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/04/27/python-select-keys-from-map-dictionary/</guid>
      <description>In this post we&amp;#8217;re going to learn how to filter a Python map/dictionary to return a subset of keys or values. I needed to do this recently while logging some maps that had a lot of keys that I wasn&amp;#8217;t interested in.
 We&amp;#8217;ll start with the following map:
 x = {&#34;a&#34;: 1, &#34;b&#34;: 2, &#34;c&#34;: 3, &#34;d&#34;: 4} {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4}   We want to filter this map so that we only have the keys a and c.</description>
    </item>
    
    <item>
      <title>Python: Find the starting Sunday for all the weeks in a month</title>
      <link>https://markhneedham.com/blog/2020/04/18/python-starting-sundays-in-a-month/</link>
      <pubDate>Sat, 18 Apr 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/04/18/python-starting-sundays-in-a-month/</guid>
      <description>In this post we&amp;#8217;re going to learn how to find the dates of all the Sundays in a given month, as well as the Sunday immediately preceding the 1st day in the month, assuming that day isn&amp;#8217;t a Sunday.
 Let&amp;#8217;s start by importing some libraries that we&amp;#8217;re going to use in this blog post:
 from dateutil import parser import datetime import calendar   Next we need to find the first day of the current month, which we can do with the following code:</description>
    </item>
    
    <item>
      <title>Python: Altair - Setting the range of Date values for an axis</title>
      <link>https://markhneedham.com/blog/2020/01/14/altair-range-values-dates-axis/</link>
      <pubDate>Tue, 14 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/14/altair-range-values-dates-axis/</guid>
      <description>In my continued experiments with the Altair visualisation library, I wanted to set a custom range of data values on the x axis of a chart. In this blog post we&amp;#8217;ll learn how to do that.
 We&amp;#8217;ll start where we left off in the last blog post, with the following code that renders a scatterplot containing the chart position of a song on a certain date:
 import altair as alt import pandas as pd import datetime df = pd.</description>
    </item>
    
    <item>
      <title>Python: Altair - TypeError: Object of type date is not JSON serializable</title>
      <link>https://markhneedham.com/blog/2020/01/10/altair-typeerror-object-type-date-not-json-serializable/</link>
      <pubDate>Fri, 10 Jan 2020 00:21:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2020/01/10/altair-typeerror-object-type-date-not-json-serializable/</guid>
      <description>I&amp;#8217;ve been playing with the Altair statistical visualisation library and recently ran into an error while trying to render a DataFrame that contained dates.
 I was trying to render a scatterplot containing the chart position of a song on a certain date, as seen in the code below:
 # pip install altair pandas import altair as alt import pandas as pd import datetime df = pd.DataFrame( [ {&#34;position&#34;: 2, &#34;</description>
    </item>
    
    <item>
      <title>Python: Click - Handling Date Parameter</title>
      <link>https://markhneedham.com/blog/2019/07/29/python-click-date-parameter-type/</link>
      <pubDate>Mon, 29 Jul 2019 11:08:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/07/29/python-click-date-parameter-type/</guid>
      <description>I&amp;#8217;ve been building a little CLI application using the Python Click Library, and I wanted to pass in a Date as a parameter. There&amp;#8217;s more than one way to do this.
 Let&amp;#8217;s first install the Click library:
 pip install click   And now we&amp;#8217;ll import our required libraries:
 from datetime import date import click   Now we&amp;#8217;ll create a sub command that takes two parameters: date-start and date-end.</description>
    </item>
    
    <item>
      <title>Jupyter: RuntimeError: This event loop is already running</title>
      <link>https://markhneedham.com/blog/2019/05/10/jupyter-runtimeerror-this-event-loop-is-already-running/</link>
      <pubDate>Fri, 10 May 2019 23:00:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/05/10/jupyter-runtimeerror-this-event-loop-is-already-running/</guid>
      <description>I&amp;#8217;ve been using the twint library to explore the Neo4j twitter community, and ran into an initially confusing error when I moved the code I&amp;#8217;d written into a Jupyter notebook.
 The first three cells of my notebook contain the following code:
 Cell 1:
 ! pip install twint   Cell 2:
 import json import twint   Cell 3:
 users = [&#34;vikatakavi11&#34;, &#34;tee_mars3&#34;] for username in users[:10]: c = twint.</description>
    </item>
    
    <item>
      <title>Python: Getting GitHub download count from the GraphQL API using requests</title>
      <link>https://markhneedham.com/blog/2019/04/07/python-github-download-count-graphql-requests/</link>
      <pubDate>Sun, 07 Apr 2019 05:03:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/04/07/python-github-download-count-graphql-requests/</guid>
      <description>I was recently trying to use some code I shared just over a year ago to compute GitHub Project download numbers from the GraphQL API, and wanted to automate this in a Python script.
 It was more fiddly than I expected, so I thought I&amp;#8217;d share the code for the benefit of future me more than anything else!
 Pre requisites We&amp;#8217;re going to use the popular requests library to query the API, so we need to import that.</description>
    </item>
    
    <item>
      <title>Finding famous MPs based on their Wikipedia Page Views</title>
      <link>https://markhneedham.com/blog/2019/04/01/famous-mps-wikipedia-pageviews/</link>
      <pubDate>Mon, 01 Apr 2019 05:03:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/04/01/famous-mps-wikipedia-pageviews/</guid>
      <description>As part of the Graphing Brexit series of blog posts, I wanted to work out who were the most important Members of the UK parliament, and after a bit of Googling I realised that views of their Wikipedia pages would do the trick.
 I initially found my way to tools.wmflabs.org, which is great for exploring the popularity of an individual MP, but not so good if you want to extract the data for 600 of them.</description>
    </item>
    
    <item>
      <title>Python: Add query parameters to a URL</title>
      <link>https://markhneedham.com/blog/2019/01/11/python-add-query-parameters-url/</link>
      <pubDate>Fri, 11 Jan 2019 09:42:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/01/11/python-add-query-parameters-url/</guid>
      <description>I was recently trying to automate adding a query parameter to a bunch of URLS and came across a neat approach a long way down this StackOverflow answer, that uses the PreparedRequest class from the requests library.
 Let&amp;#8217;s first get the class imported:
 from requests.models import PreparedRequest req = PreparedRequest()   And now let&amp;#8217;s use use this class to add a query parameter to a URL. We can do this with the following code:</description>
    </item>
    
    <item>
      <title>Python: Pandas - DataFrame plotting ignoring figure</title>
      <link>https://markhneedham.com/blog/2018/12/25/python-pandas-dataframe-plot-figure/</link>
      <pubDate>Tue, 25 Dec 2018 21:09:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/12/25/python-pandas-dataframe-plot-figure/</guid>
      <description>In my continued use of matplotlib I wanted to change the size of the chart I was plotting and struggled a bit to start with. We&amp;#8217;ll use the same DataFrame as before:
 df = pd.DataFrame({ &#34;name&#34;: [&#34;Mark&#34;, &#34;Arya&#34;, &#34;Praveena&#34;], &#34;age&#34;: [34, 1, 31] }) df   In my last blog post I showed how we can create a bar chart by executing the following code:
 df.plot.bar(x=&#34;name&#34;) plt.tight_layout() plt.</description>
    </item>
    
    <item>
      <title>Pandas: Create matplotlib plot with x-axis label not index</title>
      <link>https://markhneedham.com/blog/2018/12/21/pandas-plot-x-axis-index/</link>
      <pubDate>Fri, 21 Dec 2018 16:57:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/12/21/pandas-plot-x-axis-index/</guid>
      <description>I&amp;#8217;ve been using matplotlib a bit recently, and wanted to share a lesson I learnt about choosing the label of the x-axis. Let&amp;#8217;s first import the libraries we&amp;#8217;ll use in this post:
 import pandas as pd import matplotlib.pyplot as plt   And now we&amp;#8217;ll create a DataFrame of values that we want to chart:
 df = pd.DataFrame({ &#34;name&#34;: [&#34;Mark&#34;, &#34;Arya&#34;, &#34;Praveena&#34;], &#34;age&#34;: [34, 1, 31] }) df   This is what our DataFrame looks like:</description>
    </item>
    
    <item>
      <title>PySpark: Creating DataFrame with one column - TypeError: Can not infer schema for type: &lt;type &#39;int&#39;&gt;</title>
      <link>https://markhneedham.com/blog/2018/12/09/pyspark-creating-dataframe-one-column/</link>
      <pubDate>Sun, 09 Dec 2018 10:25:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/12/09/pyspark-creating-dataframe-one-column/</guid>
      <description>I&amp;#8217;ve been playing with PySpark recently, and wanted to create a DataFrame containing only one column. I tried to do this by writing the following code:
 spark.createDataFrame([(1)], [&#34;count&#34;])   If we run that code we&amp;#8217;ll get the following error message:
 Traceback (most recent call last): File &#34;&amp;lt;stdin&amp;gt;&#34;, line 1, in &amp;lt;module&amp;gt; File &#34;/home/markhneedham/projects/graph-algorithms/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/session.py&#34;, line 748, in createDataFrame rdd, schema = self._createFromLocal(map(prepare, data), schema) File &#34;/home/markhneedham/projects/graph-algorithms/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/session.py&#34;, line 416, in _createFromLocal struct = self.</description>
    </item>
    
    <item>
      <title>Neo4j Graph Algorithms: Calculating the cosine similarity of Game of Thrones episodes</title>
      <link>https://markhneedham.com/blog/2018/09/28/neo4j-graph-algorithms-cosine-game-of-thrones/</link>
      <pubDate>Fri, 28 Sep 2018 07:55:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/09/28/neo4j-graph-algorithms-cosine-game-of-thrones/</guid>
      <description>A couple of years ago I wrote a blog post showing how to calculate cosine similarity on Game of Thrones episodes using scikit-learn, and with the release of Similarity Algorithms in the Neo4j Graph Algorithms library I thought it was a good time to revisit that post.
 The dataset contains characters and episodes, and we want to calculate episode similarity based on the characters that appear in each episode. Before we run any algorithms we need to get the data into Neo4j.</description>
    </item>
    
    <item>
      <title>matplotlib - Create a histogram/bar chart for ratings/full numbers</title>
      <link>https://markhneedham.com/blog/2018/09/24/matplotlib-histogram-bar-chart-ratings-full-values/</link>
      <pubDate>Mon, 24 Sep 2018 07:55:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/09/24/matplotlib-histogram-bar-chart-ratings-full-values/</guid>
      <description>In my continued work with matplotlib I wanted to plot a histogram (or bar chart) for a bunch of star ratings to see how they were distributed.
 Before we do anything let&amp;#8217;s import matplotlib as well as pandas:
 import random import pandas as pd import matplotlib matplotlib.use(&#39;TkAgg&#39;) import matplotlib.pyplot as plt plt.style.use(&#39;fivethirtyeight&#39;)   Next we&amp;#8217;ll create an array of randomly chosen star ratings between 1 and 5:</description>
    </item>
    
    <item>
      <title>matplotlib - MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.</title>
      <link>https://markhneedham.com/blog/2018/09/18/matplotlib-matplotlib-deprecation-adding-axes/</link>
      <pubDate>Tue, 18 Sep 2018 07:56:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/09/18/matplotlib-matplotlib-deprecation-adding-axes/</guid>
      <description>In my last post I showed how to remove axes legends from a matplotlib chart, and while writing the post I actually had the change the code I used as my initial approach is now deprecated.
 As in the previous post, we&amp;#8217;ll first import pandas and matplotlib:
 import pandas as pd import matplotlib matplotlib.use(&#39;TkAgg&#39;) import matplotlib.pyplot as plt plt.style.use(&#39;fivethirtyeight&#39;)   And we&amp;#8217;ll still use this DataFrame:
 df = pd.</description>
    </item>
    
    <item>
      <title>matplotlib - Remove axis legend</title>
      <link>https://markhneedham.com/blog/2018/09/18/matplotlib-remove-axis-legend/</link>
      <pubDate>Tue, 18 Sep 2018 07:55:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/09/18/matplotlib-remove-axis-legend/</guid>
      <description>I&amp;#8217;ve been working with matplotlib a bit recently, and I wanted to remove all axis legends from my chart. It took me a bit longer than I expected to figure it out so I thought I&amp;#8217;d write it up.
 Before we do anything let&amp;#8217;s import matplotlib as well as pandas, since we&amp;#8217;re going to plot data from a pandas DataFrame.
 import pandas as pd import matplotlib matplotlib.use(&#39;TkAgg&#39;) import matplotlib.</description>
    </item>
    
    <item>
      <title>QuickGraph #1: Analysing Python Dependency Graph with PageRank, Closeness Centrality, and Betweenness Centrality</title>
      <link>https://markhneedham.com/blog/2018/07/16/quick-graph-python-dependency-graph/</link>
      <pubDate>Mon, 16 Jul 2018 05:25:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/07/16/quick-graph-python-dependency-graph/</guid>
      <description>I&amp;#8217;ve always wanted to build a dependency graph of libraries in the Python ecosytem but I never quite got around to it&amp;#8230;&amp;#8203;until now! I thought I might be able to get a dump of all the libraries and their dependencies, but while searching I came across this article which does a good job of explaining why that&amp;#8217;s not possible.
 Finding Python Dependencies The best we can do is generate a dependency graph of our locally installed packages using the excellent pipdeptree tool.</description>
    </item>
    
    <item>
      <title>Python: Parallel download files using requests</title>
      <link>https://markhneedham.com/blog/2018/07/15/python-parallel-download-files-requests/</link>
      <pubDate>Sun, 15 Jul 2018 15:10:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/07/15/python-parallel-download-files-requests/</guid>
      <description>I often find myself downloading web pages with Python&amp;#8217;s requests library to do some local scrapping when building datasets but I&amp;#8217;ve never come up with a good way for downloading those pages in parallel.
 Below is the code that I use. First we&amp;#8217;ll import the required libraries:
 import os import requests from time import time as timer   And now a function that streams a response into a local file:</description>
    </item>
    
    <item>
      <title>Interpreting Word2vec or GloVe embeddings using scikit-learn and Neo4j graph algorithms</title>
      <link>https://markhneedham.com/blog/2018/05/19/interpreting-word2vec-glove-embeddings-sklearn-neo4j-graph-algorithms/</link>
      <pubDate>Sat, 19 May 2018 09:47:21 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/05/19/interpreting-word2vec-glove-embeddings-sklearn-neo4j-graph-algorithms/</guid>
      <description>A couple of weeks I came across a paper titled Parameter Free Hierarchical Graph-Based Clustering for Analyzing Continuous Word Embeddings via Abigail See&#39;s blog post about ACL 2017.
  The paper explains an algorithm that helps to make sense of word embeddings generated by algorithms such as Word2vec and GloVe.
 I&amp;#8217;m fascinated by how graphs can be used to interpret seemingly black box data, so I was immediately intrigued and wanted to try and reproduce their findings using Neo4j.</description>
    </item>
    
    <item>
      <title>Python via virtualenv on Mac OS X: RuntimeError: Python is not installed as a framework.</title>
      <link>https://markhneedham.com/blog/2018/05/04/python-runtime-error-osx-matplotlib-not-installed-as-framework-mac/</link>
      <pubDate>Fri, 04 May 2018 22:03:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/05/04/python-runtime-error-osx-matplotlib-not-installed-as-framework-mac/</guid>
      <description>I&amp;#8217;ve previously written a couple of blog posts about my troubles getting matplotlib to play nicely and I run into a slightly different variant today while following Sidath Asiri&amp;#8217;s Hello World in TensorFlow tutorial.
 When I ran the script using a version of Python installed via virtualenv I got the following exception:
 Traceback (most recent call last): File &#34;iris.py&#34;, line 4, in &amp;lt;module&amp;gt; from matplotlib import pyplot as plt File &#34;</description>
    </item>
    
    <item>
      <title>PyData London 2018 Conference Experience Report</title>
      <link>https://markhneedham.com/blog/2018/04/29/pydata-london-2018/</link>
      <pubDate>Sun, 29 Apr 2018 11:54:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/04/29/pydata-london-2018/</guid>
      <description>Over the last few days I attended PyData London 2018 and wanted to share my experience. The PyData series of conferences aim to bring together users and developers of data analysis tools to share ideas and learn from each other. I presented a talk on building a recommendation with Python and Neo4j at the 2016 version but didn&amp;#8217;t attend last year.
 The organisers said there were ~ 550 attendees spread over 1 day of tutorials and 2 days of talks.</description>
    </item>
    
    <item>
      <title>Python: Serialize and Deserialize Numpy 2D arrays</title>
      <link>https://markhneedham.com/blog/2018/04/07/python-serialize-deserialize-numpy-2d-arrays/</link>
      <pubDate>Sat, 07 Apr 2018 19:38:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/04/07/python-serialize-deserialize-numpy-2d-arrays/</guid>
      <description>I&amp;#8217;ve been playing around with saving and loading scikit-learn models and needed to serialize and deserialize Numpy arrays as part of the process.
 I could use pickle but that seems a bit overkill so I decided instead to save the byte representation of the array. We can get that representation by calling the tobytes method on a Numpy array:
 import numpy as np &amp;gt;&amp;gt;&amp;gt; np.array([ [1,2,3], [4,5,6], [7,8,9] ]) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) &amp;gt;&amp;gt;&amp;gt; np.</description>
    </item>
    
    <item>
      <title>Python 3: Converting a list to a dictionary with dictionary comprehensions</title>
      <link>https://markhneedham.com/blog/2018/04/02/python-list-to-dictionary-comprehensions/</link>
      <pubDate>Mon, 02 Apr 2018 04:20:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/04/02/python-list-to-dictionary-comprehensions/</guid>
      <description>When coding in Python I often find myself with lists containing key/value pairs that I want to convert to a dictionary.
 In a recent example I had the following code:
 values = [{&#39;key&#39;: &#39;name&#39;, &#39;value&#39;: &#39;Mark&#39;}, {&#39;key&#39;: &#39;age&#39;, &#39;value&#39;: 34}]   And I wanted to create a dictionary that had the keys name and age and their respective values. The easiest way to convert this list to a dictionary is to iterate over the list and construct the dictionary key by key:</description>
    </item>
    
    <item>
      <title>Yelp: Reverse geocoding businesses to extract detailed location information</title>
      <link>https://markhneedham.com/blog/2018/03/14/yelp-reverse-geocoding-businesses-extract-detailed-location-information/</link>
      <pubDate>Wed, 14 Mar 2018 08:53:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2018/03/14/yelp-reverse-geocoding-businesses-extract-detailed-location-information/</guid>
      <description>$ cat dataset/business.json | head -n1 | jq { &amp;#34;business_id&amp;#34;: &amp;#34;FYWN1wneV18bWNgQjJ2GNg&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Dental by Design&amp;#34;, &amp;#34;neighborhood&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;address&amp;#34;: &amp;#34;4855 E Warner Rd, Ste B9&amp;#34;, &amp;#34;city&amp;#34;: &amp;#34;Ahwatukee&amp;#34;, &amp;#34;state&amp;#34;: &amp;#34;AZ&amp;#34;, &amp;#34;postal_code&amp;#34;: &amp;#34;85044&amp;#34;, &amp;#34;latitude&amp;#34;: 33.3306902, &amp;#34;longitude&amp;#34;: -111.9785992, &amp;#34;stars&amp;#34;: 4, &amp;#34;review_count&amp;#34;: 22, &amp;#34;is_open&amp;#34;: 1, &amp;#34;attributes&amp;#34;: { &amp;#34;AcceptsInsurance&amp;#34;: true, &amp;#34;ByAppointmentOnly&amp;#34;: true, &amp;#34;BusinessAcceptsCreditCards&amp;#34;: true }, &amp;#34;categories&amp;#34;: [ &amp;#34;Dentists&amp;#34;, &amp;#34;General Dentistry&amp;#34;, &amp;#34;Health &amp;amp; Medical&amp;#34;, &amp;#34;Oral Surgeons&amp;#34;, &amp;#34;Cosmetic Dentists&amp;#34;, &amp;#34;Orthodontists&amp;#34; ], &amp;#34;hours&amp;#34;: { &amp;#34;Friday&amp;#34;: &amp;#34;7:30-17:00&amp;#34;, &amp;#34;Tuesday&amp;#34;: &amp;#34;7:30-17:00&amp;#34;, &amp;#34;Thursday&amp;#34;: &amp;#34;7:30-17:00&amp;#34;, &amp;#34;Wednesday&amp;#34;: &amp;#34;7:30-17:00&amp;#34;, &amp;#34;Monday&amp;#34;: &amp;#34;7:30-17:00&amp;#34; } } import reverse_geocoder as rg lat_longs = { &amp;#34;FYWN1wneV18bWNgQjJ2GNg&amp;#34;: (33.</description>
    </item>
    
    <item>
      <title>scikit-learn: Using GridSearch to tune the hyper-parameters of VotingClassifier</title>
      <link>https://markhneedham.com/blog/2017/12/10/scikit-learn-using-gridsearch-tune-hyper-parameters-votingclassifier/</link>
      <pubDate>Sun, 10 Dec 2017 07:55:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/12/10/scikit-learn-using-gridsearch-tune-hyper-parameters-votingclassifier/</guid>
      <description>import pandas as pd from sklearn import linear_model from sklearn.ensemble import VotingClassifier from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline Y_COLUMN = &amp;#34;author&amp;#34; TEXT_COLUMN = &amp;#34;text&amp;#34; unigram_log_pipe = Pipeline([ (&amp;#39;cv&amp;#39;, CountVectorizer()), (&amp;#39;logreg&amp;#39;, linear_model.LogisticRegression()) ]) ngram_pipe = Pipeline([ (&amp;#39;cv&amp;#39;, CountVectorizer(ngram_range=(1, 2))), (&amp;#39;mnb&amp;#39;, MultinomialNB()) ]) tfidf_pipe = Pipeline([ (&amp;#39;tfidf&amp;#39;, TfidfVectorizer(min_df=3, max_features=None, strip_accents=&amp;#39;unicode&amp;#39;, analyzer=&amp;#39;word&amp;#39;, token_pattern=r&amp;#39;\w{1,}&amp;#39;, ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1, stop_words=&amp;#39;english&amp;#39;)), (&amp;#39;mnb&amp;#39;, MultinomialNB()) ]) classifiers = [ (&amp;#34;ngram&amp;#34;, ngram_pipe), (&amp;#34;unigram&amp;#34;, unigram_log_pipe), (&amp;#34;tfidf&amp;#34;, tfidf_pipe), ] mixed_pipe = Pipeline([ (&amp;#34;voting&amp;#34;, VotingClassifier(classifiers, voting=&amp;#34;soft&amp;#34;)) ]) from sklearn.</description>
    </item>
    
    <item>
      <title>scikit-learn: Building a multi class classification ensemble</title>
      <link>https://markhneedham.com/blog/2017/12/05/scikit-learn-building-multi-class-classification-ensemble/</link>
      <pubDate>Tue, 05 Dec 2017 22:19:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/12/05/scikit-learn-building-multi-class-classification-ensemble/</guid>
      <description>from sklearn import linear_model from sklearn.ensemble import VotingClassifier from sklearn.feature_extraction.text import CountVectorizer from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline ngram_pipe = Pipeline([ (&amp;#39;cv&amp;#39;, CountVectorizer(ngram_range=(1, 2))), (&amp;#39;mnb&amp;#39;, MultinomialNB()) ]) unigram_log_pipe = Pipeline([ (&amp;#39;cv&amp;#39;, CountVectorizer()), (&amp;#39;logreg&amp;#39;, linear_model.LogisticRegression()) ]) classifiers = [ (&amp;#34;ngram&amp;#34;, ngram_pipe), (&amp;#34;unigram&amp;#34;, unigram_log_pipe), ] mixed_pipe = Pipeline([ (&amp;#34;voting&amp;#34;, VotingClassifier(classifiers, voting=&amp;#34;soft&amp;#34;)) ]) import pandas as pd import numpy as np from sklearn.model_selection import StratifiedKFold from sklearn import metrics Y_COLUMN = &amp;#34;author&amp;#34; TEXT_COLUMN = &amp;#34;text&amp;#34; def test_pipeline(df, nlp_pipeline): y = df[Y_COLUMN].</description>
    </item>
    
    <item>
      <title>Python: Combinations of values on and off</title>
      <link>https://markhneedham.com/blog/2017/12/03/python-combinations-values-off/</link>
      <pubDate>Sun, 03 Dec 2017 17:23:14 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/12/03/python-combinations-values-off/</guid>
      <description>0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 &amp;gt;&amp;gt;&amp;gt; &amp;#34;{0:0b}&amp;#34;.format(1).zfill(3) &amp;#39;001&amp;#39; &amp;gt;&amp;gt;&amp;gt; &amp;#34;{0:0b}&amp;#34;.format(5).zfill(3) &amp;#39;101&amp;#39; &amp;gt;&amp;gt;&amp;gt; &amp;#34;{0:0b}&amp;#34;.format(6).zfill(3) &amp;#39;110&amp;#39; &amp;gt;&amp;gt;&amp;gt; [int(x) for x in list(&amp;#34;{0:0b}&amp;#34;.format(1).zfill(3))] [0, 0, 1] def combinations_on_off(num_classifiers): return [[int(x) for x in list(&amp;#34;{0:0b}&amp;#34;.format(i).zfill(num_classifiers))] for i in range(1, 2 ** num_classifiers)] &amp;gt;&amp;gt;&amp;gt; for combination in combinations_on_off(3): print(combination) [0, 0, 1] [0, 1, 0] [0, 1, 1] [1, 0, 0] [1, 0, 1] [1, 1, 0] [1, 1, 1] &amp;gt;&amp;gt;&amp;gt; for combination in combinations_on_off(4): print(combination) [0, 0, 0, 1] [0, 0, 1, 0] [0, 0, 1, 1] [0, 1, 0, 0] [0, 1, 0, 1] [0, 1, 1, 0] [0, 1, 1, 1] [1, 0, 0, 0] [1, 0, 0, 1] [1, 0, 1, 0] [1, 0, 1, 1] [1, 1, 0, 0] [1, 1, 0, 1] [1, 1, 1, 0] [1, 1, 1, 1] </description>
    </item>
    
    <item>
      <title>Python: Learning about defaultdict&#39;s handling of missing keys</title>
      <link>https://markhneedham.com/blog/2017/12/01/python-learning-defaultdicts-handling-missing-keys/</link>
      <pubDate>Fri, 01 Dec 2017 15:26:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/12/01/python-learning-defaultdicts-handling-missing-keys/</guid>
      <description>vocabulary = defaultdict() vocabulary.default_factory = vocabulary.__len__ &amp;gt;&amp;gt;&amp;gt; from collections import defaultdict &amp;gt;&amp;gt;&amp;gt; vocabulary = defaultdict() &amp;gt;&amp;gt;&amp;gt; vocabulary.default_factory = vocabulary.__len__ &amp;gt;&amp;gt;&amp;gt; vocabulary[&amp;#34;foo&amp;#34;] 0 &amp;gt;&amp;gt;&amp;gt; vocabulary.items() dict_items([(&amp;#39;foo&amp;#39;, 0)]) &amp;gt;&amp;gt;&amp;gt; vocabulary[&amp;#34;bar&amp;#34;] 1 &amp;gt;&amp;gt;&amp;gt; vocabulary.items() dict_items([(&amp;#39;foo&amp;#39;, 0), (&amp;#39;bar&amp;#39;, 1)]) &amp;gt;&amp;gt;&amp;gt; vocabulary[&amp;#34;baz&amp;#34;] = &amp;#34;Mark &amp;gt;&amp;gt;&amp;gt; vocabulary[&amp;#34;baz&amp;#34;] &amp;#39;Mark&amp;#39; &amp;gt;&amp;gt;&amp;gt; vocabulary[&amp;#34;python&amp;#34;] 3 &amp;gt;&amp;gt;&amp;gt; vocabulary.items() dict_items([(&amp;#39;foo&amp;#39;, 0), (&amp;#39;bar&amp;#39;, 1), (&amp;#39;baz&amp;#39;, &amp;#39;Mark&amp;#39;), (&amp;#39;python&amp;#39;, 3)]) &amp;#34;&amp;#34;&amp;#34; __missing__(key) # Called by __getitem__ for missing key; pseudo-code: if self.default_factory is None: raise KeyError((key,)) self[key] = value = self.</description>
    </item>
    
    <item>
      <title>scikit-learn: Creating a matrix of named entity counts</title>
      <link>https://markhneedham.com/blog/2017/11/29/scikit-learn-creating-a-matrix-of-named-entity-counts/</link>
      <pubDate>Wed, 29 Nov 2017 23:01:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/11/29/scikit-learn-creating-a-matrix-of-named-entity-counts/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; from polyglot.text import Text &amp;gt;&amp;gt;&amp;gt; doc = &amp;#34;My name is David Beckham. Hello from London, England&amp;#34; &amp;gt;&amp;gt;&amp;gt; Text(doc, hint_language_code=&amp;#34;en&amp;#34;).entities [I-PER([&amp;#39;David&amp;#39;, &amp;#39;Beckham&amp;#39;]), I-LOC([&amp;#39;London&amp;#39;]), I-LOC([&amp;#39;England&amp;#39;])] &amp;gt;&amp;gt;&amp;gt; [&amp;#34;_&amp;#34;.join(entity) for entity in Text(doc, hint_language_code=&amp;#34;en&amp;#34;).entities] [&amp;#39;David_Beckham&amp;#39;, &amp;#39;London&amp;#39;, &amp;#39;England&amp;#39;] from sklearn.feature_extraction.text import CountVectorizer from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline nlp_pipeline = Pipeline([ (&amp;#39;cv&amp;#39;, CountVectorizer(), (&amp;#39;mnb&amp;#39;, MultinomialNB()) ]) ... # Train and Test the model ... entities = {} def analyze(doc): if doc not in entities: entities[doc] = [&amp;#34;_&amp;#34;.</description>
    </item>
    
    <item>
      <title>Python: polyglot - ModuleNotFoundError: No module named &#39;icu&#39;</title>
      <link>https://markhneedham.com/blog/2017/11/28/python-polyglot-modulenotfounderror-no-module-named-icu/</link>
      <pubDate>Tue, 28 Nov 2017 19:52:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/11/28/python-polyglot-modulenotfounderror-no-module-named-icu/</guid>
      <description>$ pip install polyglot ImportError: No module named &amp;#39;icu&amp;#39; brew install icu4c export ICU_VERSION=58 export PYICU_INCLUDES=/usr/local/Cellar/icu4c/58.2/include export PYICU_LFLAGS=-L/usr/local/Cellar/icu4c/58.2/lib pip install pyicu $ ls -lh /usr/local/Cellar/icu4c/ total 0 drwxr-xr-x 12 markneedham admin 408B 28 Nov 06:12 58.2 pip install pycld2 pip install morfessor polyglot download embeddings2.de polyglot download ner2.de polyglot download embeddings2.en polyglot download ner2.en </description>
    </item>
    
    <item>
      <title>Python 3: TypeError: unsupported format string passed to numpy.ndarray.__format__</title>
      <link>https://markhneedham.com/blog/2017/11/19/python-3-typeerror-unsupported-format-string-passed-to-numpy-ndarray-__format__/</link>
      <pubDate>Sun, 19 Nov 2017 07:16:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/11/19/python-3-typeerror-unsupported-format-string-passed-to-numpy-ndarray-__format__/</guid>
      <description>Iteration Training set observations Testing set observations --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &amp;lt;ipython-input-28-007cbab507e3&amp;gt; in &amp;lt;module&amp;gt;() 6 print(&amp;#39;{} {:^61} {}&amp;#39;.format(&amp;#39;Iteration&amp;#39;, &amp;#39;Training set observations&amp;#39;, &amp;#39;Testing set observations&amp;#39;)) 7 for iteration, data in enumerate(kf, start=1): ----&amp;gt; 8 print(&amp;#39;{0:^9} {1} {2:^25}&amp;#39;.format(iteration, data[0], data[1])) TypeError: unsupported format string passed to numpy.ndarray.__format__ &amp;gt;&amp;gt;&amp;gt; import numpy as np &amp;gt;&amp;gt;&amp;gt; &amp;#34;{:9}&amp;#34;.format(np.array([1,2,3])) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; TypeError: unsupported format string passed to numpy.</description>
    </item>
    
    <item>
      <title>Python 3: Create sparklines using matplotlib</title>
      <link>https://markhneedham.com/blog/2017/09/23/python-3-create-sparklines-using-matplotlib/</link>
      <pubDate>Sat, 23 Sep 2017 06:51:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/09/23/python-3-create-sparklines-using-matplotlib/</guid>
      <description>import matplotlib matplotlib.use(&amp;#34;Agg&amp;#34;) import matplotlib.pyplot as plt import base64 from io import BytesIO def sparkline(data, figsize=(4, 0.25), **kwags): &amp;#34;&amp;#34;&amp;#34; Returns a HTML image tag containing a base64 encoded sparkline style plot &amp;#34;&amp;#34;&amp;#34; data = list(data) fig, ax = plt.subplots(1, 1, figsize=figsize, **kwags) ax.plot(data) for k,v in ax.spines.items(): v.set_visible(False) ax.set_xticks([]) ax.set_yticks([]) plt.plot(len(data) - 1, data[len(data) - 1], &amp;#39;r.&amp;#39;) ax.fill_between(range(len(data)), data, len(data)*[min(data)], alpha=0.1) img = BytesIO() plt.savefig(img, transparent=True, bbox_inches=&amp;#39;tight&amp;#39;) img.seek(0) plt.close() return base64.</description>
    </item>
    
    <item>
      <title>PHP vs Python: Generating a HMAC</title>
      <link>https://markhneedham.com/blog/2017/08/02/php-vs-python-generating-a-hmac/</link>
      <pubDate>Wed, 02 Aug 2017 06:09:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/08/02/php-vs-python-generating-a-hmac/</guid>
      <description>I&amp;rsquo;ve been writing a bit of code to integrate with a ClassMarker webhook, and you&amp;rsquo;re required to check that an incoming request actually came from ClassMarker by checking the value of a base64 hash using HMAC SHA256.
The example in the documentation is written in PHP which I haven&amp;rsquo;t done for about 10 years so I had to figure out how to do the same thing in Python.
$ php -a php &amp;gt; echo base64_encode(hash_hmac(&amp;#34;sha256&amp;#34;, &amp;#34;my data&amp;#34;, &amp;#34;my_secret&amp;#34;, true)); vyniKpNSlxu4AfTgSJImt+j+pRx7v6m+YBobfKsoGhE= import hmac import hashlib import base64 data = &amp;#34;my data&amp;#34;.</description>
    </item>
    
    <item>
      <title>Pandas/scikit-learn: get_dummies test/train sets - ValueError: shapes not aligned</title>
      <link>https://markhneedham.com/blog/2017/07/05/pandasscikit-learn-get_dummies-testtrain-sets-valueerror-shapes-not-aligned/</link>
      <pubDate>Wed, 05 Jul 2017 15:42:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/07/05/pandasscikit-learn-get_dummies-testtrain-sets-valueerror-shapes-not-aligned/</guid>
      <description>import pandas as pd import numpy as np from sklearn import linear_model train = pd.DataFrame({&amp;#34;letter&amp;#34;:[&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;, &amp;#34;D&amp;#34;], &amp;#34;value&amp;#34;: [1, 2, 3, 4]}) X_train = train.drop([&amp;#34;value&amp;#34;], axis=1) X_train = pd.get_dummies(X_train) y_train = train[&amp;#34;value&amp;#34;]~~~ &amp;lt;h3&amp;gt;Test set&amp;lt;/h3&amp;gt; ~~~python test = pd.DataFrame({&amp;#34;letter&amp;#34;:[&amp;#34;D&amp;#34;, &amp;#34;D&amp;#34;, &amp;#34;B&amp;#34;, &amp;#34;E&amp;#34;], &amp;#34;value&amp;#34;: [4, 5, 7, 19]}) X_test = test.drop([&amp;#34;value&amp;#34;], axis=1) X_test = pd.get_dummies(X_test) y_test = test[&amp;#34;value&amp;#34;] lr = linear_model.LinearRegression() model = lr.fit(X_train, y_train) model.score(X_test, y_test) ValueError: shapes (4,3) and (4,) not aligned: 3 (dim 1) !</description>
    </item>
    
    <item>
      <title>Pandas: Find rows where column/field is null</title>
      <link>https://markhneedham.com/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</link>
      <pubDate>Wed, 05 Jul 2017 14:31:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/07/05/pandas-find-rows-where-columnfield-is-null/</guid>
      <description>import pandas as pd train = pd.read_csv(&amp;#34;train.csv&amp;#34;) null_columns=train.columns[train.isnull().any()] train[null_columns].isnull().sum() LotFrontage 259 Alley 1369 MasVnrType 8 MasVnrArea 8 BsmtQual 37 BsmtCond 37 BsmtExposure 38 BsmtFinType1 37 BsmtFinType2 38 Electrical 1 FireplaceQu 690 GarageType 81 GarageYrBlt 81 GarageFinish 81 GarageQual 81 GarageCond 81 PoolQC 1453 Fence 1179 MiscFeature 1406 dtype: int64 print(train[train[&amp;#34;Electrical&amp;#34;].isnull()][null_columns]) LotFrontage Alley MasVnrType MasVnrArea BsmtQual BsmtCond BsmtExposure \ 1379 73.0 NaN None 0.0 Gd TA No BsmtFinType1 BsmtFinType2 Electrical FireplaceQu GarageType GarageYrBlt \ 1379 Unf Unf NaN NaN BuiltIn 2007.</description>
    </item>
    
    <item>
      <title>scikit-learn: Random forests - Feature Importance</title>
      <link>https://markhneedham.com/blog/2017/06/16/scikit-learn-random-forests-feature-importance/</link>
      <pubDate>Fri, 16 Jun 2017 05:55:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/06/16/scikit-learn-random-forests-feature-importance/</guid>
      <description>import numpy as np import pandas as pd from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import train_test_split # We&amp;#39;ll use this library to make the display pretty from tabulate import tabulate train = pd.read_csv(&amp;#39;train.csv&amp;#39;) # the model can only handle numeric values so filter out the rest data = train.select_dtypes(include=[np.number]).interpolate().dropna() y = train.SalePrice X = data.drop([&amp;#34;SalePrice&amp;#34;, &amp;#34;Id&amp;#34;], axis=1) X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33) clf = RandomForestRegressor(n_jobs=2, n_estimators=1000) model = clf.</description>
    </item>
    
    <item>
      <title>Kaggle: House Prices: Advanced Regression Techniques - Trying to fill in missing values</title>
      <link>https://markhneedham.com/blog/2017/06/04/kaggle-house-prices-advanced-regression-techniques-trying-fill-missing-values/</link>
      <pubDate>Sun, 04 Jun 2017 09:22:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/06/04/kaggle-house-prices-advanced-regression-techniques-trying-fill-missing-values/</guid>
      <description>import pandas as pd train = pd.read_csv(&amp;#39;train.csv&amp;#39;) null_columns=train.columns[train.isnull().any()] &amp;gt;&amp;gt;&amp;gt; print(train[null_columns].isnull().sum()) LotFrontage 259 Alley 1369 MasVnrType 8 MasVnrArea 8 BsmtQual 37 BsmtCond 37 BsmtExposure 38 BsmtFinType1 37 BsmtFinType2 38 Electrical 1 FireplaceQu 690 GarageType 81 GarageYrBlt 81 GarageFinish 81 GarageQual 81 GarageCond 81 PoolQC 1453 Fence 1179 MiscFeature 1406 dtype: int64 cols = [col for col in train.columns if col.startswith(&amp;#34;Lot&amp;#34;)] missing_frontage = train[cols][train[&amp;#34;LotFrontage&amp;#34;].isnull()] &amp;gt;&amp;gt;&amp;gt; print(missing_frontage.head()) LotFrontage LotArea LotShape LotConfig 7 NaN 10382 IR1 Corner 12 NaN 12968 IR2 Inside 14 NaN 10920 IR1 Corner 16 NaN 11241 IR1 CulDSac 24 NaN 8246 IR1 Inside sub_train = train[train.</description>
    </item>
    
    <item>
      <title>Python: Flask - Generating a static HTML page</title>
      <link>https://markhneedham.com/blog/2017/04/27/python-flask-generating-a-static-html-page/</link>
      <pubDate>Thu, 27 Apr 2017 20:59:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/04/27/python-flask-generating-a-static-html-page/</guid>
      <description>from flask import render_template import flask app = flask.Flask(&amp;#39;my app&amp;#39;) if __name__ == &amp;#34;__main__&amp;#34;: with app.app_context(): rendered = render_template(&amp;#39;blog.html&amp;#39;, \ title = &amp;#34;My Generated Page&amp;#34;, \ people = [{&amp;#34;name&amp;#34;: &amp;#34;Mark&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;Michael&amp;#34;}]) print(rendered) &amp;lt;!doctype html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;{{ title }}&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;{{ title }}&amp;lt;/h1&amp;gt; &amp;lt;ul&amp;gt; {% for person in people %} &amp;lt;li&amp;gt;{{ person.name }}&amp;lt;/li&amp;gt; {% endfor %} &amp;lt;/ul&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; $ python blog.py &amp;lt;!doctype html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;My Generated Page&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;My Generated Page&amp;lt;/h1&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;Mark&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Michael&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; $ python blog.</description>
    </item>
    
    <item>
      <title>Luigi: Defining dynamic requirements (on output files)</title>
      <link>https://markhneedham.com/blog/2017/03/28/luigi-defining-dynamic-requirements-on-output-files/</link>
      <pubDate>Tue, 28 Mar 2017 05:39:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/03/28/luigi-defining-dynamic-requirements-on-output-files/</guid>
      <description>class MembersToCSV(luigi.Task): key = luigi.Parameter() lat = luigi.Parameter() lon = luigi.Parameter() def requires(self): yield GroupsToJSON(self.key, self.lat, self.lon) class MembersToCSV(luigi.Task): key = luigi.Parameter() lat = luigi.Parameter() lon = luigi.Parameter() def run(self): outputs = [] for input in self.input(): with input.open(&amp;#39;r&amp;#39;) as group_file: groups_json = json.load(group_file) groups = [str(group[&amp;#39;id&amp;#39;]) for group in groups_json] for group_id in groups: members = MembersToJSON(group_id, self.key) outputs.append(members.output().path) yield members def requires(self): yield GroupsToJSON(self.key, self.lat, self.lon) class MembersToJSON(luigi.Task): group_id = luigi.</description>
    </item>
    
    <item>
      <title>Luigi: An ExternalProgramTask example - Converting JSON to CSV</title>
      <link>https://markhneedham.com/blog/2017/03/25/luigi-externalprogramtask-example-converting-json-csv/</link>
      <pubDate>Sat, 25 Mar 2017 14:09:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/03/25/luigi-externalprogramtask-example-converting-json-csv/</guid>
      <description>import luigi import requests import json from collections import Counter class GroupsToJSON(luigi.Task): key = luigi.Parameter() lat = luigi.Parameter() lon = luigi.Parameter() def run(self): seed_topic = &amp;#34;nosql&amp;#34; uri = &amp;#34;https://api.meetup.com/2/groups?&amp;amp;topic={0}&amp;amp;lat={1}&amp;amp;lon={2}&amp;amp;key={3}&amp;#34;.format(seed_topic, self.lat, self.lon, self.key) r = requests.get(uri) all_topics = [topic[&amp;#34;urlkey&amp;#34;] for result in r.json()[&amp;#34;results&amp;#34;] for topic in result[&amp;#34;topics&amp;#34;]] c = Counter(all_topics) topics = [entry[0] for entry in c.most_common(10)] groups = {} for topic in topics: uri = &amp;#34;https://api.meetup.com/2/groups?&amp;amp;topic={0}&amp;amp;lat={1}&amp;amp;lon={2}&amp;amp;key={3}&amp;#34;.format(topic, self.lat, self.lon, self.key) r = requests.</description>
    </item>
    
    <item>
      <title>Python 3: TypeError: Object of type &#39;dict_values&#39; is not JSON serializable</title>
      <link>https://markhneedham.com/blog/2017/03/19/python-3-typeerror-object-type-dict_values-not-json-serializable/</link>
      <pubDate>Sun, 19 Mar 2017 16:40:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/03/19/python-3-typeerror-object-type-dict_values-not-json-serializable/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; import json &amp;gt;&amp;gt;&amp;gt; x = {&amp;#34;mark&amp;#34;: {&amp;#34;name&amp;#34;: &amp;#34;Mark&amp;#34;}, &amp;#34;michael&amp;#34;: {&amp;#34;name&amp;#34;: &amp;#34;Michael&amp;#34;} } &amp;gt;&amp;gt;&amp;gt; json.dumps(x.values()) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/__init__.py&amp;#34;, line 231, in dumps return _default_encoder.encode(obj) File &amp;#34;/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py&amp;#34;, line 199, in encode chunks = self.iterencode(o, _one_shot=True) File &amp;#34;/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py&amp;#34;, line 257, in iterencode return _iterencode(o, 0) File &amp;#34;/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py&amp;#34;, line 180, in default o.__class__.__name__) TypeError: Object of type &amp;#39;dict_values&amp;#39; is not JSON serializable &amp;gt;&amp;gt;&amp;gt; json.</description>
    </item>
    
    <item>
      <title>Go vs Python: Parsing a JSON response from a HTTP API</title>
      <link>https://markhneedham.com/blog/2017/01/21/go-vs-python-parsing-a-json-response-from-a-http-api/</link>
      <pubDate>Sat, 21 Jan 2017 10:49:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2017/01/21/go-vs-python-parsing-a-json-response-from-a-http-api/</guid>
      <description>As part of a recommendations with Neo4j talkthat I&amp;rsquo;ve presented a few times over the last year I have a set of scripts that download some data from the meetup.com API.
They&amp;rsquo;re all written in Python but I thought it&amp;rsquo;d be a fun exercise to see what they&amp;rsquo;d look like in Go. My eventual goal is to try and parallelise the API calls.
This is the Python version of the script:</description>
    </item>
    
    <item>
      <title>scikit-learn: First steps with log_loss</title>
      <link>https://markhneedham.com/blog/2016/09/14/scikit-learn-first-steps-with-log_loss/</link>
      <pubDate>Wed, 14 Sep 2016 05:33:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/09/14/scikit-learn-first-steps-with-log_loss/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; actual_labels = [&amp;#34;bam&amp;#34;, &amp;#34;ham&amp;#34;, &amp;#34;spam&amp;#34;] &amp;gt;&amp;gt;&amp;gt; from sklearn.metrics import log_loss &amp;gt;&amp;gt;&amp;gt; log_loss(actual_labels, [[1, 0, 0], [0, 1, 0], [0, 0, 1]]) 2.1094237467877998e-15 &amp;gt;&amp;gt;&amp;gt; log_loss(actual_labels, [[0, 0, 1], [1, 0, 0], [0, 1, 0]]) 34.538776394910684 This means that the predicted probability for that given class would be less than exp(-1) or around 0.368.
So, seeing a log loss greater than one can be expected in the cass that that your model only gives less than a 36% probability estimate for the correct class.</description>
    </item>
    
    <item>
      <title>scikit-learn: Clustering and the curse of dimensionality</title>
      <link>https://markhneedham.com/blog/2016/08/27/scikit-learn-clustering-and-the-curse-of-dimensionality/</link>
      <pubDate>Sat, 27 Aug 2016 20:32:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/08/27/scikit-learn-clustering-and-the-curse-of-dimensionality/</guid>
      <description>But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”).
Running a dimensionality reduction algorithm such as PCA prior to k-means clustering can alleviate this problem and speed up the computations.
from sklearn.metrics.pairwise import cosine_similarity import numpy as np def distances(a, b): return np.linalg.norm(a-b), cosine_similarity([a, b])[0][1] def mixed(n_zeros, n_ones): return np.concatenate((np.repeat([1], n_ones), np.repeat([0], n_zeros)), axis=0) def ones(n_ones): return np.repeat([1], n_ones) print distances(mixed(2, 2), ones(4)) print distances(mixed(3, 3), ones(6)) print distances(mixed(50, 50), ones(100)) print distances(mixed(300, 300), ones(600)) (1.</description>
    </item>
    
    <item>
      <title>scikit-learn: Trying to find clusters of Game of Thrones episodes</title>
      <link>https://markhneedham.com/blog/2016/08/25/scikit-learn-trying-to-find-clusters-of-game-of-thrones-episodes/</link>
      <pubDate>Thu, 25 Aug 2016 22:07:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/08/25/scikit-learn-trying-to-find-clusters-of-game-of-thrones-episodes/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; all.shape (60, 638) &amp;gt;&amp;gt;&amp;gt; all array([[0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], ..., [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]]) &amp;gt;&amp;gt;&amp;gt; from sklearn.cluster import KMeans &amp;gt;&amp;gt;&amp;gt; n_clusters = 3 &amp;gt;&amp;gt;&amp;gt; km = KMeans(n_clusters=n_clusters, init=&amp;#39;k-means++&amp;#39;, max_iter=100, n_init=1) &amp;gt;&amp;gt;&amp;gt; cluster_labels = km.fit_predict(all) &amp;gt;&amp;gt;&amp;gt; cluster_labels array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32) &amp;gt;&amp;gt;&amp;gt; import numpy as np &amp;gt;&amp;gt;&amp;gt; np.</description>
    </item>
    
    <item>
      <title>Neo4j/scikit-learn: Calculating the cosine similarity of Game of Thrones episodes</title>
      <link>https://markhneedham.com/blog/2016/08/22/neo4jscikit-learn-calculating-the-cosine-similarity-of-game-of-thrones-episodes/</link>
      <pubDate>Mon, 22 Aug 2016 21:12:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/08/22/neo4jscikit-learn-calculating-the-cosine-similarity-of-game-of-thrones-episodes/</guid>
      <description>:play http://guides.neo4j.com/got Episode 1 = [1, 1, 0] Episode 2 = [0, 1, 1] &amp;gt;&amp;gt;&amp;gt; from sklearn.metrics.pairwise import cosine_similarity &amp;gt;&amp;gt;&amp;gt; one = [1,1,0] &amp;gt;&amp;gt;&amp;gt; two = [0,1,1] &amp;gt;&amp;gt;&amp;gt; cosine_similarity([one, two]) array([[ 1. , 0.5], [ 0.5, 1. ]]) from neo4j.v1 import GraphDatabase, basic_auth driver = GraphDatabase.driver(&amp;#34;bolt://localhost&amp;#34;, auth=basic_auth(&amp;#34;neo4j&amp;#34;, &amp;#34;neo&amp;#34;)) session = driver.session() rows = session.run(&amp;#34;&amp;#34;&amp;#34; MATCH (c:Character), (e:Episode) OPTIONAL MATCH (c)-[appearance:APPEARED_IN]-&amp;gt;(e) RETURN e, c, appearance ORDER BY e.id, c.id&amp;#34;&amp;#34;&amp;#34;) &amp;gt;&amp;gt;&amp;gt; for row in rows: print row &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5415 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Addam Marbrand&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Addam_Marbrand&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5882 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Adrack Humble&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Adrack_Humble&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=6747 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aegon V Targaryen&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aegon_V_Targaryen&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5750 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aemon&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aemon&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5928 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aeron Greyjoy&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aeron_Greyjoy&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5503 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Aerys II Targaryen&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Aerys_II_Targaryen&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=6753 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alannys Greyjoy&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alannys_Greyjoy&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=6750 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alerie Tyrell&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alerie_Tyrell&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5753 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alliser Thorne&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alliser_Thorne&amp;#39;}&amp;gt; appearance=None&amp;gt; &amp;lt;Record e=&amp;lt;Node id=6780 labels=set([u&amp;#39;Episode&amp;#39;]) properties={u&amp;#39;season&amp;#39;: 1, u&amp;#39;number&amp;#39;: 1, u&amp;#39;id&amp;#39;: 1, u&amp;#39;title&amp;#39;: u&amp;#39;Winter Is Coming&amp;#39;}&amp;gt; c=&amp;lt;Node id=5858 labels=set([u&amp;#39;Character&amp;#39;]) properties={u&amp;#39;name&amp;#39;: u&amp;#39;Alton Lannister&amp;#39;, u&amp;#39;id&amp;#39;: u&amp;#39;/wiki/Alton_Lannister&amp;#39;}&amp;gt; appearance=None&amp;gt; episodes = {} for row in rows: if episodes.</description>
    </item>
    
    <item>
      <title>Python: matplotlib, seaborn, virtualenv - Python is not installed as a framework</title>
      <link>https://markhneedham.com/blog/2016/08/14/python-matplotlibseabornvirtualenv-python-is-not-installed-as-a-framework/</link>
      <pubDate>Sun, 14 Aug 2016 18:56:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/08/14/python-matplotlibseabornvirtualenv-python-is-not-installed-as-a-framework/</guid>
      <description>$ python 5_content_based_recommender/run.py Traceback (most recent call last): File &amp;#34;5_content_based_recommender/run.py&amp;#34;, line 14, in &amp;lt;module&amp;gt; import seaborn as sns File &amp;#34;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/seaborn/__init__.py&amp;#34;, line 6, in &amp;lt;module&amp;gt; from .rcmod import * File &amp;#34;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/seaborn/rcmod.py&amp;#34;, line 8, in &amp;lt;module&amp;gt; from . import palettes, _orig_rc_params File &amp;#34;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/seaborn/palettes.py&amp;#34;, line 12, in &amp;lt;module&amp;gt; from .utils import desaturate, set_hls_values, get_color_cycle File &amp;#34;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/seaborn/utils.py&amp;#34;, line 12, in &amp;lt;module&amp;gt; import matplotlib.pyplot as plt File &amp;#34;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.7/site-packages/matplotlib/pyplot.py&amp;#34;, line 114, in &amp;lt;module&amp;gt; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup() File &amp;#34;/Users/markneedham/projects/themarketingtechnologist/tmt/lib/python2.</description>
    </item>
    
    <item>
      <title>scikit-learn: TF/IDF and cosine similarity for computer science papers</title>
      <link>https://markhneedham.com/blog/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers/</link>
      <pubDate>Wed, 27 Jul 2016 02:45:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers/</guid>
      <description>In other words, these algorithms try to recommend items that are similar to those that a user liked in the past (or is examining in the present).
for each paper: generate a TF/IDF vector of the terms in the paper&amp;#39;s title calculate the cosine similarity of each paper&amp;#39;s TF/IDF vector with every other paper&amp;#39;s TF/IDF vector import glob corpus = [] for file in glob.glob(&amp;#34;papers/*.txt&amp;#34;): with open(file, &amp;#34;r&amp;#34;) as paper: corpus.</description>
    </item>
    
    <item>
      <title>Python: Scraping elements relative to each other with BeautifulSoup</title>
      <link>https://markhneedham.com/blog/2016/07/11/python-scraping-elements-relative-to-each-other-with-beautifulsoup/</link>
      <pubDate>Mon, 11 Jul 2016 06:01:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/07/11/python-scraping-elements-relative-to-each-other-with-beautifulsoup/</guid>
      <description>from bs4 import BeautifulSoup file_name = &amp;#34;Arya_Stark&amp;#34; wikia = BeautifulSoup(open(&amp;#34;data/wikia/characters/{0}&amp;#34;.format(file_name), &amp;#34;r&amp;#34;), &amp;#34;html.parser&amp;#34;) allegiance_element = [tag for tag in wikia.find_all(&amp;#39;h3&amp;#39;) if tag.text == &amp;#34;Allegiance&amp;#34;] &amp;gt; print allegiance_element [&amp;lt;h3 class=&amp;#34;pi-data-label pi-secondary-font&amp;#34;&amp;gt;Allegiance&amp;lt;/h3&amp;gt;] next_element = allegiance_element[0].next_sibling &amp;gt; print next_element &amp;gt; print next_element.name, type(next_element) None &amp;lt;class &amp;#39;bs4.element.NavigableString&amp;#39;&amp;gt; next_element = allegiance_element[0].next_sibling.next_sibling &amp;gt; print next_element.name, type(next_element) [&amp;lt;a href=&amp;#34;/wiki/House_Stark&amp;#34; title=&amp;#34;House Stark&amp;#34;&amp;gt;House Stark&amp;lt;/a&amp;gt;, &amp;lt;br/&amp;gt;, &amp;lt;a href=&amp;#34;/wiki/Faceless_Men&amp;#34; title=&amp;#34;Faceless Men&amp;#34;&amp;gt;Faceless Men&amp;lt;/a&amp;gt;, u&amp;#39; (Formerly)&amp;#39;] </description>
    </item>
    
    <item>
      <title>Python: BeautifulSoup - Insert tag</title>
      <link>https://markhneedham.com/blog/2016/06/30/python-beautifulsoup-insert-tag/</link>
      <pubDate>Thu, 30 Jun 2016 21:28:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/30/python-beautifulsoup-insert-tag/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; from bs4 import BeautifulSoup &amp;gt;&amp;gt;&amp;gt; tag = BeautifulSoup(&amp;#34;&amp;lt;br /&amp;gt;&amp;#34;, &amp;#34;html.parser&amp;#34;) &amp;gt;&amp;gt;&amp;gt; tag &amp;lt;br/&amp;gt; &amp;gt;&amp;gt;&amp;gt; tag.name u&amp;#39;[document]&amp;#39; &amp;gt;&amp;gt;&amp;gt; from bs4 import Tag &amp;gt;&amp;gt;&amp;gt; tag = Tag(name = &amp;#34;br&amp;#34;) &amp;gt;&amp;gt;&amp;gt; tag &amp;lt;br&amp;gt;&amp;lt;/br&amp;gt; &amp;gt;&amp;gt;&amp;gt; tag.name &amp;#39;br&amp;#39; </description>
    </item>
    
    <item>
      <title>Python: Regex - matching foreign characters/unicode letters</title>
      <link>https://markhneedham.com/blog/2016/06/18/python-regex-matching-foreign-charactersunicode-letters/</link>
      <pubDate>Sat, 18 Jun 2016 07:38:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2016/06/18/python-regex-matching-foreign-charactersunicode-letters/</guid>
      <description>Peter Dinklage as Tyrion Lannister Daniel Naprous as Oznak zo Pahl(credited as Stunt Performer) Filip Lozić as Young Nobleman Morgan C. Jones as a Braavosi captain Adewale Akinnuoye-Agbaje as Malko &amp;lt;actor&amp;gt; as &amp;lt;character&amp;gt; Peter Dinklage, Tyrion Lannister Daniel Naprous, Oznak zo Pahl Filip Lozić, Young Nobleman Morgan C. Jones, a Braavosi captain Adewale Akinnuoye-Agbaje, Malko import re strings = [ &amp;#34;Peter Dinklage as Tyrion Lannister&amp;#34;, &amp;#34;Filip Lozić as Young Nobleman&amp;#34;, &amp;#34;Daniel Naprous as Oznak zo Pahl(credited as Stunt Performer)&amp;#34;, &amp;#34;Morgan C.</description>
    </item>
    
    <item>
      <title>Python: Squashing &#39;duplicate&#39; pairs together</title>
      <link>https://markhneedham.com/blog/2015/12/20/python-squashing-duplicate-pairs-together/</link>
      <pubDate>Sun, 20 Dec 2015 12:12:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/20/python-squashing-duplicate-pairs-together/</guid>
      <description>A	B	(A is the same as B) B	C	(B is the same as C) C	D	... E	F	(E is the same as F) F	G	... (A, B, C, D) (E, F, G) pairs = [ (&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;), (&amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;), (&amp;#34;C&amp;#34;, &amp;#34;D&amp;#34;), (&amp;#34;E&amp;#34;, &amp;#34;F&amp;#34;), (&amp;#34;F&amp;#34;, &amp;#34;G&amp;#34;) ] def find_matching_index(pair, dups): return [index for index, dup in enumerate(dups) if pair[0] in dup or pair[1] in dup] print find_matching_index((&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;), [set([&amp;#34;D&amp;#34;, &amp;#34;E&amp;#34;])]) [] print find_matching_index((&amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;), [set([&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;])]) [0] print find_matching_index((&amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;), [set([&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;]), set([&amp;#34;C&amp;#34;, &amp;#34;D&amp;#34;])]) [0, 1] def extract_groups(items): dups = [] for pair in items: matching_index = find_matching_index(pair, dups) if len(matching_index) == 0: dups.</description>
    </item>
    
    <item>
      <title>Python: Parsing a JSON HTTP chunking stream</title>
      <link>https://markhneedham.com/blog/2015/11/28/python-parsing-a-json-http-chunking-stream/</link>
      <pubDate>Sat, 28 Nov 2015 13:56:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/28/python-parsing-a-json-http-chunking-stream/</guid>
      <description>import requests import json def stream_meetup_initial(): uri = &amp;#34;http://stream.meetup.com/2/rsvps&amp;#34; response = requests.get(uri, stream = True) for chunk in response.iter_content(chunk_size = None): yield chunk for raw_rsvp in stream_meetup_initial(): print raw_rsvp try: rsvp = json.loads(raw_rsvp) except ValueError as e: print e continue No JSON object could be decoded def stream_meetup_newline(): uri = &amp;#34;http://stream.meetup.com/2/rsvps&amp;#34; response = requests.get(uri, stream = True) buffer = &amp;#34;&amp;#34; for chunk in response.iter_content(chunk_size = 1): if chunk.endswith(&amp;#34;\n&amp;#34;): buffer += chunk yield buffer buffer = &amp;#34;&amp;#34; else: buffer += chunk r = requests.</description>
    </item>
    
    <item>
      <title>Python: Extracting Excel spreadsheet into CSV files</title>
      <link>https://markhneedham.com/blog/2015/08/19/python-extracting-excel-spreadsheet-into-csv-files/</link>
      <pubDate>Wed, 19 Aug 2015 23:27:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/19/python-extracting-excel-spreadsheet-into-csv-files/</guid>
      <description>from xlrd import open_workbook import csv wb = open_workbook(&amp;#39;Road-Accident-Safety-Data-Guide-1979-2004.xls&amp;#39;) for i in range(2, wb.nsheets): sheet = wb.sheet_by_index(i) print sheet.name with open(&amp;#34;data/%s.csv&amp;#34; %(sheet.name.replace(&amp;#34; &amp;#34;,&amp;#34;&amp;#34;)), &amp;#34;w&amp;#34;) as file: writer = csv.writer(file, delimiter = &amp;#34;,&amp;#34;) print sheet, sheet.name, sheet.ncols, sheet.nrows header = [cell.value for cell in sheet.row(0)] writer.writerow(header) for row_idx in range(1, sheet.nrows): row = [int(cell.value) if isinstance(cell.value, float) else cell.value for cell in sheet.row(row_idx)] writer.writerow(row) $ cat data/1stPointofImpact.csv code,label 0,Did not impact 1,Front 2,Back 3,Offside 4,Nearside -1,Data missing or out of range $ cat data/RoadType.</description>
    </item>
    
    <item>
      <title>Python: Difference between two datetimes in milliseconds</title>
      <link>https://markhneedham.com/blog/2015/07/28/python-difference-between-two-datetimes-in-milliseconds/</link>
      <pubDate>Tue, 28 Jul 2015 20:05:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/28/python-difference-between-two-datetimes-in-milliseconds/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; import datetime &amp;gt;&amp;gt;&amp;gt; start = datetime.datetime.now() &amp;gt;&amp;gt;&amp;gt; end = datetime.datetime.now() &amp;gt;&amp;gt;&amp;gt; end - start datetime.timedelta(0, 3, 519319) &amp;gt;&amp;gt;&amp;gt; dir(end - start) [&amp;#39;__abs__&amp;#39;, &amp;#39;__add__&amp;#39;, &amp;#39;__class__&amp;#39;, &amp;#39;__delattr__&amp;#39;, &amp;#39;__div__&amp;#39;, &amp;#39;__doc__&amp;#39;, &amp;#39;__eq__&amp;#39;, &amp;#39;__floordiv__&amp;#39;, &amp;#39;__format__&amp;#39;, &amp;#39;__ge__&amp;#39;, &amp;#39;__getattribute__&amp;#39;, &amp;#39;__gt__&amp;#39;, &amp;#39;__hash__&amp;#39;, &amp;#39;__init__&amp;#39;, &amp;#39;__le__&amp;#39;, &amp;#39;__lt__&amp;#39;, &amp;#39;__mul__&amp;#39;, &amp;#39;__ne__&amp;#39;, &amp;#39;__neg__&amp;#39;, &amp;#39;__new__&amp;#39;, &amp;#39;__nonzero__&amp;#39;, &amp;#39;__pos__&amp;#39;, &amp;#39;__radd__&amp;#39;, &amp;#39;__rdiv__&amp;#39;, &amp;#39;__reduce__&amp;#39;, &amp;#39;__reduce_ex__&amp;#39;, &amp;#39;__repr__&amp;#39;, &amp;#39;__rfloordiv__&amp;#39;, &amp;#39;__rmul__&amp;#39;, &amp;#39;__rsub__&amp;#39;, &amp;#39;__setattr__&amp;#39;, &amp;#39;__sizeof__&amp;#39;, &amp;#39;__str__&amp;#39;, &amp;#39;__sub__&amp;#39;, &amp;#39;__subclasshook__&amp;#39;, &amp;#39;days&amp;#39;, &amp;#39;max&amp;#39;, &amp;#39;microseconds&amp;#39;, &amp;#39;min&amp;#39;, &amp;#39;resolution&amp;#39;, &amp;#39;seconds&amp;#39;, &amp;#39;total_seconds&amp;#39;] &amp;gt;&amp;gt;&amp;gt; diff = end - start &amp;gt;&amp;gt;&amp;gt; elapsed_ms = (diff.</description>
    </item>
    
    <item>
      <title>Python: UnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe2 in position 0: ordinal not in range(128)</title>
      <link>https://markhneedham.com/blog/2015/07/15/python-unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-0-ordinal-not-in-range128/</link>
      <pubDate>Wed, 15 Jul 2015 06:20:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/15/python-unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-0-ordinal-not-in-range128/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39; u&amp;#39;foo \u2020&amp;#39; &amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39;.replace(&amp;#34; †&amp;#34;, &amp;#34;&amp;#34;) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; UnicodeDecodeError: &amp;#39;ascii&amp;#39; codec can&amp;#39;t decode byte 0xe2 in position 1: ordinal not in range(128) &amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39;.replace(u&amp;#39; †&amp;#39;, &amp;#34;&amp;#34;) u&amp;#39;foo&amp;#39; &amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39;.replace(unicode(&amp;#39; †&amp;#39;, &amp;#34;utf-8&amp;#34;), &amp;#34;&amp;#34;) u&amp;#39;foo&amp;#39; </description>
    </item>
    
    <item>
      <title>Python: Converting WordPress posts in CSV format</title>
      <link>https://markhneedham.com/blog/2015/07/07/python-converting-wordpress-posts-in-csv-format/</link>
      <pubDate>Tue, 07 Jul 2015 06:28:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/07/python-converting-wordpress-posts-in-csv-format/</guid>
      <description>&amp;lt;rss version=&amp;#34;2.0&amp;#34; xmlns:excerpt=&amp;#34;http://wordpress.org/export/1.2/excerpt/&amp;#34; xmlns:content=&amp;#34;http://purl.org/rss/1.0/modules/content/&amp;#34; xmlns:wfw=&amp;#34;http://wellformedweb.org/CommentAPI/&amp;#34; xmlns:dc=&amp;#34;http://purl.org/dc/elements/1.1/&amp;#34; xmlns:wp=&amp;#34;http://wordpress.org/export/1.2/&amp;#34; &amp;gt; ... &amp;lt;channel&amp;gt; &amp;lt;item&amp;gt; &amp;lt;title&amp;gt;First thoughts on Ruby...&amp;lt;/title&amp;gt; &amp;lt;link&amp;gt;http://www.markhneedham.com/blog/2006/08/29/first-thoughts-on-ruby/&amp;lt;/link&amp;gt; &amp;lt;pubDate&amp;gt;Tue, 29 Aug 2006 13:31:05 +0000&amp;lt;/pubDate&amp;gt; ... from bs4 import BeautifulSoup from soupselect import select from dateutil import parser import csv def read_page(page): return BeautifulSoup(open(page, &amp;#39;r&amp;#39;).read()) with open(&amp;#34;posts.csv&amp;#34;, &amp;#34;w&amp;#34;) as file: writer = csv.writer(file, delimiter=&amp;#34;,&amp;#34;) writer.writerow([&amp;#34;title&amp;#34;, &amp;#34;date&amp;#34;]) for row in select(read_page(&amp;#34;part2.xml&amp;#34;), &amp;#34;item&amp;#34;): title = select(row, &amp;#34;title&amp;#34;)[0].text.encode(&amp;#34;utf-8&amp;#34;) date = parser.parse(select(row, &amp;#34;pubdate&amp;#34;)[0].text) writer.writerow([title, date]) for row in select(read_page(&amp;#34;part1.</description>
    </item>
    
    <item>
      <title>Python: CSV writing - TypeError: &#39;builtin_function_or_method&#39; object has no attribute &#39;__getitem__&#39;</title>
      <link>https://markhneedham.com/blog/2015/05/31/python-csv-writing-typeerror-builtin_function_or_method-object-has-no-attribute-__getitem__/</link>
      <pubDate>Sun, 31 May 2015 22:33:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/31/python-csv-writing-typeerror-builtin_function_or_method-object-has-no-attribute-__getitem__/</guid>
      <description>import csv writer = csv.writer(file, delimiter=&amp;#34;,&amp;#34;) writer.writerow[&amp;#34;player&amp;#34;, &amp;#34;team&amp;#34;] TypeError: &amp;#39;builtin_function_or_method&amp;#39; object has no attribute &amp;#39;__getitem__&amp;#39; writer.writerow([&amp;#34;player&amp;#34;, &amp;#34;team&amp;#34;]) </description>
    </item>
    
    <item>
      <title>Python: Look ahead multiple elements in an iterator/generator</title>
      <link>https://markhneedham.com/blog/2015/05/28/python-look-ahead-multiple-elements-in-an-iteratorgenerator/</link>
      <pubDate>Thu, 28 May 2015 20:56:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/28/python-look-ahead-multiple-elements-in-an-iteratorgenerator/</guid>
      <description>events = [ {&amp;#39;event&amp;#39;: u&amp;#39;Booking Pedro (Barcelona) is shown the yellow card for a bad foul.&amp;#39;, &amp;#39;sortable_time&amp;#39;: 5083, &amp;#39;match_id&amp;#39;: &amp;#39;32683310&amp;#39;, &amp;#39;formatted_time&amp;#39;: u&amp;#39;84:43&amp;#39;}, {&amp;#39;event&amp;#39;: u&amp;#39;Rafinha (FC Bayern M\xfcnchen) wins a free kick on the right wing.&amp;#39;, &amp;#39;sortable_time&amp;#39;: 5078, &amp;#39;match_id&amp;#39;: &amp;#39;32683310&amp;#39;, &amp;#39;formatted_time&amp;#39;: u&amp;#39;84:38&amp;#39;}, {&amp;#39;event&amp;#39;: u&amp;#39;Foul by Pedro (Barcelona).&amp;#39;, &amp;#39;sortable_time&amp;#39;: 5078, &amp;#39;match_id&amp;#39;: &amp;#39;32683310&amp;#39;, &amp;#39;formatted_time&amp;#39;: u&amp;#39;84:38&amp;#39;} ] def cards(events): events = iter(events) item = events.next() next = events.next() event_id = 0 for next_next in events: event = item[&amp;#34;event&amp;#34;] booking = re.</description>
    </item>
    
    <item>
      <title>Python: Joining multiple generators/iterators</title>
      <link>https://markhneedham.com/blog/2015/05/24/python-joining-multiple-generatorsiterators/</link>
      <pubDate>Sun, 24 May 2015 23:51:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/24/python-joining-multiple-generatorsiterators/</guid>
      <description>In my previous blog post I described how I&amp;rsquo;d refactored some scraping code I&amp;rsquo;ve been working on to use iteratorsand ended up with a function which returned a generator containing all the events for one BBC live text match:
match_id = &amp;#34;32683310&amp;#34; events = extract_events(&amp;#34;data/raw/%s&amp;#34; % (match_id)) &amp;gt;&amp;gt;&amp;gt; print type(events) &amp;lt;type &amp;#39;generator&amp;#39;&amp;gt; Make an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable, until all of the iterables are exhausted.</description>
    </item>
    
    <item>
      <title>Python: Refactoring to iterator</title>
      <link>https://markhneedham.com/blog/2015/05/23/python-refactoring-to-iterator/</link>
      <pubDate>Sat, 23 May 2015 10:14:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/23/python-refactoring-to-iterator/</guid>
      <description>import bs4 import re from bs4 import BeautifulSoup from soupselect import select def extract_events(file): match = open(file, &amp;#39;r&amp;#39;) soup = BeautifulSoup(match.read()) all_events = [] for event in select(soup, &amp;#39;div#live-text-commentary-wrapper div#live-text&amp;#39;): for child in event.children: if type(child) is bs4.element.Tag: all_events.append(child.getText().strip()) for event in select(soup, &amp;#39;div#live-text-commentary-wrapper div#more-live-text&amp;#39;): for child in event.children: if type(child) is bs4.element.Tag: all_events.append(child.getText().strip()) timed_events = [] for i in range(0, len(all_events)): event = all_events[i] time = re.findall(&amp;#34;\d{1,2}:\d{2}&amp;#34;, event) formatted_time = &amp;#34; +&amp;#34;.</description>
    </item>
    
    <item>
      <title>Python: UnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode character u&#39;\xfc&#39; in position 11: ordinal not in range(128)</title>
      <link>https://markhneedham.com/blog/2015/05/21/python-unicodeencodeerror-ascii-codec-cant-encode-character-uxfc-in-position-11-ordinal-not-in-range128/</link>
      <pubDate>Thu, 21 May 2015 06:14:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/21/python-unicodeencodeerror-ascii-codec-cant-encode-character-uxfc-in-position-11-ordinal-not-in-range128/</guid>
      <description>$ python extract_players.py (u&amp;#39;Sergio Busquets&amp;#39;, u&amp;#39;Barcelona&amp;#39;) (u&amp;#39;Javier Mascherano&amp;#39;, u&amp;#39;Barcelona&amp;#39;) (u&amp;#39;Jordi Alba&amp;#39;, u&amp;#39;Barcelona&amp;#39;) (u&amp;#39;Bastian Schweinsteiger&amp;#39;, u&amp;#39;FC Bayern M\xfcnchen&amp;#39;) (u&amp;#39;Dani Alves&amp;#39;, u&amp;#39;Barcelona&amp;#39;) with open(&amp;#34;data/players.csv&amp;#34;, &amp;#34;w&amp;#34;) as file: writer = csv.writer(file, delimiter=&amp;#34;,&amp;#34;) writer.writerow([&amp;#34;player&amp;#34;, &amp;#34;team&amp;#34;]) for player, team in players: print player, team, type(player), type(team) writer.writerow([player, team]) $ python extract_players.py ... Bastian Schweinsteiger FC Bayern München &amp;lt;type &amp;#39;unicode&amp;#39;&amp;gt; &amp;lt;type &amp;#39;unicode&amp;#39;&amp;gt; Traceback (most recent call last): File &amp;#34;extract_players.py&amp;#34;, line 67, in &amp;lt;module&amp;gt; writer.writerow([player, team]) UnicodeEncodeError: &amp;#39;ascii&amp;#39; codec can&amp;#39;t encode character u&amp;#39;\xfc&amp;#39; in position 11: ordinal not in range(128) with open(&amp;#34;data/players.</description>
    </item>
    
    <item>
      <title>Python: Selecting certain indexes in an array</title>
      <link>https://markhneedham.com/blog/2015/05/05/python-selecting-certain-indexes-in-an-array/</link>
      <pubDate>Tue, 05 May 2015 21:39:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/05/python-selecting-certain-indexes-in-an-array/</guid>
      <description>import requests from bs4 import BeautifulSoup from soupselect import select page = open(&amp;#34;constituencies.html&amp;#34;, &amp;#39;r&amp;#39;) soup = BeautifulSoup(page.read()) for row in select(soup, &amp;#34;table.wikitable tr&amp;#34;): if select(row, &amp;#34;th&amp;#34;): print [cell.text for cell in select(row, &amp;#34;th&amp;#34;)] if select(row, &amp;#34;td&amp;#34;): print [cell.text for cell in select(row, &amp;#34;td&amp;#34;)] $ python blog.py [u&amp;#39;Constituency&amp;#39;, u&amp;#39;Electorate (2000)&amp;#39;, u&amp;#39;Electorate (2010)&amp;#39;, u&amp;#39;Largest Local Authority&amp;#39;, u&amp;#39;Country of the UK&amp;#39;] [u&amp;#39;Aldershot&amp;#39;, u&amp;#39;66,499&amp;#39;, u&amp;#39;71,908&amp;#39;, u&amp;#39;Hampshire&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Aldridge-Brownhills&amp;#39;, u&amp;#39;58,695&amp;#39;, u&amp;#39;59,506&amp;#39;, u&amp;#39;West Midlands&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Altrincham and Sale West&amp;#39;, u&amp;#39;69,605&amp;#39;, u&amp;#39;72,008&amp;#39;, u&amp;#39;Greater Manchester&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Amber Valley&amp;#39;, u&amp;#39;66,406&amp;#39;, u&amp;#39;69,538&amp;#39;, u&amp;#39;Derbyshire&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Arundel and South Downs&amp;#39;, u&amp;#39;71,203&amp;#39;, u&amp;#39;76,697&amp;#39;, u&amp;#39;West Sussex&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Ashfield&amp;#39;, u&amp;#39;74,674&amp;#39;, u&amp;#39;77,049&amp;#39;, u&amp;#39;Nottinghamshire&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Ashford&amp;#39;, u&amp;#39;72,501&amp;#39;, u&amp;#39;81,947&amp;#39;, u&amp;#39;Kent&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Ashton-under-Lyne&amp;#39;, u&amp;#39;67,334&amp;#39;, u&amp;#39;68,553&amp;#39;, u&amp;#39;Greater Manchester&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Aylesbury&amp;#39;, u&amp;#39;72,023&amp;#39;, u&amp;#39;78,750&amp;#39;, u&amp;#39;Buckinghamshire&amp;#39;, u&amp;#39;England&amp;#39;] .</description>
    </item>
    
    <item>
      <title>Python: Creating a skewed random discrete distribution</title>
      <link>https://markhneedham.com/blog/2015/03/30/python-creating-a-skewed-random-discrete-distribution/</link>
      <pubDate>Mon, 30 Mar 2015 22:28:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/30/python-creating-a-skewed-random-discrete-distribution/</guid>
      <description>import math import numpy as np values = range(1, 209) probs = [1.0 / 208] * 208 for idx, prob in enumerate(probs): if idx &amp;gt; 3 and idx &amp;lt; 20: probs[idx] = probs[idx] * (1 + math.log(idx + 1)) if idx &amp;gt; 20 and idx &amp;lt; 40: probs[idx] = probs[idx] * (1 + math.log((40 - idx) + 1)) probs = [p / sum(probs) for p in probs] sample = np.random.choice(values, 1000, p=probs) &amp;gt;&amp;gt;&amp;gt; print sample[:10] [ 33 9 22 126 54 4 20 17 45 56] import matplotlib matplotlib.</description>
    </item>
    
    <item>
      <title>Python: matplotlib hangs and shows nothing (Mac OS X)</title>
      <link>https://markhneedham.com/blog/2015/03/26/python-matplotlib-hangs-and-shows-nothing-mac-os-x/</link>
      <pubDate>Thu, 26 Mar 2015 00:02:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/26/python-matplotlib-hangs-and-shows-nothing-mac-os-x/</guid>
      <description>import numpy as np import matplotlib.pyplot as plt N = 5 ind = np.arange(N) fig, ax = plt.subplots() menMeans = (20, 35, 30, 35, 27) menStd = (2, 3, 4, 1, 2) width = 0.35 # the width of the bars rects1 = ax.bar(ind, menMeans, width, color=&amp;#39;r&amp;#39;, yerr=menStd) plt.show() import numpy as np import matplotlib matplotlib.use(&amp;#39;TkAgg&amp;#39;) import matplotlib.pyplot as plt N = 5 ind = np.arange(N) fig, ax = plt.subplots() menMeans = (20, 35, 30, 35, 27) menStd = (2, 3, 4, 1, 2) width = 0.</description>
    </item>
    
    <item>
      <title>Topic Modelling: Working out the optimal number of topics</title>
      <link>https://markhneedham.com/blog/2015/03/24/topic-modelling-working-out-the-optimal-number-of-topics/</link>
      <pubDate>Tue, 24 Mar 2015 22:33:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/24/topic-modelling-working-out-the-optimal-number-of-topics/</guid>
      <description>There are computational ways of searching for this, including using MALLETs hlda command, but for the reader of this tutorial, it is probably just quicker to cycle through a number of iterations (but for more see Griffiths, T. L., &amp;amp; Steyvers, M. (2004). Finding scientific topics. Proceedings of the National Academy of Science, 101, 5228-5235).
As I understand it, the idea is to try and get a uniform spread of topics -&amp;gt; documents i.</description>
    </item>
    
    <item>
      <title>Python: Equivalent to flatMap for flattening an array of arrays</title>
      <link>https://markhneedham.com/blog/2015/03/23/python-equivalent-to-flatmap-for-flattening-an-array-of-arrays/</link>
      <pubDate>Mon, 23 Mar 2015 00:45:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/23/python-equivalent-to-flatmap-for-flattening-an-array-of-arrays/</guid>
      <description>episodes = [ {&amp;#34;id&amp;#34;: 1, &amp;#34;topics&amp;#34;: [1,2,3]}, {&amp;#34;id&amp;#34;: 2, &amp;#34;topics&amp;#34;: [4,5,6]} ] flattened_episodes = [] for episode in episodes: for topic in episode[&amp;#34;topics&amp;#34;]: flattened_episodes.append({&amp;#34;id&amp;#34;: episode[&amp;#34;id&amp;#34;], &amp;#34;topic&amp;#34;: topic}) for episode in flattened_episodes: print episode $ python flatten.py {&amp;#39;topic&amp;#39;: 1, &amp;#39;id&amp;#39;: 1} {&amp;#39;topic&amp;#39;: 2, &amp;#39;id&amp;#39;: 1} {&amp;#39;topic&amp;#39;: 3, &amp;#39;id&amp;#39;: 1} {&amp;#39;topic&amp;#39;: 4, &amp;#39;id&amp;#39;: 2} {&amp;#39;topic&amp;#39;: 5, &amp;#39;id&amp;#39;: 2} {&amp;#39;topic&amp;#39;: 6, &amp;#39;id&amp;#39;: 2} flattened_episodes = [{&amp;#34;id&amp;#34;: episode[&amp;#34;id&amp;#34;], &amp;#34;topic&amp;#34;: topic} for episode in episodes for topic in episode[&amp;#34;topics&amp;#34;]] for episode in flattened_episodes: print episode from itertools import chain, imap flattened_episodes = chain.</description>
    </item>
    
    <item>
      <title>Python: Simplifying the creation of a stop word list with defaultdict</title>
      <link>https://markhneedham.com/blog/2015/03/22/python-simplifying-the-creation-of-a-stop-word-list-with-defaultdict/</link>
      <pubDate>Sun, 22 Mar 2015 01:51:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/22/python-simplifying-the-creation-of-a-stop-word-list-with-defaultdict/</guid>
      <description>import csv from sklearn.feature_extraction.text import CountVectorizer from collections import defaultdict episodes = defaultdict(str) with open(&amp;#34;sentences.csv&amp;#34;, &amp;#34;r&amp;#34;) as file: reader = csv.reader(file, delimiter = &amp;#34;,&amp;#34;) reader.next() for row in reader: episodes[row[1]] += row[4] vectorizer = CountVectorizer(analyzer=&amp;#39;word&amp;#39;, min_df = 0, stop_words = &amp;#39;english&amp;#39;) matrix = vectorizer.fit_transform(episodes.values()) features = vectorizer.get_feature_names() words = {} for doc_id, doc in enumerate(matrix.todense()): for word_id, score in enumerate(doc.tolist()[0]): word = features[word_id] if not words.get(word): words[word] = {} if not words[word].</description>
    </item>
    
    <item>
      <title>Python: Forgetting to use enumerate</title>
      <link>https://markhneedham.com/blog/2015/03/22/python-forgetting-to-use-enumerate/</link>
      <pubDate>Sun, 22 Mar 2015 01:28:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/22/python-forgetting-to-use-enumerate/</guid>
      <description>words = [&amp;#34;mark&amp;#34;, &amp;#34;neo4j&amp;#34;, &amp;#34;michael&amp;#34;] word_position = 0 for word in words: print word_position, word word_position +=1 for word_position, word in enumerate(words): print word_position, word </description>
    </item>
    
    <item>
      <title>Python: Transforming Twitter datetime string to timestamp (z&#39; is a bad directive in format)</title>
      <link>https://markhneedham.com/blog/2015/03/15/python-transforming-twitter-datetime-string-to-timestamp-z-is-a-bad-directive-in-format/</link>
      <pubDate>Sun, 15 Mar 2015 22:43:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/15/python-transforming-twitter-datetime-string-to-timestamp-z-is-a-bad-directive-in-format/</guid>
      <description>from datetime import datetime date = &amp;#34;Sat Mar 14 18:43:19 +0000 2015&amp;#34; &amp;gt;&amp;gt;&amp;gt; datetime.strptime(date, &amp;#34;%a %b %d%H:%M:%S %z %Y&amp;#34;) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/_strptime.py&amp;#34;, line 317, in _strptime (bad_directive, format)) ValueError: &amp;#39;z&amp;#39; is a bad directive in format &amp;#39;%a %b %d%H:%M:%S %z %Y&amp;#39; $ pip install python-dateutil from dateutil import parser parsed_date = parser.parse(date) &amp;gt;&amp;gt;&amp;gt; parsed_date datetime.datetime(2015, 3, 14, 18, 43, 19, tzinfo=tzutc()) import calendar timestamp = calendar.</description>
    </item>
    
    <item>
      <title>Python: Checking any value in a list exists in a line of text</title>
      <link>https://markhneedham.com/blog/2015/03/14/python-checking-any-value-in-a-list-exists-in-a-line-of-text/</link>
      <pubDate>Sat, 14 Mar 2015 02:52:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/14/python-checking-any-value-in-a-list-exists-in-a-line-of-text/</guid>
      <description>$ cat blog.txt MATCH n RETURN n MERGE (n:Person {name: &amp;#34;Mark&amp;#34;}) RETURN n MATCH (n:Person {name: &amp;#34;Mark&amp;#34;}) ON MATCH SET n.counter = 1 RETURN n with open(&amp;#34;blog.txt&amp;#34;, &amp;#34;r&amp;#34;) as ins: for line in ins: if &amp;#34;MERGE&amp;#34; in line or &amp;#34;DELETE&amp;#34; in line or &amp;#34;SET&amp;#34; in line or &amp;#34;CREATE&amp;#34; in line: print line.strip() mutating_commands = [&amp;#34;SET&amp;#34;, &amp;#34;DELETE&amp;#34;, &amp;#34;MERGE&amp;#34;, &amp;#34;CREATE&amp;#34;] with open(&amp;#34;blog.txt&amp;#34;, &amp;#34;r&amp;#34;) as ins: for line in ins: if any(command in line for command in mutating_commands): print line.</description>
    </item>
    
    <item>
      <title>Python/Neo4j: Finding interesting computer sciency people to follow on Twitter</title>
      <link>https://markhneedham.com/blog/2015/03/11/pythonneo4j-finding-interesting-computer-sciency-people-to-follow-on-twitter/</link>
      <pubDate>Wed, 11 Mar 2015 21:13:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/11/pythonneo4j-finding-interesting-computer-sciency-people-to-follow-on-twitter/</guid>
      <description>import tweepy import csv from collections import Counter, deque auth = tweepy.OAuthHandler(consumer_key, consumer_secret) auth.set_access_token(access_token, access_token_secret) api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True) counter = Counter() users_to_process = deque() USERS_TO_PROCESS = 50 def extract_tweet(tweet): user_mentions = &amp;#34;,&amp;#34;.join([user[&amp;#34;screen_name&amp;#34;].encode(&amp;#34;utf-8&amp;#34;) for user in tweet.entities[&amp;#34;user_mentions&amp;#34;]]) urls = &amp;#34;,&amp;#34;.join([url[&amp;#34;expanded_url&amp;#34;] for url in tweet.entities[&amp;#34;urls&amp;#34;]]) return [tweet.user.screen_name.encode(&amp;#34;utf-8&amp;#34;), tweet.id, tweet.text.encode(&amp;#34;utf-8&amp;#34;), user_mentions, urls] starting_user = &amp;#34;chvest&amp;#34; with open(&amp;#34;tweets.csv&amp;#34;, &amp;#34;a&amp;#34;) as tweets: writer = csv.writer(tweets, delimiter=&amp;#34;,&amp;#34;, escapechar=&amp;#34;\\&amp;#34;, doublequote = False) for tweet in tweepy.</description>
    </item>
    
    <item>
      <title>Python: Streaming/Appending to a file</title>
      <link>https://markhneedham.com/blog/2015/03/09/python-streamingappending-to-a-file/</link>
      <pubDate>Mon, 09 Mar 2015 23:00:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/09/python-streamingappending-to-a-file/</guid>
      <description>import csv import time with open(&amp;#34;rows.csv&amp;#34;, &amp;#34;a&amp;#34;) as file: writer = csv.writer(file, delimiter = &amp;#34;,&amp;#34;) end = time.time() + 10 while True: if time.time() &amp;gt; end: break else: writer.writerow([&amp;#34;mark&amp;#34;, &amp;#34;123&amp;#34;]) time.sleep(1) $ date &amp;amp;&amp;amp; wc -l rows.csv Mon 9 Mar 2015 22:54:27 GMT 0 rows.csv $ date &amp;amp;&amp;amp; wc -l rows.csv Mon 9 Mar 2015 22:54:31 GMT 0 rows.csv $ date &amp;amp;&amp;amp; wc -l rows.csv Mon 9 Mar 2015 22:54:34 GMT 0 rows.</description>
    </item>
    
    <item>
      <title>Python: scikit-learn/lda: Extracting topics from QCon talk abstracts</title>
      <link>https://markhneedham.com/blog/2015/03/05/python-scikit-learnlda-extracting-topics-from-qcon-talk-abstracts/</link>
      <pubDate>Thu, 05 Mar 2015 08:52:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/05/python-scikit-learnlda-extracting-topics-from-qcon-talk-abstracts/</guid>
      <description>import csv from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer from sklearn.decomposition import NMF from collections import defaultdict from bs4 import BeautifulSoup, NavigableString from soupselect import select def uri_to_file_name(uri): return uri.replace(&amp;#34;/&amp;#34;, &amp;#34;-&amp;#34;) sessions = {} with open(&amp;#34;data/sessions.csv&amp;#34;, &amp;#34;r&amp;#34;) as sessions_file: reader = csv.reader(sessions_file, delimiter = &amp;#34;,&amp;#34;) reader.next() # header for row in reader: session_id = int(row[0]) filename = &amp;#34;data/sessions/&amp;#34; + uri_to_file_name(row[4]) page = open(filename).read() soup = BeautifulSoup(page) abstract = select(soup, &amp;#34;div.brenham-main-content p&amp;#34;) if abstract: sessions[session_id] = {&amp;#34;abstract&amp;#34; : abstract[0].</description>
    </item>
    
    <item>
      <title>Python: scikit-learn - Training a classifier with non numeric features</title>
      <link>https://markhneedham.com/blog/2015/03/02/python-scikit-learn-training-a-classifier-with-non-numeric-features/</link>
      <pubDate>Mon, 02 Mar 2015 07:48:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/02/python-scikit-learn-training-a-classifier-with-non-numeric-features/</guid>
      <description>import json import nltk import collections from himymutil.ml import pos_features from sklearn import tree from sklearn.cross_validation import train_test_split with open(&amp;#34;data/import/trained_sentences.json&amp;#34;, &amp;#34;r&amp;#34;) as json_file: json_data = json.load(json_file) tagged_sents = [] for sentence in json_data: tagged_sents.append([(word[&amp;#34;word&amp;#34;], word[&amp;#34;speaker&amp;#34;]) for word in sentence[&amp;#34;words&amp;#34;]]) featuresets = [] for tagged_sent in tagged_sents: untagged_sent = nltk.tag.untag(tagged_sent) sentence_pos = nltk.pos_tag(untagged_sent) for i, (word, tag) in enumerate(tagged_sent): featuresets.append((pos_features(untagged_sent, sentence_pos, i), tag) ) clf = tree.DecisionTreeClassifier() train_data, test_data = train_test_split(featuresets, test_size=0.</description>
    </item>
    
    <item>
      <title>Python: Detecting the speaker in HIMYM using Parts of Speech (POS) tagging</title>
      <link>https://markhneedham.com/blog/2015/03/01/python-detecting-the-speaker-in-himym-using-parts-of-speech-pos-tagging/</link>
      <pubDate>Sun, 01 Mar 2015 02:36:06 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/01/python-detecting-the-speaker-in-himym-using-parts-of-speech-pos-tagging/</guid>
      <description>def pos_features(sentence, sentence_pos, i): features = {} features[&amp;#34;word&amp;#34;] = sentence[i] features[&amp;#34;word-pos&amp;#34;] = sentence_pos[i][1] if i == 0: features[&amp;#34;prev-word&amp;#34;] = &amp;#34;&amp;lt;START&amp;gt;&amp;#34; features[&amp;#34;prev-word-pos&amp;#34;] = &amp;#34;&amp;lt;START&amp;gt;&amp;#34; else: features[&amp;#34;prev-word&amp;#34;] = sentence[i-1] features[&amp;#34;prev-word-pos&amp;#34;] = sentence_pos[i-1][1] if i == len(sentence) - 1: features[&amp;#34;next-word&amp;#34;] = &amp;#34;&amp;lt;END&amp;gt;&amp;#34; features[&amp;#34;next-word-pos&amp;#34;] = &amp;#34;&amp;lt;END&amp;gt;&amp;#34; else: features[&amp;#34;next-word&amp;#34;] = sentence[i+1] features[&amp;#34;next-word-pos&amp;#34;] = sentence_pos[i+1][1] return features featuresets = [] for tagged_sent in tagged_sents: untagged_sent = nltk.tag.untag(tagged_sent) sentence_pos = nltk.pos_tag(untagged_sent) for i, (word, tag) in enumerate(tagged_sent): featuresets.</description>
    </item>
    
    <item>
      <title>Python/nltk: Naive vs Naive Bayes vs Decision Tree</title>
      <link>https://markhneedham.com/blog/2015/02/24/pythonnltk-naive-vs-naive-bayes-vs-decision-tree/</link>
      <pubDate>Tue, 24 Feb 2015 22:39:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/24/pythonnltk-naive-vs-naive-bayes-vs-decision-tree/</guid>
      <description>import nltk from nltk import ClassifierI class NaiveClassifier(ClassifierI): def classify(self, featureset): if featureset[&amp;#39;next-word&amp;#39;] == &amp;#34;:&amp;#34;: return True else: return False import nltk import collections def assess_classifier(classifier, test_data, text): refsets = collections.defaultdict(set) testsets = collections.defaultdict(set) for i, (feats, label) in enumerate(test_data): refsets[label].add(i) observed = classifier.classify(feats) testsets[observed].add(i) speaker_precision = nltk.metrics.precision(refsets[True], testsets[True]) speaker_recall = nltk.metrics.recall(refsets[True], testsets[True]) non_speaker_precision = nltk.metrics.precision(refsets[False], testsets[False]) non_speaker_recall = nltk.metrics.recall(refsets[False], testsets[False]) return [text, speaker_precision, speaker_recall, non_speaker_precision, non_speaker_recall] import json from sklearn.</description>
    </item>
    
    <item>
      <title>Python/scikit-learn: Detecting which sentences in a transcript contain a speaker</title>
      <link>https://markhneedham.com/blog/2015/02/20/pythonscikit-learn-detecting-which-sentences-in-a-transcript-contain-a-speaker/</link>
      <pubDate>Fri, 20 Feb 2015 22:42:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/20/pythonscikit-learn-detecting-which-sentences-in-a-transcript-contain-a-speaker/</guid>
      <description>&amp;lt;speaker&amp;gt;: &amp;lt;sentence&amp;gt; import json with open(&amp;#34;data/import/trained_sentences.json&amp;#34;, &amp;#34;r&amp;#34;) as json_file: json_data = json.load(json_file) &amp;gt;&amp;gt;&amp;gt; json_data[0] {u&amp;#39;words&amp;#39;: [{u&amp;#39;word&amp;#39;: u&amp;#39;You&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;ca&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#34;n&amp;#39;t&amp;#34;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;be&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;friends&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;with&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;Robin&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;.&amp;#39;, u&amp;#39;speaker&amp;#39;: False}]} &amp;gt;&amp;gt;&amp;gt; json_data[1] {u&amp;#39;words&amp;#39;: [{u&amp;#39;word&amp;#39;: u&amp;#39;Robin&amp;#39;, u&amp;#39;speaker&amp;#39;: True}, {u&amp;#39;word&amp;#39;: u&amp;#39;:&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;Well&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;...&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;it&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#34;&amp;#39;s&amp;#34;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;a&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;bit&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;early&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;.</description>
    </item>
    
    <item>
      <title>Python/pandas: Column value in list (ValueError: The truth value of a Series is ambiguous.)</title>
      <link>https://markhneedham.com/blog/2015/02/16/pythonpandas-column-value-in-list-valueerror-the-truth-value-of-a-series-is-ambiguous/</link>
      <pubDate>Mon, 16 Feb 2015 21:39:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/16/pythonpandas-column-value-in-list-valueerror-the-truth-value-of-a-series-is-ambiguous/</guid>
      <description>$ cat foo.csv &amp;#34;Foo&amp;#34; 1 2 3 4 5 6 7 8 9 10 import pandas as pd df = pd.read_csv(&amp;#39;foo.csv&amp;#39;, index_col=False, header=0) &amp;gt;&amp;gt;&amp;gt; df Foo 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 &amp;gt;&amp;gt;&amp;gt; df[df[&amp;#34;Foo&amp;#34;] == 1] Foo 0 1 &amp;gt;&amp;gt;&amp;gt; df[df[&amp;#34;Foo&amp;#34;] &amp;lt; 7] Foo 0 1 1 2 2 3 3 4 4 5 5 6 odds = [i for i in range(1,10) if i % 2 &amp;lt;&amp;gt; 0] &amp;gt;&amp;gt;&amp;gt; odds [1, 3, 5, 7, 9] &amp;gt;&amp;gt;&amp;gt; df[df[&amp;#34;Foo&amp;#34;] in odds] Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.</description>
    </item>
    
    <item>
      <title>Python/scikit-learn: Calculating TF/IDF on How I met your mother transcripts</title>
      <link>https://markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/</link>
      <pubDate>Sun, 15 Feb 2015 15:56:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/</guid>
      <description>It is often used as a weighting factor in information retrieval and text mining.
The tf-idf value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.
from collections import defaultdict import csv episodes = defaultdict(list) with open(&amp;#34;data/import/sentences.csv&amp;#34;, &amp;#34;r&amp;#34;) as sentences_file: reader = csv.</description>
    </item>
    
    <item>
      <title>Neo4j: Building a topic graph with Prismatic Interest Graph API</title>
      <link>https://markhneedham.com/blog/2015/02/13/neo4j-building-a-topic-graph-with-prismatic-interest-graph-api/</link>
      <pubDate>Fri, 13 Feb 2015 23:38:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/13/neo4j-building-a-topic-graph-with-prismatic-interest-graph-api/</guid>
      <description>import requests payload = { &amp;#39;title&amp;#39;: &amp;#34;insert title of article here&amp;#34;, &amp;#39;body&amp;#39;: &amp;#34;insert body of text here&amp;#34;), &amp;#39;api-token&amp;#39;: &amp;#34;insert token sent by email here&amp;#34;} r = requests.post(&amp;#34;http://interest-graph.getprismatic.com/text/topic&amp;#34;, data=payload) import time def RateLimited(maxPerSecond): minInterval = 1.0 / float(maxPerSecond) def decorate(func): lastTimeCalled = [0.0] def rateLimitedFunction(*args,**kargs): elapsed = time.clock() - lastTimeCalled[0] leftToWait = minInterval - elapsed if leftToWait&amp;gt;0: time.sleep(leftToWait) ret = func(*args,**kargs) lastTimeCalled[0] = time.clock() return ret return rateLimitedFunction return decorate @RateLimited(0.3) def topics(title, body): payload = { &amp;#39;title&amp;#39;: title, &amp;#39;body&amp;#39;: body, &amp;#39;api-token&amp;#39;: &amp;#34;insert token sent by email here&amp;#34;} r = requests.</description>
    </item>
    
    <item>
      <title>Python/gensim: Creating bigrams over How I met your mother transcripts</title>
      <link>https://markhneedham.com/blog/2015/02/12/pythongensim-creating-bigrams-over-how-i-met-your-mother-transcripts/</link>
      <pubDate>Thu, 12 Feb 2015 23:45:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/12/pythongensim-creating-bigrams-over-how-i-met-your-mother-transcripts/</guid>
      <description>$ head -n 15 data/import/sentences.csv | tail 5,1,1,1,Son: Are we being punished for something? 6,1,1,1,Narrator: No 7,1,1,1,&amp;#34;Daughter: Yeah, is this going to take a while?&amp;#34; 8,1,1,1,&amp;#34;Narrator: Yes. (Kids are annoyed) Twenty-five years ago, before I was dad, I had this whole other life.&amp;#34; 9,1,1,1,&amp;#34;(Music Plays, Title &amp;#34;&amp;#34;How I Met Your Mother&amp;#34;&amp;#34; appears)&amp;#34; 10,1,1,1,&amp;#34;Narrator: It was way back in 2005. I was twenty-seven just starting to make it as an architect and living in New York with my friend Marshall, my best friend from college.</description>
    </item>
    
    <item>
      <title>Python/matpotlib: Plotting occurrences of the main characters in How I Met Your Mother</title>
      <link>https://markhneedham.com/blog/2015/01/30/pythonmatpotlib-plotting-occurrences-of-the-main-characters-in-how-i-met-your-mother/</link>
      <pubDate>Fri, 30 Jan 2015 21:29:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/30/pythonmatpotlib-plotting-occurrences-of-the-main-characters-in-how-i-met-your-mother/</guid>
      <description>$ head -n 10 data/import/sentences.csv SentenceId,EpisodeId,Season,Episode,Sentence 1,1,1,1,Pilot 2,1,1,1,Scene One 3,1,1,1,[Title: The Year 2030] 4,1,1,1,&amp;#34;Narrator: Kids, I&amp;#39;m going to tell you an incredible story. The story of how I met your mother&amp;#34; 5,1,1,1,Son: Are we being punished for something? 6,1,1,1,Narrator: No 7,1,1,1,&amp;#34;Daughter: Yeah, is this going to take a while?&amp;#34; 8,1,1,1,&amp;#34;Narrator: Yes. (Kids are annoyed) Twenty-five years ago, before I was dad, I had this whole other life.&amp;#34; 9,1,1,1,&amp;#34;(Music Plays, Title &amp;#34;&amp;#34;How I Met Your Mother&amp;#34;&amp;#34; appears)&amp;#34; import csv from collections import defaultdict episodes = defaultdict(list) with open(&amp;#34;data/import/sentences.</description>
    </item>
    
    <item>
      <title>Python: Find the highest value in a group</title>
      <link>https://markhneedham.com/blog/2015/01/25/python-find-the-highest-value-in-a-group/</link>
      <pubDate>Sun, 25 Jan 2015 12:47:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/25/python-find-the-highest-value-in-a-group/</guid>
      <description>$ head -n 10 data/import/episodes.csv NumberOverall,NumberInSeason,Episode,Season,DateAired,Timestamp 1,1,/wiki/Pilot,1,&amp;#34;September 19, 2005&amp;#34;,1127084400 2,2,/wiki/Purple_Giraffe,1,&amp;#34;September 26, 2005&amp;#34;,1127689200 3,3,/wiki/Sweet_Taste_of_Liberty,1,&amp;#34;October 3, 2005&amp;#34;,1128294000 4,4,/wiki/Return_of_the_Shirt,1,&amp;#34;October 10, 2005&amp;#34;,1128898800 5,5,/wiki/Okay_Awesome,1,&amp;#34;October 17, 2005&amp;#34;,1129503600 6,6,/wiki/Slutty_Pumpkin,1,&amp;#34;October 24, 2005&amp;#34;,1130108400 7,7,/wiki/Matchmaker,1,&amp;#34;November 7, 2005&amp;#34;,1131321600 8,8,/wiki/The_Duel,1,&amp;#34;November 14, 2005&amp;#34;,1131926400 9,9,/wiki/Belly_Full_of_Turkey,1,&amp;#34;November 21, 2005&amp;#34;,1132531200 import csv from collections import defaultdict seasons = defaultdict(list) with open(&amp;#34;data/import/episodes.csv&amp;#34;, &amp;#34;r&amp;#34;) as episodesfile: reader = csv.reader(episodesfile, delimiter = &amp;#34;,&amp;#34;) reader.next() for row in reader: seasons[int(row[3])].append(int(row[0])) print seasons $ python blog.py defaultdict(&amp;lt;type &amp;#39;list&amp;#39;&amp;gt;, { 1: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], 2: [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], 3: [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64], 4: [65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], 5: [89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], 6: [113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136], 7: [137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160], 8: [161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], 9: [185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]}) for season, episode_ids in seasons.</description>
    </item>
    
    <item>
      <title>Python/pdfquery: Scraping the FIFA World Player of the Year votes PDF into shape</title>
      <link>https://markhneedham.com/blog/2015/01/22/pythonpdfquery-scraping-the-fifa-world-player-of-the-year-votes-pdf-into-shape/</link>
      <pubDate>Thu, 22 Jan 2015 00:25:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/22/pythonpdfquery-scraping-the-fifa-world-player-of-the-year-votes-pdf-into-shape/</guid>
      <description>import pdfquery pdf = pdfquery.PDFQuery(&amp;#34;fboaward_menplayer2014_neutral.pdf&amp;#34;) pdf.load() pdf.tree.write(&amp;#34;/tmp/yadda&amp;#34;, pretty_print=True) $ head -n 10 /tmp/yadda &amp;lt;pdfxml ModDate=&amp;#34;D:20150110224554+01&amp;#39;00&amp;#39;&amp;#34; CreationDate=&amp;#34;D:20150110224539+01&amp;#39;00&amp;#39;&amp;#34; Producer=&amp;#34;Microsoft&amp;amp;#174; Excel&amp;amp;#174; 2010&amp;#34; Creator=&amp;#34;Microsoft&amp;amp;#174; Excel&amp;amp;#174; 2010&amp;#34;&amp;gt; &amp;lt;LTPage bbox=&amp;#34;[0, 0, 841.8, 595.2]&amp;#34; height=&amp;#34;595.2&amp;#34; pageid=&amp;#34;1&amp;#34; rotate=&amp;#34;0&amp;#34; width=&amp;#34;841.8&amp;#34; x0=&amp;#34;0&amp;#34; x1=&amp;#34;841.8&amp;#34; y0=&amp;#34;0&amp;#34; y1=&amp;#34;595.2&amp;#34; page_index=&amp;#34;0&amp;#34; page_label=&amp;#34;&amp;#34;&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTTextLineHorizontal bbox=&amp;#34;[31.08, 546.15, 122.524, 556.59]&amp;#34; height=&amp;#34;10.44&amp;#34; width=&amp;#34;91.444&amp;#34; word_margin=&amp;#34;0.1&amp;#34; x0=&amp;#34;31.08&amp;#34; x1=&amp;#34;122.524&amp;#34; y0=&amp;#34;546.15&amp;#34; y1=&amp;#34;556.59&amp;#34;&amp;gt;&amp;lt;LTTextBoxHorizontal bbox=&amp;#34;[31.08, 546.15, 122.524, 556.59]&amp;#34; height=&amp;#34;10.44&amp;#34; index=&amp;#34;0&amp;#34; width=&amp;#34;91.444&amp;#34; x0=&amp;#34;31.08&amp;#34; x1=&amp;#34;122.524&amp;#34; y0=&amp;#34;546.15&amp;#34; y1=&amp;#34;556.59&amp;#34;&amp;gt;FIFA Ballon d&amp;#39;Or 2014 &amp;lt;/LTTextBoxHorizontal&amp;gt;&amp;lt;/LTTextLineHorizontal&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;gt;&amp;gt;&amp;gt; name_element = pdf.</description>
    </item>
    
    <item>
      <title>Python/NLTK: Finding the most common phrases in How I Met Your Mother</title>
      <link>https://markhneedham.com/blog/2015/01/19/pythonnltk-finding-the-most-common-phrases-in-how-i-met-your-mother/</link>
      <pubDate>Mon, 19 Jan 2015 00:24:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/19/pythonnltk-finding-the-most-common-phrases-in-how-i-met-your-mother/</guid>
      <description>Following on from last week&amp;rsquo;s blog postwhere I found the most popular words in How I met your mother transcripts, in this post we&amp;rsquo;ll have a look at how we can pull out sentences and then phrases from our corpus.
The first thing I did was tweak the scraping script to pull out the sentences spoken by characters in the transcripts.import csv import nltk import re import bs4 from bs4 import BeautifulSoup, NavigableString from soupselect import select from nltk.</description>
    </item>
    
    <item>
      <title>Python: Counter - ValueError: too many values to unpack</title>
      <link>https://markhneedham.com/blog/2015/01/12/python-counter-valueerror-too-many-values-to-unpack/</link>
      <pubDate>Mon, 12 Jan 2015 23:16:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/12/python-counter-valueerror-too-many-values-to-unpack/</guid>
      <description>&amp;gt;&amp;gt; from collections import Counter &amp;gt;&amp;gt; counter = Counter([&amp;#34;word1&amp;#34;, &amp;#34;word2&amp;#34;, &amp;#34;word3&amp;#34;, &amp;#34;word1&amp;#34;]) &amp;gt;&amp;gt; print counter Counter({&amp;#39;word1&amp;#39;: 2, &amp;#39;word3&amp;#39;: 1, &amp;#39;word2&amp;#39;: 1}) &amp;gt;&amp;gt;&amp;gt; for key, value in counter: ... print key, value ... Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; ValueError: too many values to unpack &amp;gt;&amp;gt;&amp;gt; for key, value in counter.iteritems(): ... print key, value ... word1 2 word3 1 word2 1 </description>
    </item>
    
    <item>
      <title>Python: scikit-learn: ImportError: cannot import name __check_build</title>
      <link>https://markhneedham.com/blog/2015/01/10/python-scikit-learn-importerror-cannot-import-name-__check_build/</link>
      <pubDate>Sat, 10 Jan 2015 08:48:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/10/python-scikit-learn-importerror-cannot-import-name-__check_build/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; from sklearn.feature_extraction.text import CountVectorizer Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/sklearn/__init__.py&amp;#34;, line 37, in &amp;lt;module&amp;gt; from . import __check_build ImportError: cannot import name __check_build &amp;gt;&amp;gt;&amp;gt; from sklearn.feature_extraction.text import CountVectorizer Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/sklearn/__init__.py&amp;#34;, line 38, in &amp;lt;module&amp;gt; from .base import clone File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/sklearn/base.py&amp;#34;, line 10, in &amp;lt;module&amp;gt; from scipy import sparse ImportError: No module named scipy $ pip install scipy $ python Python 2.</description>
    </item>
    
    <item>
      <title>Python: gensim - clang: error: unknown argument: &#39;-mno-fused-madd&#39; [-Wunused-command-line-argument-hard-error-in-future]</title>
      <link>https://markhneedham.com/blog/2015/01/10/python-gensim-clang-error-unknown-argument-mno-fused-madd-wunused-command-line-argument-hard-error-in-future/</link>
      <pubDate>Sat, 10 Jan 2015 08:39:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/10/python-gensim-clang-error-unknown-argument-mno-fused-madd-wunused-command-line-argument-hard-error-in-future/</guid>
      <description>$ pip install gensim ... cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe -I/Users/markneedham/projects/neo4j-himym/himym/build/gensim/gensim/models -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -I/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/numpy/core/include -c ./gensim/models/word2vec_inner.c -o build/temp.macosx-10.9-intel-2.7/./gensim/models/word2vec_inner.o clang: error: unknown argument: &amp;#39;-mno-fused-madd&amp;#39; [-Wunused-command-line-argument-hard-error-in-future] clang: note: this will be a hard error (cannot be downgraded to a warning) in the future command &amp;#39;cc&amp;#39; failed with exit status 1 an integer is required Traceback (most recent call last): File &amp;#34;&amp;lt;string&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/build/gensim/setup.</description>
    </item>
    
    <item>
      <title>Python NLTK/Neo4j: Analysing the transcripts of How I Met Your Mother</title>
      <link>https://markhneedham.com/blog/2015/01/10/python-nltkneo4j-analysing-the-transcripts-of-how-i-met-your-mother/</link>
      <pubDate>Sat, 10 Jan 2015 01:22:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/10/python-nltkneo4j-analysing-the-transcripts-of-how-i-met-your-mother/</guid>
      <description>import requests from bs4 import BeautifulSoup from soupselect import select episodes = {} for i in range(1,3): page = open(&amp;#34;data/transcripts/page-&amp;#34; + str(i) + &amp;#34;.html&amp;#34;, &amp;#39;r&amp;#39;) soup = BeautifulSoup(page.read()) for row in select(soup, &amp;#34;td.topic-titles a&amp;#34;): parts = row.text.split(&amp;#34; - &amp;#34;) episodes[parts[0]] = {&amp;#34;title&amp;#34;: parts[1], &amp;#34;link&amp;#34;: row.get(&amp;#34;href&amp;#34;)} for key, value in episodes.iteritems(): parts = key.split(&amp;#34;x&amp;#34;) season = int(parts[0]) episode = int(parts[1]) filename = &amp;#34;data/transcripts/S%d-Ep%d&amp;#34; %(season, episode) print filename with open(filename, &amp;#39;wb&amp;#39;) as handle: headers = {&amp;#39;User-Agent&amp;#39;: &amp;#39;Mozilla/5.</description>
    </item>
    
    <item>
      <title>Python: Converting a date string to timestamp</title>
      <link>https://markhneedham.com/blog/2014/10/20/python-converting-a-date-string-to-timestamp/</link>
      <pubDate>Mon, 20 Oct 2014 15:53:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/10/20/python-converting-a-date-string-to-timestamp/</guid>
      <description>date_text = &amp;#34;13SEP2014&amp;#34; import datetime date_text = &amp;#34;13SEP2014&amp;#34; date = datetime.datetime.strptime(date_text, &amp;#34;%d%b%Y&amp;#34;) print(date) $ python dates.py 2014-09-13 00:00:00 import datetime import calendar date_text = &amp;#34;13SEP2014&amp;#34; date = datetime.datetime.strptime(date_text, &amp;#34;%d%b%Y&amp;#34;) print(date) print(calendar.timegm(date.utctimetuple())) $ python dates.py 2014-09-13 00:00:00 1410566400 </description>
    </item>
    
    <item>
      <title>Jython/Neo4j: java.lang.ExceptionInInitializerError: java.lang.ExceptionInInitializerError</title>
      <link>https://markhneedham.com/blog/2014/02/05/jythonneo4j-java-lang-exceptionininitializererror-java-lang-exceptionininitializererror/</link>
      <pubDate>Wed, 05 Feb 2014 12:21:30 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2014/02/05/jythonneo4j-java-lang-exceptionininitializererror-java-lang-exceptionininitializererror/</guid>
      <description>$ jython -Dpython.path /path/to/neo4j.jar Jython 2.5.3 (2.5:c56500f08d34+, Aug 13 2012, 14:48:36) [Java HotSpot(TM) 64-Bit Server VM (Oracle Corporation)] on java1.7.0_45 Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information. &amp;gt;&amp;gt;&amp;gt; import org.neo4j.graphdb.factory &amp;gt;&amp;gt;&amp;gt; org.neo4j.graphdb.factory.GraphDatabaseFactory().newEmbeddedDatabase(&amp;#34;/tmp/foo&amp;#34;) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; at org.neo4j.graphdb.factory.GraphDatabaseFactory$1.newDatabase(GraphDatabaseFactory.java:83) at org.neo4j.graphdb.factory.GraphDatabaseBuilder.newGraphDatabase(GraphDatabaseBuilder.java:198) at org.neo4j.graphdb.factory.GraphDatabaseFactory.newEmbeddedDatabase(GraphDatabaseFactory.java:69) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) java.lang.ExceptionInInitializerError: java.lang.ExceptionInInitializerError &amp;gt;&amp;gt;&amp;gt; import org.neo4j.graphdb.factory.GraphDatabaseSettings Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; java.</description>
    </item>
    
    <item>
      <title>Python: Making scikit-learn and pandas play nice</title>
      <link>https://markhneedham.com/blog/2013/11/09/python-making-scikit-learn-and-pandas-play-nice/</link>
      <pubDate>Sat, 09 Nov 2013 13:58:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/11/09/python-making-scikit-learn-and-pandas-play-nice/</guid>
      <description>import pandas as pd from sklearn.ensemble import ExtraTreesClassifier from sklearn.cross_validation import cross_val_score train_df = pd.read_csv(&amp;#34;train.csv&amp;#34;) et = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=1, random_state=0) columns = [&amp;#34;Fare&amp;#34;, &amp;#34;Pclass&amp;#34;] labels = train_df[&amp;#34;Survived&amp;#34;].values features = train_df[list(columns)].values et_score = cross_val_score(et, features, labels, n_jobs=-1).mean() print(&amp;#34;{0} -&amp;gt; ET: {1})&amp;#34;.format(columns, et_score)) $ head -n5 train.csv PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked 1,0,3,&amp;#34;Braund, Mr. Owen Harris&amp;#34;,male,22,1,0,A/5 21171,7.25,,S 2,1,1,&amp;#34;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&amp;#34;,female,38,1,0,PC 17599,71.2833,C85,C 3,1,3,&amp;#34;Heikkinen, Miss. Laina&amp;#34;,female,26,0,0,STON/O2. 3101282,7.925,,S 4,1,1,&amp;#34;Futrelle, Mrs. Jacques Heath (Lily May Peel)&amp;#34;,female,35,1,0,113803,53.</description>
    </item>
    
    <item>
      <title>Python: Scoping variables to use with timeit</title>
      <link>https://markhneedham.com/blog/2013/11/09/python-scoping-variables-to-use-with-timeit/</link>
      <pubDate>Sat, 09 Nov 2013 11:01:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/11/09/python-scoping-variables-to-use-with-timeit/</guid>
      <description>import query_profiler as qp attempts = [ {&amp;#34;query&amp;#34;: &amp;#39;&amp;#39;&amp;#39;MATCH (player:Player)-[:played]-&amp;gt;stats-[:in]-&amp;gt;game, stats-[:for]-&amp;gt;team WHERE game&amp;lt;-[:away_team]-team RETURN player.name, SUM(stats.goals) AS goals ORDER BY goals DESC LIMIT 10&amp;#39;&amp;#39;&amp;#39;} ] qp.profile(attempts, iterations=5, runs=3) from py2neo import neo4j import timeit graph_db = neo4j.GraphDatabaseService() def run_query(query, params): query = neo4j.CypherQuery(graph_db, query) return query.execute(**params).data def profile(attempts, iterations=10, runs=3): print &amp;#34;&amp;#34; for attempt in attempts: query = attempt[&amp;#34;query&amp;#34;] potential_params = attempt.get(&amp;#34;params&amp;#34;) params = {} if potential_params == None else potential_params timings = timeit.</description>
    </item>
    
    <item>
      <title>Python: Generate all combinations of a list</title>
      <link>https://markhneedham.com/blog/2013/11/06/python-generate-all-combinations-of-a-list/</link>
      <pubDate>Wed, 06 Nov 2013 07:25:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/11/06/python-generate-all-combinations-of-a-list/</guid>
      <description>all_columns = [&amp;#34;Fare&amp;#34;, &amp;#34;Sex&amp;#34;, &amp;#34;Pclass&amp;#34;, &amp;#39;Embarked&amp;#39;] &amp;gt;&amp;gt;&amp;gt; import itertools as it &amp;gt;&amp;gt;&amp;gt; list(it.combinations(all_columns, 3)) [(&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;)] &amp;gt;&amp;gt;&amp;gt; list(it.combinations(all_columns, 2)) + list(it.combinations(all_columns, 3)) [(&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Pclass&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;), (&amp;#39;Sex&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;)] all_the_features = [] for r in range(1, len(all_columns) + 1): all_the_features + list(it.combinations(all_columns, r)) &amp;gt;&amp;gt;&amp;gt; all_the_features [(&amp;#39;Fare&amp;#39;,), (&amp;#39;Sex&amp;#39;,), (&amp;#39;Pclass&amp;#39;,), (&amp;#39;Embarked&amp;#39;,), (&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Pclass&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;), (&amp;#39;Sex&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;), (&amp;#39;Fare&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;Embarked&amp;#39;)] &amp;gt;&amp;gt;&amp;gt; reduce(lambda acc, x: acc + list(it.</description>
    </item>
    
    <item>
      <title>Python: matplotlib -  Import error ft2font Symbol not found: _FT_Attach_File (Mac OS X 10.8.3/Mountain Lion)</title>
      <link>https://markhneedham.com/blog/2013/11/03/python-matplotlib-import-error-ft2font-symbol-not-found-_ft_attach_file-mac-os-x-10-8-3mountain-lion/</link>
      <pubDate>Sun, 03 Nov 2013 11:14:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/11/03/python-matplotlib-import-error-ft2font-symbol-not-found-_ft_attach_file-mac-os-x-10-8-3mountain-lion/</guid>
      <description>import pylab as pl ImportError: dlopen(/Library/Python/2.7/site-packages/matplotlib/ft2font.so, 2): Symbol not found: _FT_Attach_File matplotlib 1.2.1 can&amp;#39;t be installed on this disk. matplotlib requires System Python 2.7 to install. sudo brew install pkgconfig cd /tmp git clone git://github.com/matplotlib/matplotlib.git cd matplotlib/ python setup.py build sudo python setup.py install &amp;gt;&amp;gt;&amp;gt; from sklearn.tree import DecisionTreeRegressor Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 2, in &amp;lt;module&amp;gt; ImportError: No module named sklearn.tree $ sudo easy_install scikit-learn &amp;gt;&amp;gt;&amp;gt; from sklearn.</description>
    </item>
    
    <item>
      <title>pandas: Adding a column to a DataFrame (based on another DataFrame)</title>
      <link>https://markhneedham.com/blog/2013/10/30/pandas-adding-a-column-to-a-dataframe-based-on-another-dataframe/</link>
      <pubDate>Wed, 30 Oct 2013 06:12:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/10/30/pandas-adding-a-column-to-a-dataframe-based-on-another-dataframe/</guid>
      <description>def addrow(df, row): return df.append(pd.DataFrame(row), ignore_index=True) customers = pd.DataFrame(columns=[&amp;#39;PassengerId&amp;#39;,&amp;#39;Pclass&amp;#39;,&amp;#39;Name&amp;#39;,&amp;#39;Sex&amp;#39;,&amp;#39;Fare&amp;#39;]) customers = addrow(customers, [dict(PassengerId=892, Pclass=3, Name=&amp;#34;Kelly, Mr. James&amp;#34;, Sex=&amp;#34;male&amp;#34;, Fare=7.8292)]) customers = addrow(customers, [dict(PassengerId=893, Pclass=3, Name=&amp;#34;Wilkes, Mrs. James (Ellen Needs)&amp;#34;, Sex=&amp;#34;female&amp;#34;, Fare=7)]) &amp;gt;&amp;gt;&amp;gt; customers Fare Name PassengerId Pclass Sex 0 7.8292 Kelly, Mr. James 892 3 male 1 7.0000 Wilkes, Mrs. James (Ellen Needs) 893 3 female survival_table = pd.DataFrame(columns=[&amp;#39;Sex&amp;#39;, &amp;#39;Pclass&amp;#39;, &amp;#39;PriceDist&amp;#39;, &amp;#39;Survived&amp;#39;]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;female&amp;#34;, PriceDist = 0, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;male&amp;#34;, PriceDist = 0, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;female&amp;#34;, PriceDist = 1, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;male&amp;#34;, PriceDist = 1, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;female&amp;#34;, PriceDist = 2, Survived = 1)]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;male&amp;#34;, PriceDist = 2, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;female&amp;#34;, PriceDist = 3, Survived = 1)]) survival_table = addrow(survival_table, [dict(Pclass=1, Sex=&amp;#34;male&amp;#34;, PriceDist = 3, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;female&amp;#34;, PriceDist = 0, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;male&amp;#34;, PriceDist = 0, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;female&amp;#34;, PriceDist = 1, Survived = 1)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;male&amp;#34;, PriceDist = 1, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;female&amp;#34;, PriceDist = 2, Survived = 1)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;male&amp;#34;, PriceDist = 2, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;female&amp;#34;, PriceDist = 3, Survived = 1)]) survival_table = addrow(survival_table, [dict(Pclass=2, Sex=&amp;#34;male&amp;#34;, PriceDist = 3, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;female&amp;#34;, PriceDist = 0, Survived = 1)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;male&amp;#34;, PriceDist = 0, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;female&amp;#34;, PriceDist = 1, Survived = 1)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;male&amp;#34;, PriceDist = 1, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;female&amp;#34;, PriceDist = 2, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;male&amp;#34;, PriceDist = 2, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;female&amp;#34;, PriceDist = 3, Survived = 0)]) survival_table = addrow(survival_table, [dict(Pclass=3, Sex=&amp;#34;male&amp;#34;, PriceDist = 3, Survived = 0)]) &amp;gt;&amp;gt;&amp;gt; survival_table Pclass PriceDist Sex Survived 0 1 0 female 0 1 1 0 male 0 2 1 1 female 0 3 1 1 male 0 4 1 2 female 1 5 1 2 male 0 6 1 3 female 1 7 1 3 male 0 8 2 0 female 0 9 2 0 male 0 10 2 1 female 1 11 2 1 male 0 12 2 2 female 1 13 2 2 male 0 14 2 3 female 1 15 2 3 male 0 16 3 0 female 1 17 3 0 male 0 18 3 1 female 1 19 3 1 male 0 20 3 2 female 0 21 3 2 male 0 22 3 3 female 0 23 3 3 male 0 def select_bucket(fare): if (fare &amp;gt;= 0 and fare &amp;lt; 10): return 0 elif (fare &amp;gt;= 10 and fare &amp;lt; 20): return 1 elif (fare &amp;gt;= 20 and fare &amp;lt; 30): return 2 else: return 3 def calculate_survival(survival_table, customer): survival_row = survival_table[(survival_table[&amp;#34;Sex&amp;#34;] == customer[&amp;#34;Sex&amp;#34;]) &amp;amp; (survival_table[&amp;#34;Pclass&amp;#34;] == customer[&amp;#34;Pclass&amp;#34;]) &amp;amp; (survival_table[&amp;#34;PriceDist&amp;#34;] == select_bucket(customer[&amp;#34;Fare&amp;#34;]))] return survival_row[&amp;#34;Survived&amp;#34;] &amp;gt;&amp;gt;&amp;gt; customers[&amp;#34;Survived&amp;#34;] = customers.</description>
    </item>
    
    <item>
      <title>Python: for/list comprehensions and dictionaries</title>
      <link>https://markhneedham.com/blog/2013/08/13/python-forlist-comprehensions-and-dictionaries/</link>
      <pubDate>Tue, 13 Aug 2013 22:59:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/08/13/python-forlist-comprehensions-and-dictionaries/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; x = { &amp;#34;a&amp;#34;: 1, &amp;#34;b&amp;#34;:2 } &amp;gt;&amp;gt;&amp;gt; y = {1: &amp;#34;mark&amp;#34;, 2: &amp;#34;will&amp;#34;} &amp;gt;&amp;gt;&amp;gt; x {&amp;#39;a&amp;#39;: 1, &amp;#39;b&amp;#39;: 2} &amp;gt;&amp;gt;&amp;gt; y {1: &amp;#39;mark&amp;#39;, 2: &amp;#39;will&amp;#39;} {&amp;#34;a&amp;#34;: &amp;#39;mark&amp;#39;, &amp;#34;b&amp;#34;: &amp;#39;will&amp;#39;} &amp;gt;&amp;gt;&amp;gt; for key, value in x.iteritems(): ... print (key, value) ... (&amp;#39;a&amp;#39;, 1) (&amp;#39;b&amp;#39;, 2) &amp;gt;&amp;gt;&amp;gt; [key:value for key, value in x.iteritems()] File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1 [key:value for key, value in x.iteritems()] ^ SyntaxError: invalid syntax &amp;gt;&amp;gt;&amp;gt; {key:value for key, value in x.</description>
    </item>
    
    <item>
      <title>Ruby/Python: Constructing a taxonomy from an array using zip</title>
      <link>https://markhneedham.com/blog/2013/05/19/rubypython-constructing-a-taxonomy-from-an-array-using-zip/</link>
      <pubDate>Sun, 19 May 2013 22:44:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/05/19/rubypython-constructing-a-taxonomy-from-an-array-using-zip/</guid>
      <description>taxonomy = [&amp;#34;Cat&amp;#34;, &amp;#34;SubCat&amp;#34;, &amp;#34;SubSubCat&amp;#34;] # I wanted this to become [(&amp;#34;Cat&amp;#34;, &amp;#34;SubCat&amp;#34;), (&amp;#34;SubCat&amp;#34;, &amp;#34;SubSubCat&amp;#34;) &amp;gt;&amp;gt;&amp;gt; zip(taxonomy[:-1], taxonomy[1:]) [(&amp;#39;Cat&amp;#39;, &amp;#39;SubCat&amp;#39;), (&amp;#39;SubCat&amp;#39;, &amp;#39;SubSubCat&amp;#39;)] &amp;gt; taxonomy[..-1] SyntaxError: (irb):10: syntax error, unexpected tDOT2, expecting &amp;#39;]&amp;#39; taxonomy[..-1] ^ from /Users/markhneedham/.rbenv/versions/1.9.3-p327/bin/irb:12:in `&amp;lt;main&amp;gt;&amp;#39; &amp;gt; taxonomy[0..-2].zip(taxonomy[1..-1]) =&amp;gt; [[&amp;#34;Cat&amp;#34;, &amp;#34;SubCat&amp;#34;], [&amp;#34;SubCat&amp;#34;, &amp;#34;SubSubCat&amp;#34;]] </description>
    </item>
    
    <item>
      <title>Python: Reading a JSON file</title>
      <link>https://markhneedham.com/blog/2013/04/09/python-reading-a-json-file/</link>
      <pubDate>Tue, 09 Apr 2013 07:23:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/04/09/python-reading-a-json-file/</guid>
      <description>config/defaults.json{ &amp;#34;region&amp;#34; : &amp;#34;eu-west-1&amp;#34;, &amp;#34;instanceType&amp;#34;: &amp;#34;m1.small&amp;#34; } &amp;gt;&amp;gt;&amp;gt; open(&amp;#39;config/defaults.json&amp;#39;).read() &amp;#39;{\n\t&amp;#34;region&amp;#34; : &amp;#34;eu-west-1&amp;#34;,\n\t&amp;#34;instanceType&amp;#34;: &amp;#34;m1.small&amp;#34;\n}&amp;#39; &amp;gt;&amp;gt;&amp;gt; import json &amp;gt;&amp;gt;&amp;gt; config = json.loads(open(&amp;#39;config/defaults.json&amp;#39;).read()) &amp;gt;&amp;gt;&amp;gt; config {u&amp;#39;region&amp;#39;: u&amp;#39;eu-west-1&amp;#39;, u&amp;#39;instanceType&amp;#39;: u&amp;#39;m1.small&amp;#39;} &amp;gt;&amp;gt;&amp;gt; config[&amp;#34;region&amp;#34;] u&amp;#39;eu-west-1&amp;#39; </description>
    </item>
    
    <item>
      <title>Python: (Conceptually) removing an item from a tuple</title>
      <link>https://markhneedham.com/blog/2013/01/27/python-conceptually-removing-an-item-from-a-tuple/</link>
      <pubDate>Sun, 27 Jan 2013 02:30:05 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/27/python-conceptually-removing-an-item-from-a-tuple/</guid>
      <description>def tuple_without(original_tuple, element_to_remove): new_tuple = [] for s in list(original_tuple): if not s == element_to_remove: new_tuple.append(s) return tuple(new_tuple) &amp;gt;&amp;gt;&amp;gt; tuple_without((1,2,3,4), 1) (2, 3, 4) &amp;gt;&amp;gt;&amp;gt; tuple_without((1,2,3,4), 0) (1, 2, 3, 4) </description>
    </item>
    
    <item>
      <title>Python/numpy: Selecting values by multiple indices</title>
      <link>https://markhneedham.com/blog/2013/01/27/pythonnumpy-selecting-values-by-multiple-indices/</link>
      <pubDate>Sun, 27 Jan 2013 02:21:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/27/pythonnumpy-selecting-values-by-multiple-indices/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; x = arange(20).reshape(4,5) &amp;gt;&amp;gt;&amp;gt; x array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) &amp;gt;&amp;gt;&amp;gt; x[0:3] array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) &amp;gt;&amp;gt;&amp;gt; x[[0,2,3]] array([[ 0, 1, 2, 3, 4], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) &amp;gt;&amp;gt;&amp;gt; x[list((0,2,3))] array([[ 0, 1, 2, 3, 4], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) </description>
    </item>
    
    <item>
      <title>Python/numpy: Selecting specific column in 2D array</title>
      <link>https://markhneedham.com/blog/2013/01/27/pythonnumpy-selecting-specific-column-in-2d-array/</link>
      <pubDate>Sun, 27 Jan 2013 02:10:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2013/01/27/pythonnumpy-selecting-specific-column-in-2d-array/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; x = arange(20).reshape(4,5) &amp;gt;&amp;gt;&amp;gt; x array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) &amp;gt;&amp;gt;&amp;gt; x[:, 1] array([ 1, 6, 11, 16]) &amp;gt;&amp;gt; x[2,1] 11 &amp;gt;&amp;gt; x[2][1] 11 </description>
    </item>
    
  </channel>
</rss>