<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2015s on Mark Needham</title>
    <link>https://markhneedham.com/blog/2015/</link>
    <description>Recent content in 2015s on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Dec 2015 13:58:39 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/2015/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>2015: A year in the life of the Neo4j London meetup group</title>
      <link>https://markhneedham.com/blog/2015/12/31/2015-a-year-in-the-life-of-the-neo4j-london-meetup-group/</link>
      <pubDate>Thu, 31 Dec 2015 13:58:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/31/2015-a-year-in-the-life-of-the-neo4j-london-meetup-group/</guid>
      <description>library(RNeo4j) library(ggplot2) library(dplyr) library(zoo) graph = startGraph(&amp;#34;http://localhost:7474/db/data/&amp;#34;, username = &amp;#34;neo4j&amp;#34;, password = &amp;#34;myPassword&amp;#34;) query = &amp;#34;MATCH (:Group {name: {name}})&amp;lt;-[membership:MEMBER_OF]-() RETURN membership.joined AS timestamp&amp;#34; joinedDF = cypher(graph, query, name = &amp;#34;Neo4j - London User Group&amp;#34;) joinedDF$joinDate = as.Date(as.POSIXct(joinedDF$timestamp / 1000, origin=&amp;#34;1970-01-01&amp;#34;)) joinedDF$joinDate = as.Date(as.POSIXct(joinedDF$timestamp / 1000, origin=&amp;#34;1970-01-01&amp;#34;)) ggplot(aes(x = year, y = n, label = n), data = joinedDF %&amp;gt;% mutate(year = format(joinDate, &amp;#34;%Y&amp;#34;)) %&amp;gt;% count(year)) + geom_bar(stat = &amp;#34;identity&amp;#34;, fill = &amp;#34;Dark Blue&amp;#34;) + ggtitle(&amp;#34;Number of new members by year&amp;#34;) + geom_text(vjust=-0.</description>
    </item>
    
    <item>
      <title>Study until your mind wanders</title>
      <link>https://markhneedham.com/blog/2015/12/31/study-until-your-mind-wanders/</link>
      <pubDate>Thu, 31 Dec 2015 10:47:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/31/study-until-your-mind-wanders/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R: Error in approxfun(x.values.1, y.values.1, method = &#34;constant&#34;, f = 1, :  zero non-NA points</title>
      <link>https://markhneedham.com/blog/2015/12/27/r-error-in-approxfunx-values-1-y-values-1-method-constant-f-1-zero-non-na-points/</link>
      <pubDate>Sun, 27 Dec 2015 12:24:05 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/27/r-error-in-approxfunx-values-1-y-values-1-method-constant-f-1-zero-non-na-points/</guid>
      <description>Source: local data frame [2 x 2] attended n (dbl) (int) 1 0 1541 2 1 53 attended = as.factor((df %&amp;gt;% dplyr::select(attended))$attended) upSampledDf = upSample(df %&amp;gt;% dplyr::select(-attended), attended) upSampledDf$attended = as.numeric(as.character(upSampledDf$Class)) p &amp;lt;- predict(model, newdata=test, type=&amp;#34;response&amp;#34;) pr &amp;lt;- prediction(p, test$attended) prf &amp;lt;- performance(pr, measure = &amp;#34;tpr&amp;#34;, x.measure = &amp;#34;fpr&amp;#34;) Error in approxfun(x.values.1, y.values.1, method = &amp;#34;constant&amp;#34;, f = 1, : zero non-NA points &amp;gt; test %&amp;gt;% count(attended) Source: local data frame [1 x 2] attended n (dbl) (int) 1 1 582 </description>
    </item>
    
    <item>
      <title>Python: Squashing &#39;duplicate&#39; pairs together</title>
      <link>https://markhneedham.com/blog/2015/12/20/python-squashing-duplicate-pairs-together/</link>
      <pubDate>Sun, 20 Dec 2015 12:12:46 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/20/python-squashing-duplicate-pairs-together/</guid>
      <description>A	B	(A is the same as B) B	C	(B is the same as C) C	D	... E	F	(E is the same as F) F	G	... (A, B, C, D) (E, F, G) pairs = [ (&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;), (&amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;), (&amp;#34;C&amp;#34;, &amp;#34;D&amp;#34;), (&amp;#34;E&amp;#34;, &amp;#34;F&amp;#34;), (&amp;#34;F&amp;#34;, &amp;#34;G&amp;#34;) ] def find_matching_index(pair, dups): return [index for index, dup in enumerate(dups) if pair[0] in dup or pair[1] in dup] print find_matching_index((&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;), [set([&amp;#34;D&amp;#34;, &amp;#34;E&amp;#34;])]) [] print find_matching_index((&amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;), [set([&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;])]) [0] print find_matching_index((&amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;), [set([&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;]), set([&amp;#34;C&amp;#34;, &amp;#34;D&amp;#34;])]) [0, 1] def extract_groups(items): dups = [] for pair in items: matching_index = find_matching_index(pair, dups) if len(matching_index) == 0: dups.</description>
    </item>
    
    <item>
      <title>Neo4j: Specific relationship vs Generic relationship &#43; property</title>
      <link>https://markhneedham.com/blog/2015/12/13/neo4j-specific-relationship-vs-generic-relationship-property/</link>
      <pubDate>Sun, 13 Dec 2015 21:22:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/13/neo4j-specific-relationship-vs-generic-relationship-property/</guid>
      <description>MATCH (member:Member {name: &amp;quot;Mark Needham&amp;quot;}) MATCH (futureEvent:Event) WHERE futureEvent.time &amp;gt;= timestamp() MATCH (futureEvent)&amp;lt;-[:HOSTED_EVENT]-(group) OPTIONAL MATCH (member)-[rsvp:RSVPD {response: &amp;quot;yes&amp;quot;}]-&amp;gt;(pastEvent)&amp;lt;-[:HOSTED_EVENT]-(group) WHERE pastEvent.time &amp;lt; timestamp() RETURN group.name, futureEvent.name, COUNT(rsvp) AS previousEvents ORDER BY previousEvents DESC MATCH (member:Member {name: &amp;quot;Mark Needham&amp;quot;}) MATCH (futureEvent:Event) WHERE futureEvent.time &amp;gt;= timestamp() MATCH (futureEvent)&amp;lt;-[:HOSTED_EVENT]-(group) OPTIONAL MATCH (member)-[rsvp:RSVP_YES]-&amp;gt;(pastEvent)&amp;lt;-[:HOSTED_EVENT]-(group) WHERE pastEvent.time &amp;lt; timestamp() RETURN group.name, futureEvent.name, COUNT(rsvp) AS previousEvents ORDER BY previousEvents DESC RSVPD {response: &amp;#34;yes&amp;#34;} Cypher version: CYPHER 2.3, planner: COST.</description>
    </item>
    
    <item>
      <title>Neo4j: Facts as nodes</title>
      <link>https://markhneedham.com/blog/2015/12/04/neo4j-facts-as-nodes/</link>
      <pubDate>Fri, 04 Dec 2015 07:52:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/12/04/neo4j-facts-as-nodes/</guid>
      <description>Modeling an action in terms of its product—that is, in terms of the thing that results from the action—produces a similar structure: an intermediate node that represents the outcome of an interaction between two or more entities.
MATCH (member:Member {name: &amp;quot;Mark Needham&amp;quot;})-[:MEMBER_OF]-&amp;gt;(group)-[:HAS_TOPIC]-&amp;gt;(topic) WITH member, topic, COUNT(*) AS score MATCH (topic)&amp;lt;-[:HAS_TOPIC]-(otherGroup) WHERE NOT (member)-[:MEMBER_OF]-&amp;gt;(otherGroup) RETURN otherGroup.name, COLLECT(topic.name), SUM(score) as score ORDER BY score DESC Cypher version: CYPHER 2.3, planner: COST. 89100 total db hits in 113 ms.</description>
    </item>
    
    <item>
      <title>Python: Parsing a JSON HTTP chunking stream</title>
      <link>https://markhneedham.com/blog/2015/11/28/python-parsing-a-json-http-chunking-stream/</link>
      <pubDate>Sat, 28 Nov 2015 13:56:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/28/python-parsing-a-json-http-chunking-stream/</guid>
      <description>import requests import json def stream_meetup_initial(): uri = &amp;#34;http://stream.meetup.com/2/rsvps&amp;#34; response = requests.get(uri, stream = True) for chunk in response.iter_content(chunk_size = None): yield chunk for raw_rsvp in stream_meetup_initial(): print raw_rsvp try: rsvp = json.loads(raw_rsvp) except ValueError as e: print e continue No JSON object could be decoded def stream_meetup_newline(): uri = &amp;#34;http://stream.meetup.com/2/rsvps&amp;#34; response = requests.get(uri, stream = True) buffer = &amp;#34;&amp;#34; for chunk in response.iter_content(chunk_size = 1): if chunk.endswith(&amp;#34;\n&amp;#34;): buffer += chunk yield buffer buffer = &amp;#34;&amp;#34; else: buffer += chunk r = requests.</description>
    </item>
    
    <item>
      <title>jq: Cannot iterate over number / string and number cannot be added</title>
      <link>https://markhneedham.com/blog/2015/11/24/jq-cannot-iterate-over-number-string-and-number-cannot-be-added/</link>
      <pubDate>Tue, 24 Nov 2015 00:12:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/24/jq-cannot-iterate-over-number-string-and-number-cannot-be-added/</guid>
      <description>$ head -n40 data/members/18313232.json [ { &amp;#34;status&amp;#34;: &amp;#34;active&amp;#34;, &amp;#34;city&amp;#34;: &amp;#34;London&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;. .&amp;#34;, &amp;#34;other_services&amp;#34;: {}, &amp;#34;country&amp;#34;: &amp;#34;gb&amp;#34;, &amp;#34;topics&amp;#34;: [], &amp;#34;lon&amp;#34;: -0.13, &amp;#34;joined&amp;#34;: 1438866605000, &amp;#34;id&amp;#34;: 92951932, &amp;#34;state&amp;#34;: &amp;#34;17&amp;#34;, &amp;#34;link&amp;#34;: &amp;#34;http://www.meetup.com/members/92951932&amp;#34;, &amp;#34;photo&amp;#34;: { &amp;#34;thumb_link&amp;#34;: &amp;#34;http://photos1.meetupstatic.com/photos/member/8/d/6/b/thumb_250896203.jpeg&amp;#34;, &amp;#34;photo_id&amp;#34;: 250896203, &amp;#34;highres_link&amp;#34;: &amp;#34;http://photos1.meetupstatic.com/photos/member/8/d/6/b/highres_250896203.jpeg&amp;#34;, &amp;#34;photo_link&amp;#34;: &amp;#34;http://photos1.meetupstatic.com/photos/member/8/d/6/b/member_250896203.jpeg&amp;#34; }, &amp;#34;lat&amp;#34;: 51.49, &amp;#34;visited&amp;#34;: 1446745707000, &amp;#34;self&amp;#34;: { &amp;#34;common&amp;#34;: {} } }, { &amp;#34;status&amp;#34;: &amp;#34;active&amp;#34;, &amp;#34;city&amp;#34;: &amp;#34;London&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Abdelkader Idryssy&amp;#34;, &amp;#34;other_services&amp;#34;: {}, &amp;#34;country&amp;#34;: &amp;#34;gb&amp;#34;, &amp;#34;topics&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Weekend Adventures&amp;#34;, &amp;#34;urlkey&amp;#34;: &amp;#34;weekend-adventures&amp;#34;, &amp;#34;id&amp;#34;: 16438 }, { &amp;#34;name&amp;#34;: &amp;#34;Community Building&amp;#34;, &amp;#34;urlkey&amp;#34;: &amp;#34;community-building&amp;#34;, $ jq -r &amp;#39;.</description>
    </item>
    
    <item>
      <title>jq: Filtering missing keys</title>
      <link>https://markhneedham.com/blog/2015/11/14/jq-filtering-missing-keys/</link>
      <pubDate>Sat, 14 Nov 2015 22:51:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/14/jq-filtering-missing-keys/</guid>
      <description>$ jq -r &amp;#34;.[0]&amp;#34; data/events/0.json { &amp;#34;status&amp;#34;: &amp;#34;past&amp;#34;, &amp;#34;rating&amp;#34;: { &amp;#34;count&amp;#34;: 1, &amp;#34;average&amp;#34;: 1 }, &amp;#34;utc_offset&amp;#34;: 3600000, &amp;#34;event_url&amp;#34;: &amp;#34;http://www.meetup.com/londonweb/events/3261890/&amp;#34;, &amp;#34;group&amp;#34;: { &amp;#34;who&amp;#34;: &amp;#34;Web Peeps&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;London Web&amp;#34;, &amp;#34;group_lat&amp;#34;: 51.52000045776367, &amp;#34;created&amp;#34;: 1034097743000, &amp;#34;join_mode&amp;#34;: &amp;#34;approval&amp;#34;, &amp;#34;group_lon&amp;#34;: -0.12999999523162842, &amp;#34;urlname&amp;#34;: &amp;#34;londonweb&amp;#34;, &amp;#34;id&amp;#34;: 163876 }, &amp;#34;name&amp;#34;: &amp;#34;London Web Design October Meetup&amp;#34;, &amp;#34;created&amp;#34;: 1094756756000, &amp;#34;venue&amp;#34;: { &amp;#34;city&amp;#34;: &amp;#34;London&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Roadhouse Live Music Restaurant , Bar &amp;amp; Club&amp;#34;, &amp;#34;country&amp;#34;: &amp;#34;GB&amp;#34;, &amp;#34;lon&amp;#34;: -0.1, &amp;#34;phone&amp;#34;: &amp;#34;44-020-7240-6001&amp;#34;, &amp;#34;address_1&amp;#34;: &amp;#34;The Piazza&amp;#34;, &amp;#34;address_2&amp;#34;: &amp;#34;Covent Garden&amp;#34;, &amp;#34;repinned&amp;#34;: false, &amp;#34;lat&amp;#34;: 51.</description>
    </item>
    
    <item>
      <title>Docker 1.9: Port forwarding on Mac OS X</title>
      <link>https://markhneedham.com/blog/2015/11/08/docker-1-9-port-forwarding-on-mac-os-x/</link>
      <pubDate>Sun, 08 Nov 2015 20:58:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/08/docker-1-9-port-forwarding-on-mac-os-x/</guid>
      <description>docker run --detach --publish=7474:7474 neo4j/neo4j $ curl http://localhost:7474 curl: (7) Failed to connect to localhost port 7474: Connection refused $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1f7c48e267f0 neo4j/neo4j &amp;#34;/docker-entrypoint.s&amp;#34; 10 minutes ago Up 10 minutes 7473/tcp, 0.0.0.0:7474-&amp;gt;7474/tcp kickass_easley $ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM default * virtualbox Running tcp://192.168.99.100:2376 $ curl http://192.168.99.100:7474 { &amp;#34;management&amp;#34; : &amp;#34;http://192.168.99.100:7474/db/manage/&amp;#34;, &amp;#34;data&amp;#34; : &amp;#34;http://192.168.99.100:7474/db/data/&amp;#34; } </description>
    </item>
    
    <item>
      <title>IntelliJ &#39;java: cannot find JDK 1.8&#39;</title>
      <link>https://markhneedham.com/blog/2015/11/08/intellij-java-cannot-find-jdk-1-8/</link>
      <pubDate>Sun, 08 Nov 2015 11:47:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/11/08/intellij-java-cannot-find-jdk-1-8/</guid>
      <description>module-name java: cannot find JDK 1.8 $ less /Users/markneedham/Library/Logs/IntelliJIdea15/idea.log 2015-11-05 16:31:28,429 [ 428129] INFO - figurations.GeneralCommandLine - Cannot run program &amp;#34;/Library/Java/JavaVirtualMachines/jdk1.7.0_71.jdk/Contents/Home/bin/java&amp;#34; (in directory &amp;#34;/Applications/IntelliJ IDEA 15.app/Contents/bin&amp;#34;): error=2, No such file or directory java.io.IOException: Cannot run program &amp;#34;/Library/Java/JavaVirtualMachines/jdk1.7.0_71.jdk/Contents/Home/bin/java&amp;#34; (in directory &amp;#34;/Applications/IntelliJ IDEA 15.app/Contents/bin&amp;#34;): error=2, No such file or directory at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048) at com.intellij.execution.configurations.GeneralCommandLine.startProcess(GeneralCommandLine.java:368) at com.intellij.execution.configurations.GeneralCommandLine.createProcess(GeneralCommandLine.java:354) at com.intellij.execution.process.OSProcessHandler.&amp;lt;init&amp;gt;(OSProcessHandler.java:38) at org.jetbrains.idea.maven.server.MavenServerManager$3.startProcess(MavenServerManager.java:359) at org.jetbrains.idea.maven.server.MavenServerManager$3.execute(MavenServerManager.java:345) at com.intellij.execution.rmi.RemoteProcessSupport.a(RemoteProcessSupport.java:206) at com.intellij.execution.rmi.RemoteProcessSupport.acquire(RemoteProcessSupport.java:139) at org.jetbrains.idea.maven.server.MavenServerManager.create(MavenServerManager.java:163) at org.jetbrains.idea.maven.server.MavenServerManager.create(MavenServerManager.java:71) at org.jetbrains.idea.maven.server.RemoteObjectWrapper.getOrCreateWrappee(RemoteObjectWrapper.java:41) at org.</description>
    </item>
    
    <item>
      <title>Hadoop: HDFS - ava.lang.NoSuchMethodError: org.apache.hadoop.fs.FSOutputSummer.&lt;init&gt;(Ljava/util/zip/Checksum;II)V</title>
      <link>https://markhneedham.com/blog/2015/10/31/hadoop-hdfs-ava-lang-nosuchmethoderror-org-apache-hadoop-fs-fsoutputsummer-ljavautilzipchecksumiiv/</link>
      <pubDate>Sat, 31 Oct 2015 23:58:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/31/hadoop-hdfs-ava-lang-nosuchmethoderror-org-apache-hadoop-fs-fsoutputsummer-ljavautilzipchecksumiiv/</guid>
      <description>package org.playground; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.FSDataInputStream; import org.apache.hadoop.fs.FSDataOutputStream; import org.apache.hadoop.fs.FileSystem; import org.apache.hadoop.fs.Path; import java.io.IOException; public class HadoopDFSFileReadWrite { static void printAndExit(String str) { System.err.println( str ); System.exit(1); } public static void main (String[] argv) throws IOException { Configuration conf = new Configuration(); conf.addResource(new Path(&amp;#34;/Users/markneedham/Downloads/core-site.xml&amp;#34;)); FileSystem fs = FileSystem.get(conf); Path inFile = new Path(&amp;#34;hdfs://192.168.0.11/user/markneedham/explore.R&amp;#34;); Path outFile = new Path(&amp;#34;hdfs://192.168.0.11/user/markneedham/output-&amp;#34; + System.currentTimeMillis()); // Check if input/output are valid  if (!fs.exists(inFile)) printAndExit(&amp;#34;Input file not found&amp;#34;); if (!</description>
    </item>
    
    <item>
      <title>Spark: MatchError (of class org.apache.spark.sql.catalyst.expressions.GenericRow) spark</title>
      <link>https://markhneedham.com/blog/2015/10/27/spark-matcherror-of-class-org-apache-spark-sql-catalyst-expressions-genericrow-spark/</link>
      <pubDate>Tue, 27 Oct 2015 23:10:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/27/spark-matcherror-of-class-org-apache-spark-sql-catalyst-expressions-genericrow-spark/</guid>
      <description>$ head -n5 pp-complete.csv &amp;#34;{0C7ADEF5-878D-4066-B785-0000003ED74A}&amp;#34;,&amp;#34;163000&amp;#34;,&amp;#34;2003-02-21 00:00&amp;#34;,&amp;#34;UB5 4PJ&amp;#34;,&amp;#34;T&amp;#34;,&amp;#34;N&amp;#34;,&amp;#34;F&amp;#34;,&amp;#34;106&amp;#34;,&amp;#34;&amp;#34;,&amp;#34;READING ROAD&amp;#34;,&amp;#34;NORTHOLT&amp;#34;,&amp;#34;NORTHOLT&amp;#34;,&amp;#34;EALING&amp;#34;,&amp;#34;GREATER LONDON&amp;#34;,&amp;#34;A&amp;#34; &amp;#34;{35F67271-ABD4-40DA-AB09-00000085B9D3}&amp;#34;,&amp;#34;247500&amp;#34;,&amp;#34;2005-07-15 00:00&amp;#34;,&amp;#34;TA19 9DD&amp;#34;,&amp;#34;D&amp;#34;,&amp;#34;N&amp;#34;,&amp;#34;F&amp;#34;,&amp;#34;58&amp;#34;,&amp;#34;&amp;#34;,&amp;#34;ADAMS MEADOW&amp;#34;,&amp;#34;ILMINSTER&amp;#34;,&amp;#34;ILMINSTER&amp;#34;,&amp;#34;SOUTH SOMERSET&amp;#34;,&amp;#34;SOMERSET&amp;#34;,&amp;#34;A&amp;#34; &amp;#34;{B20B1C74-E8E1-4137-AB3E-0000011DF342}&amp;#34;,&amp;#34;320000&amp;#34;,&amp;#34;2010-09-10 00:00&amp;#34;,&amp;#34;W4 1DZ&amp;#34;,&amp;#34;F&amp;#34;,&amp;#34;N&amp;#34;,&amp;#34;L&amp;#34;,&amp;#34;58&amp;#34;,&amp;#34;&amp;#34;,&amp;#34;WHELLOCK ROAD&amp;#34;,&amp;#34;&amp;#34;,&amp;#34;LONDON&amp;#34;,&amp;#34;EALING&amp;#34;,&amp;#34;GREATER LONDON&amp;#34;,&amp;#34;A&amp;#34; &amp;#34;{7D6B0915-C56B-4275-AF9B-00000156BCE7}&amp;#34;,&amp;#34;104000&amp;#34;,&amp;#34;1997-08-27 00:00&amp;#34;,&amp;#34;NE61 2BH&amp;#34;,&amp;#34;D&amp;#34;,&amp;#34;N&amp;#34;,&amp;#34;F&amp;#34;,&amp;#34;17&amp;#34;,&amp;#34;&amp;#34;,&amp;#34;WESTGATE&amp;#34;,&amp;#34;MORPETH&amp;#34;,&amp;#34;MORPETH&amp;#34;,&amp;#34;CASTLE MORPETH&amp;#34;,&amp;#34;NORTHUMBERLAND&amp;#34;,&amp;#34;A&amp;#34; &amp;#34;{47B60101-B64C-413D-8F60-000002F1692D}&amp;#34;,&amp;#34;147995&amp;#34;,&amp;#34;2003-05-02 00:00&amp;#34;,&amp;#34;PE33 0RU&amp;#34;,&amp;#34;D&amp;#34;,&amp;#34;N&amp;#34;,&amp;#34;F&amp;#34;,&amp;#34;4&amp;#34;,&amp;#34;&amp;#34;,&amp;#34;MASON GARDENS&amp;#34;,&amp;#34;WEST WINCH&amp;#34;,&amp;#34;KING&amp;#39;S LYNN&amp;#34;,&amp;#34;KING&amp;#39;S LYNN AND WEST NORFOLK&amp;#34;,&amp;#34;NORFOLK&amp;#34;,&amp;#34;A&amp;#34; import org.apache.spark.sql.{SQLContext, _} import org.apache.spark.{SparkConf, SparkContext} case class BlogTransaction(price: Integer, date: String, postCode:String, paon:String, saon:String, street:String, locality:String, city:String, district:String, county:String) object BlogApp { def main(args: Array[String]) { val conf = new SparkConf().setAppName(&amp;#34;Simple Application&amp;#34;) val sc = new SparkContext(conf) val sqlContext = new SQLContext(sc) import sqlContext.</description>
    </item>
    
    <item>
      <title>Exploring (potential) data entry errors in the Land Registry data set</title>
      <link>https://markhneedham.com/blog/2015/10/18/exploring-potential-data-entry-errors-in-the-land-registry-data-set/</link>
      <pubDate>Sun, 18 Oct 2015 10:03:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/18/exploring-potential-data-entry-errors-in-the-land-registry-data-set/</guid>
      <description>&amp;gt; library(data.table) &amp;gt; dt = fread(&amp;#34;pp-complete.csv&amp;#34;, header = FALSE) &amp;gt; dt[1:5] V1 V2 V3 V4 V5 1: {0C7ADEF5-878D-4066-B785-0000003ED74A} 163000 2003-02-21 00:00 UB5 4PJ T 2: {35F67271-ABD4-40DA-AB09-00000085B9D3} 247500 2005-07-15 00:00 TA19 9DD D 3: {B20B1C74-E8E1-4137-AB3E-0000011DF342} 320000 2010-09-10 00:00 W4 1DZ F 4: {7D6B0915-C56B-4275-AF9B-00000156BCE7} 104000 1997-08-27 00:00 NE61 2BH D 5: {47B60101-B64C-413D-8F60-000002F1692D} 147995 2003-05-02 00:00 PE33 0RU D V6 V7 V8 V9 V10 V11 V12 1: N F 106 READING ROAD NORTHOLT NORTHOLT 2: N F 58 ADAMS MEADOW ILMINSTER ILMINSTER 3: N L 58 WHELLOCK ROAD LONDON 4: N F 17 WESTGATE MORPETH MORPETH 5: N F 4 MASON GARDENS WEST WINCH KING&amp;#39;S LYNN V13 V14 V15 1: EALING GREATER LONDON A 2: SOUTH SOMERSET SOMERSET A 3: EALING GREATER LONDON A 4: CASTLE MORPETH NORTHUMBERLAND A 5: KING&amp;#39;S LYNN AND WEST NORFOLK NORFOLK A &amp;gt; dt = dt[, V2:= as.</description>
    </item>
    
    <item>
      <title>jq: error - Cannot iterate over null (null)</title>
      <link>https://markhneedham.com/blog/2015/10/09/jq-error-cannot-iterate-over-null-null/</link>
      <pubDate>Fri, 09 Oct 2015 06:34:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/09/jq-error-cannot-iterate-over-null-null/</guid>
      <description>$ head -n 100 so.json [ { &amp;#34;has_more&amp;#34;: true, &amp;#34;items&amp;#34;: [ { &amp;#34;is_answered&amp;#34;: false, &amp;#34;delete_vote_count&amp;#34;: 0, &amp;#34;body_markdown&amp;#34;: &amp;#34;...&amp;#34;, &amp;#34;tags&amp;#34;: [ &amp;#34;jdbc&amp;#34;, &amp;#34;neo4j&amp;#34;, &amp;#34;cypher&amp;#34;, &amp;#34;spring-data-neo4j&amp;#34; ], &amp;#34;question_id&amp;#34;: 33023306, &amp;#34;title&amp;#34;: &amp;#34;How to delete multiple nodes by specific ID using Cypher&amp;#34;, &amp;#34;down_vote_count&amp;#34;: 0, &amp;#34;view_count&amp;#34;: 8, &amp;#34;answers&amp;#34;: [ { ... ] $ jq -r \  &amp;#39;.[] | .items[] | { question_id: .question_id, answer: .answers[] } | [.question_id, .answer.answer_id, .answer.title] | @csv&amp;#39; so.json 33023306,33024189,&amp;#34;How to delete multiple nodes by specific ID using Cypher&amp;#34; 33020796,33021958,&amp;#34;How do a general search across string properties in my nodes?</description>
    </item>
    
    <item>
      <title>Mac OS X: Installing the PROJ.4 - Cartographic Projections Library</title>
      <link>https://markhneedham.com/blog/2015/10/05/mac-os-x-installing-the-proj-4-cartographic-projections-library/</link>
      <pubDate>Mon, 05 Oct 2015 22:41:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/05/mac-os-x-installing-the-proj-4-cartographic-projections-library/</guid>
      <description>$ wget http://download.osgeo.org/proj/proj-4.9.1.tar.gz $ tar -xvf proj-4.9.1.tar.gz $ cd proj-4.9.1 $ ./configure --prefix ~/projects/land-registry/proj-4.9.1 $ make $ make install $ ls -alh bin/ total 184 drwxr-xr-x 8 markneedham staff 272B 5 Oct 23:07 . drwxr-xr-x@ 41 markneedham staff 1.4K 5 Oct 20:46 .. -rwxr-xr-x 1 markneedham staff 20K 5 Oct 23:07 cs2cs -rwxr-xr-x 1 markneedham staff 16K 5 Oct 23:07 geod lrwxr-xr-x 1 markneedham staff 4B 5 Oct 23:07 invgeod -&amp;gt; geod lrwxr-xr-x 1 markneedham staff 4B 5 Oct 23:07 invproj -&amp;gt; proj -rwxr-xr-x 1 markneedham staff 13K 5 Oct 23:07 nad2bin -rwxr-xr-x 1 markneedham staff 21K 5 Oct 23:07 proj $ .</description>
    </item>
    
    <item>
      <title>R: data.table - Finding the maximum row</title>
      <link>https://markhneedham.com/blog/2015/10/02/r-data-table-finding-the-maximum-row/</link>
      <pubDate>Fri, 02 Oct 2015 18:42:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/10/02/r-data-table-finding-the-maximum-row/</guid>
      <description>&amp;gt; blogDT = data.table(name = c(&amp;#34;Property 1&amp;#34;,&amp;#34;Property 1&amp;#34;,&amp;#34;Property 1&amp;#34;,&amp;#34;Property 2&amp;#34;,&amp;#34;Property 2&amp;#34;,&amp;#34;Property 2&amp;#34;), price = c(10000, 12500, 18000, 245000, 512000, 1000000), date = c(&amp;#34;Day 1&amp;#34;, &amp;#34;Day 7&amp;#34;, &amp;#34;Day 10&amp;#34;, &amp;#34;Day 3&amp;#34;, &amp;#34;Day 5&amp;#34;, &amp;#34;Day 12&amp;#34;)) &amp;gt; blogDT[, lag.price := c(NA, price[-.N]), by = name] &amp;gt; blogDT[, diff := price - lag.price] &amp;gt; blogDT name price date lag.price diff 1: Property 1 10000 Day 1 NA NA 2: Property 1 12500 Day 7 10000 2500 3: Property 1 18000 Day 10 12500 5500 4: Property 2 245000 Day 3 NA NA 5: Property 2 512000 Day 5 245000 267000 6: Property 2 1000000 Day 12 512000 488000 &amp;gt; blogDT[!</description>
    </item>
    
    <item>
      <title>IntelliJ 14.1.5: Unable to import maven project</title>
      <link>https://markhneedham.com/blog/2015/09/30/intellij-14-1-5-unable-to-import-maven-project/</link>
      <pubDate>Wed, 30 Sep 2015 05:54:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/09/30/intellij-14-1-5-unable-to-import-maven-project/</guid>
      <description>-Didea.maven3.use.compat.resolver </description>
    </item>
    
    <item>
      <title>R: data.table - Comparing adjacent rows</title>
      <link>https://markhneedham.com/blog/2015/09/27/r-data-table-comparing-adjacent-rows/</link>
      <pubDate>Sun, 27 Sep 2015 22:02:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/09/27/r-data-table-comparing-adjacent-rows/</guid>
      <description>&amp;gt; blogDT = data.table(name = c(&amp;#34;Property 1&amp;#34;,&amp;#34;Property 1&amp;#34;,&amp;#34;Property 1&amp;#34;,&amp;#34;Property 2&amp;#34;,&amp;#34;Property 2&amp;#34;,&amp;#34;Property 2&amp;#34;), price = c(10000, 12500, 18000, 245000, 512000, 1000000)) &amp;gt; blogDT name price 1: Property 1 10000 2: Property 1 12500 3: Property 1 18000 4: Property 2 245000 5: Property 2 512000 6: Property 2 1000000 &amp;gt; blogDT[, lag.price := c(NA, price[-.N]), by = name] &amp;gt; blogDT name price lag.price 1: Property 1 10000 NA 2: Property 1 12500 10000 3: Property 1 18000 12500 4: Property 2 245000 NA 5: Property 2 512000 245000 6: Property 2 1000000 512000 &amp;gt; blogDT[, diff := price - lag.</description>
    </item>
    
    <item>
      <title>R: Querying a 20 million line CSV file - data.table vs data frame</title>
      <link>https://markhneedham.com/blog/2015/09/25/r-querying-a-20-million-line-csv-file-data-table-vs-data-frame/</link>
      <pubDate>Fri, 25 Sep 2015 06:28:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/09/25/r-querying-a-20-million-line-csv-file-data-table-vs-data-frame/</guid>
      <description>&amp;gt; library(readr) &amp;gt; system.time(read_csv(&amp;#34;pp-complete.csv&amp;#34;, col_names = FALSE)) user system elapsed 127.367 21.957 159.963 &amp;gt; df = read_csv(&amp;#34;pp-complete.csv&amp;#34;, col_names = FALSE) &amp;gt; head(df) Source: local data frame [6 x 16] X1 X2 X3 X4 X5 X6 X7 X8 X9 (chr) (int) (date) (chr) (chr) (chr) (chr) (chr) (chr) 1 {0C7ADEF5-878D-4066-B785-0000003ED74A} 163000 &amp;lt;NA&amp;gt; UB5 4PJ T N F 106 2 {35F67271-ABD4-40DA-AB09-00000085B9D3} 247500 &amp;lt;NA&amp;gt; TA19 9DD D N F 58 3 {B20B1C74-E8E1-4137-AB3E-0000011DF342} 320000 &amp;lt;NA&amp;gt; W4 1DZ F N L 58 4 {7D6B0915-C56B-4275-AF9B-00000156BCE7} 104000 &amp;lt;NA&amp;gt; NE61 2BH D N F 17 5 {47B60101-B64C-413D-8F60-000002F1692D} 147995 &amp;lt;NA&amp;gt; PE33 0RU D N F 4 6 {51F797CA-7BEB-4958-821F-000003E464AE} 110000 &amp;lt;NA&amp;gt; NR35 2SF T N F 5 Variables not shown: X10 (chr), X11 (chr), X12 (chr), X13 (chr), X14 (chr), X15 (chr), address (chr) &amp;gt; library(dplyr) &amp;gt; system.</description>
    </item>
    
    <item>
      <title>SparkR: Add new column to data frame by concatenating other columns</title>
      <link>https://markhneedham.com/blog/2015/09/21/sparkr-add-new-column-to-data-frame-by-concatenating-other-columns/</link>
      <pubDate>Mon, 21 Sep 2015 22:30:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/09/21/sparkr-add-new-column-to-data-frame-by-concatenating-other-columns/</guid>
      <description>./spark-1.5.0-bin-hadoop2.6/bin/sparkR --packages com.databricks:spark-csv_2.11:1.2.0 &amp;gt; sales &amp;lt;- read.df(sqlContext, &amp;#34;pp-complete.csv&amp;#34;, &amp;#34;com.databricks.spark.csv&amp;#34;, header=&amp;#34;false&amp;#34;) &amp;gt; head(sales) C0 C1 C2 C3 C4 C5 1 {0C7ADEF5-878D-4066-B785-0000003ED74A} 163000 2003-02-21 00:00 UB5 4PJ T N 2 {35F67271-ABD4-40DA-AB09-00000085B9D3} 247500 2005-07-15 00:00 TA19 9DD D N 3 {B20B1C74-E8E1-4137-AB3E-0000011DF342} 320000 2010-09-10 00:00 W4 1DZ F N 4 {7D6B0915-C56B-4275-AF9B-00000156BCE7} 104000 1997-08-27 00:00 NE61 2BH D N 5 {47B60101-B64C-413D-8F60-000002F1692D} 147995 2003-05-02 00:00 PE33 0RU D N 6 {51F797CA-7BEB-4958-821F-000003E464AE} 110000 2013-03-22 00:00 NR35 2SF T N C6 C7 C8 C9 C10 C11 1 F 106 READING ROAD NORTHOLT NORTHOLT 2 F 58 ADAMS MEADOW ILMINSTER ILMINSTER 3 L 58 WHELLOCK ROAD LONDON 4 F 17 WESTGATE MORPETH MORPETH 5 F 4 MASON GARDENS WEST WINCH KING&amp;#39;S LYNN 6 F 5 WILD FLOWER WAY DITCHINGHAM BUNGAY C12 C13 C14 1 EALING GREATER LONDON A 2 SOUTH SOMERSET SOMERSET A 3 EALING GREATER LONDON A 4 CASTLE MORPETH NORTHUMBERLAND A 5 KING&amp;#39;S LYNN AND WEST NORFOLK NORFOLK A 6 SOUTH NORFOLK NORFOLK A &amp;gt; sales$address = paste(sales$C9, sales$C10, sales$C11, sales$C12, sep=&amp;#34;, &amp;#34;) Error in as.</description>
    </item>
    
    <item>
      <title>SparkR: Error in invokeJava(isStatic = TRUE, className, methodName, ...) :  java.lang.ClassNotFoundException: Failed to load class for data source: csv.</title>
      <link>https://markhneedham.com/blog/2015/09/21/sparkr-error-in-invokejavaisstatic-true-classname-methodname-java-lang-classnotfoundexception-failed-to-load-class-for-data-source-csv/</link>
      <pubDate>Mon, 21 Sep 2015 22:06:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/09/21/sparkr-error-in-invokejavaisstatic-true-classname-methodname-java-lang-classnotfoundexception-failed-to-load-class-for-data-source-csv/</guid>
      <description>./spark-1.5.0-bin-hadoop2.6/bin/sparkR --packages com.databricks:spark-csv_2.11:1.2.0 &amp;gt; sales &amp;lt;- read.df(sqlContext, &amp;#34;pp-complete.csv&amp;#34;, &amp;#34;csv&amp;#34;) 15/09/20 19:13:02 ERROR RBackendHandler: loadDF on org.apache.spark.sql.api.r.SQLUtils failed Error in invokeJava(isStatic = TRUE, className, methodName, ...) : java.lang.ClassNotFoundException: Failed to load class for data source: csv. at org.apache.spark.sql.execution.datasources.ResolvedDataSource$.lookupDataSource(ResolvedDataSource.scala:67) at org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:87) at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:114) at org.apache.spark.sql.api.r.SQLUtils$.loadDF(SQLUtils.scala:156) at org.apache.spark.sql.api.r.SQLUtils.loadDF(SQLUtils.scala) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.spark.api.r.RBackendHandler.handleMethodCall(RBackendHandler.scala:132) at org.apache.spark.api.r.RBackendHandler.channelRead0(RBackendHandler.scala:79) at org.apache.spark.api.r.RBackendH &amp;gt; sales &amp;lt;- read.df(sqlContext, &amp;#34;pp-complete.csv&amp;#34;, &amp;#34;com.databricks.spark.csv&amp;#34;, header=&amp;#34;false&amp;#34;) &amp;gt; sales DataFrame[C0:string, C1:string, C2:string, C3:string, C4:string, C5:string, C6:string, C7:string, C8:string, C9:string, C10:string, C11:string, C12:string, C13:string, C14:string] </description>
    </item>
    
    <item>
      <title>Neo4j: Summarising neo4j-shell output</title>
      <link>https://markhneedham.com/blog/2015/08/21/neo4j-summarising-neo4j-shell-output/</link>
      <pubDate>Fri, 21 Aug 2015 20:59:37 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/21/neo4j-summarising-neo4j-shell-output/</guid>
      <description>I frequently find myself trying to optimise a set of cypher queries and I tend to group them together in a script that I fed to the Neo4j shell.
import re import sys from tabulate import tabulate lines = sys.stdin.readlines() def search(term, line): m = re.match(term + &amp;#34;: (.*)&amp;#34;, line) return (int(m.group(1)) if m else 0) nodes_created, relationships_created, constraints_added, indexes_added, labels_added, properties_set = 0, 0, 0, 0, 0, 0 for line in lines: nodes_created = nodes_created + search(&amp;#34;Nodes created&amp;#34;, line) relationships_created = relationships_created + search(&amp;#34;Relationships created&amp;#34;, line) constraints_added = constraints_added + search(&amp;#34;Constraints added&amp;#34;, line) indexes_added = indexes_added + search(&amp;#34;Indexes added&amp;#34;, line) labels_added = labels_added + search(&amp;#34;Labels added&amp;#34;, line) properties_set = properties_set + search(&amp;#34;Properties set&amp;#34;, line) time_match = re.</description>
    </item>
    
    <item>
      <title>Python: Extracting Excel spreadsheet into CSV files</title>
      <link>https://markhneedham.com/blog/2015/08/19/python-extracting-excel-spreadsheet-into-csv-files/</link>
      <pubDate>Wed, 19 Aug 2015 23:27:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/19/python-extracting-excel-spreadsheet-into-csv-files/</guid>
      <description>from xlrd import open_workbook import csv wb = open_workbook(&amp;#39;Road-Accident-Safety-Data-Guide-1979-2004.xls&amp;#39;) for i in range(2, wb.nsheets): sheet = wb.sheet_by_index(i) print sheet.name with open(&amp;#34;data/%s.csv&amp;#34; %(sheet.name.replace(&amp;#34; &amp;#34;,&amp;#34;&amp;#34;)), &amp;#34;w&amp;#34;) as file: writer = csv.writer(file, delimiter = &amp;#34;,&amp;#34;) print sheet, sheet.name, sheet.ncols, sheet.nrows header = [cell.value for cell in sheet.row(0)] writer.writerow(header) for row_idx in range(1, sheet.nrows): row = [int(cell.value) if isinstance(cell.value, float) else cell.value for cell in sheet.row(row_idx)] writer.writerow(row) $ cat data/1stPointofImpact.csv code,label 0,Did not impact 1,Front 2,Back 3,Offside 4,Nearside -1,Data missing or out of range $ cat data/RoadType.</description>
    </item>
    
    <item>
      <title>Unix: Stripping first n bytes in a file / Byte Order Mark (BOM)</title>
      <link>https://markhneedham.com/blog/2015/08/19/unix-stripping-first-n-bytes-in-a-file-byte-order-mark-bom/</link>
      <pubDate>Wed, 19 Aug 2015 23:27:28 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/19/unix-stripping-first-n-bytes-in-a-file-byte-order-mark-bom/</guid>
      <description>$ time tail -c +4 Casualty7904.csv &amp;gt; Casualty7904_stripped.csv real	0m31.945s user	0m31.370s sys	0m0.518s -c number The location is number bytes. </description>
    </item>
    
    <item>
      <title>Unix: Redirecting stderr to stdout</title>
      <link>https://markhneedham.com/blog/2015/08/15/unix-redirecting-stderr-to-stdout/</link>
      <pubDate>Sat, 15 Aug 2015 15:55:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/15/unix-redirecting-stderr-to-stdout/</guid>
      <description>#!/bin/sh ./neo4j-community-2.2.3/bin/neo4j start $ ./foo.sh &amp;gt; /tmp/output.txt Unable to find any JVMs matching version &amp;#34;1.7&amp;#34;. $ cat /tmp/output.txt Starting Neo4j Server...WARNING: not changing user process [48230]... waiting for server to be ready.... OK. http://localhost:7474/ is ready. #!/bin/sh ./neo4j-community-2.2.3/bin/neo4j start 2&amp;gt;&amp;amp;1 $ ./foo.sh &amp;gt; /tmp/output.txt $ cat /tmp/output.txt Unable to find any JVMs matching version &amp;#34;1.7&amp;#34;. Starting Neo4j Server...WARNING: not changing user process [47989]... waiting for server to be ready.... OK. http://localhost:7474/ is ready.</description>
    </item>
    
    <item>
      <title>Sed: Using environment variables</title>
      <link>https://markhneedham.com/blog/2015/08/13/sed-using-environment-variables/</link>
      <pubDate>Thu, 13 Aug 2015 19:30:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/13/sed-using-environment-variables/</guid>
      <description>LOAD CSV WITH HEADERS FROM &amp;#34;https://raw.githubusercontent.com/mneedham/neo4j-bbc/master/data/matches.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;file:///Users/markneedham/repos/neo4j-bbc/data/matches.csv&amp;#34; AS row $ echo $PWD /Users/markneedham/repos/neo4j-bbc $ sed &amp;#39;s_https://raw.githubusercontent.com/mneedham/neo4j-bbc/master__&amp;#39; import.cql $ sed &amp;#39;s_https://raw.githubusercontent.com/mneedham/neo4j-bbc/master__&amp;#39; import.cql | grep LOAD LOAD CSV WITH HEADERS FROM &amp;#34;/data/matches.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/players.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/players.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/fouls.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/attempts.csv&amp;#34; AS row LOAD CSV WITH HEADERS FROM &amp;#34;/data/attempts.</description>
    </item>
    
    <item>
      <title>Java: Jersey - java.lang.NoSuchMethodError: com.sun.jersey.core.reflection.ReflectionHelper. getContextClassLoaderPA()Ljava/security/PrivilegedAction;</title>
      <link>https://markhneedham.com/blog/2015/08/11/java-jersey-java-lang-nosuchmethoderror-com-sun-jersey-core-reflection-reflectionhelper-getcontextclassloaderpaljavasecurityprivilegedaction/</link>
      <pubDate>Tue, 11 Aug 2015 06:59:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/11/java-jersey-java-lang-nosuchmethoderror-com-sun-jersey-core-reflection-reflectionhelper-getcontextclassloaderpaljavasecurityprivilegedaction/</guid>
      <description>public class ExampleResourceTest { @Rule public Neo4jRule neo4j = new Neo4jRule() .withFixture(&amp;#34;CREATE (:Person {name: &amp;#39;Mark&amp;#39;})&amp;#34;) .withFixture(&amp;#34;CREATE (:Person {name: &amp;#39;Nicole&amp;#39;})&amp;#34;) .withExtension( &amp;#34;/unmanaged&amp;#34;, ExampleResource.class ); @Test public void shouldReturnAllTheNodes() { // Given  URI serverURI = neo4j.httpURI(); // When  HTTP.Response response = HTTP.GET(serverURI.resolve(&amp;#34;/unmanaged/example/people&amp;#34;).toString()); // Then  assertEquals(200, response.status()); List content = response.content(); assertEquals(2, content.size()); } } 07:51:32.985 [main] WARN o.e.j.u.component.AbstractLifeCycle - FAILED o.e.j.s.ServletContextHandler@29eda4f8{/unmanaged,null,STARTING}: java.lang.NoSuchMethodError: com.sun.jersey.core.reflection.ReflectionHelper.getContextClassLoaderPA()Ljava/security/PrivilegedAction; java.lang.NoSuchMethodError: com.sun.jersey.core.reflection.ReflectionHelper.getContextClassLoaderPA()Ljava/security/PrivilegedAction; at com.sun.jersey.spi.scanning.AnnotationScannerListener.&amp;lt;init&amp;gt;(AnnotationScannerListener.java:94) ~[jersey-server-1.19.jar:1.19] at com.</description>
    </item>
    
    <item>
      <title>Neo4j 2.2.3: Unmanaged extensions - Creating gzipped streamed responses with Jetty</title>
      <link>https://markhneedham.com/blog/2015/08/10/neo4j-2-2-3-unmanaged-extensions-creating-gzipped-streamed-responses-with-jetty/</link>
      <pubDate>Mon, 10 Aug 2015 23:57:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/10/neo4j-2-2-3-unmanaged-extensions-creating-gzipped-streamed-responses-with-jetty/</guid>
      <description>@Path(&amp;#34;/example&amp;#34;) public class ExampleResource { private final GraphDatabaseService db; private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper(); public ExampleResource(@Context GraphDatabaseService db) { this.db = db; } @GET @Produces(MediaType.APPLICATION_JSON) @Path(&amp;#34;/people&amp;#34;) public Response allNodes() throws IOException { StreamingOutput stream = streamQueryResponse(&amp;#34;MATCH (n:Person) RETURN n.name AS name&amp;#34;); return Response.ok().entity(stream).type(MediaType.APPLICATION_JSON).build(); } private StreamingOutput streamQueryResponse(final String query) { return new StreamingOutput() { @Override public void write(OutputStream os) throws IOException, WebApplicationException { JsonGenerator jg = OBJECT_MAPPER.getJsonFactory().createJsonGenerator(os, JsonEncoding.</description>
    </item>
    
    <item>
      <title>Record Linkage: Playing around with Duke</title>
      <link>https://markhneedham.com/blog/2015/08/08/record-linkage-playing-around-with-duke/</link>
      <pubDate>Sat, 08 Aug 2015 22:50:41 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/08/record-linkage-playing-around-with-duke/</guid>
      <description>export JAVA_HOME=`/usr/libexec/java_home` mvn clean package -DskipTests unzip duke-dist/target/duke-dist-1.3-SNAPSHOT-bin.zip wget https://raw.githubusercontent.com/larsga/Duke/master/doc/example-data/countries-dbpedia.csv wget https://raw.githubusercontent.com/larsga/Duke/master/doc/example-data/countries.xml wget https://raw.githubusercontent.com/larsga/Duke/master/doc/example-data/countries-mondial.csv wget https://raw.githubusercontent.com/larsga/Duke/master/doc/example-data/countries-test.txt java -cp &amp;#34;duke-dist-1.3-SNAPSHOT/lib/*&amp;#34; no.priv.garshol.duke.Duke --testfile=countries-test.txt --testdebug --showmatches countries.xml ... NO MATCH FOR: ID: &amp;#39;7706&amp;#39;, NAME: &amp;#39;guatemala&amp;#39;, AREA: &amp;#39;108890&amp;#39;, CAPITAL: &amp;#39;guatemala city&amp;#39;, MATCH 0.9825124555160142 ID: &amp;#39;10052&amp;#39;, NAME: &amp;#39;pitcairn islands&amp;#39;, AREA: &amp;#39;47&amp;#39;, CAPITAL: &amp;#39;adamstown&amp;#39;, ID: &amp;#39;http://dbpedia.org/resource/Pitcairn_Islands&amp;#39;, NAME: &amp;#39;pitcairn islands&amp;#39;, AREA: &amp;#39;47&amp;#39;, CAPITAL: &amp;#39;adamstown&amp;#39;, Correct links found: 200 / 218 (91.7%) Wrong links found: 0 / 24 (0.</description>
    </item>
    
    <item>
      <title>Spark: Convert RDD to DataFrame</title>
      <link>https://markhneedham.com/blog/2015/08/06/spark-convert-rdd-to-dataframe/</link>
      <pubDate>Thu, 06 Aug 2015 21:11:44 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/06/spark-convert-rdd-to-dataframe/</guid>
      <description>import org.apache.spark.sql.{SQLContext, Row, DataFrame} val sqlContext = new SQLContext(sc) val crimeFile = &amp;#34;Crimes_-_2001_to_present.csv&amp;#34; sqlContext.load(&amp;#34;com.databricks.spark.csv&amp;#34;, Map(&amp;#34;path&amp;#34; -&amp;gt; crimeFile, &amp;#34;header&amp;#34; -&amp;gt; &amp;#34;true&amp;#34;)).registerTempTable(&amp;#34;crimes&amp;#34;) private def createFile(df: DataFrame, file: String, header: String): Unit = { FileUtil.fullyDelete(new File(file)) val tmpFile = &amp;#34;tmp/&amp;#34; + System.currentTimeMillis() + &amp;#34;-&amp;#34; + file df.distinct.save(tmpFile, &amp;#34;com.databricks.spark.csv&amp;#34;) } val rows = sqlContext.sql(&amp;#34;select `Primary Type` as primaryType FROM crimes LIMIT 10&amp;#34;) rows.collect() res4: Array[org.apache.spark.sql.Row] = Array([ASSAULT], [ROBBERY], [CRIMINAL DAMAGE], [THEFT], [THEFT], [BURGLARY], [THEFT], [BURGLARY], [THEFT], [CRIMINAL DAMAGE]) rows.</description>
    </item>
    
    <item>
      <title>Spark: pyspark/Hadoop - py4j.protocol.Py4JJavaError: An error occurred while calling o23.load.: org.apache.hadoop.ipc.RemoteException: Server IPC version 9 cannot communicate with client version 4</title>
      <link>https://markhneedham.com/blog/2015/08/04/spark-pysparkhadoop-py4j-protocol-py4jjavaerror-an-error-occurred-while-calling-o23-load-org-apache-hadoop-ipc-remoteexception-server-ipc-version-9-cannot-communicate-with-client-version-4/</link>
      <pubDate>Tue, 04 Aug 2015 06:35:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/04/spark-pysparkhadoop-py4j-protocol-py4jjavaerror-an-error-occurred-while-calling-o23-load-org-apache-hadoop-ipc-remoteexception-server-ipc-version-9-cannot-communicate-with-client-version-4/</guid>
      <description>from pyspark import SparkContext from pyspark.sql import SQLContext sc = SparkContext(&amp;#34;local&amp;#34;, &amp;#34;Simple App&amp;#34;) sqlContext = SQLContext(sc) file = &amp;#34;hdfs://localhost:9000/user/markneedham/Crimes_-_2001_to_present.csv&amp;#34; sqlContext.load(source=&amp;#34;com.databricks.spark.csv&amp;#34;, header=&amp;#34;true&amp;#34;, path = file).registerTempTable(&amp;#34;crimes&amp;#34;) rows = sqlContext.sql(&amp;#34;select `FBI Code` AS fbiCode, COUNT(*) AS times FROM crimes GROUP BY `FBI Code` ORDER BY times DESC&amp;#34;).collect() for row in rows: print(&amp;#34;{0} -&amp;gt; {1}&amp;#34;.format(row.fbiCode, row.times)) $ ./spark-1.3.0-bin-hadoop1/bin/spark-submit --driver-memory 5g --packages com.databricks:spark-csv_2.10:1.1.0 fbi_spark.py ... Traceback (most recent call last): File &amp;#34;/Users/markneedham/projects/neo4j-spark-chicago/fbi_spark.py&amp;#34;, line 11, in &amp;lt;module&amp;gt; sqlContext.</description>
    </item>
    
    <item>
      <title>Spark: Processing CSV files using Databricks Spark CSV Library</title>
      <link>https://markhneedham.com/blog/2015/08/02/spark-processing-csv-files-using-databricks-spark-csv-library/</link>
      <pubDate>Sun, 02 Aug 2015 18:08:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/08/02/spark-processing-csv-files-using-databricks-spark-csv-library/</guid>
      <description>$ ./spark-1.3.0-bin-hadoop1/bin/spark-shell scala&amp;gt; import org.apache.spark.sql.SQLContext import org.apache.spark.sql.SQLContext scala&amp;gt; val crimeFile = &amp;#34;/Users/markneedham/Downloads/Crimes_-_2001_to_present.csv&amp;#34; crimeFile: String = /Users/markneedham/Downloads/Crimes_-_2001_to_present.csv scala&amp;gt; val sqlContext = new SQLContext(sc) sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@9746157 scala&amp;gt; sqlContext.load(&amp;#34;com.databricks.spark.csv&amp;#34;, Map(&amp;#34;path&amp;#34; -&amp;gt; crimeFile, &amp;#34;header&amp;#34; -&amp;gt; &amp;#34;true&amp;#34;)).registerTempTable(&amp;#34;crimes&amp;#34;) java.lang.RuntimeException: Failed to load class for data source: com.databricks.spark.csv at scala.sys.package$.error(package.scala:27) at org.apache.spark.sql.sources.ResolvedDataSource$.lookupDataSource(ddl.scala:268) at org.apache.spark.sql.sources.ResolvedDataSource$.apply(ddl.scala:279) at org.apache.spark.sql.SQLContext.load(SQLContext.scala:679) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065) at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338) at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840) at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871) at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819) at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:856) at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:901) at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:813) at org.</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Removing consecutive duplicates</title>
      <link>https://markhneedham.com/blog/2015/07/30/neo4j-cypher-removing-consecutive-duplicates/</link>
      <pubDate>Thu, 30 Jul 2015 06:23:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/30/neo4j-cypher-removing-consecutive-duplicates/</guid>
      <description>RETURN [1,1,2,3,4,5,6,7,7,8] AS values ==&amp;gt; +-----------------------+ ==&amp;gt; | values | ==&amp;gt; +-----------------------+ ==&amp;gt; | [1,1,2,3,4,5,6,7,7,8] | ==&amp;gt; +-----------------------+ ==&amp;gt; 1 row WITH [1,1,2,3,4,5,6,7,7,8] AS values UNWIND RANGE(0, LENGTH(values) - 2) AS idx RETURN idx, idx+1, values[idx], values[idx+1] ==&amp;gt; +-------------------------------------------+ ==&amp;gt; | idx | idx+1 | values[idx] | values[idx+1] | ==&amp;gt; +-------------------------------------------+ ==&amp;gt; | 0 | 1 | 1 | 1 | ==&amp;gt; | 1 | 2 | 1 | 2 | ==&amp;gt; | 2 | 3 | 2 | 3 | ==&amp;gt; | 3 | 4 | 3 | 4 | ==&amp;gt; | 4 | 5 | 4 | 5 | ==&amp;gt; | 5 | 6 | 5 | 6 | ==&amp;gt; | 6 | 7 | 6 | 7 | ==&amp;gt; | 7 | 8 | 7 | 7 | ==&amp;gt; | 8 | 9 | 7 | 8 | ==&amp;gt; +-------------------------------------------+ ==&amp;gt; 9 rows WITH [1,1,2,3,4,5,6,7,7,8] AS values UNWIND RANGE(0, LENGTH(values) - 2) AS idx WITH values[idx] AS a, values[idx+1] AS b WHERE a &amp;lt;&amp;gt; b RETURN a,b ==&amp;gt; +-------+ ==&amp;gt; | a | b | ==&amp;gt; +-------+ ==&amp;gt; | 1 | 2 | ==&amp;gt; | 2 | 3 | ==&amp;gt; | 3 | 4 | ==&amp;gt; | 4 | 5 | ==&amp;gt; | 5 | 6 | ==&amp;gt; | 6 | 7 | ==&amp;gt; | 7 | 8 | ==&amp;gt; +-------+ ==&amp;gt; 7 rows WITH [1,1,2,3,4,5,6,7,7,8] AS values UNWIND RANGE(0, LENGTH(values) - 2) AS idx WITH values[idx] AS a, values[idx+1] AS b WHERE a &amp;lt;&amp;gt; b RETURN COLLECT(a)[0] + COLLECT(b) AS noDuplicates ==&amp;gt; +-------------------+ ==&amp;gt; | noDuplicates | ==&amp;gt; +-------------------+ ==&amp;gt; | [1,2,3,4,5,6,7,8] | ==&amp;gt; +-------------------+ ==&amp;gt; 1 row WITH [1,1,1,2,3,4,5,5,6,7,7,8] AS values UNWIND RANGE(0, LENGTH(values) - 2) AS idx WITH values[idx] AS a, values[idx+1] AS b WHERE a &amp;lt;&amp;gt; b RETURN COLLECT(a)[0] + COLLECT(b) AS noDuplicates ==&amp;gt; +-------------------+ ==&amp;gt; | noDuplicates | ==&amp;gt; +-------------------+ ==&amp;gt; | [1,2,3,4,5,6,7,8] | ==&amp;gt; +-------------------+ ==&amp;gt; 1 row WITH [1,1,1,2,3,4,5,5,6,7,7,8,1] AS values UNWIND RANGE(0, LENGTH(values) - 2) AS idx WITH values[idx] AS a, values[idx+1] AS b WHERE a &amp;lt;&amp;gt; b RETURN COLLECT(a)[0] + COLLECT(b) AS noDuplicates ==&amp;gt; +---------------------+ ==&amp;gt; | noDuplicates | ==&amp;gt; +---------------------+ ==&amp;gt; | [1,2,3,4,5,6,7,8,1] | ==&amp;gt; +---------------------+ ==&amp;gt; 1 row </description>
    </item>
    
    <item>
      <title>Neo4j: MERGE&#39;ing on super nodes</title>
      <link>https://markhneedham.com/blog/2015/07/28/neo4j-mergeing-on-super-nodes/</link>
      <pubDate>Tue, 28 Jul 2015 21:04:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/28/neo4j-mergeing-on-super-nodes/</guid>
      <description>MATCH (crime:Crime) WITH crime SKIP {skip} LIMIT 10000 MATCH (subCat:SubCategory {code: crime.fbiCode}) MERGE (crime)-[:CATEGORY]-&amp;gt;(subCat) RETURN COUNT(*) AS crimesProcessed MATCH (crime:Crime) WITH crime SKIP {skip} LIMIT 10000 MATCH (subCat:SubCategory {code: crime.fbiCode}) WITH crime, subCat, shortestPath((crime)-[:CATEGORY]-&amp;gt;(subCat)) AS path FOREACH(ignoreMe IN CASE WHEN path is NULL THEN [1] ELSE [] END | CREATE (crime)-[:CATEGORY]-&amp;gt;(subCat)) RETURN COUNT(*) MATCH (crime:Crime) WITH crime SKIP {skip} LIMIT 10000 MATCH (subCat:SubCategory {code: crime.fbiCode}) CREATE UNIQUE (crime)-[:CATEGORY]-&amp;gt;(subCat) RETURN COUNT(*) AS crimesProcessed </description>
    </item>
    
    <item>
      <title>Python: Difference between two datetimes in milliseconds</title>
      <link>https://markhneedham.com/blog/2015/07/28/python-difference-between-two-datetimes-in-milliseconds/</link>
      <pubDate>Tue, 28 Jul 2015 20:05:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/28/python-difference-between-two-datetimes-in-milliseconds/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; import datetime &amp;gt;&amp;gt;&amp;gt; start = datetime.datetime.now() &amp;gt;&amp;gt;&amp;gt; end = datetime.datetime.now() &amp;gt;&amp;gt;&amp;gt; end - start datetime.timedelta(0, 3, 519319) &amp;gt;&amp;gt;&amp;gt; dir(end - start) [&amp;#39;__abs__&amp;#39;, &amp;#39;__add__&amp;#39;, &amp;#39;__class__&amp;#39;, &amp;#39;__delattr__&amp;#39;, &amp;#39;__div__&amp;#39;, &amp;#39;__doc__&amp;#39;, &amp;#39;__eq__&amp;#39;, &amp;#39;__floordiv__&amp;#39;, &amp;#39;__format__&amp;#39;, &amp;#39;__ge__&amp;#39;, &amp;#39;__getattribute__&amp;#39;, &amp;#39;__gt__&amp;#39;, &amp;#39;__hash__&amp;#39;, &amp;#39;__init__&amp;#39;, &amp;#39;__le__&amp;#39;, &amp;#39;__lt__&amp;#39;, &amp;#39;__mul__&amp;#39;, &amp;#39;__ne__&amp;#39;, &amp;#39;__neg__&amp;#39;, &amp;#39;__new__&amp;#39;, &amp;#39;__nonzero__&amp;#39;, &amp;#39;__pos__&amp;#39;, &amp;#39;__radd__&amp;#39;, &amp;#39;__rdiv__&amp;#39;, &amp;#39;__reduce__&amp;#39;, &amp;#39;__reduce_ex__&amp;#39;, &amp;#39;__repr__&amp;#39;, &amp;#39;__rfloordiv__&amp;#39;, &amp;#39;__rmul__&amp;#39;, &amp;#39;__rsub__&amp;#39;, &amp;#39;__setattr__&amp;#39;, &amp;#39;__sizeof__&amp;#39;, &amp;#39;__str__&amp;#39;, &amp;#39;__sub__&amp;#39;, &amp;#39;__subclasshook__&amp;#39;, &amp;#39;days&amp;#39;, &amp;#39;max&amp;#39;, &amp;#39;microseconds&amp;#39;, &amp;#39;min&amp;#39;, &amp;#39;resolution&amp;#39;, &amp;#39;seconds&amp;#39;, &amp;#39;total_seconds&amp;#39;] &amp;gt;&amp;gt;&amp;gt; diff = end - start &amp;gt;&amp;gt;&amp;gt; elapsed_ms = (diff.</description>
    </item>
    
    <item>
      <title>Neo4j: From JSON to CSV to LOAD CSV via jq</title>
      <link>https://markhneedham.com/blog/2015/07/25/neo4j-from-json-to-csv-to-load-csv-via-jq/</link>
      <pubDate>Sat, 25 Jul 2015 23:05:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/25/neo4j-from-json-to-csv-to-load-csv-via-jq/</guid>
      <description>{ &amp;#34;categories&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Index Crime&amp;#34;, &amp;#34;sub_categories&amp;#34;: [ { &amp;#34;code&amp;#34;: &amp;#34;01A&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;Homicide 1st &amp;amp; 2nd Degree&amp;#34; }, ] }, { &amp;#34;name&amp;#34;: &amp;#34;Non-Index Crime&amp;#34;, &amp;#34;sub_categories&amp;#34;: [ { &amp;#34;code&amp;#34;: &amp;#34;01B&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;Involuntary Manslaughter&amp;#34; }, ] }, { &amp;#34;name&amp;#34;: &amp;#34;Violent Crime&amp;#34;, &amp;#34;sub_categories&amp;#34;: [ { &amp;#34;code&amp;#34;: &amp;#34;01A&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;Homicide 1st &amp;amp; 2nd Degree&amp;#34; }, ] } ] } We want to get one row for each sub category which contains three columns - category name, sub category code, sub category description.</description>
    </item>
    
    <item>
      <title>Neo4j: Loading JSON documents with Cypher</title>
      <link>https://markhneedham.com/blog/2015/07/23/neo4j-loading-json-documents-with-cypher/</link>
      <pubDate>Thu, 23 Jul 2015 06:15:11 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/23/neo4j-loading-json-documents-with-cypher/</guid>
      <description>{ &amp;#34;categories&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Index Crime&amp;#34;, &amp;#34;sub_categories&amp;#34;: [ { &amp;#34;code&amp;#34;: &amp;#34;01A&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;Homicide 1st &amp;amp; 2nd Degree&amp;#34; } ] }, { &amp;#34;name&amp;#34;: &amp;#34;Non-Index Crime&amp;#34;, &amp;#34;sub_categories&amp;#34;: [ { &amp;#34;code&amp;#34;: &amp;#34;01B&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;Involuntary Manslaughter&amp;#34; } ] }, { &amp;#34;name&amp;#34;: &amp;#34;Violent Crime&amp;#34;, &amp;#34;sub_categories&amp;#34;: [ { &amp;#34;code&amp;#34;: &amp;#34;01A&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;Homicide 1st &amp;amp; 2nd Degree&amp;#34; } ] } ] } import json from py2neo import Graph, authenticate # replace &amp;#39;foobar&amp;#39; with your password authenticate(&amp;#34;localhost:7474&amp;#34;, &amp;#34;neo4j&amp;#34;, &amp;#34;foobar&amp;#34;) graph = Graph() with open(&amp;#39;categories.</description>
    </item>
    
    <item>
      <title>Neo4j 2.2.3: neo4j-import - Encoder StringEncoder[2] returned an illegal encoded value 0</title>
      <link>https://markhneedham.com/blog/2015/07/21/neo4j-2-2-3-neo4j-import-encoder-stringencoder2-returned-an-illegal-encoded-value-0/</link>
      <pubDate>Tue, 21 Jul 2015 06:11:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/21/neo4j-2-2-3-neo4j-import-encoder-stringencoder2-returned-an-illegal-encoded-value-0/</guid>
      <description>Importing the contents of these files into tmp/crimes.db: Nodes: /Users/markneedham/projects/neo4j-spark-chicago/tmp/crimes.csv /Users/markneedham/projects/neo4j-spark-chicago/tmp/beats.csv /Users/markneedham/projects/neo4j-spark-chicago/tmp/primaryTypes.csv /Users/markneedham/projects/neo4j-spark-chicago/tmp/locations.csv Relationships: /Users/markneedham/projects/neo4j-spark-chicago/tmp/crimesBeats.csv /Users/markneedham/projects/neo4j-spark-chicago/tmp/crimesPrimaryTypes.csv /Users/markneedham/projects/neo4j-spark-chicago/tmp/crimesLocationsCleaned.csv Available memory: Free machine memory: 263.17 MB Max heap memory : 3.56 GB Nodes [*&amp;gt;:17.41 MB/s-------------------------|PROPERTIES(3)=|NODE:3|LABEL SCAN----|v:36.30 MB/s(2)===] 3MImport error: Panic called, so exiting java.lang.RuntimeException: Panic called, so exiting at org.neo4j.unsafe.impl.batchimport.staging.AbstractStep.assertHealthy(AbstractStep.java:200) at org.neo4j.unsafe.impl.batchimport.staging.AbstractStep.await(AbstractStep.java:191) at org.neo4j.unsafe.impl.batchimport.staging.ProcessorStep.receive(ProcessorStep.java:98) at org.neo4j.unsafe.impl.batchimport.staging.ProcessorStep.sendDownstream(ProcessorStep.java:224) at org.neo4j.unsafe.impl.batchimport.staging.ProcessorStep.access$400(ProcessorStep.java:42) at org.neo4j.unsafe.impl.batchimport.staging.ProcessorStep$Sender.send(ProcessorStep.java:250) at org.neo4j.unsafe.impl.batchimport.LabelScanStorePopulationStep.process(LabelScanStorePopulationStep.java:60) at org.neo4j.unsafe.impl.batchimport.LabelScanStorePopulationStep.process(LabelScanStorePopulationStep.java:37) at org.neo4j.unsafe.impl.batchimport.staging.ProcessorStep$4.run(ProcessorStep.java:120) at org.neo4j.unsafe.impl.batchimport.staging.ProcessorStep$4.run(ProcessorStep.java:102) at org.neo4j.unsafe.impl.batchimport.executor.DynamicTaskExecutor$Processor.run(DynamicTaskExecutor.java:237) Caused by: java.</description>
    </item>
    
    <item>
      <title>R: Bootstrap confidence intervals</title>
      <link>https://markhneedham.com/blog/2015/07/19/r-bootstrap-confidence-intervals/</link>
      <pubDate>Sun, 19 Jul 2015 19:44:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/19/r-bootstrap-confidence-intervals/</guid>
      <description>&amp;gt; data = c(0, 1, 3, 2, 8, 2, 3, 4) &amp;gt; quantile(data, 0.05) 5% 0.35 &amp;gt; sample(data, replace = TRUE) [1] 0 3 2 8 8 0 8 0 &amp;gt; sample(data, replace = TRUE) [1] 2 2 4 3 4 4 2 2 library(ggplot) bootstrap_5th_percentile = function(data, n_bootstraps) { return(sapply(1:n_bootstraps, function(iteration) quantile(sample(data, replace = TRUE), 0.05))) } values = bootstrap_5th_percentile(data, 10000) ggplot(aes(x = value), data = data.frame(value = values)) + geom_histogram(binwidth=0.</description>
    </item>
    
    <item>
      <title>R: Blog post frequency anomaly detection</title>
      <link>https://markhneedham.com/blog/2015/07/17/r-blog-post-frequency-anomaly-detection/</link>
      <pubDate>Fri, 17 Jul 2015 23:34:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/17/r-blog-post-frequency-anomaly-detection/</guid>
      <description>install.packages(&amp;#34;devtools&amp;#34;) devtools::install_github(&amp;#34;twitter/AnomalyDetection&amp;#34;) library(AnomalyDetection) &amp;gt; library(dplyr) &amp;gt; raw_data %&amp;gt;% head() timestamp count 1 1980-09-25 14:01:00 182.478 2 1980-09-25 14:02:00 176.231 3 1980-09-25 14:03:00 183.917 4 1980-09-25 14:04:00 177.798 5 1980-09-25 14:05:00 165.469 6 1980-09-25 14:06:00 181.878 res = AnomalyDetectionTs(raw_data, max_anoms=0.02, direction=&amp;#39;both&amp;#39;, plot=TRUE) res$plot &amp;gt; df %&amp;gt;% sample_n(5) title date 1425 Coding: Copy/Paste then refactor 2009-10-31 07:54:31 783 Neo4j 2.0.0-M06 -&amp;gt; 2.0.0-RC1: Working with path expressions 2013-11-23 10:30:41 960 R: Removing for loops 2015-04-18 23:53:20 966 R: dplyr - Error in (list: invalid subscript type &amp;#39;double&amp;#39; 2015-04-27 22:34:43 343 Parsing XML from the unix terminal/shell 2011-09-03 23:42:11 &amp;gt; byWeek = df %&amp;gt;% mutate(year = year(date), week = week(date)) %&amp;gt;% group_by(week, year) %&amp;gt;% summarise(n = n()) %&amp;gt;% ungroup() %&amp;gt;% arrange(desc(n)) &amp;gt; byWeek %&amp;gt;% sample_n(5) Source: local data frame [5 x 3] week year n 1 44 2009 6 2 37 2011 4 3 39 2012 3 4 7 2013 4 5 6 2010 6 &amp;gt; data = byWeek %&amp;gt;% mutate(start_of_week = calculate_start_of_week(week, year)) %&amp;gt;% filter(start_of_week &amp;gt; ymd(&amp;#34;2008-07-01&amp;#34;)) %&amp;gt;% select(start_of_week, n) &amp;gt; data %&amp;gt;% sample_n(5) Source: local data frame [5 x 2] start_of_week n 1 2010-09-10 4 2 2013-04-09 4 3 2010-04-30 6 4 2012-03-11 3 5 2014-12-03 3 res = AnomalyDetectionTs(data, max_anoms=0.</description>
    </item>
    
    <item>
      <title>Neo4j: The football transfers graph</title>
      <link>https://markhneedham.com/blog/2015/07/16/neo4j-the-football-transfers-graph/</link>
      <pubDate>Thu, 16 Jul 2015 06:40:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/16/neo4j-the-football-transfers-graph/</guid>
      <description>$ head -n 10 data/transfers.csv player,from_team,from_team_id,to_team,to_team_id,fee,season Martin Keown,Everton,29,Arsenal FC,11,&amp;#34;2,10 Mill. £&amp;#34;,1992-1993 John Jensen,Bröndby IF,206,Arsenal FC,11,&amp;#34;1,12 Mill. £&amp;#34;,1992-1993 Alan Miller,Birmingham,337,Arsenal FC,11,,1992-1993 Jim Will,Sheffield Utd.,350,Arsenal FC,11,,1992-1993 David Rocastle,Arsenal FC,11,Leeds,399,&amp;#34;1,68 Mill. £&amp;#34;,1992-1993 Perry Groves,Arsenal FC,11,Southampton FC,180,595 Th. £,1992-1993 Ty Gooden,Arsenal FC,11,Wycombe Wand.,2805,?,1992-1993 Geraint Williams,Derby,22,Ipswich Town,677,525 Th. £,1992-1993 Jason Winters,Chelsea U21,9250,Ipswich Town,677,?,1992-1993 create index on :Team(id); create index on :Season(name); create index on :Transfer(description); create index on :Player(name); // teams load csv with headers from &amp;quot;file:///Users/markneedham/projects/football-transfers/data/teams.</description>
    </item>
    
    <item>
      <title>Python: UnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe2 in position 0: ordinal not in range(128)</title>
      <link>https://markhneedham.com/blog/2015/07/15/python-unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-0-ordinal-not-in-range128/</link>
      <pubDate>Wed, 15 Jul 2015 06:20:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/15/python-unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2-in-position-0-ordinal-not-in-range128/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39; u&amp;#39;foo \u2020&amp;#39; &amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39;.replace(&amp;#34; †&amp;#34;, &amp;#34;&amp;#34;) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; UnicodeDecodeError: &amp;#39;ascii&amp;#39; codec can&amp;#39;t decode byte 0xe2 in position 1: ordinal not in range(128) &amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39;.replace(u&amp;#39; †&amp;#39;, &amp;#34;&amp;#34;) u&amp;#39;foo&amp;#39; &amp;gt;&amp;gt;&amp;gt; u&amp;#39;foo †&amp;#39;.replace(unicode(&amp;#39; †&amp;#39;, &amp;#34;utf-8&amp;#34;), &amp;#34;&amp;#34;) u&amp;#39;foo&amp;#39; </description>
    </item>
    
    <item>
      <title>R: I write more in the last week of the month, or do I?</title>
      <link>https://markhneedham.com/blog/2015/07/12/r-i-write-more-in-the-last-week-of-the-month-or-do-i/</link>
      <pubDate>Sun, 12 Jul 2015 09:53:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/12/r-i-write-more-in-the-last-week-of-the-month-or-do-i/</guid>
      <description>&amp;gt; df %&amp;gt;% sample_n(5) title date 946 Python: Equivalent to flatMap for flattening an array of arrays 2015-03-23 00:45:00 175 Ruby: Hash default value 2010-10-16 14:02:37 375 Java/Scala: Runtime.exec hanging/in &amp;#39;pipe_w&amp;#39; state 2011-11-20 20:20:08 1319 Coding Dojo #18: Groovy Bowling Game 2009-06-26 08:15:23 381 Continuous Delivery: Removing manual scenarios 2011-12-05 23:13:34 calculate_start_of_week = function(week, year) { date &amp;lt;- ymd(paste(year, 1, 1, sep=&amp;#34;-&amp;#34;)) week(date) = week return(date) } tidy_df = df %&amp;gt;% mutate(year = year(date), week = week(date), week_in_month = ceiling(day(date) / 7), max_week = max(week_in_month), weeks_from_end = max_week - week_in_month, start_of_week = calculate_start_of_week(week, year)) &amp;gt; tidy_df %&amp;gt;% select(date, weeks_from_end, start_of_week) %&amp;gt;% sample_n(5) date weeks_from_end start_of_week 1023 2008-08-08 21:16:02 3 2008-08-05 800 2014-01-31 06:51:06 0 2014-01-29 859 2014-08-14 10:24:52 3 2014-08-13 107 2010-07-10 22:49:52 3 2010-07-09 386 2011-12-20 23:57:51 2 2011-12-17 weeks_from_end_counts = tidy_df %&amp;gt;% group_by(start_of_week, weeks_from_end) %&amp;gt;% summarise(count = n()) &amp;gt; weeks_from_end_counts Source: local data frame [540 x 4] Groups: start_of_week, weeks_from_end start_of_week weeks_from_end year count 1 2006-08-27 0 2006 1 2 2006-08-27 4 2006 3 3 2006-09-03 4 2006 1 4 2008-02-05 3 2008 2 5 2008-02-12 3 2008 2 6 2008-07-15 2 2008 1 7 2008-07-22 1 2008 1 8 2008-08-05 3 2008 8 9 2008-08-12 2 2008 5 10 2008-08-12 3 2008 9 .</description>
    </item>
    
    <item>
      <title>R: Filling in missing dates with 0s</title>
      <link>https://markhneedham.com/blog/2015/07/12/r-filling-in-missing-dates-with-0s/</link>
      <pubDate>Sun, 12 Jul 2015 08:30:40 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/12/r-filling-in-missing-dates-with-0s/</guid>
      <description>&amp;gt; library(zoo) &amp;gt; library(dplyr) &amp;gt; df %&amp;gt;% sample_n(5) title date 888 R: Converting a named vector to a data frame 2014-10-31 23:47:26 144 Rails: Populating a dropdown list using &amp;#39;form_for&amp;#39; 2010-08-31 01:22:14 615 Onboarding: Sketch the landscape 2013-02-15 07:36:06 28 Javascript: The &amp;#39;new&amp;#39; keyword 2010-03-06 15:16:02 1290 Coding Dojo #16: Reading SUnit code 2009-05-28 23:23:19 &amp;gt; posts_by_date = df %&amp;gt;% mutate(year_mon = as.Date(as.yearmon(date))) %&amp;gt;% count(year_mon) &amp;gt; posts_by_date %&amp;gt;% head(5) year_mon n 1 2006-08-01 1 2 2006-09-01 4 3 2008-02-01 4 4 2008-07-01 2 5 2008-08-01 38 &amp;gt; ggplot(aes(x = year_mon, y = n), data = posts_by_date) + geom_line() &amp;gt; all_dates = seq(as.</description>
    </item>
    
    <item>
      <title>R: Date for given week/year</title>
      <link>https://markhneedham.com/blog/2015/07/10/r-date-for-given-weekyear/</link>
      <pubDate>Fri, 10 Jul 2015 22:01:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/10/r-date-for-given-weekyear/</guid>
      <description>&amp;gt; library(dplyr) &amp;gt; df = read.csv(&amp;#34;posts.csv&amp;#34;) &amp;gt; df$date = ymd_hms(df$date) &amp;gt; df %&amp;gt;% sample_n(10) title date 538 Nygard Big Data Model: The Investigation Stage 2012-10-10 00:00:36 341 The read-only database 2011-08-29 23:32:26 1112 CSS in Internet Explorer - Some lessons learned 2008-10-31 15:24:51 143 Coding: Mutating parameters 2010-08-26 07:47:23 433 Scala: Counting number of inversions (via merge sort) for an unsorted collection 2012-03-20 06:53:18 618 neo4j/cypher: SQL style GROUP BY functionality 2013-02-17 21:05:27 1111 Testing Hibernate mappings: Setting up test data 2008-10-30 13:24:14 462 neo4j: What question do you want to answer?</description>
    </item>
    
    <item>
      <title>R: dplyr - Error: cannot modify grouping variable</title>
      <link>https://markhneedham.com/blog/2015/07/09/r-dplyr-error-cannot-modify-grouping-variable/</link>
      <pubDate>Thu, 09 Jul 2015 05:55:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/09/r-dplyr-error-cannot-modify-grouping-variable/</guid>
      <description>&amp;gt; library(dplyr) &amp;gt; df %&amp;gt;% sample_n(5) title date 1148 Taiichi Ohno&amp;#39;s Workplace Management: Book Review 2008-12-08 14:14:48 158 Rails: Faking a delete method with &amp;#39;form_for&amp;#39; 2010-09-20 18:52:15 331 Retrospectives: The 4 L&amp;#39;s Retrospective 2011-07-25 21:00:30 1035 msbuild - Use OutputPath instead of OutDir 2008-08-14 18:54:03 1181 The danger of commenting out code 2009-01-17 06:02:33 &amp;gt; df %&amp;gt;% mutate(day = as.Date(date)) %&amp;gt;% count(day) %&amp;gt;% arrange(desc(n)) Source: local data frame [1,140 x 2] day n 1 2012-12-31 6 2 2014-05-31 6 3 2008-08-08 5 4 2013-01-27 5 5 2009-08-24 4 6 2012-06-24 4 7 2012-09-30 4 8 2012-10-27 4 9 2012-11-24 4 10 2013-02-28 4 &amp;gt; df %&amp;gt;% mutate(day = as.</description>
    </item>
    
    <item>
      <title>Python: Converting WordPress posts in CSV format</title>
      <link>https://markhneedham.com/blog/2015/07/07/python-converting-wordpress-posts-in-csv-format/</link>
      <pubDate>Tue, 07 Jul 2015 06:28:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/07/python-converting-wordpress-posts-in-csv-format/</guid>
      <description>&amp;lt;rss version=&amp;#34;2.0&amp;#34; xmlns:excerpt=&amp;#34;http://wordpress.org/export/1.2/excerpt/&amp;#34; xmlns:content=&amp;#34;http://purl.org/rss/1.0/modules/content/&amp;#34; xmlns:wfw=&amp;#34;http://wellformedweb.org/CommentAPI/&amp;#34; xmlns:dc=&amp;#34;http://purl.org/dc/elements/1.1/&amp;#34; xmlns:wp=&amp;#34;http://wordpress.org/export/1.2/&amp;#34; &amp;gt; ... &amp;lt;channel&amp;gt; &amp;lt;item&amp;gt; &amp;lt;title&amp;gt;First thoughts on Ruby...&amp;lt;/title&amp;gt; &amp;lt;link&amp;gt;http://www.markhneedham.com/blog/2006/08/29/first-thoughts-on-ruby/&amp;lt;/link&amp;gt; &amp;lt;pubDate&amp;gt;Tue, 29 Aug 2006 13:31:05 +0000&amp;lt;/pubDate&amp;gt; ... from bs4 import BeautifulSoup from soupselect import select from dateutil import parser import csv def read_page(page): return BeautifulSoup(open(page, &amp;#39;r&amp;#39;).read()) with open(&amp;#34;posts.csv&amp;#34;, &amp;#34;w&amp;#34;) as file: writer = csv.writer(file, delimiter=&amp;#34;,&amp;#34;) writer.writerow([&amp;#34;title&amp;#34;, &amp;#34;date&amp;#34;]) for row in select(read_page(&amp;#34;part2.xml&amp;#34;), &amp;#34;item&amp;#34;): title = select(row, &amp;#34;title&amp;#34;)[0].text.encode(&amp;#34;utf-8&amp;#34;) date = parser.parse(select(row, &amp;#34;pubdate&amp;#34;)[0].text) writer.writerow([title, date]) for row in select(read_page(&amp;#34;part1.</description>
    </item>
    
    <item>
      <title>R: Wimbledon - How do the seeds get on?</title>
      <link>https://markhneedham.com/blog/2015/07/05/r-wimbledon-how-do-the-seeds-get-on/</link>
      <pubDate>Sun, 05 Jul 2015 08:38:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/05/r-wimbledon-how-do-the-seeds-get-on/</guid>
      <description>expected_round = function(seeding) { if(seeding == 1) { return(&amp;#34;Winner&amp;#34;) } else if(seeding == 2) { return(&amp;#34;Finals&amp;#34;) } else if(seeding &amp;lt;= 4) { return(&amp;#34;Semi-Finals&amp;#34;) } else if(seeding &amp;lt;= 8) { return(&amp;#34;Quarter-Finals&amp;#34;) } else if(seeding &amp;lt;= 16) { return(&amp;#34;Round of 16&amp;#34;) } else { return(&amp;#34;Round of 32&amp;#34;) } } &amp;gt; expected_round(1) [1] &amp;#34;Winner&amp;#34; &amp;gt; expected_round(4) [1] &amp;#34;Semi-Finals&amp;#34; round_reached = function(player, main_matches) { furthest_match = main_matches %&amp;gt;% filter(winner == player | loser == player) %&amp;gt;% arrange(desc(round)) %&amp;gt;% head(1) return(ifelse(furthest_match$winner == player, &amp;#34;Winner&amp;#34;, as.</description>
    </item>
    
    <item>
      <title>R: Calculating the difference between ordered factor variables</title>
      <link>https://markhneedham.com/blog/2015/07/02/r-calculating-the-difference-between-ordered-factor-variables/</link>
      <pubDate>Thu, 02 Jul 2015 22:55:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/07/02/r-calculating-the-difference-between-ordered-factor-variables/</guid>
      <description>rounds = c(&amp;#34;Did not enter&amp;#34;, &amp;#34;Round of 128&amp;#34;, &amp;#34;Round of 64&amp;#34;, &amp;#34;Round of 32&amp;#34;, &amp;#34;Round of 16&amp;#34;, &amp;#34;Quarter-Finals&amp;#34;, &amp;#34;Semi-Finals&amp;#34;, &amp;#34;Finals&amp;#34;, &amp;#34;Winner&amp;#34;) round = factor(&amp;#34;Finals&amp;#34;, levels = rounds, ordered = TRUE) expected = factor(&amp;#34;Winner&amp;#34;, levels = rounds, ordered = TRUE) &amp;gt; round [1] Finals 9 Levels: Did not enter &amp;lt; Round of 128 &amp;lt; Round of 64 &amp;lt; Round of 32 &amp;lt; Round of 16 &amp;lt; Quarter-Finals &amp;lt; ... &amp;lt; Winner &amp;gt; expected [1] Winner 9 Levels: Did not enter &amp;lt; Round of 128 &amp;lt; Round of 64 &amp;lt; Round of 32 &amp;lt; Round of 16 &amp;lt; Quarter-Finals &amp;lt; .</description>
    </item>
    
    <item>
      <title>R: write.csv - unimplemented type &#39;list&#39; in &#39;EncodeElement&#39;</title>
      <link>https://markhneedham.com/blog/2015/06/30/r-write-csv-unimplemented-type-list-in-encodeelement/</link>
      <pubDate>Tue, 30 Jun 2015 22:26:39 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/30/r-write-csv-unimplemented-type-list-in-encodeelement/</guid>
      <description>&amp;gt; write.csv(foo, &amp;#34;/tmp/foo.csv&amp;#34;, row.names = FALSE) Error in .External2(C_writetable, x, file, nrow(x), p, rnames, sep, eol, : unimplemented type &amp;#39;list&amp;#39; in &amp;#39;EncodeElement&amp;#39; &amp;gt; foo col1 col2 1 1 a 2 2 b 3 3 c &amp;gt; typeof(foo$col1) [1] &amp;#34;double&amp;#34; &amp;gt; typeof(foo$col2) [1] &amp;#34;list&amp;#34; library(dplyr) foo = data.frame(col1 = c(1,2,3)) %&amp;gt;% mutate(col2 = list(&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;)) foo = data.frame(col1 = c(1,2,3)) %&amp;gt;% mutate(col2 = list(&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;) %&amp;gt;% unlist()) write.csv(foo, &amp;#34;/tmp/foo.csv&amp;#34;, row.</description>
    </item>
    
    <item>
      <title>R: Speeding up the Wimbledon scraping job</title>
      <link>https://markhneedham.com/blog/2015/06/29/r-speeding-up-the-wimbledon-scraping-job/</link>
      <pubDate>Mon, 29 Jun 2015 05:36:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/29/r-speeding-up-the-wimbledon-scraping-job/</guid>
      <description>library(rvest) library(dplyr) scrape_matches1 = function(uri) { matches = data.frame() s = html(uri) rows = s %&amp;gt;% html_nodes(&amp;#34;div#scoresResultsContent tr&amp;#34;) i = 0 for(row in rows) { players = row %&amp;gt;% html_nodes(&amp;#34;td.day-table-name a&amp;#34;) seedings = row %&amp;gt;% html_nodes(&amp;#34;td.day-table-seed&amp;#34;) score = row %&amp;gt;% html_node(&amp;#34;td.day-table-score a&amp;#34;) flags = row %&amp;gt;% html_nodes(&amp;#34;td.day-table-flag img&amp;#34;) if(!is.null(score)) { player1 = players[1] %&amp;gt;% html_text() %&amp;gt;% str_trim() seeding1 = ifelse(!is.na(seedings[1]), seedings[1] %&amp;gt;% html_node(&amp;#34;span&amp;#34;) %&amp;gt;% html_text() %&amp;gt;% str_trim(), NA) flag1 = flags[1] %&amp;gt;% html_attr(&amp;#34;alt&amp;#34;) player2 = players[2] %&amp;gt;% html_text() %&amp;gt;% str_trim() seeding2 = ifelse(!</description>
    </item>
    
    <item>
      <title>R: dplyr - Update rows with earlier/previous rows values</title>
      <link>https://markhneedham.com/blog/2015/06/28/r-dplyr-update-rows-with-earlierprevious-rows-values/</link>
      <pubDate>Sun, 28 Jun 2015 22:30:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/28/r-dplyr-update-rows-with-earlierprevious-rows-values/</guid>
      <description>&amp;gt; data.frame(col1 = c(1,2,3,4,5), col2 = c(&amp;#34;a&amp;#34;, NA, NA , &amp;#34;b&amp;#34;, NA)) col1 col2 1 1 a 2 2 &amp;lt;NA&amp;gt; 3 3 &amp;lt;NA&amp;gt; 4 4 b 5 5 &amp;lt;NA&amp;gt; 1 1 a 2 2 a 3 3 a 4 4 b 5 5 b library(zoo) library(dplyr) &amp;gt; data.frame(col1 = c(1,2,3,4,5), col2 = c(&amp;#34;a&amp;#34;, NA, NA , &amp;#34;b&amp;#34;, NA)) %&amp;gt;% do(na.locf(.)) col1 col2 1 1 a 2 2 a 3 3 a 4 4 b 5 5 b &amp;gt; data.</description>
    </item>
    
    <item>
      <title>R: Command line - Error in GenericTranslator$new : could not find function &#34;loadMethod&#34;</title>
      <link>https://markhneedham.com/blog/2015/06/27/r-command-line-error-in-generictranslatornew-could-not-find-function-loadmethod/</link>
      <pubDate>Sat, 27 Jun 2015 22:47:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/27/r-command-line-error-in-generictranslatornew-could-not-find-function-loadmethod/</guid>
      <description>wimbledon#!/usr/bin/env Rscript library(rvest) library(dplyr) library(stringr) library(readr) # stuff $ time ./wimbledon ... Error in GenericTranslator$new : could not find function &amp;#34;loadMethod&amp;#34; Calls: write.csv ... html_extract_n -&amp;gt; &amp;lt;Anonymous&amp;gt; -&amp;gt; Map -&amp;gt; mapply -&amp;gt; &amp;lt;Anonymous&amp;gt; -&amp;gt; $ Execution halted real	0m1.431s user	0m1.127s sys	0m0.078s library(methods) #!/usr/bin/env Rscript library(methods) library(rvest) library(dplyr) library(stringr) library(readr) </description>
    </item>
    
    <item>
      <title>R: dplyr - squashing multiple rows per group into one</title>
      <link>https://markhneedham.com/blog/2015/06/27/r-dplyr-squashing-multiple-rows-per-group-into-one/</link>
      <pubDate>Sat, 27 Jun 2015 22:36:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/27/r-dplyr-squashing-multiple-rows-per-group-into-one/</guid>
      <description>library(dplyr) &amp;gt; main_matches %&amp;gt;% filter(loser == &amp;#34;Andy Murray&amp;#34;) %&amp;gt;% select(winner, year) winner year 1 Grigor Dimitrov 2014 2 Roger Federer 2012 3 Rafael Nadal 2011 4 Rafael Nadal 2010 5 Andy Roddick 2009 6 Rafael Nadal 2008 7 Marcos Baghdatis 2006 8 David Nalbandian 2005 &amp;gt; main_matches %&amp;gt;% filter(loser == &amp;#34;Andy Murray&amp;#34;) %&amp;gt;% group_by(winner) %&amp;gt;% summarise(years = paste(year)) Source: local data frame [6 x 2] winner years 1 Andy Roddick 2009 2 David Nalbandian 2005 3 Grigor Dimitrov 2014 4 Marcos Baghdatis 2006 5 Rafael Nadal 2011 6 Roger Federer 2012 &amp;gt; paste(c(2008,2009,2010)) [1] &amp;#34;2008&amp;#34; &amp;#34;2009&amp;#34; &amp;#34;2010&amp;#34; &amp;gt; paste(c(2008,2009,2010), collapse=&amp;#34;, &amp;#34;) [1] &amp;#34;2008, 2009, 2010&amp;#34; &amp;gt; main_matches %&amp;gt;% filter(loser == &amp;#34;Andy Murray&amp;#34;) %&amp;gt;% group_by(winner) %&amp;gt;% summarise(years = paste(year, collapse=&amp;#34;, &amp;#34;)) Source: local data frame [6 x 2] winner years 1 Andy Roddick 2009 2 David Nalbandian 2005 3 Grigor Dimitrov 2014 4 Marcos Baghdatis 2006 5 Rafael Nadal 2011, 2010, 2008 6 Roger Federer 2012 &amp;gt; main_matches %&amp;gt;% filter(loser == &amp;#34;Andy Murray&amp;#34;) %&amp;gt;% group_by(winner) %&amp;gt;% arrange(year) %&amp;gt;% summarise(years = paste(year, collapse =&amp;#34;,&amp;#34;), times = length(year)) %&amp;gt;% arrange(desc(times), years) Source: local data frame [6 x 3] winner years times 1 Rafael Nadal 2008,2010,2011 3 2 David Nalbandian 2005 1 3 Marcos Baghdatis 2006 1 4 Andy Roddick 2009 1 5 Roger Federer 2012 1 6 Grigor Dimitrov 2014 1 </description>
    </item>
    
    <item>
      <title>R: ggplot - Show discrete scale even with no value</title>
      <link>https://markhneedham.com/blog/2015/06/26/r-ggplot-show-discrete-scale-even-with-no-value/</link>
      <pubDate>Fri, 26 Jun 2015 22:48:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/26/r-ggplot-show-discrete-scale-even-with-no-value/</guid>
      <description>round_reached = function(player, main_matches) { furthest_match = main_matches %&amp;gt;% filter(winner == player | loser == player) %&amp;gt;% arrange(desc(round)) %&amp;gt;% head(1) return(ifelse(furthest_match$winner == player, &amp;#34;Winner&amp;#34;, as.character(furthest_match$round))) } player_performance = function(name, matches) { player = data.frame() for(y in 2005:2014) { round = round_reached(name, filter(matches, year == y)) if(length(round) == 1) { player = rbind(player, data.frame(year = y, round = round)) } else { player = rbind(player, data.frame(year = y, round = &amp;#34;Did not enter&amp;#34;)) } } return(player) } &amp;gt; player_performance(&amp;#34;Andy Murray&amp;#34;, main_matches) year round 1 2005 Round of 32 2 2006 Round of 16 3 2007 Did not enter 4 2008 Quarter-Finals 5 2009 Semi-Finals 6 2010 Semi-Finals 7 2011 Semi-Finals 8 2012 Finals 9 2013 Winner 10 2014 Quarter-Finals df = player_performance(&amp;#34;Andy Murray&amp;#34;, main_matches) rounds = c(&amp;#34;Did not enter&amp;#34;, &amp;#34;Round of 128&amp;#34;, &amp;#34;Round of 64&amp;#34;, &amp;#34;Round of 32&amp;#34;, &amp;#34;Round of 16&amp;#34;, &amp;#34;Quarter-Finals&amp;#34;, &amp;#34;Semi-Finals&amp;#34;, &amp;#34;Finals&amp;#34;, &amp;#34;Winner&amp;#34;) df$round = factor(df$round, levels = rounds) &amp;gt; df$round [1] Round of 32 Round of 16 Did not enter Quarter-Finals Semi-Finals Semi-Finals Semi-Finals [8] Finals Winner Quarter-Finals Levels: Did not enter Round of 128 Round of 64 Round of 32 Round of 16 Quarter-Finals Semi-Finals Finals Winner ggplot(aes(x = year, y = round, group=1), data = df) + geom_point() + geom_line() + scale_x_continuous(breaks=df$year) + scale_y_discrete(breaks = rounds) ggplot(aes(x = year, y = round, group=1), data = df) + geom_point() + geom_line() + scale_x_continuous(breaks=df$year) + scale_y_discrete(breaks = rounds, drop = FALSE) draw_chart = function(player, main_matches){ df = player_performance(player, main_matches) df$round = factor(df$round, levels = rounds) ggplot(aes(x = year, y = round, group=1), data = df) + geom_point() + geom_line() + scale_x_continuous(breaks=df$year) + scale_y_discrete(breaks = rounds, drop=FALSE) + ggtitle(player) + theme(axis.</description>
    </item>
    
    <item>
      <title>R: Scraping Wimbledon draw data</title>
      <link>https://markhneedham.com/blog/2015/06/25/r-scraping-wimbledon-draw-data/</link>
      <pubDate>Thu, 25 Jun 2015 23:14:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/25/r-scraping-wimbledon-draw-data/</guid>
      <description>library(rvest) library(dplyr) library(stringr) s = html_session(&amp;#34;http://www.atpworldtour.com/en/scores/archive/wimbledon/540/2013/results&amp;#34;) rows = s %&amp;gt;% html_nodes(&amp;#34;div#scoresResultsContent tr&amp;#34;) matches = data.frame() for(row in rows) { players = row %&amp;gt;% html_nodes(&amp;#34;td.day-table-name a&amp;#34;) seedings = row %&amp;gt;% html_nodes(&amp;#34;td.day-table-seed&amp;#34;) score = row %&amp;gt;% html_node(&amp;#34;td.day-table-score a&amp;#34;) if(!is.null(score)) { player1 = players[1] %&amp;gt;% html_text() %&amp;gt;% str_trim() seeding1 = ifelse(!is.na(seedings[1]), seedings[1] %&amp;gt;% html_node(&amp;#34;span&amp;#34;) %&amp;gt;% html_text() %&amp;gt;% str_trim(), NA) player2 = players[2] %&amp;gt;% html_text() %&amp;gt;% str_trim() seeding2 = ifelse(!is.na(seedings[2]), seedings[2] %&amp;gt;% html_node(&amp;#34;span&amp;#34;) %&amp;gt;% html_text() %&amp;gt;% str_trim(), NA) matches = rbind(data.</description>
    </item>
    
    <item>
      <title>R: Scraping the release dates of github projects</title>
      <link>https://markhneedham.com/blog/2015/06/23/r-scraping-the-release-dates-of-github-projects/</link>
      <pubDate>Tue, 23 Jun 2015 22:34:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/23/r-scraping-the-release-dates-of-github-projects/</guid>
      <description>library(dplyr) library(rvest) process_page = function(releases, session) { rows = session %&amp;gt;% html_nodes(&amp;#34;ul.release-timeline-tags li&amp;#34;) for(row in rows) { date = row %&amp;gt;% html_node(&amp;#34;span.date&amp;#34;) version = row %&amp;gt;% html_node(&amp;#34;div.tag-info a&amp;#34;) if(!is.null(version) &amp;amp;&amp;amp; !is.null(date)) { date = date %&amp;gt;% html_text() %&amp;gt;% str_trim() version = version %&amp;gt;% html_text() %&amp;gt;% str_trim() releases = rbind(releases, data.frame(date = date, version = version)) } } return(releases) } &amp;gt; r = process_page(data.frame(), html_session(&amp;#34;https://github.com/apache/cassandra/releases&amp;#34;)) &amp;gt; r date version 1 Jun 22, 2015 cassandra-2.</description>
    </item>
    
    <item>
      <title>R: Scraping Neo4j release dates with rvest</title>
      <link>https://markhneedham.com/blog/2015/06/21/r-scraping-neo4j-release-dates-with-rvest/</link>
      <pubDate>Sun, 21 Jun 2015 22:07:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/21/r-scraping-neo4j-release-dates-with-rvest/</guid>
      <description>download.file(&amp;#34;http://neo4j.com/release-notes/page/1&amp;#34;, &amp;#34;release-notes.html&amp;#34;) download.file(&amp;#34;http://neo4j.com/release-notes/page/2&amp;#34;, &amp;#34;release-notes2.html&amp;#34;) library(rvest) library(dplyr) page1 &amp;lt;- html(&amp;#34;release-notes.html&amp;#34;) page2 &amp;lt;- html(&amp;#34;release-notes2.html&amp;#34;) rows = c(page1 %&amp;gt;% html_nodes(&amp;#34;div.small-12 div.row&amp;#34;), page2 %&amp;gt;% html_nodes(&amp;#34;div.small-12 div.row&amp;#34;) ) &amp;gt; rows %&amp;gt;% head(1) [[1]] &amp;lt;div class=&amp;#34;row&amp;#34;&amp;gt; &amp;lt;h3 class=&amp;#34;entry-title&amp;#34;&amp;gt;&amp;lt;a href=&amp;#34;http://neo4j.com/release-notes/neo4j-2-2-2/&amp;#34;&amp;gt;Latest Release: Neo4j 2.2.2&amp;lt;/a&amp;gt;&amp;lt;/h3&amp;gt; &amp;lt;h6&amp;gt;05/21/2015&amp;lt;/h6&amp;gt; &amp;lt;p&amp;gt;Neo4j 2.2.2 is a maintenance release, with critical improvements.&amp;lt;/p&amp;gt; &amp;lt;p&amp;gt;Notably, this release:&amp;lt;/p&amp;gt; &amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;Provides support for running Neo4j on Oracle and OpenJDK Java 8 runtimes&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Resolves an issue that prevented the Neo4j Browser from loading in the latest Chrome release (43.</description>
    </item>
    
    <item>
      <title>R: dplyr - segfault cause &#39;memory not mapped&#39;</title>
      <link>https://markhneedham.com/blog/2015/06/20/r-dplyr-segfault-cause-memory-not-mapped/</link>
      <pubDate>Sat, 20 Jun 2015 22:18:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/20/r-dplyr-segfault-cause-memory-not-mapped/</guid>
      <description>library(readr) dlines = data.frame(column = read_lines(&amp;#34;~/projects/logs/2015-06-18-22-docs&amp;#34;)) extract_uri = function(log) { parts = str_extract_all(log, &amp;#34;\&amp;#34;[^\&amp;#34;]*\&amp;#34;&amp;#34;) return(lapply(parts, function(p) str_match(p[1], &amp;#34;GET (.*) HTTP&amp;#34;)[2] %&amp;gt;% as.character)) } library(dplyr) pages_viewed = dlines %&amp;gt;% mutate(uri = extract_uri(column)) %&amp;gt;% count(uri) %&amp;gt;% arrange(desc(n)) segfault cause &amp;#39;memory not mapped&amp;#39; ## Error in eval(expr, envir, enclos): cannot group column uri, of class &amp;#39;list&amp;#39; extract_uri = function(log) { parts = str_extract_all(log, &amp;#34;\&amp;#34;[^\&amp;#34;]*\&amp;#34;&amp;#34;) return(unlist(lapply(parts, function(p) str_match(p[1], &amp;#34;GET (.*) HTTP&amp;#34;)[2] %&amp;gt;% as.character))) } </description>
    </item>
    
    <item>
      <title>R: Regex - capturing multiple matches of the same group</title>
      <link>https://markhneedham.com/blog/2015/06/19/r-regex-capturing-multiple-matches-of-the-same-group/</link>
      <pubDate>Fri, 19 Jun 2015 21:38:47 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/19/r-regex-capturing-multiple-matches-of-the-same-group/</guid>
      <description>log = &amp;#39;2015-06-18-22:277:548311224723746831\t2015-06-18T22:00:11\t2015-06-18T22:00:05Z\t93317114\tip-127-0-0-1\t127.0.0.5\tUser\tNotice\tneo4j.com.access.log\t127.0.0.3 - - [18/Jun/2015:22:00:11 +0000] &amp;#34;GET /docs/stable/query-updating.html HTTP/1.1&amp;#34; 304 0 &amp;#34;http://neo4j.com/docs/stable/cypher-introduction.html&amp;#34; &amp;#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36&amp;#34;&amp;#39; &amp;gt; library(stringr) &amp;gt; str_match(log, &amp;#34;\&amp;#34;[^\&amp;#34;]*\&amp;#34;&amp;#34;) [,1] [1,] &amp;#34;\&amp;#34;GET /docs/stable/query-updating.html HTTP/1.1\&amp;#34;&amp;#34; &amp;gt; str_extract_all(log, &amp;#34;\&amp;#34;[^\&amp;#34;]*\&amp;#34;&amp;#34;) [[1]] [1] &amp;#34;\&amp;#34;GET /docs/stable/query-updating.html HTTP/1.1\&amp;#34;&amp;#34; [2] &amp;#34;\&amp;#34;http://neo4j.com/docs/stable/cypher-introduction.html\&amp;#34;&amp;#34; [3] &amp;#34;\&amp;#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36\&amp;#34;&amp;#34; parts = str_extract_all(log, &amp;#34;\&amp;#34;[^\&amp;#34;]*\&amp;#34;&amp;#34;)[[1]] uri = str_match(parts[1], &amp;#34;GET (.*) HTTP&amp;#34;)[2] referer = str_match(parts[2], &amp;#34;\&amp;#34;(.</description>
    </item>
    
    <item>
      <title>Coding: Explore and retreat</title>
      <link>https://markhneedham.com/blog/2015/06/17/coding-explore-and-retreat/</link>
      <pubDate>Wed, 17 Jun 2015 17:23:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/17/coding-explore-and-retreat/</guid>
      <description>public class Network implements Cloneable, Serializable { private static final long serialVersionUID = 1; private int numberOfNodes; private int[] firstNeighborIndex; private int[] neighbor; private double[] edgeWeight; private double totalEdgeWeightSelfLinks; private double[] nodeWeight; private int nClusters; private int[] cluster; private double[] clusterWeight; private int[] numberNodesPerCluster; private int[][] nodePerCluster; private boolean clusteringStatsAvailable; ... } </description>
    </item>
    
    <item>
      <title>Northwind: Finding direct/transitive Reports in SQL and Neo4j&#39;s Cypher</title>
      <link>https://markhneedham.com/blog/2015/06/15/northwind-finding-directtransitive-reports-in-sql-and-neo4js-cypher/</link>
      <pubDate>Mon, 15 Jun 2015 22:53:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/15/northwind-finding-directtransitive-reports-in-sql-and-neo4js-cypher/</guid>
      <description>SELECT e.&amp;#34;EmployeeID&amp;#34;, e.&amp;#34;ReportsTo&amp;#34; FROM employees AS e WHERE e.&amp;#34;ReportsTo&amp;#34; is not null; EmployeeID | ReportsTo ------------+-----------  1 | 2 3 | 2 4 | 2 5 | 2 6 | 5 7 | 5 8 | 2 9 | 5 (8 rows) MATCH (e:Employee)&amp;lt;-[:REPORTS_TO]-(sub) RETURN sub.EmployeeID, e.EmployeeID +-------------------------------+ | sub.EmployeeID | e.EmployeeID | +-------------------------------+ | &amp;quot;4&amp;quot; | &amp;quot;2&amp;quot; | | &amp;quot;5&amp;quot; | &amp;quot;2&amp;quot; | | &amp;quot;1&amp;quot; | &amp;quot;2&amp;quot; | | &amp;quot;3&amp;quot; | &amp;quot;2&amp;quot; | | &amp;quot;8&amp;quot; | &amp;quot;2&amp;quot; | | &amp;quot;9&amp;quot; | &amp;quot;5&amp;quot; | | &amp;quot;6&amp;quot; | &amp;quot;5&amp;quot; | | &amp;quot;7&amp;quot; | &amp;quot;5&amp;quot; | +-------------------------------+ 8 rows SELECT e.</description>
    </item>
    
    <item>
      <title>The Willpower Instinct: Reducing time spent mindlessly scrolling for things to read</title>
      <link>https://markhneedham.com/blog/2015/06/12/the-willpower-instinct-reducing-time-spent-mindlessly-scrolling-for-things-to-read/</link>
      <pubDate>Fri, 12 Jun 2015 23:12:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/12/the-willpower-instinct-reducing-time-spent-mindlessly-scrolling-for-things-to-read/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neo4j: Using LOAD CSV to help explore CSV files</title>
      <link>https://markhneedham.com/blog/2015/06/11/neo4j-using-load-csv-to-help-explore-csv-files/</link>
      <pubDate>Thu, 11 Jun 2015 23:15:06 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/11/neo4j-using-load-csv-to-help-explore-csv-files/</guid>
      <description>$ head -n 5 data/import/references.csv ReferencedEpisodeId,ReferencingEpisodeId,ReferenceText 168,184,&amp;#34;Marshall will eventually hear back from the New York State Judicatory Committee in Something New, which will become a main plot point of Season 9.&amp;#34; 168,169,Barney proclaiming to be done with Robin will be the focal point of Lobster Crawl. 58,57,&amp;#34;Barney finally confronts his saboteur (Abby, whom he slept with in Ten Sessions) in Everything Must Go.&amp;#34; 58,63,&amp;#34;Barney finally confronts his saboteur (Abby, whom he slept with in Ten Sessions) in Everything Must Go.</description>
    </item>
    
    <item>
      <title>Mac OS X: GNU sed -  Hex string replacement / replacing new line characters</title>
      <link>https://markhneedham.com/blog/2015/06/11/mac-os-x-gnu-sed-hex-string-replacement-replacing-new-line-characters/</link>
      <pubDate>Thu, 11 Jun 2015 21:38:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/11/mac-os-x-gnu-sed-hex-string-replacement-replacing-new-line-characters/</guid>
      <description>brew install coreutils brew install gnu-sed --with-default-names $ echo -e &amp;#34;Hello\x0AMark\x0A\x0D&amp;#34; Hello Mark $ echo -e &amp;#34;Hello\x0AMark\x0A\x0D&amp;#34; | \  sed &amp;#39;N;/\x0A[^\x0D]/s/\n/ /&amp;#39; Hello Mark $ echo -e &amp;#34;Hello\x0AMark\x0A\x0DHello\x0AMichael\x0A\x0D&amp;#34; Hello Mark Hello Michael $ echo -e &amp;#34;Hello\x0AMark\x0A\x0DHello\x0AMichael\x0A\x0D&amp;#34; | \  sed &amp;#39;N;/\x0A[^\x0D]/s/\n/ /&amp;#39; Hello Mark Hello Michael </description>
    </item>
    
    <item>
      <title>Unix: Converting a file of values into a comma separated list</title>
      <link>https://markhneedham.com/blog/2015/06/08/unix-converting-a-file-of-values-into-a-comma-separated-list/</link>
      <pubDate>Mon, 08 Jun 2015 22:23:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/08/unix-converting-a-file-of-values-into-a-comma-separated-list/</guid>
      <description>$ cat foo2.txt | head -n 5 1.0 1.0 1.0 1.0 1.0 &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34; $ sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt | head -n 5 &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; &amp;#34;1.0&amp;#34; $ sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt | tr &amp;#39;\n&amp;#39; &amp;#39;,&amp;#39; &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;, $ paste -s -d &amp;#39;,&amp;#39; &amp;lt;(sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt) &amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34;,&amp;#34;1.0&amp;#34; $ paste -s -d &amp;#39;,&amp;#39; &amp;lt;(sed &amp;#39;s/.*/&amp;#34;&amp;amp;&amp;#34;/g&amp;#39; foo2.txt) | pbcopy </description>
    </item>
    
    <item>
      <title>Netty: Testing encoders/decoders</title>
      <link>https://markhneedham.com/blog/2015/06/05/netty-testing-encodersdecoders/</link>
      <pubDate>Fri, 05 Jun 2015 21:25:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/05/netty-testing-encodersdecoders/</guid>
      <description>// Examples uses Netty 4.0.28.Final public static class MessageEncoder extends MessageToMessageEncoder&amp;lt;Foo&amp;gt; { @Override protected void encode( ChannelHandlerContext ctx, Foo msg, List&amp;lt;Object&amp;gt; out ) throws Exception { ByteBuf buf = ctx.alloc().buffer(); buf.writeInt( msg.value() ); out.add( buf ); } } public static class Foo { private Integer value; public Foo(Integer value) { this.value = value; } public int value() { return value; } } @Test public void shouldEncodeAndDecodeVoteRequest() { // given  EmbeddedChannel channel = new EmbeddedChannel( new MessageEncoder(), new MessageDecoder() ); // when  Foo foo = new Foo( 42 ); channel.</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Step by step to creating a linked list of adjacent nodes using UNWIND</title>
      <link>https://markhneedham.com/blog/2015/06/04/neo4j-cypher-step-by-step-to-creating-a-linked-list-of-adjacent-nodes-using-unwind/</link>
      <pubDate>Thu, 04 Jun 2015 22:17:34 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/04/neo4j-cypher-step-by-step-to-creating-a-linked-list-of-adjacent-nodes-using-unwind/</guid>
      <description>CREATE (:Season {name: &amp;quot;2013/2014&amp;quot;, timestamp: 1375315200}) CREATE (:Season {name: &amp;quot;2012/2013&amp;quot;, timestamp: 1343779200}) CREATE (:Season {name: &amp;quot;2011/2012&amp;quot;, timestamp: 1312156800}) CREATE (:Season {name: &amp;quot;2010/2011&amp;quot;, timestamp: 1280620800}) CREATE (:Season {name: &amp;quot;2009/2010&amp;quot;, timestamp: 1249084800}) MATCH (s:Season) WITH s ORDER BY s.timestamp WITH COLLECT(s) AS seasons FOREACH(i in RANGE(0, length(seasons)-2) | FOREACH(si in [seasons[i]] | FOREACH(si2 in [seasons[i+1]] | MERGE (si)-[:NEXT]-&amp;gt;(si2)))) MATCH (s:Season) WITH s ORDER BY s.timestamp RETURN COLLECT(s) AS seasons ==&amp;gt; +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ ==&amp;gt; | seasons | ==&amp;gt; +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ ==&amp;gt; | [Node[1973]{timestamp:1249084800,name:&amp;quot;2009/2010&amp;quot;},Node[1972]{timestamp:1280620800,name:&amp;quot;2010/2011&amp;quot;},Node[1971]{timestamp:1312156800,name:&amp;quot;2011/2012&amp;quot;},Node[1970]{timestamp:1343779200,name:&amp;quot;2012/2013&amp;quot;},Node[1969]{timestamp:1375315200,name:&amp;quot;2013/2014&amp;quot;}] | ==&amp;gt; +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 2009/2010	2010/2011 2010/2011	2011/2012 2011/2012	2012/2013 2012/2013	2013/2014 &amp;gt;&amp;gt;&amp;gt; seasons = [&amp;#34;2009/2010&amp;#34;, &amp;#34;2010/2011&amp;#34;, &amp;#34;2011/2012&amp;#34;, &amp;#34;2012/2013&amp;#34;, &amp;#34;2013/2014&amp;#34;] &amp;gt;&amp;gt;&amp;gt; zip(seasons, seasons[1:]) [(&amp;#39;2009/2010&amp;#39;, &amp;#39;2010/2011&amp;#39;), (&amp;#39;2010/2011&amp;#39;, &amp;#39;2011/2012&amp;#39;), (&amp;#39;2011/2012&amp;#39;, &amp;#39;2012/2013&amp;#39;), (&amp;#39;2012/2013&amp;#39;, &amp;#39;2013/2014&amp;#39;)] return RANGE(0,4) ==&amp;gt; +-------------+ ==&amp;gt; | RANGE(0,4) | ==&amp;gt; +-------------+ ==&amp;gt; | [0,1,2,3,4] | ==&amp;gt; +-------------+ UNWIND RANGE(0,4) as idx RETURN idx, idx +1; ==&amp;gt; +--------------+ ==&amp;gt; | idx | idx +1 | ==&amp;gt; +--------------+ ==&amp;gt; | 0 | 1 | ==&amp;gt; | 1 | 2 | ==&amp;gt; | 2 | 3 | ==&amp;gt; | 3 | 4 | ==&amp;gt; | 4 | 5 | ==&amp;gt; +--------------+ ==&amp;gt; 5 rows MATCH (s:Season) WITH s ORDER BY s.</description>
    </item>
    
    <item>
      <title>R: ggplot geom_density - Error in exists(name, envir = env, mode = mode) : argument &#34;env&#34; is missing, with no default</title>
      <link>https://markhneedham.com/blog/2015/06/03/r-ggplot-geom_density-error-in-existsname-envir-env-mode-mode-argument-env-is-missing-with-no-default/</link>
      <pubDate>Wed, 03 Jun 2015 05:52:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/03/r-ggplot-geom_density-error-in-existsname-envir-env-mode-mode-argument-env-is-missing-with-no-default/</guid>
      <description>library(dplyr) df2011 = read.csv(&amp;#34;~/projects/rLearning/showcases.2011.csv&amp;#34;, na.strings = c(&amp;#34;&amp;#34;, &amp;#34;NA&amp;#34;)) df2011 = df2011 %&amp;gt;% na.omit() &amp;gt; df2011 %&amp;gt;% head() X Sep..19 Sep..20 Sep..21 Sep..22 Sep..23 Sep..26 Sep..27 Sep..28 Sep..29 Sep..30 Oct..3 3 Showcase 1 50969 21901 32815 44432 24273 30554 20963 28941 25851 28800 37703 4 Showcase 2 45429 34061 53186 31428 22320 24337 41373 45437 41125 36319 38752 6 Bid 1 42000 14000 32000 27000 18750 27222 25000 35000 22500 21300 21567 7 Bid 2 34000 59900 45000 38000 23000 18525 32000 45000 32000 27500 23800 9 Difference 1 8969 7901 815 17432 5523 3332 -4037 -6059 3351 7500 16136 10 Difference 2 11429 -25839 8186 -6572 -680 5812 9373 437 9125 8819 14952 .</description>
    </item>
    
    <item>
      <title>R: dplyr - removing empty rows</title>
      <link>https://markhneedham.com/blog/2015/06/02/r-dplyr-removing-empty-rows/</link>
      <pubDate>Tue, 02 Jun 2015 06:49:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/06/02/r-dplyr-removing-empty-rows/</guid>
      <description>wget ￼http://www.greenteapress.com/thinkbayes/showcases.2011.csv￼ library(dplyr) df2011 = read.csv(&amp;#34;~/projects/rLearning/showcases.2011.csv&amp;#34;) &amp;gt; df2011 %&amp;gt;% head(10) X Sep..19 Sep..20 Sep..21 Sep..22 Sep..23 Sep..26 Sep..27 Sep..28 Sep..29 Sep..30 Oct..3 1 5631K 5632K 5633K 5634K 5635K 5641K 5642K 5643K 5644K 5645K 5681K 2 3 Showcase 1 50969 21901 32815 44432 24273 30554 20963 28941 25851 28800 37703 4 Showcase 2 45429 34061 53186 31428 22320 24337 41373 45437 41125 36319 38752 5 ... df2011 = read.csv(&amp;#34;~/projects/rLearning/showcases.2011.csv&amp;#34;, na.strings = c(&amp;#34;&amp;#34;, &amp;#34;NA&amp;#34;)) df2011 = df2011 %&amp;gt;% na.</description>
    </item>
    
    <item>
      <title>R: Think Bayes Euro Problem</title>
      <link>https://markhneedham.com/blog/2015/05/31/r-think-bayes-euro-problem/</link>
      <pubDate>Sun, 31 May 2015 23:11:50 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/31/r-think-bayes-euro-problem/</guid>
      <description>When spun on edge 250 times, a Belgian one-euro coin came up heads 140 times and tails 110. ‘It looks very suspicious to me,’ said Barry Blight, a statistics lecturer at the London School of Economics. ‘If the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.’
But do these data give evidence that the coin is biased rather than fair?</description>
    </item>
    
    <item>
      <title>Python: CSV writing - TypeError: &#39;builtin_function_or_method&#39; object has no attribute &#39;__getitem__&#39;</title>
      <link>https://markhneedham.com/blog/2015/05/31/python-csv-writing-typeerror-builtin_function_or_method-object-has-no-attribute-__getitem__/</link>
      <pubDate>Sun, 31 May 2015 22:33:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/31/python-csv-writing-typeerror-builtin_function_or_method-object-has-no-attribute-__getitem__/</guid>
      <description>import csv writer = csv.writer(file, delimiter=&amp;#34;,&amp;#34;) writer.writerow[&amp;#34;player&amp;#34;, &amp;#34;team&amp;#34;] TypeError: &amp;#39;builtin_function_or_method&amp;#39; object has no attribute &amp;#39;__getitem__&amp;#39; writer.writerow([&amp;#34;player&amp;#34;, &amp;#34;team&amp;#34;]) </description>
    </item>
    
    <item>
      <title>Neo4j: The BBC Champions League graph</title>
      <link>https://markhneedham.com/blog/2015/05/30/neo4j-the-bbc-champions-league-graph/</link>
      <pubDate>Sat, 30 May 2015 21:45:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/30/neo4j-the-bbc-champions-league-graph/</guid>
      <description>from bs4 import BeautifulSoup from soupselect import select import bs4 soup = BeautifulSoup(open(&amp;#34;data/results&amp;#34;, &amp;#34;r&amp;#34;)) matches = select(soup, &amp;#34;a.report&amp;#34;) for match in matches: print &amp;#34;http://www.bbc.co.uk/%s&amp;#34; %(match.get(&amp;#34;href&amp;#34;)) I then piped the output of running this script into wget:
find_all_matches.py | xargs wget -O data/raw match (a:Attempt)&amp;lt;-[:HAD_ATTEMPT]-(app)&amp;lt;-[:MADE_APPEARANCE]-(player), (app)-[:FOR_TEAM]-(team) WITH player, COUNT(*) as times, COLLECT(a) AS attempts, team WITH player, times, LENGTH([a in attempts WHERE a:Goal]) AS goals, team WHERE times &amp;gt; 10 RETURN player.</description>
    </item>
    
    <item>
      <title>Python: Look ahead multiple elements in an iterator/generator</title>
      <link>https://markhneedham.com/blog/2015/05/28/python-look-ahead-multiple-elements-in-an-iteratorgenerator/</link>
      <pubDate>Thu, 28 May 2015 20:56:08 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/28/python-look-ahead-multiple-elements-in-an-iteratorgenerator/</guid>
      <description>events = [ {&amp;#39;event&amp;#39;: u&amp;#39;Booking Pedro (Barcelona) is shown the yellow card for a bad foul.&amp;#39;, &amp;#39;sortable_time&amp;#39;: 5083, &amp;#39;match_id&amp;#39;: &amp;#39;32683310&amp;#39;, &amp;#39;formatted_time&amp;#39;: u&amp;#39;84:43&amp;#39;}, {&amp;#39;event&amp;#39;: u&amp;#39;Rafinha (FC Bayern M\xfcnchen) wins a free kick on the right wing.&amp;#39;, &amp;#39;sortable_time&amp;#39;: 5078, &amp;#39;match_id&amp;#39;: &amp;#39;32683310&amp;#39;, &amp;#39;formatted_time&amp;#39;: u&amp;#39;84:38&amp;#39;}, {&amp;#39;event&amp;#39;: u&amp;#39;Foul by Pedro (Barcelona).&amp;#39;, &amp;#39;sortable_time&amp;#39;: 5078, &amp;#39;match_id&amp;#39;: &amp;#39;32683310&amp;#39;, &amp;#39;formatted_time&amp;#39;: u&amp;#39;84:38&amp;#39;} ] def cards(events): events = iter(events) item = events.next() next = events.next() event_id = 0 for next_next in events: event = item[&amp;#34;event&amp;#34;] booking = re.</description>
    </item>
    
    <item>
      <title>Neo4j: The foul revenge graph</title>
      <link>https://markhneedham.com/blog/2015/05/26/neo4j-the-foul-revenge-graph/</link>
      <pubDate>Tue, 26 May 2015 07:03:36 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/26/neo4j-the-foul-revenge-graph/</guid>
      <description>MATCH (foul:Foul)-[:COMMITTED_IN_MATCH]-&amp;gt;(match) WITH foul,match ORDER BY match.id, foul.sortableTime WITH match, COLLECT(foul) AS fouls FOREACH(i in range(0, length(fouls) -2) | FOREACH(foul1 in [fouls[i]] | FOREACH (foul2 in [fouls[i+1]] | MERGE (foul1)-[:NEXT]-&amp;gt;(foul2) ))); match (foul1:Foul)-[:COMMITTED_AGAINST]-&amp;gt;(app1)-[:COMMITTED_FOUL]-&amp;gt;(foul2)-[:COMMITTED_AGAINST]-&amp;gt;(app2)-[:COMMITTED_FOUL]-&amp;gt;(foul1), (player1)-[:MADE_APPEARANCE]-&amp;gt;(app1), (player2)-[:MADE_APPEARANCE]-&amp;gt;(app2), (foul1)-[:COMMITTED_IN_MATCH]-&amp;gt;(match:Match {id: &amp;quot;32683310&amp;quot;})&amp;lt;-[:COMMITTED_IN_MATCH]-(foul2) WHERE (foul1)-[:NEXT*]-&amp;gt;(foul2) RETURN player2.name AS firstFouler, player1.name AS revengeFouler, foul1.time, foul1.location, foul2.time, foul2.location match (foul1:Foul)-[:COMMITTED_AGAINST]-&amp;gt;(app1)-[:COMMITTED_FOUL]-&amp;gt;(foul2)-[:COMMITTED_AGAINST]-&amp;gt;(app2)-[:COMMITTED_FOUL]-&amp;gt;(foul1), (player1)-[:MADE_APPEARANCE]-&amp;gt;(app1), (player2)-[:MADE_APPEARANCE]-&amp;gt;(app2), (foul1)-[:COMMITTED_IN_MATCH]-&amp;gt;(match:Match {id: &amp;quot;32683310&amp;quot;})&amp;lt;-[:COMMITTED_IN_MATCH]-(foul2), (foul1)-[:NEXT*]-&amp;gt;(foul2) RETURN * </description>
    </item>
    
    <item>
      <title>Python: Joining multiple generators/iterators</title>
      <link>https://markhneedham.com/blog/2015/05/24/python-joining-multiple-generatorsiterators/</link>
      <pubDate>Sun, 24 May 2015 23:51:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/24/python-joining-multiple-generatorsiterators/</guid>
      <description>In my previous blog post I described how I&amp;rsquo;d refactored some scraping code I&amp;rsquo;ve been working on to use iteratorsand ended up with a function which returned a generator containing all the events for one BBC live text match:
match_id = &amp;#34;32683310&amp;#34; events = extract_events(&amp;#34;data/raw/%s&amp;#34; % (match_id)) &amp;gt;&amp;gt;&amp;gt; print type(events) &amp;lt;type &amp;#39;generator&amp;#39;&amp;gt; Make an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable, until all of the iterables are exhausted.</description>
    </item>
    
    <item>
      <title>Python: Refactoring to iterator</title>
      <link>https://markhneedham.com/blog/2015/05/23/python-refactoring-to-iterator/</link>
      <pubDate>Sat, 23 May 2015 10:14:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/23/python-refactoring-to-iterator/</guid>
      <description>import bs4 import re from bs4 import BeautifulSoup from soupselect import select def extract_events(file): match = open(file, &amp;#39;r&amp;#39;) soup = BeautifulSoup(match.read()) all_events = [] for event in select(soup, &amp;#39;div#live-text-commentary-wrapper div#live-text&amp;#39;): for child in event.children: if type(child) is bs4.element.Tag: all_events.append(child.getText().strip()) for event in select(soup, &amp;#39;div#live-text-commentary-wrapper div#more-live-text&amp;#39;): for child in event.children: if type(child) is bs4.element.Tag: all_events.append(child.getText().strip()) timed_events = [] for i in range(0, len(all_events)): event = all_events[i] time = re.findall(&amp;#34;\d{1,2}:\d{2}&amp;#34;, event) formatted_time = &amp;#34; +&amp;#34;.</description>
    </item>
    
    <item>
      <title>Python: UnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode character u&#39;\xfc&#39; in position 11: ordinal not in range(128)</title>
      <link>https://markhneedham.com/blog/2015/05/21/python-unicodeencodeerror-ascii-codec-cant-encode-character-uxfc-in-position-11-ordinal-not-in-range128/</link>
      <pubDate>Thu, 21 May 2015 06:14:32 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/21/python-unicodeencodeerror-ascii-codec-cant-encode-character-uxfc-in-position-11-ordinal-not-in-range128/</guid>
      <description>$ python extract_players.py (u&amp;#39;Sergio Busquets&amp;#39;, u&amp;#39;Barcelona&amp;#39;) (u&amp;#39;Javier Mascherano&amp;#39;, u&amp;#39;Barcelona&amp;#39;) (u&amp;#39;Jordi Alba&amp;#39;, u&amp;#39;Barcelona&amp;#39;) (u&amp;#39;Bastian Schweinsteiger&amp;#39;, u&amp;#39;FC Bayern M\xfcnchen&amp;#39;) (u&amp;#39;Dani Alves&amp;#39;, u&amp;#39;Barcelona&amp;#39;) with open(&amp;#34;data/players.csv&amp;#34;, &amp;#34;w&amp;#34;) as file: writer = csv.writer(file, delimiter=&amp;#34;,&amp;#34;) writer.writerow([&amp;#34;player&amp;#34;, &amp;#34;team&amp;#34;]) for player, team in players: print player, team, type(player), type(team) writer.writerow([player, team]) $ python extract_players.py ... Bastian Schweinsteiger FC Bayern München &amp;lt;type &amp;#39;unicode&amp;#39;&amp;gt; &amp;lt;type &amp;#39;unicode&amp;#39;&amp;gt; Traceback (most recent call last): File &amp;#34;extract_players.py&amp;#34;, line 67, in &amp;lt;module&amp;gt; writer.writerow([player, team]) UnicodeEncodeError: &amp;#39;ascii&amp;#39; codec can&amp;#39;t encode character u&amp;#39;\xfc&amp;#39; in position 11: ordinal not in range(128) with open(&amp;#34;data/players.</description>
    </item>
    
    <item>
      <title>Neo4j: Finding all shortest paths</title>
      <link>https://markhneedham.com/blog/2015/05/19/neo4j-finding-all-shortest-paths/</link>
      <pubDate>Tue, 19 May 2015 22:45:48 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/19/neo4j-finding-all-shortest-paths/</guid>
      <description>MATCH (p1:Person)-[:ACTED_IN]-&amp;gt;()&amp;lt;-[:ACTED_IN]-(p2:Person) MERGE (p1)-[:KNOWS]-(p2) MATCH (p1:Person {name: &amp;quot;Tom Hanks&amp;quot;}), (p2:Person {name: &amp;quot;Tom Cruise&amp;quot;}), path = shortestpath((p1)-[:KNOWS*]-(p2)) RETURN path MATCH (p1:Person), (p2:Person), path = shortestpath((p1)-[:KNOWS*]-(p2)) RETURN path ORDER BY LENGTH(path) DESC LIMIT 1 MATCH (p1:Person)-[:ACTED_IN]-&amp;gt;() WITH p1, COUNT(*) AS appearances ORDER BY appearances DESC LIMIT 10 WITH p1 AS p1, p1 AS p2 MATCH path = shortestpath((p1)-[:KNOWS*]-(p2)) RETURN path ORDER BY LENGTH(path) DESC LIMIT 1 MATCH (p1:Person)-[:ACTED_IN]-&amp;gt;() WITH p1, COUNT(*) AS appearances ORDER BY appearances DESC LIMIT 10 WITH COLLECT(p1) AS ps UNWIND ps AS p1 UNWIND ps AS p2 MATCH path = shortestpath((p1)-[:KNOWS*]-(p2)) RETURN path ORDER BY LENGTH(path) DESC LIMIT 1 </description>
    </item>
    
    <item>
      <title>Neo4j: Refactoring the BBC football live text fouls graph</title>
      <link>https://markhneedham.com/blog/2015/05/17/neo4j-refactoring-the-bbc-football-live-text-fouls-graph/</link>
      <pubDate>Sun, 17 May 2015 11:04:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/17/neo4j-refactoring-the-bbc-football-live-text-fouls-graph/</guid>
      <description>First up let&amp;rsquo;s write a query to introduce the new structure.
match (foul:Foul)-[:COMMITTED_AGAINST]-&amp;gt;(fouledPlayer), (foul)&amp;lt;-[:COMMITTED_FOUL]-(foulingPlayer), (foul)-[:COMMITTED_IN_MATCH]-&amp;gt;(match:Match {id: &amp;quot;32683310&amp;quot;}), (foulingPlayer)-[:MADE_APPEARANCE]-(foulingPlayerApp)-[:IN_MATCH]-&amp;gt;(match), (fouledPlayer)-[:MADE_APPEARANCE]-(fouledPlayerApp)-[:IN_MATCH]-&amp;gt;(match) MERGE (foul)&amp;lt;-[:COMMITTED_FOUL]-(foulingPlayerApp) MERGE (foul)-[:COMMITTED_AGAINST]-&amp;gt;(fouledPlayerApp) match (match:Match {id: &amp;quot;32683310&amp;quot;})&amp;lt;-[:COMMITTED_IN_MATCH]-(foul) RETURN foul.location AS location, COUNT(*) as fouls ORDER BY fouls DESC match (match:Match {id: &amp;quot;32683310&amp;quot;})&amp;lt;-[:IN_MATCH]-()&amp;lt;-[]-(foul:Foul) RETURN foul.location AS location, COUNT(*) as fouls ORDER BY fouls DESC match (match:Match {id: &amp;quot;32683310&amp;quot;})&amp;lt;-[:COMMITTED_IN_MATCH]-(foul:Foul)&amp;lt;-[:COMMITTED_FOUL]-(fouler:Player) RETURN fouler.name AS fouler, COUNT(*) as fouls ORDER BY fouls DESC LIMIT 10; match (match:Match {id: &amp;quot;32683310&amp;quot;})&amp;lt;-[:IN_MATCH]-(appearance)-[:COMMITTED_FOUL]-&amp;gt;(foul:Foul), (appearance)&amp;lt;-[:MADE_APPEARANCE]-(fouler) RETURN fouler.</description>
    </item>
    
    <item>
      <title>Neo4j: BBC football live text fouls graph</title>
      <link>https://markhneedham.com/blog/2015/05/16/neo4j-bbc-football-live-text-fouls-graph/</link>
      <pubDate>Sat, 16 May 2015 21:13:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/16/neo4j-bbc-football-live-text-fouls-graph/</guid>
      <description>I find the feedback cycle with this type of work is dramatically improved if we have the source data available locally so the first step was to get the BBC web page downloaded:
$ wget http://www.bbc.co.uk/sport/0/football/32683310 $ head -n 10 data/events.csv matchId,foulId,freeKickId,time,foulLocation,fouledPlayer,fouledPlayerTeam,foulingPlayer,foulingPlayerTeam 32683310,3,2,90:00 +0:40,in the defensive half.,Xabi Alonso,FC Bayern München,Pedro,Barcelona 32683310,9,8,84:38,on the right wing.,Rafinha,FC Bayern München,Pedro,Barcelona 32683310,12,13,83:17,in the attacking half.,Lionel Messi,Barcelona,Sebastian Rode,FC Bayern München 32683310,15,14,82:43,in the defensive half.,Sebastian Rode,FC Bayern München,Neymar,Barcelona 32683310,17,18,80:41,in the attacking half.</description>
    </item>
    
    <item>
      <title>R: ggplot - Displaying multiple charts with a for loop</title>
      <link>https://markhneedham.com/blog/2015/05/14/r-ggplot-displaying-multiple-charts-with-a-for-loop/</link>
      <pubDate>Thu, 14 May 2015 00:17:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/14/r-ggplot-displaying-multiple-charts-with-a-for-loop/</guid>
      <description>library(RNeo4j) graph = startGraph(&amp;#34;http://127.0.0.1:7474/db/data/&amp;#34;) eventId = &amp;#34;220750415&amp;#34; query = &amp;#34;match (g:Group {name: &amp;#39;Neo4j - London User Group&amp;#39;})-[:HOSTED_EVENT]-&amp;gt; (e {id: {id}})&amp;lt;-[:TO]-(rsvp {response: &amp;#39;yes&amp;#39;})&amp;lt;-[:RSVPD]-(person) WITH rsvp, person MATCH (person)-[:RSVPD]-&amp;gt;(otherRSVP) WITH person, rsvp, otherRSVP ORDER BY person.id, otherRSVP.time WITH person, rsvp, COLLECT(otherRSVP)[0] AS earliestRSVP return rsvp.time, earliestRSVP.time, person.id&amp;#34; df = cypher(graph, query, id= eventId) &amp;gt; df %&amp;gt;% sample_n(10) rsvp.time earliestRSVP.time person.id 18 1.430819e+12 1.392726e+12 130976662 95 1.430069e+12 1.430069e+12 10286388 79 1.429035e+12 1.429035e+12 38344282 64 1.</description>
    </item>
    
    <item>
      <title>R: Cohort heatmap of Neo4j London meetup</title>
      <link>https://markhneedham.com/blog/2015/05/11/r-cohort-heatmap-of-neo4j-london-meetup/</link>
      <pubDate>Mon, 11 May 2015 23:16:07 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/11/r-cohort-heatmap-of-neo4j-london-meetup/</guid>
      <description>df = read.csv(&amp;#34;/tmp/df.csv&amp;#34;) &amp;gt; df %&amp;gt;% sample_n(5) rsvp.time person.id time date 255 1.354277e+12 12228948 2012-11-30 12:05:08 2012-11 2475 1.407342e+12 19057581 2014-08-06 16:26:04 2014-08 3988 1.421769e+12 66122172 2015-01-20 15:58:02 2015-01 4411 1.419377e+12 165750262 2014-12-23 23:27:44 2014-12 1010 1.383057e+12 74602292 2013-10-29 14:24:32 2013-10 firstMeetup = df %&amp;gt;% group_by(person.id) %&amp;gt;% summarise(firstEvent = min(time), count = n()) %&amp;gt;% arrange(desc(count)) firstMeetup$date = format(as.Date(firstMeetup$firstEvent), &amp;#34;%Y-%m&amp;#34;) countsForCohort = function(df, firstMeetup, cohort) { members = (firstMeetup %&amp;gt;% filter(date == cohort))$person.</description>
    </item>
    
    <item>
      <title>R: Neo4j London meetup group - How many events do people come to?</title>
      <link>https://markhneedham.com/blog/2015/05/09/r-neo4j-london-meetup-group-how-many-events-do-people-come-to/</link>
      <pubDate>Sat, 09 May 2015 22:33:05 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/09/r-neo4j-london-meetup-group-how-many-events-do-people-come-to/</guid>
      <description>How often do people come to meetups?
library(RNeo4j) library(dplyr) graph = startGraph(&amp;#34;http://localhost:7474/db/data/&amp;#34;) query = &amp;#34;MATCH (g:Group {name: &amp;#39;Neo4j - London User Group&amp;#39;})-[:HOSTED_EVENT]-&amp;gt;(event)&amp;lt;-[:TO]-({response: &amp;#39;yes&amp;#39;})&amp;lt;-[:RSVPD]-(profile)-[:HAS_MEMBERSHIP]-&amp;gt;(membership)-[:OF_GROUP]-&amp;gt;(g) WHERE (event.time + event.utc_offset) &amp;lt; timestamp() RETURN event.id, event.time + event.utc_offset AS eventTime, profile.id, membership.joined&amp;#34; df = cypher(graph, query) &amp;gt; df %&amp;gt;% head() event.id eventTime profile.id membership.joined 1 20616111 1.309372e+12 6436797 1.307285e+12 2 20616111 1.309372e+12 12964956 1.307275e+12 3 20616111 1.309372e+12 14533478 1.307290e+12 4 20616111 1.309372e+12 10793775 1.307705e+12 5 24528711 1.</description>
    </item>
    
    <item>
      <title>Python: Selecting certain indexes in an array</title>
      <link>https://markhneedham.com/blog/2015/05/05/python-selecting-certain-indexes-in-an-array/</link>
      <pubDate>Tue, 05 May 2015 21:39:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/05/python-selecting-certain-indexes-in-an-array/</guid>
      <description>import requests from bs4 import BeautifulSoup from soupselect import select page = open(&amp;#34;constituencies.html&amp;#34;, &amp;#39;r&amp;#39;) soup = BeautifulSoup(page.read()) for row in select(soup, &amp;#34;table.wikitable tr&amp;#34;): if select(row, &amp;#34;th&amp;#34;): print [cell.text for cell in select(row, &amp;#34;th&amp;#34;)] if select(row, &amp;#34;td&amp;#34;): print [cell.text for cell in select(row, &amp;#34;td&amp;#34;)] $ python blog.py [u&amp;#39;Constituency&amp;#39;, u&amp;#39;Electorate (2000)&amp;#39;, u&amp;#39;Electorate (2010)&amp;#39;, u&amp;#39;Largest Local Authority&amp;#39;, u&amp;#39;Country of the UK&amp;#39;] [u&amp;#39;Aldershot&amp;#39;, u&amp;#39;66,499&amp;#39;, u&amp;#39;71,908&amp;#39;, u&amp;#39;Hampshire&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Aldridge-Brownhills&amp;#39;, u&amp;#39;58,695&amp;#39;, u&amp;#39;59,506&amp;#39;, u&amp;#39;West Midlands&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Altrincham and Sale West&amp;#39;, u&amp;#39;69,605&amp;#39;, u&amp;#39;72,008&amp;#39;, u&amp;#39;Greater Manchester&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Amber Valley&amp;#39;, u&amp;#39;66,406&amp;#39;, u&amp;#39;69,538&amp;#39;, u&amp;#39;Derbyshire&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Arundel and South Downs&amp;#39;, u&amp;#39;71,203&amp;#39;, u&amp;#39;76,697&amp;#39;, u&amp;#39;West Sussex&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Ashfield&amp;#39;, u&amp;#39;74,674&amp;#39;, u&amp;#39;77,049&amp;#39;, u&amp;#39;Nottinghamshire&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Ashford&amp;#39;, u&amp;#39;72,501&amp;#39;, u&amp;#39;81,947&amp;#39;, u&amp;#39;Kent&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Ashton-under-Lyne&amp;#39;, u&amp;#39;67,334&amp;#39;, u&amp;#39;68,553&amp;#39;, u&amp;#39;Greater Manchester&amp;#39;, u&amp;#39;England&amp;#39;] [u&amp;#39;Aylesbury&amp;#39;, u&amp;#39;72,023&amp;#39;, u&amp;#39;78,750&amp;#39;, u&amp;#39;Buckinghamshire&amp;#39;, u&amp;#39;England&amp;#39;] .</description>
    </item>
    
    <item>
      <title>Neo4j: LOAD CSV - java.io.InputStreamReader there&#39;s a field starting with a quote and whereas it ends that quote there seems  to be character in that field after that ending quote. That isn&#39;t supported.</title>
      <link>https://markhneedham.com/blog/2015/05/04/neo4j-load-csv-java-io-inputstreamreader-theres-a-field-starting-with-a-quote-and-whereas-it-ends-that-quote-there-seems-to-be-character-in-that-field-after-that-ending-quote-that-isnt-suppor/</link>
      <pubDate>Mon, 04 May 2015 09:56:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/04/neo4j-load-csv-java-io-inputstreamreader-theres-a-field-starting-with-a-quote-and-whereas-it-ends-that-quote-there-seems-to-be-character-in-that-field-after-that-ending-quote-that-isnt-suppor/</guid>
      <description>LOAD CSV FROM &amp;quot;file:///Users/markneedham/projects/neo4j-recommendations/lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv&amp;quot; AS row FIELDTERMINATOR &amp;quot;\t&amp;quot; return COUNT(*) At java.io.InputStreamReader@4d307fda:6484 there&#39;s a field starting with a quote and whereas it ends that quote there seems to be character in that field after that ending quote. That isn&#39;t supported. This is what I read: &#39;weird al&amp;quot;&#39; $ grep &amp;#34;\&amp;#34;weird&amp;#34; lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv | head -n 1 0015371426d2cbef354b2f680340de38d0ebd2f0	7746d775-9550-4360-b8d5-c37bd448ce01	&amp;#34;weird al&amp;#34; yankovic	4099 $ tr &amp;#34;\&amp;#34;&amp;#34; &amp;#34;&amp;#39;&amp;#34; &amp;lt; lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv &amp;gt; lastfm-dataset-360K/clean.tsv LOAD CSV FROM &amp;quot;file:///Users/markneedham/projects/neo4j-recommendations/lastfm-dataset-360K/clean.</description>
    </item>
    
    <item>
      <title>Coding: Visualising a bitmap</title>
      <link>https://markhneedham.com/blog/2015/05/03/coding-visualising-a-bitmap/</link>
      <pubDate>Sun, 03 May 2015 00:19:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/05/03/coding-visualising-a-bitmap/</guid>
      <description>java&amp;gt; (1 &amp;lt;&amp;lt; 31) &amp;amp; 0x80000000 java.lang.Integer res5 = -2147483648 java&amp;gt; (1 &amp;lt;&amp;lt; 0) &amp;amp; 0x00000001 java.lang.Integer res7 = 0 java&amp;gt; (1 &amp;lt;&amp;lt; 0) &amp;amp; 0x00000001 java.lang.Integer res8 = 1 private String asString( int bitmap ) { StringBuilder sb = new StringBuilder(); sb.append( &amp;#34;[&amp;#34; ); for ( int i = Integer.SIZE - 1; i &amp;gt;= 0; i-- ) { int bitMask = 1 &amp;lt;&amp;lt; i; boolean bitIsSet = (bitmap &amp;amp; bitMask) !</description>
    </item>
    
    <item>
      <title>Deliberate Practice: Building confidence vs practicing</title>
      <link>https://markhneedham.com/blog/2015/04/30/deliberate-practice-building-confidence-vs-practicing/</link>
      <pubDate>Thu, 30 Apr 2015 07:48:38 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/30/deliberate-practice-building-confidence-vs-practicing/</guid>
      <description>me, April 2015</description>
    </item>
    
    <item>
      <title>R: dplyr - Error in (list: invalid subscript type &#39;double&#39;</title>
      <link>https://markhneedham.com/blog/2015/04/27/r-dplyr-error-in-list-invalid-subscript-type-double/</link>
      <pubDate>Mon, 27 Apr 2015 22:34:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/27/r-dplyr-error-in-list-invalid-subscript-type-double/</guid>
      <description>library(dplyr) df = data.frame(score = c(5,7,8,10,12,20), percentile = c(0.05,0.1,0.15,0.20,0.25,0.5)) &amp;gt; (df %&amp;gt;% filter(percentile &amp;gt; 0.05) %&amp;gt;% slice(1))$score [1] 7 targetPercentiles = c(0.05, 0.2) percentilesDf = data.frame(targetPercentile = targetPercentiles) &amp;gt; percentilesDf %&amp;gt;% group_by(targetPercentile) %&amp;gt;% mutate(x = (df %&amp;gt;% filter(percentile &amp;gt; targetPercentile) %&amp;gt;% slice(1))$score) Error in (list(score = c(5, 7, 8, 10, 12, 20), percentile = c(0.05, 0.1, : invalid subscript type &amp;#39;double&amp;#39; df = data.frame(score = c(5,7,8,10,12,20), percentile = c(0.05,0.1,0.15,0.20,0.25,0.5)) targetPercentiles = c(0.</description>
    </item>
    
    <item>
      <title>Deliberate Practice: Watching yourself fail</title>
      <link>https://markhneedham.com/blog/2015/04/25/deliberate-practice-watching-yourself-fail/</link>
      <pubDate>Sat, 25 Apr 2015 22:26:51 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/25/deliberate-practice-watching-yourself-fail/</guid>
      <description>It&amp;rsquo;s much easier to see the error in approach if there is an approach! On one occasion where I hadn&amp;rsquo;t planned out an approach I ended up staring at the question for 10 minutes and didn&amp;rsquo;t make any progress at all.
e.g. one exercise was to calculate the 5th percentile of a posterior distribution which I flailed around with for 15 minutes before giving up. Watching back on the video it was obvious that I hadn&amp;rsquo;t completely understood what a probability mass functionwas.</description>
    </item>
    
    <item>
      <title>R: Think Bayes Locomotive Problem - Posterior probabilities for different priors</title>
      <link>https://markhneedham.com/blog/2015/04/24/r-think-bayes-locomotive-problem-posterior-probabilities-for-different-priors/</link>
      <pubDate>Fri, 24 Apr 2015 23:53:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/24/r-think-bayes-locomotive-problem-posterior-probabilities-for-different-priors/</guid>
      <description>One day you see a locomotive with the number 60. Estimate how many loco- motives the railroad has.
library(dplyr) possibleValues = 1:1000 observations = c(60) l = list(value = possibleValues, observation = observations) df = expand.grid(l) &amp;gt; df %&amp;gt;% head() value observation 1 1 60 2 2 60 3 3 60 4 4 60 5 5 60 6 6 60 prior = 1 / length(possibleValues) df = df %&amp;gt;% mutate(score = ifelse(value &amp;lt; observation, 0, 1/value)) &amp;gt; df %&amp;gt;% sample_n(10) value observation score 179 179 60 0.</description>
    </item>
    
    <item>
      <title>R: Replacing for loops with data frames</title>
      <link>https://markhneedham.com/blog/2015/04/22/r-replacing-for-loops-with-data-frames/</link>
      <pubDate>Wed, 22 Apr 2015 22:18:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/22/r-replacing-for-loops-with-data-frames/</guid>
      <description>Suppose I select a die from the box at random, roll it, and get a 6. What is the probability that I rolled each die?
likelihoods = function(names, observations) { scores = rep(1.0 / length(names), length(names)) names(scores) = names for(name in names) { for(observation in observations) { if(name &amp;lt; observation) { scores[paste(name)] = 0 } else { scores[paste(name)] = scores[paste(name)] * (1.0 / name) } } } return(scores) } dice = c(4,6,8,12,20) l1 = likelihoods(dice, c(6)) &amp;gt; l1 / sum(l1) 4 6 8 12 20 0.</description>
    </item>
    
    <item>
      <title>R: Numeric keys in the nested list/dictionary</title>
      <link>https://markhneedham.com/blog/2015/04/21/r-numeric-keys-in-the-nested-listdictionary/</link>
      <pubDate>Tue, 21 Apr 2015 05:59:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/21/r-numeric-keys-in-the-nested-listdictionary/</guid>
      <description>Suppose I select a die from the box at random, roll it, and get a 6. What is the probability that I rolled each die?
dice = c(4,6,8,12,20) priors = rep(1.0 / length(dice), length(dice)) names(priors) = dice &amp;gt; priors 4 6 8 12 20 0.2 0.2 0.2 0.2 0.2 &amp;gt; priors[8] &amp;lt;NA&amp;gt; NA dice = c(4,6,8,12,20) priors = rep(1.0 / length(dice), length(dice)) names(priors) = sapply(dice, paste) &amp;gt; priors[&amp;#34;8&amp;#34;] 8 0.2 dice = c(4,6,8,12,20) priors = rep(1.</description>
    </item>
    
    <item>
      <title>R: non-numeric argument to binary operator</title>
      <link>https://markhneedham.com/blog/2015/04/19/r-non-numeric-argument-to-binary-operator/</link>
      <pubDate>Sun, 19 Apr 2015 23:08:45 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/19/r-non-numeric-argument-to-binary-operator/</guid>
      <description>names = c(1,2,3,4,5,6) &amp;gt; print(&amp;#34;names: &amp;#34; + names) Error in &amp;#34;names: &amp;#34; + names : non-numeric argument to binary operator &amp;gt; print(&amp;#34;names: &amp;#34;, names) [1] &amp;#34;names: &amp;#34; &amp;gt; print(paste(&amp;#34;names: &amp;#34;, names)) [1] &amp;#34;names: 1&amp;#34; &amp;#34;names: 2&amp;#34; &amp;#34;names: 3&amp;#34; &amp;#34;names: 4&amp;#34; &amp;#34;names: 5&amp;#34; &amp;#34;names: 6&amp;#34; &amp;gt; print(paste(&amp;#34;names: &amp;#34;, toString(names))) [1] &amp;#34;names: 1, 2, 3, 4, 5, 6&amp;#34; </description>
    </item>
    
    <item>
      <title>R: Removing for loops</title>
      <link>https://markhneedham.com/blog/2015/04/18/r-removing-for-loops/</link>
      <pubDate>Sat, 18 Apr 2015 23:53:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/18/r-removing-for-loops/</guid>
      <description>likelihoods = function(names, mixes, observations) { scores = rep(1, length(names)) names(scores) = names for(name in names) { for(observation in observations) { scores[name] = scores[name] * mixes[[name]][observation] } } return(scores) } Names = c(&amp;#34;Bowl 1&amp;#34;, &amp;#34;Bowl 2&amp;#34;) bowl1Mix = c(0.75, 0.25) names(bowl1Mix) = c(&amp;#34;vanilla&amp;#34;, &amp;#34;chocolate&amp;#34;) bowl2Mix = c(0.5, 0.5) names(bowl2Mix) = c(&amp;#34;vanilla&amp;#34;, &amp;#34;chocolate&amp;#34;) Mixes = list(&amp;#34;Bowl 1&amp;#34; = bowl1Mix, &amp;#34;Bowl 2&amp;#34; = bowl2Mix) Mixes Observations = c(&amp;#34;vanilla&amp;#34;, &amp;#34;vanilla&amp;#34;, &amp;#34;vanilla&amp;#34;, &amp;#34;chocolate&amp;#34;) l = likelihoods(Names, Mixes, Observations) &amp;gt; l / sum(l) Bowl 1 Bowl 2 0.</description>
    </item>
    
    <item>
      <title>R: Think Bayes - More posterior probability calculations</title>
      <link>https://markhneedham.com/blog/2015/04/16/r-think-bayes-more-posterior-probability-calculations/</link>
      <pubDate>Thu, 16 Apr 2015 20:57:20 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/16/r-think-bayes-more-posterior-probability-calculations/</guid>
      <description>f = function(names,likelihoods) { # Assume each option has an equal prior priors = rep(1, length(names)) / length(names) # create a data frame with all info you have dt = data.frame(names,priors,likelihoods) # calculate posterior probabilities dt$post = dt$priors*dt$likelihoods / sum(dt$priors*dt$likelihoods) # specify what you want the function to return list(names=dt$names, priors=dt$priors, likelihoods=dt$likelihoods, posteriors=dt$post) } mixes = { &amp;#39;Bowl 1&amp;#39;:dict(vanilla=0.75, chocolate=0.25), &amp;#39;Bowl 2&amp;#39;:dict(vanilla=0.5, chocolate=0.5), } Likelihoods = c(0.75,0.5) Names = c(&amp;#34;Bowl 1&amp;#34;, &amp;#34;Bowl 2&amp;#34;) res=f(Names,Likelihoods) &amp;gt; res$posteriors[res$name == &amp;#34;Bowl 1&amp;#34;] [1] 0.</description>
    </item>
    
    <item>
      <title>Spark: Generating CSV files to import into Neo4j</title>
      <link>https://markhneedham.com/blog/2015/04/14/spark-generating-csv-files-to-import-into-neo4j/</link>
      <pubDate>Tue, 14 Apr 2015 22:56:35 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/14/spark-generating-csv-files-to-import-into-neo4j/</guid>
      <description>About a year ago Ian pointed me at a Chicago Crime data set which seemed like a good fit for Neo4j and after much procrastination I&amp;#8217;ve finally got around to importing it.
 The data set covers crimes committed from 2001 until now. It contains around 4 million crimes and meta data around those crimes such as the location, type of crime and year to name a few.
 The contents of the file follow this structure:</description>
    </item>
    
    <item>
      <title>R: Creating an object with functions to calculate conditional probability</title>
      <link>https://markhneedham.com/blog/2015/04/12/r-creating-an-object-with-functions-to-calculate-conditional-probability/</link>
      <pubDate>Sun, 12 Apr 2015 07:55:29 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/12/r-creating-an-object-with-functions-to-calculate-conditional-probability/</guid>
      <description>Now suppose you choose one of the bowls at random and, without looking, select a cookie at random. The cookie is vanilla.
What is the probability that it came from Bowl 1?
pmf = Pmf() pmf.Set(&amp;#39;Bowl 1&amp;#39;, 0.5) pmf.Set(&amp;#39;Bowl 2&amp;#39;, 0.5) pmf.Mult(&amp;#39;Bowl 1&amp;#39;, 0.75) pmf.Mult(&amp;#39;Bowl 2&amp;#39;, 0.5) pmf.Normalize() print pmf.Prob(&amp;#39;Bowl 1&amp;#39;) pBowl1 = 0.5 pBowl2 = 0.5 pVanillaGivenBowl1 = 0.75 pVanillaGivenBowl2 = 0.5 &amp;gt; (pBowl1 * pVanillaGivenBowl1) / ((pBowl1 * pVanillaGivenBowl1) + (PBowl2 * pVanillaGivenBowl2)) 0.</description>
    </item>
    
    <item>
      <title>R: Snakes and ladders markov chain</title>
      <link>https://markhneedham.com/blog/2015/04/09/r-snakes-and-ladders-markov-chain/</link>
      <pubDate>Thu, 09 Apr 2015 22:02:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/09/r-snakes-and-ladders-markov-chain/</guid>
      <description>n=100 # We have 6 extra columns because we want to represent throwing of the dice which results in a final square &amp;gt; 100 M=matrix(0,n+1,n+1+6) rownames(M)=0:n colnames(M)=0:(n+6) # set probabilities of landing on each square assuming that there aren&amp;#39;t any snakes or ladders for(i in 1:6){ diag(M[,(i+1):(i+1+n)])=1/6 } # account for &amp;#39;bounce back&amp;#39; if a dice roll leads to a final score &amp;gt; 100 for(i in 96:100) { for(c in 102:107) { idx = 101 - (c - 101) M[i, idx] = M[i, idx] + M[i, c] } } &amp;gt; M[95:100,95:101] 94 95 96 97 98 99 100 94 0 0.</description>
    </item>
    
    <item>
      <title>Neo4j: The learning to cycle dependency graph</title>
      <link>https://markhneedham.com/blog/2015/04/07/neo4j-the-learning-to-cycle-dependency-graph/</link>
      <pubDate>Tue, 07 Apr 2015 20:59:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/07/neo4j-the-learning-to-cycle-dependency-graph/</guid>
      <description>MERGE (:Goal:Task {name: &amp;quot;Be able to cycle through a public park&amp;quot;}) MERGE (task:Task {name: &amp;quot;Take a few steps forward while standing over the bike&amp;quot;}) WITH task MATCH (goal:Goal:Task {name: &amp;quot;Be able to cycle through a public park&amp;quot;}) MERGE (goal)-[:DEPENDS_ON]-&amp;gt;(task) // First let&#39;s get rid of the relationship between our initial task and the goal MATCH (initialTask:Task {name: &amp;quot;Take a few steps forward while standing over the bike&amp;quot;}) MATCH (goal:Goal {name: &amp;quot;Be able to cycle through a public park&amp;quot;}) MATCH (goal)-[rel:DEPENDS_ON]-&amp;gt;(initialTask) DELETE rel WITH initialTask, goal, [&amp;quot;Get bike moving from standing start&amp;quot;, &amp;quot;Cycle forward while standing&amp;quot;, &amp;quot;Cycle forward while sitting&amp;quot;] AS newTasks // Create some nodes for our new tasks UNWIND newTasks AS newTask MERGE (t:Task {name: newTask}) WITH initialTask, goal, COLLECT(t) AS newTasks WITH initialTask, goal, newTasks, newTasks[0] AS firstTask, newTasks[-1] AS lastTask // Connect the last task to the goal MERGE (goal)-[:DEPENDS_ON]-&amp;gt;(lastTask) // And the first task to our initial task MERGE (firstTask)-[:DEPENDS_ON]-&amp;gt;(initialTask) // And all the tasks to each other FOREACH(i in RANGE(0, length(newTasks) - 2) | FOREACH(t1 in [newTasks[i]] | FOREACH(t2 in [newTasks[i+1]] | MERGE (t2)-[:DEPENDS_ON]-&amp;gt;(t1) ))) MATCH (sitting:Task {name: &amp;quot;Cycle forward while sitting&amp;quot;}) MATCH (moving:Task {name: &amp;quot;Get bike moving from standing start&amp;quot;}) MERGE (sitting)-[:DEPENDS_ON]-&amp;gt;(moving) WITH [ {skill: &amp;quot;Controlled stop using brakes/feet&amp;quot;, dependsOn: &amp;quot;Cycle forward while sitting&amp;quot;}, {skill: &amp;quot;Steer around stationary objects&amp;quot;, dependsOn: &amp;quot;Controlled stop using brakes/feet&amp;quot;}, {skill: &amp;quot;Steer around people&amp;quot;, dependsOn: &amp;quot;Steer around stationary objects&amp;quot;}, {skill: &amp;quot;Navigate a small circular circuit&amp;quot;, dependsOn: &amp;quot;Steer around stationary objects&amp;quot;}, {skill: &amp;quot;Navigate a loop of a section of the park&amp;quot;, dependsOn: &amp;quot;Navigate a small circular circuit&amp;quot;}, {skill: &amp;quot;Navigate a loop of a section of the park&amp;quot;, dependsOn: &amp;quot;Steer around people&amp;quot;}, {skill: &amp;quot;Be able to cycle through a public park&amp;quot;, dependsOn: &amp;quot;Navigate a loop of a section of the park&amp;quot;} ] AS newTasks FOREACH(newTask in newTasks | MERGE (t1:Task {name: newTask.</description>
    </item>
    
    <item>
      <title>R: Markov Chain Wikipedia Example</title>
      <link>https://markhneedham.com/blog/2015/04/05/r-markov-chain-wikipedia-example/</link>
      <pubDate>Sun, 05 Apr 2015 10:07:12 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/05/r-markov-chain-wikipedia-example/</guid>
      <description>It is required to possess a property that is usually characterized as &amp;ldquo;memoryless&amp;rdquo;: the probability distribution of the next state depends only on the current state and not on the sequence of events that preceded it.
M = matrix(c(0.9, 0.075, 0.025, 0.15, 0.8, 0.05, 0.25, 0.25, 0.5), nrow = 3, ncol = 3, byrow = TRUE) &amp;gt; M [,1] [,2] [,3] [1,] 0.90 0.075 0.025 [2,] 0.15 0.800 0.050 [3,] 0.</description>
    </item>
    
    <item>
      <title>How I met your mother: Story arcs</title>
      <link>https://markhneedham.com/blog/2015/04/03/how-i-met-your-mother-story-arcs/</link>
      <pubDate>Fri, 03 Apr 2015 23:31:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/03/how-i-met-your-mother-story-arcs/</guid>
      <description>#!/bin/bash find_term() { arc=${1} searchTerm=${2} episodes=$(grep --color -iE &amp;#34;${searchTerm}&amp;#34; data/import/sentences.csv | awk -F&amp;#34;,&amp;#34; &amp;#39;{ print $2 }&amp;#39; | sort | uniq) for episode in ${episodes}; do echo ${arc},${episode} done } find_term &amp;#34;Bro Code&amp;#34; &amp;#34;bro code&amp;#34; find_term &amp;#34;Legendary&amp;#34; &amp;#34;legen(.*)ary&amp;#34; find_term &amp;#34;Slutty Pumpkin&amp;#34; &amp;#34;slutty pumpkin&amp;#34; find_term &amp;#34;Magician&amp;#39;s Code&amp;#34; &amp;#34;magician&amp;#39;s code&amp;#34; find_term &amp;#34;Thanksgiving&amp;#34; &amp;#34;thanksgiving&amp;#34; find_term &amp;#34;The Playbook&amp;#34; &amp;#34;playbook&amp;#34; find_term &amp;#34;Slap Bet&amp;#34; &amp;#34;slap bet&amp;#34; find_term &amp;#34;Wrestlers and Robots&amp;#34; &amp;#34;wrestlers&amp;#34; find_term &amp;#34;Robin Sparkles&amp;#34; &amp;#34;sparkles&amp;#34; find_term &amp;#34;Blue French Horn&amp;#34; &amp;#34;blue french horn&amp;#34; find_term &amp;#34;Olive Theory&amp;#34; &amp;#34;olive&amp;#34; find_term &amp;#34;Thank You Linus&amp;#34; &amp;#34;thank you, linus&amp;#34; find_term &amp;#34;Have you met.</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Building the query for a movie&#39;s profile page</title>
      <link>https://markhneedham.com/blog/2015/04/01/neo4j-cypher-building-the-query-for-a-movies-profile-page/</link>
      <pubDate>Wed, 01 Apr 2015 11:54:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/04/01/neo4j-cypher-building-the-query-for-a-movies-profile-page/</guid>
      <description>match (movie:Movie {title: &amp;quot;The Matrix&amp;quot;}) return movie.title ==&amp;gt; +--------------+ ==&amp;gt; | movie.title | ==&amp;gt; +--------------+ ==&amp;gt; | &amp;quot;The Matrix&amp;quot; | ==&amp;gt; +--------------+ ==&amp;gt; 1 row Easy enough. Now let&amp;rsquo;s get back the producers:
match (movie:Movie {title: &amp;quot;The Matrix&amp;quot;}) optional match (producer)-[:PRODUCED]-&amp;gt;(movie) RETURN movie.title, COLLECT(producer.name) AS producers ==&amp;gt; +--------------------------------+ ==&amp;gt; | movie.title | producers | ==&amp;gt; +--------------------------------+ ==&amp;gt; | &amp;quot;The Matrix&amp;quot; | [&amp;quot;Joel Silver&amp;quot;] | ==&amp;gt; +--------------------------------+ ==&amp;gt; 1 row match (movie:Movie {title: &amp;quot;The Matrix&amp;quot;}) optional match (director)-[:DIRECTED]-&amp;gt;(movie) RETURN movie.</description>
    </item>
    
    <item>
      <title>Python: Creating a skewed random discrete distribution</title>
      <link>https://markhneedham.com/blog/2015/03/30/python-creating-a-skewed-random-discrete-distribution/</link>
      <pubDate>Mon, 30 Mar 2015 22:28:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/30/python-creating-a-skewed-random-discrete-distribution/</guid>
      <description>import math import numpy as np values = range(1, 209) probs = [1.0 / 208] * 208 for idx, prob in enumerate(probs): if idx &amp;gt; 3 and idx &amp;lt; 20: probs[idx] = probs[idx] * (1 + math.log(idx + 1)) if idx &amp;gt; 20 and idx &amp;lt; 40: probs[idx] = probs[idx] * (1 + math.log((40 - idx) + 1)) probs = [p / sum(probs) for p in probs] sample = np.random.choice(values, 1000, p=probs) &amp;gt;&amp;gt;&amp;gt; print sample[:10] [ 33 9 22 126 54 4 20 17 45 56] import matplotlib matplotlib.</description>
    </item>
    
    <item>
      <title>InetAddressImpl#lookupAllHostAddr slow/hangs</title>
      <link>https://markhneedham.com/blog/2015/03/29/inetaddressimpllookupallhostaddr-slowhangs/</link>
      <pubDate>Sun, 29 Mar 2015 00:31:37 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/29/inetaddressimpllookupallhostaddr-slowhangs/</guid>
      <description>$ cat /etc/hosts ## # Host Database # # localhost is used to configure the loopback interface # when the system is booting. Do not change this entry. ## 127.0.0.1	localhost 255.255.255.255	broadcasthost ::1 localhost #fe80::1%lo0	localhost 127.0.0.1	wuqour.local 127.0.0.1 teetotal import java.net.InetAddress; import java.net.UnknownHostException; public class LocalhostResolution { public static void main( String[] args ) throws UnknownHostException { long start = System.currentTimeMillis(); InetAddress localHost = InetAddress.getLocalHost(); System.out.println(localHost); System.out.println(System.currentTimeMillis() - start); } } Exception in thread &amp;#34;main&amp;#34; java.</description>
    </item>
    
    <item>
      <title>Neo4j: Generating real time recommendations with Cypher</title>
      <link>https://markhneedham.com/blog/2015/03/27/neo4j-generating-real-time-recommendations-with-cypher/</link>
      <pubDate>Fri, 27 Mar 2015 06:59:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/27/neo4j-generating-real-time-recommendations-with-cypher/</guid>
      <description>CREATE (m:Person:Male {name:&#39;Michal&#39;, age:30}), (d:Person:Female {name:&#39;Daniela&#39;, age:20}), (v:Person:Male {name:&#39;Vince&#39;, age:40}), (a:Person:Male {name:&#39;Adam&#39;, age:30}), (l:Person:Female {name:&#39;Luanne&#39;, age:25}), (c:Person:Male {name:&#39;Christophe&#39;, age:60}), (lon:City {name:&#39;London&#39;}), (mum:City {name:&#39;Mumbai&#39;}), (m)-[:FRIEND_OF]-&amp;gt;(d), (m)-[:FRIEND_OF]-&amp;gt;(l), (m)-[:FRIEND_OF]-&amp;gt;(a), (m)-[:FRIEND_OF]-&amp;gt;(v), (d)-[:FRIEND_OF]-&amp;gt;(v), (c)-[:FRIEND_OF]-&amp;gt;(v), (d)-[:LIVES_IN]-&amp;gt;(lon), (v)-[:LIVES_IN]-&amp;gt;(lon), (m)-[:LIVES_IN]-&amp;gt;(lon), (l)-[:LIVES_IN]-&amp;gt;(mum); MATCH (me:Person {name: &amp;quot;Adam&amp;quot;}) MATCH (me)-[:FRIEND_OF]-()-[:FRIEND_OF]-(potentialFriend) RETURN me, potentialFriend, COUNT(*) AS friendsInCommon ==&amp;gt; +--------------------------------------------------------------------------------------+ ==&amp;gt; | me | potentialFriend | friendsInCommon | ==&amp;gt; +--------------------------------------------------------------------------------------+ ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1006]{name:&amp;quot;Vince&amp;quot;,age:40} | 1 | ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1005]{name:&amp;quot;Daniela&amp;quot;,age:20} | 1 | ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1008]{name:&amp;quot;Luanne&amp;quot;,age:25} | 1 | ==&amp;gt; +--------------------------------------------------------------------------------------+ ==&amp;gt; 3 rows MATCH (me:Person {name: &amp;quot;Adam&amp;quot;}) MATCH (me)-[:FRIEND_OF]-()-[:FRIEND_OF]-(potentialFriend) WITH me, potentialFriend, COUNT(*) AS friendsInCommon RETURN me, potentialFriend, SIZE((potentialFriend)-[:LIVES_IN]-&amp;gt;()&amp;lt;-[:LIVES_IN]-(me)) AS sameLocation ==&amp;gt; +-----------------------------------------------------------------------------------+ ==&amp;gt; | me | potentialFriend | sameLocation | ==&amp;gt; +-----------------------------------------------------------------------------------+ ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1006]{name:&amp;quot;Vince&amp;quot;,age:40} | 0 | ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1005]{name:&amp;quot;Daniela&amp;quot;,age:20} | 0 | ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1008]{name:&amp;quot;Luanne&amp;quot;,age:25} | 0 | ==&amp;gt; +-----------------------------------------------------------------------------------+ ==&amp;gt; 3 rows MATCH (me:Person {name: &amp;quot;Adam&amp;quot;}) MATCH (me)-[:FRIEND_OF]-()-[:FRIEND_OF]-(potentialFriend) WITH me, potentialFriend, COUNT(*) AS friendsInCommon RETURN me, potentialFriend, SIZE((potentialFriend)-[:LIVES_IN]-&amp;gt;()&amp;lt;-[:LIVES_IN]-(me)) AS sameLocation, LABELS(me) = LABELS(potentialFriend) AS gender ==&amp;gt; +--------------------------------------------------------------------------------------------+ ==&amp;gt; | me | potentialFriend | sameLocation | gender | ==&amp;gt; +--------------------------------------------------------------------------------------------+ ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1006]{name:&amp;quot;Vince&amp;quot;,age:40} | 0 | true | ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1005]{name:&amp;quot;Daniela&amp;quot;,age:20} | 0 | false | ==&amp;gt; | Node[1007]{name:&amp;quot;Adam&amp;quot;,age:30} | Node[1008]{name:&amp;quot;Luanne&amp;quot;,age:25} | 0 | false | ==&amp;gt; +--------------------------------------------------------------------------------------------+ ==&amp;gt; 3 rows MATCH (me:Person {name: &amp;quot;Adam&amp;quot;}) MATCH (me)-[:FRIEND_OF]-()-[:FRIEND_OF]-(potentialFriend) WITH me, potentialFriend, COUNT(*) AS friendsInCommon RETURN me, potentialFriend, SIZE((potentialFriend)-[:LIVES_IN]-&amp;gt;()&amp;lt;-[:LIVES_IN]-(me)) AS sameLocation, abs( me.</description>
    </item>
    
    <item>
      <title>Python: matplotlib hangs and shows nothing (Mac OS X)</title>
      <link>https://markhneedham.com/blog/2015/03/26/python-matplotlib-hangs-and-shows-nothing-mac-os-x/</link>
      <pubDate>Thu, 26 Mar 2015 00:02:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/26/python-matplotlib-hangs-and-shows-nothing-mac-os-x/</guid>
      <description>import numpy as np import matplotlib.pyplot as plt N = 5 ind = np.arange(N) fig, ax = plt.subplots() menMeans = (20, 35, 30, 35, 27) menStd = (2, 3, 4, 1, 2) width = 0.35 # the width of the bars rects1 = ax.bar(ind, menMeans, width, color=&amp;#39;r&amp;#39;, yerr=menStd) plt.show() import numpy as np import matplotlib matplotlib.use(&amp;#39;TkAgg&amp;#39;) import matplotlib.pyplot as plt N = 5 ind = np.arange(N) fig, ax = plt.subplots() menMeans = (20, 35, 30, 35, 27) menStd = (2, 3, 4, 1, 2) width = 0.</description>
    </item>
    
    <item>
      <title>Topic Modelling: Working out the optimal number of topics</title>
      <link>https://markhneedham.com/blog/2015/03/24/topic-modelling-working-out-the-optimal-number-of-topics/</link>
      <pubDate>Tue, 24 Mar 2015 22:33:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/24/topic-modelling-working-out-the-optimal-number-of-topics/</guid>
      <description>There are computational ways of searching for this, including using MALLETs hlda command, but for the reader of this tutorial, it is probably just quicker to cycle through a number of iterations (but for more see Griffiths, T. L., &amp;amp; Steyvers, M. (2004). Finding scientific topics. Proceedings of the National Academy of Science, 101, 5228-5235).
As I understand it, the idea is to try and get a uniform spread of topics -&amp;gt; documents i.</description>
    </item>
    
    <item>
      <title>Python: Equivalent to flatMap for flattening an array of arrays</title>
      <link>https://markhneedham.com/blog/2015/03/23/python-equivalent-to-flatmap-for-flattening-an-array-of-arrays/</link>
      <pubDate>Mon, 23 Mar 2015 00:45:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/23/python-equivalent-to-flatmap-for-flattening-an-array-of-arrays/</guid>
      <description>episodes = [ {&amp;#34;id&amp;#34;: 1, &amp;#34;topics&amp;#34;: [1,2,3]}, {&amp;#34;id&amp;#34;: 2, &amp;#34;topics&amp;#34;: [4,5,6]} ] flattened_episodes = [] for episode in episodes: for topic in episode[&amp;#34;topics&amp;#34;]: flattened_episodes.append({&amp;#34;id&amp;#34;: episode[&amp;#34;id&amp;#34;], &amp;#34;topic&amp;#34;: topic}) for episode in flattened_episodes: print episode $ python flatten.py {&amp;#39;topic&amp;#39;: 1, &amp;#39;id&amp;#39;: 1} {&amp;#39;topic&amp;#39;: 2, &amp;#39;id&amp;#39;: 1} {&amp;#39;topic&amp;#39;: 3, &amp;#39;id&amp;#39;: 1} {&amp;#39;topic&amp;#39;: 4, &amp;#39;id&amp;#39;: 2} {&amp;#39;topic&amp;#39;: 5, &amp;#39;id&amp;#39;: 2} {&amp;#39;topic&amp;#39;: 6, &amp;#39;id&amp;#39;: 2} flattened_episodes = [{&amp;#34;id&amp;#34;: episode[&amp;#34;id&amp;#34;], &amp;#34;topic&amp;#34;: topic} for episode in episodes for topic in episode[&amp;#34;topics&amp;#34;]] for episode in flattened_episodes: print episode from itertools import chain, imap flattened_episodes = chain.</description>
    </item>
    
    <item>
      <title>Python: Simplifying the creation of a stop word list with defaultdict</title>
      <link>https://markhneedham.com/blog/2015/03/22/python-simplifying-the-creation-of-a-stop-word-list-with-defaultdict/</link>
      <pubDate>Sun, 22 Mar 2015 01:51:52 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/22/python-simplifying-the-creation-of-a-stop-word-list-with-defaultdict/</guid>
      <description>import csv from sklearn.feature_extraction.text import CountVectorizer from collections import defaultdict episodes = defaultdict(str) with open(&amp;#34;sentences.csv&amp;#34;, &amp;#34;r&amp;#34;) as file: reader = csv.reader(file, delimiter = &amp;#34;,&amp;#34;) reader.next() for row in reader: episodes[row[1]] += row[4] vectorizer = CountVectorizer(analyzer=&amp;#39;word&amp;#39;, min_df = 0, stop_words = &amp;#39;english&amp;#39;) matrix = vectorizer.fit_transform(episodes.values()) features = vectorizer.get_feature_names() words = {} for doc_id, doc in enumerate(matrix.todense()): for word_id, score in enumerate(doc.tolist()[0]): word = features[word_id] if not words.get(word): words[word] = {} if not words[word].</description>
    </item>
    
    <item>
      <title>Python: Forgetting to use enumerate</title>
      <link>https://markhneedham.com/blog/2015/03/22/python-forgetting-to-use-enumerate/</link>
      <pubDate>Sun, 22 Mar 2015 01:28:33 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/22/python-forgetting-to-use-enumerate/</guid>
      <description>words = [&amp;#34;mark&amp;#34;, &amp;#34;neo4j&amp;#34;, &amp;#34;michael&amp;#34;] word_position = 0 for word in words: print word_position, word word_position +=1 for word_position, word in enumerate(words): print word_position, word </description>
    </item>
    
    <item>
      <title>Badass: Making users awesome - Kathy Sierra: Book Review</title>
      <link>https://markhneedham.com/blog/2015/03/20/badass-making-users-awesome-kathy-sierra-book-review/</link>
      <pubDate>Fri, 20 Mar 2015 07:30:55 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/20/badass-making-users-awesome-kathy-sierra-book-review/</guid>
      <description>Extract topics for HIMYM corpus -&amp;gt; Train a topic model with mallet -&amp;gt; Tweak an existing topic model that uses mallet -&amp;gt; Run an existing topic model that uses mallet -&amp;gt; Install mallet </description>
    </item>
    
    <item>
      <title>Neo4j: Detecting potential typos using EXPLAIN</title>
      <link>https://markhneedham.com/blog/2015/03/17/neo4j-detecting-potential-typos-using-explain/</link>
      <pubDate>Tue, 17 Mar 2015 22:46:13 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/17/neo4j-detecting-potential-typos-using-explain/</guid>
      <description>MATCH (actor:Person)-[:ACTED_IN]-&amp;gt;(movie)&amp;lt;-[:DIRECTED]-(director) RETURN actor.name, director.name, COLLECT(movie.title) AS movies ORDER BY LENGTH(movies) DESC LIMIT 5 ==&amp;gt; +-----------------------------------------------------------------------------------------------------------------------+ ==&amp;gt; | actor.name | director.name | movies | ==&amp;gt; +-----------------------------------------------------------------------------------------------------------------------+ ==&amp;gt; | &amp;#34;Hugo Weaving&amp;#34; | &amp;#34;Andy Wachowski&amp;#34; | [&amp;#34;Cloud Atlas&amp;#34;,&amp;#34;The Matrix Revolutions&amp;#34;,&amp;#34;The Matrix Reloaded&amp;#34;,&amp;#34;The Matrix&amp;#34;] | ==&amp;gt; | &amp;#34;Hugo Weaving&amp;#34; | &amp;#34;Lana Wachowski&amp;#34; | [&amp;#34;Cloud Atlas&amp;#34;,&amp;#34;The Matrix Revolutions&amp;#34;,&amp;#34;The Matrix Reloaded&amp;#34;,&amp;#34;The Matrix&amp;#34;] | ==&amp;gt; | &amp;#34;Laurence Fishburne&amp;#34; | &amp;#34;Lana Wachowski&amp;#34; | [&amp;#34;The Matrix Revolutions&amp;#34;,&amp;#34;The Matrix Reloaded&amp;#34;,&amp;#34;The Matrix&amp;#34;] | ==&amp;gt; | &amp;#34;Keanu Reeves&amp;#34; | &amp;#34;Lana Wachowski&amp;#34; | [&amp;#34;The Matrix Revolutions&amp;#34;,&amp;#34;The Matrix Reloaded&amp;#34;,&amp;#34;The Matrix&amp;#34;] | ==&amp;gt; | &amp;#34;Carrie-Anne Moss&amp;#34; | &amp;#34;Lana Wachowski&amp;#34; | [&amp;#34;The Matrix Revolutions&amp;#34;,&amp;#34;The Matrix Reloaded&amp;#34;,&amp;#34;The Matrix&amp;#34;] | ==&amp;gt; +-----------------------------------------------------------------------------------------------------------------------+ MATCH (actor:Person)-[:ACTED_IN]-&amp;gt;(movie)&amp;lt;-[:DIRECTED_IN]-(director) RETURN actor.</description>
    </item>
    
    <item>
      <title>One month of mini habits</title>
      <link>https://markhneedham.com/blog/2015/03/17/one-month-of-mini-habits/</link>
      <pubDate>Tue, 17 Mar 2015 01:32:18 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/17/one-month-of-mini-habits/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Python: Transforming Twitter datetime string to timestamp (z&#39; is a bad directive in format)</title>
      <link>https://markhneedham.com/blog/2015/03/15/python-transforming-twitter-datetime-string-to-timestamp-z-is-a-bad-directive-in-format/</link>
      <pubDate>Sun, 15 Mar 2015 22:43:17 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/15/python-transforming-twitter-datetime-string-to-timestamp-z-is-a-bad-directive-in-format/</guid>
      <description>from datetime import datetime date = &amp;#34;Sat Mar 14 18:43:19 +0000 2015&amp;#34; &amp;gt;&amp;gt;&amp;gt; datetime.strptime(date, &amp;#34;%a %b %d%H:%M:%S %z %Y&amp;#34;) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/_strptime.py&amp;#34;, line 317, in _strptime (bad_directive, format)) ValueError: &amp;#39;z&amp;#39; is a bad directive in format &amp;#39;%a %b %d%H:%M:%S %z %Y&amp;#39; $ pip install python-dateutil from dateutil import parser parsed_date = parser.parse(date) &amp;gt;&amp;gt;&amp;gt; parsed_date datetime.datetime(2015, 3, 14, 18, 43, 19, tzinfo=tzutc()) import calendar timestamp = calendar.</description>
    </item>
    
    <item>
      <title>Python: Checking any value in a list exists in a line of text</title>
      <link>https://markhneedham.com/blog/2015/03/14/python-checking-any-value-in-a-list-exists-in-a-line-of-text/</link>
      <pubDate>Sat, 14 Mar 2015 02:52:02 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/14/python-checking-any-value-in-a-list-exists-in-a-line-of-text/</guid>
      <description>$ cat blog.txt MATCH n RETURN n MERGE (n:Person {name: &amp;#34;Mark&amp;#34;}) RETURN n MATCH (n:Person {name: &amp;#34;Mark&amp;#34;}) ON MATCH SET n.counter = 1 RETURN n with open(&amp;#34;blog.txt&amp;#34;, &amp;#34;r&amp;#34;) as ins: for line in ins: if &amp;#34;MERGE&amp;#34; in line or &amp;#34;DELETE&amp;#34; in line or &amp;#34;SET&amp;#34; in line or &amp;#34;CREATE&amp;#34; in line: print line.strip() mutating_commands = [&amp;#34;SET&amp;#34;, &amp;#34;DELETE&amp;#34;, &amp;#34;MERGE&amp;#34;, &amp;#34;CREATE&amp;#34;] with open(&amp;#34;blog.txt&amp;#34;, &amp;#34;r&amp;#34;) as ins: for line in ins: if any(command in line for command in mutating_commands): print line.</description>
    </item>
    
    <item>
      <title>Python/Neo4j: Finding interesting computer sciency people to follow on Twitter</title>
      <link>https://markhneedham.com/blog/2015/03/11/pythonneo4j-finding-interesting-computer-sciency-people-to-follow-on-twitter/</link>
      <pubDate>Wed, 11 Mar 2015 21:13:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/11/pythonneo4j-finding-interesting-computer-sciency-people-to-follow-on-twitter/</guid>
      <description>import tweepy import csv from collections import Counter, deque auth = tweepy.OAuthHandler(consumer_key, consumer_secret) auth.set_access_token(access_token, access_token_secret) api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True) counter = Counter() users_to_process = deque() USERS_TO_PROCESS = 50 def extract_tweet(tweet): user_mentions = &amp;#34;,&amp;#34;.join([user[&amp;#34;screen_name&amp;#34;].encode(&amp;#34;utf-8&amp;#34;) for user in tweet.entities[&amp;#34;user_mentions&amp;#34;]]) urls = &amp;#34;,&amp;#34;.join([url[&amp;#34;expanded_url&amp;#34;] for url in tweet.entities[&amp;#34;urls&amp;#34;]]) return [tweet.user.screen_name.encode(&amp;#34;utf-8&amp;#34;), tweet.id, tweet.text.encode(&amp;#34;utf-8&amp;#34;), user_mentions, urls] starting_user = &amp;#34;chvest&amp;#34; with open(&amp;#34;tweets.csv&amp;#34;, &amp;#34;a&amp;#34;) as tweets: writer = csv.writer(tweets, delimiter=&amp;#34;,&amp;#34;, escapechar=&amp;#34;\\&amp;#34;, doublequote = False) for tweet in tweepy.</description>
    </item>
    
    <item>
      <title>Python: Streaming/Appending to a file</title>
      <link>https://markhneedham.com/blog/2015/03/09/python-streamingappending-to-a-file/</link>
      <pubDate>Mon, 09 Mar 2015 23:00:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/09/python-streamingappending-to-a-file/</guid>
      <description>import csv import time with open(&amp;#34;rows.csv&amp;#34;, &amp;#34;a&amp;#34;) as file: writer = csv.writer(file, delimiter = &amp;#34;,&amp;#34;) end = time.time() + 10 while True: if time.time() &amp;gt; end: break else: writer.writerow([&amp;#34;mark&amp;#34;, &amp;#34;123&amp;#34;]) time.sleep(1) $ date &amp;amp;&amp;amp; wc -l rows.csv Mon 9 Mar 2015 22:54:27 GMT 0 rows.csv $ date &amp;amp;&amp;amp; wc -l rows.csv Mon 9 Mar 2015 22:54:31 GMT 0 rows.csv $ date &amp;amp;&amp;amp; wc -l rows.csv Mon 9 Mar 2015 22:54:34 GMT 0 rows.</description>
    </item>
    
    <item>
      <title>Neo4j: TF/IDF (and variants) with cypher</title>
      <link>https://markhneedham.com/blog/2015/03/08/neo4j-tfidf-and-variants-with-cypher/</link>
      <pubDate>Sun, 08 Mar 2015 13:24:19 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/08/neo4j-tfidf-and-variants-with-cypher/</guid>
      <description>WITH 3 as termFrequency, 2 AS numberOfDocuments, 1 as numberOfDocumentsWithTerm WITH termFrequency, log10(numberOfDocuments / numberOfDocumentsWithTerm) AS inverseDocumentFrequency return termFrequency * inverseDocumentFrequency 0.9030899869919435 $ head -n 10 data/import/words_scikit.csv EpisodeId,Phrase,Count 1,2005,1 1,2005 seven,1 1,2005 seven just,1 1,2030,3 1,2030 kids,1 1,2030 kids intently,1 1,2030 narrator,1 1,2030 narrator kids,1 1,2030 son,1 // phrases USING PERIODIC COMMIT 1000 LOAD CSV WITH HEADERS FROM &amp;quot;file:///Users/markneedham/projects/neo4j-himym/data/import/words_scikit.csv&amp;quot; AS row MERGE (phrase:Phrase {value: row.Phrase}); // episode -&amp;gt; phrase USING PERIODIC COMMIT 1000 LOAD CSV WITH HEADERS FROM &amp;quot;file:///Users/markneedham/projects/neo4j-himym/data/import/words_scikit.</description>
    </item>
    
    <item>
      <title>Python: scikit-learn/lda: Extracting topics from QCon talk abstracts</title>
      <link>https://markhneedham.com/blog/2015/03/05/python-scikit-learnlda-extracting-topics-from-qcon-talk-abstracts/</link>
      <pubDate>Thu, 05 Mar 2015 08:52:22 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/05/python-scikit-learnlda-extracting-topics-from-qcon-talk-abstracts/</guid>
      <description>import csv from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer from sklearn.decomposition import NMF from collections import defaultdict from bs4 import BeautifulSoup, NavigableString from soupselect import select def uri_to_file_name(uri): return uri.replace(&amp;#34;/&amp;#34;, &amp;#34;-&amp;#34;) sessions = {} with open(&amp;#34;data/sessions.csv&amp;#34;, &amp;#34;r&amp;#34;) as sessions_file: reader = csv.reader(sessions_file, delimiter = &amp;#34;,&amp;#34;) reader.next() # header for row in reader: session_id = int(row[0]) filename = &amp;#34;data/sessions/&amp;#34; + uri_to_file_name(row[4]) page = open(filename).read() soup = BeautifulSoup(page) abstract = select(soup, &amp;#34;div.brenham-main-content p&amp;#34;) if abstract: sessions[session_id] = {&amp;#34;abstract&amp;#34; : abstract[0].</description>
    </item>
    
    <item>
      <title>Python: scikit-learn - Training a classifier with non numeric features</title>
      <link>https://markhneedham.com/blog/2015/03/02/python-scikit-learn-training-a-classifier-with-non-numeric-features/</link>
      <pubDate>Mon, 02 Mar 2015 07:48:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/02/python-scikit-learn-training-a-classifier-with-non-numeric-features/</guid>
      <description>import json import nltk import collections from himymutil.ml import pos_features from sklearn import tree from sklearn.cross_validation import train_test_split with open(&amp;#34;data/import/trained_sentences.json&amp;#34;, &amp;#34;r&amp;#34;) as json_file: json_data = json.load(json_file) tagged_sents = [] for sentence in json_data: tagged_sents.append([(word[&amp;#34;word&amp;#34;], word[&amp;#34;speaker&amp;#34;]) for word in sentence[&amp;#34;words&amp;#34;]]) featuresets = [] for tagged_sent in tagged_sents: untagged_sent = nltk.tag.untag(tagged_sent) sentence_pos = nltk.pos_tag(untagged_sent) for i, (word, tag) in enumerate(tagged_sent): featuresets.append((pos_features(untagged_sent, sentence_pos, i), tag) ) clf = tree.DecisionTreeClassifier() train_data, test_data = train_test_split(featuresets, test_size=0.</description>
    </item>
    
    <item>
      <title>Python: Detecting the speaker in HIMYM using Parts of Speech (POS) tagging</title>
      <link>https://markhneedham.com/blog/2015/03/01/python-detecting-the-speaker-in-himym-using-parts-of-speech-pos-tagging/</link>
      <pubDate>Sun, 01 Mar 2015 02:36:06 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/03/01/python-detecting-the-speaker-in-himym-using-parts-of-speech-pos-tagging/</guid>
      <description>def pos_features(sentence, sentence_pos, i): features = {} features[&amp;#34;word&amp;#34;] = sentence[i] features[&amp;#34;word-pos&amp;#34;] = sentence_pos[i][1] if i == 0: features[&amp;#34;prev-word&amp;#34;] = &amp;#34;&amp;lt;START&amp;gt;&amp;#34; features[&amp;#34;prev-word-pos&amp;#34;] = &amp;#34;&amp;lt;START&amp;gt;&amp;#34; else: features[&amp;#34;prev-word&amp;#34;] = sentence[i-1] features[&amp;#34;prev-word-pos&amp;#34;] = sentence_pos[i-1][1] if i == len(sentence) - 1: features[&amp;#34;next-word&amp;#34;] = &amp;#34;&amp;lt;END&amp;gt;&amp;#34; features[&amp;#34;next-word-pos&amp;#34;] = &amp;#34;&amp;lt;END&amp;gt;&amp;#34; else: features[&amp;#34;next-word&amp;#34;] = sentence[i+1] features[&amp;#34;next-word-pos&amp;#34;] = sentence_pos[i+1][1] return features featuresets = [] for tagged_sent in tagged_sents: untagged_sent = nltk.tag.untag(tagged_sent) sentence_pos = nltk.pos_tag(untagged_sent) for i, (word, tag) in enumerate(tagged_sent): featuresets.</description>
    </item>
    
    <item>
      <title>R/ggplot: Controlling X axis order</title>
      <link>https://markhneedham.com/blog/2015/02/27/rggplot-controlling-x-axis-order/</link>
      <pubDate>Fri, 27 Feb 2015 00:49:54 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/27/rggplot-controlling-x-axis-order/</guid>
      <description>df = read.csv(&amp;#34;/tmp/friends.csv&amp;#34;) top = df %&amp;gt;% head(20) ggplot(aes(x = p.name, y = colleagues), data = top) + geom_bar(fill = &amp;#34;dark blue&amp;#34;, stat = &amp;#34;identity&amp;#34;) ggplot(aes(x = p.name, y = colleagues), data = top) + geom_bar(fill = &amp;#34;dark blue&amp;#34;, stat = &amp;#34;identity&amp;#34;) + scale_x_discrete(limits= top$p.name) </description>
    </item>
    
    <item>
      <title>R: Conditionally updating rows of a data frame</title>
      <link>https://markhneedham.com/blog/2015/02/26/r-conditionally-updating-rows-of-a-data-frame/</link>
      <pubDate>Thu, 26 Feb 2015 00:45:42 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/26/r-conditionally-updating-rows-of-a-data-frame/</guid>
      <description>library(zoo) library(dplyr) monthNumber = function(cohort, date) { cohortAsDate = as.yearmon(cohort) dateAsDate = as.yearmon(date) if(cohortAsDate &amp;gt; dateAsDate) { &amp;#34;NA&amp;#34; } else { paste(round((dateAsDate - cohortAsDate) * 12), sep=&amp;#34;&amp;#34;) } } cohortAttendance %&amp;gt;% group_by(row_number()) %&amp;gt;% mutate(monthNumber = monthNumber(cohort, date)) %&amp;gt;% filter(monthNumber != &amp;#34;NA&amp;#34;) %&amp;gt;% filter(monthNumber != &amp;#34;0&amp;#34;) %&amp;gt;% mutate(monthNumber = as.numeric(monthNumber)) %&amp;gt;% arrange(monthNumber) system.time(cohortAttendance %&amp;gt;% group_by(row_number()) %&amp;gt;% mutate(monthNumber = monthNumber(cohort, date)) %&amp;gt;% filter(monthNumber != &amp;#34;NA&amp;#34;) %&amp;gt;% filter(monthNumber != &amp;#34;0&amp;#34;) %&amp;gt;% mutate(monthNumber = as.</description>
    </item>
    
    <item>
      <title>Python/nltk: Naive vs Naive Bayes vs Decision Tree</title>
      <link>https://markhneedham.com/blog/2015/02/24/pythonnltk-naive-vs-naive-bayes-vs-decision-tree/</link>
      <pubDate>Tue, 24 Feb 2015 22:39:49 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/24/pythonnltk-naive-vs-naive-bayes-vs-decision-tree/</guid>
      <description>import nltk from nltk import ClassifierI class NaiveClassifier(ClassifierI): def classify(self, featureset): if featureset[&amp;#39;next-word&amp;#39;] == &amp;#34;:&amp;#34;: return True else: return False import nltk import collections def assess_classifier(classifier, test_data, text): refsets = collections.defaultdict(set) testsets = collections.defaultdict(set) for i, (feats, label) in enumerate(test_data): refsets[label].add(i) observed = classifier.classify(feats) testsets[observed].add(i) speaker_precision = nltk.metrics.precision(refsets[True], testsets[True]) speaker_recall = nltk.metrics.recall(refsets[True], testsets[True]) non_speaker_precision = nltk.metrics.precision(refsets[False], testsets[False]) non_speaker_recall = nltk.metrics.recall(refsets[False], testsets[False]) return [text, speaker_precision, speaker_recall, non_speaker_precision, non_speaker_recall] import json from sklearn.</description>
    </item>
    
    <item>
      <title>R: Cohort analysis of Neo4j meetup members</title>
      <link>https://markhneedham.com/blog/2015/02/24/r-cohort-analysis-of-neo4j-meetup-members/</link>
      <pubDate>Tue, 24 Feb 2015 01:19:26 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/24/r-cohort-analysis-of-neo4j-meetup-members/</guid>
      <description>library(RNeo4j) graph = startGraph(&amp;#34;http://127.0.0.1:7474/db/data/&amp;#34;) query = &amp;#34;MATCH (g:Group {name: \&amp;#34;Neo4j - London User Group\&amp;#34;})-[:HOSTED_EVENT]-&amp;gt;(e), (e)&amp;lt;-[:TO]-(rsvp {response: \&amp;#34;yes\&amp;#34;})&amp;lt;-[:RSVPD]-(person) RETURN rsvp.time, person.id&amp;#34; timestampToDate &amp;lt;- function(x) as.POSIXct(x / 1000, origin=&amp;#34;1970-01-01&amp;#34;, tz = &amp;#34;GMT&amp;#34;) df = cypher(graph, query) df$time = timestampToDate(df$rsvp.time) df$date = format(as.Date(df$time), &amp;#34;%Y-%m&amp;#34;) &amp;gt; df %&amp;gt;% head() ## rsvp.time person.id time date ## 612 1.404857e+12 23362191 2014-07-08 22:00:29 2014-07 ## 1765 1.380049e+12 112623332 2013-09-24 18:58:00 2013-09 ## 1248 1.390563e+12 9746061 2014-01-24 11:24:35 2014-01 ## 1541 1.</description>
    </item>
    
    <item>
      <title>R/dplyr: Extracting data frame column value for filtering with %in%</title>
      <link>https://markhneedham.com/blog/2015/02/22/rdplyr-extracting-data-frame-column-value-for-filtering-with-in/</link>
      <pubDate>Sun, 22 Feb 2015 08:58:57 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/22/rdplyr-extracting-data-frame-column-value-for-filtering-with-in/</guid>
      <description>library(dplyr) df = data.frame(userId = c(1,2,3,4,5), score = c(2,3,4,5,5)) highScoringPeople = df %&amp;gt;% filter(score &amp;gt; 3) %&amp;gt;% select(userId) &amp;gt; highScoringPeople userId 1 3 2 4 3 5 &amp;gt; df %&amp;gt;% filter(userId %in% highScoringPeople) [1] userId score &amp;lt;0 rows&amp;gt; (or 0-length row.names) &amp;gt; df %&amp;gt;% filter(userId %in% c(3,4,5)) userId score 1 3 4 2 4 5 3 5 5 &amp;gt; str(c(3,4,5)) num [1:3] 3 4 5 &amp;gt; str(highScoringPeople) &amp;#39;data.frame&amp;#39;:	3 obs. of 1 variable: $ userId: num 3 4 5 highScoringPeople = (df %&amp;gt;% filter(score &amp;gt; 3))$userId &amp;gt; str(highScoringPeople) num [1:3] 3 4 5 &amp;gt; df %&amp;gt;% filter(userId %in% highScoringPeople) userId score 1 3 4 2 4 5 3 5 5 highScoringPeople = (df %&amp;gt;% filter(score &amp;gt; 3) %&amp;gt;% select(userId))[[1]] &amp;gt; str(highScoringPeople) num [1:3] 3 4 5 </description>
    </item>
    
    <item>
      <title>Python/scikit-learn: Detecting which sentences in a transcript contain a speaker</title>
      <link>https://markhneedham.com/blog/2015/02/20/pythonscikit-learn-detecting-which-sentences-in-a-transcript-contain-a-speaker/</link>
      <pubDate>Fri, 20 Feb 2015 22:42:59 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/20/pythonscikit-learn-detecting-which-sentences-in-a-transcript-contain-a-speaker/</guid>
      <description>&amp;lt;speaker&amp;gt;: &amp;lt;sentence&amp;gt; import json with open(&amp;#34;data/import/trained_sentences.json&amp;#34;, &amp;#34;r&amp;#34;) as json_file: json_data = json.load(json_file) &amp;gt;&amp;gt;&amp;gt; json_data[0] {u&amp;#39;words&amp;#39;: [{u&amp;#39;word&amp;#39;: u&amp;#39;You&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;ca&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#34;n&amp;#39;t&amp;#34;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;be&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;friends&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;with&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;Robin&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;.&amp;#39;, u&amp;#39;speaker&amp;#39;: False}]} &amp;gt;&amp;gt;&amp;gt; json_data[1] {u&amp;#39;words&amp;#39;: [{u&amp;#39;word&amp;#39;: u&amp;#39;Robin&amp;#39;, u&amp;#39;speaker&amp;#39;: True}, {u&amp;#39;word&amp;#39;: u&amp;#39;:&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;Well&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;...&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;it&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#34;&amp;#39;s&amp;#34;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;a&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;bit&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;early&amp;#39;, u&amp;#39;speaker&amp;#39;: False}, {u&amp;#39;word&amp;#39;: u&amp;#39;.</description>
    </item>
    
    <item>
      <title>Python&#39;s pandas vs Neo4j&#39;s cypher: Exploring popular phrases in How I met your mother transcripts</title>
      <link>https://markhneedham.com/blog/2015/02/19/pythons-pandas-vs-neo4js-cypher-exploring-popular-phrases-in-how-i-met-your-mother-transcripts/</link>
      <pubDate>Thu, 19 Feb 2015 00:52:10 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/19/pythons-pandas-vs-neo4js-cypher-exploring-popular-phrases-in-how-i-met-your-mother-transcripts/</guid>
      <description>To do anything with Neo4j we need to first load the CSV file into the database. The easiest way to do that is with Cypher&amp;rsquo;s LOAD CSV command.
First we&amp;rsquo;ll load the phrases in and then we&amp;rsquo;ll connect them to the episodes which were previously loaded:
USING PERIODIC COMMIT 1000 LOAD CSV WITH HEADERS FROM &amp;quot;file:///Users/markneedham/projects/neo4j-himym/data/import/tfidf_scikit.csv&amp;quot; AS row MERGE (phrase:Phrase {value: row.Phrase}); USING PERIODIC COMMIT 1000 LOAD CSV WITH HEADERS FROM &amp;quot;file:///Users/markneedham/projects/neo4j-himym/data/import/tfidf_scikit.</description>
    </item>
    
    <item>
      <title>Python/pandas: Column value in list (ValueError: The truth value of a Series is ambiguous.)</title>
      <link>https://markhneedham.com/blog/2015/02/16/pythonpandas-column-value-in-list-valueerror-the-truth-value-of-a-series-is-ambiguous/</link>
      <pubDate>Mon, 16 Feb 2015 21:39:16 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/16/pythonpandas-column-value-in-list-valueerror-the-truth-value-of-a-series-is-ambiguous/</guid>
      <description>$ cat foo.csv &amp;#34;Foo&amp;#34; 1 2 3 4 5 6 7 8 9 10 import pandas as pd df = pd.read_csv(&amp;#39;foo.csv&amp;#39;, index_col=False, header=0) &amp;gt;&amp;gt;&amp;gt; df Foo 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 &amp;gt;&amp;gt;&amp;gt; df[df[&amp;#34;Foo&amp;#34;] == 1] Foo 0 1 &amp;gt;&amp;gt;&amp;gt; df[df[&amp;#34;Foo&amp;#34;] &amp;lt; 7] Foo 0 1 1 2 2 3 3 4 4 5 5 6 odds = [i for i in range(1,10) if i % 2 &amp;lt;&amp;gt; 0] &amp;gt;&amp;gt;&amp;gt; odds [1, 3, 5, 7, 9] &amp;gt;&amp;gt;&amp;gt; df[df[&amp;#34;Foo&amp;#34;] in odds] Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.</description>
    </item>
    
    <item>
      <title>Python/scikit-learn: Calculating TF/IDF on How I met your mother transcripts</title>
      <link>https://markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/</link>
      <pubDate>Sun, 15 Feb 2015 15:56:09 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/</guid>
      <description>It is often used as a weighting factor in information retrieval and text mining.
The tf-idf value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.
from collections import defaultdict import csv episodes = defaultdict(list) with open(&amp;#34;data/import/sentences.csv&amp;#34;, &amp;#34;r&amp;#34;) as sentences_file: reader = csv.</description>
    </item>
    
    <item>
      <title>Neo4j: Building a topic graph with Prismatic Interest Graph API</title>
      <link>https://markhneedham.com/blog/2015/02/13/neo4j-building-a-topic-graph-with-prismatic-interest-graph-api/</link>
      <pubDate>Fri, 13 Feb 2015 23:38:43 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/13/neo4j-building-a-topic-graph-with-prismatic-interest-graph-api/</guid>
      <description>import requests payload = { &amp;#39;title&amp;#39;: &amp;#34;insert title of article here&amp;#34;, &amp;#39;body&amp;#39;: &amp;#34;insert body of text here&amp;#34;), &amp;#39;api-token&amp;#39;: &amp;#34;insert token sent by email here&amp;#34;} r = requests.post(&amp;#34;http://interest-graph.getprismatic.com/text/topic&amp;#34;, data=payload) import time def RateLimited(maxPerSecond): minInterval = 1.0 / float(maxPerSecond) def decorate(func): lastTimeCalled = [0.0] def rateLimitedFunction(*args,**kargs): elapsed = time.clock() - lastTimeCalled[0] leftToWait = minInterval - elapsed if leftToWait&amp;gt;0: time.sleep(leftToWait) ret = func(*args,**kargs) lastTimeCalled[0] = time.clock() return ret return rateLimitedFunction return decorate @RateLimited(0.3) def topics(title, body): payload = { &amp;#39;title&amp;#39;: title, &amp;#39;body&amp;#39;: body, &amp;#39;api-token&amp;#39;: &amp;#34;insert token sent by email here&amp;#34;} r = requests.</description>
    </item>
    
    <item>
      <title>Python/gensim: Creating bigrams over How I met your mother transcripts</title>
      <link>https://markhneedham.com/blog/2015/02/12/pythongensim-creating-bigrams-over-how-i-met-your-mother-transcripts/</link>
      <pubDate>Thu, 12 Feb 2015 23:45:03 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/12/pythongensim-creating-bigrams-over-how-i-met-your-mother-transcripts/</guid>
      <description>$ head -n 15 data/import/sentences.csv | tail 5,1,1,1,Son: Are we being punished for something? 6,1,1,1,Narrator: No 7,1,1,1,&amp;#34;Daughter: Yeah, is this going to take a while?&amp;#34; 8,1,1,1,&amp;#34;Narrator: Yes. (Kids are annoyed) Twenty-five years ago, before I was dad, I had this whole other life.&amp;#34; 9,1,1,1,&amp;#34;(Music Plays, Title &amp;#34;&amp;#34;How I Met Your Mother&amp;#34;&amp;#34; appears)&amp;#34; 10,1,1,1,&amp;#34;Narrator: It was way back in 2005. I was twenty-seven just starting to make it as an architect and living in New York with my friend Marshall, my best friend from college.</description>
    </item>
    
    <item>
      <title>R: Weather vs attendance at NoSQL meetups</title>
      <link>https://markhneedham.com/blog/2015/02/11/r-weather-vs-attendance-at-nosql-meetups/</link>
      <pubDate>Wed, 11 Feb 2015 07:09:25 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/02/11/r-weather-vs-attendance-at-nosql-meetups/</guid>
      <description>library(weatherData) # London City Airport getDetailedWeatherForYear = function(year) { getWeatherForDate(&amp;#34;LCY&amp;#34;, start_date= paste(sep=&amp;#34;&amp;#34;, year, &amp;#34;-01-01&amp;#34;), end_date = paste(sep=&amp;#34;&amp;#34;, year, &amp;#34;-12-31&amp;#34;), opt_detailed = FALSE, opt_all_columns = TRUE) } df = rbind(getDetailedWeatherForYear(2011), getDetailedWeatherForYear(2012), getDetailedWeatherForYear(2013), getDetailedWeatherForYear(2014), getWeatherForDate(&amp;#34;LCY&amp;#34;, start_date=&amp;#34;2015-01-01&amp;#34;, end_date = &amp;#34;2015-01-25&amp;#34;, opt_detailed = FALSE, opt_all_columns = TRUE)) write.csv(df, &amp;#39;weather/temp_data.csv&amp;#39;, row.names = FALSE) &amp;#34;Date&amp;#34;,&amp;#34;GMT&amp;#34;,&amp;#34;Max_TemperatureC&amp;#34;,&amp;#34;Mean_TemperatureC&amp;#34;,&amp;#34;Min_TemperatureC&amp;#34;,&amp;#34;Dew_PointC&amp;#34;,&amp;#34;MeanDew_PointC&amp;#34;,&amp;#34;Min_DewpointC&amp;#34;,&amp;#34;Max_Humidity&amp;#34;,&amp;#34;Mean_Humidity&amp;#34;,&amp;#34;Min_Humidity&amp;#34;,&amp;#34;Max_Sea_Level_PressurehPa&amp;#34;,&amp;#34;Mean_Sea_Level_PressurehPa&amp;#34;,&amp;#34;Min_Sea_Level_PressurehPa&amp;#34;,&amp;#34;Max_VisibilityKm&amp;#34;,&amp;#34;Mean_VisibilityKm&amp;#34;,&amp;#34;Min_VisibilitykM&amp;#34;,&amp;#34;Max_Wind_SpeedKm_h&amp;#34;,&amp;#34;Mean_Wind_SpeedKm_h&amp;#34;,&amp;#34;Max_Gust_SpeedKm_h&amp;#34;,&amp;#34;Precipitationmm&amp;#34;,&amp;#34;CloudCover&amp;#34;,&amp;#34;Events&amp;#34;,&amp;#34;WindDirDegrees&amp;#34; 2011-01-01,&amp;#34;2011-1-1&amp;#34;,7,6,4,5,3,1,93,85,76,1027,1025,1023,10,9,3,14,10,NA,0,7,&amp;#34;Rain&amp;#34;,312 2011-01-02,&amp;#34;2011-1-2&amp;#34;,4,3,2,1,0,-1,87,81,75,1029,1028,1027,10,10,10,11,8,NA,0,7,&amp;#34;&amp;#34;,321 2011-01-03,&amp;#34;2011-1-3&amp;#34;,4,2,1,0,-2,-5,87,74,56,1028,1024,1019,10,10,10,8,5,NA,0,6,&amp;#34;Rain-Snow&amp;#34;,249 2011-01-04,&amp;#34;2011-1-4&amp;#34;,6,3,1,3,1,-1,93,83,65,1019,1013,1008,10,10,10,21,6,NA,0,5,&amp;#34;Rain&amp;#34;,224 2011-01-05,&amp;#34;2011-1-5&amp;#34;,8,7,5,6,3,0,93,80,61,1008,1000,994,10,9,4,26,16,45,0,4,&amp;#34;Rain&amp;#34;,200 2011-01-06,&amp;#34;2011-1-6&amp;#34;,7,4,3,6,3,1,93,90,87,1002,996,993,10,9,5,13,6,NA,0,5,&amp;#34;Rain&amp;#34;,281 2011-01-07,&amp;#34;2011-1-7&amp;#34;,11,6,2,9,5,2,100,91,82,1003,999,996,10,7,2,24,11,NA,0,5,&amp;#34;Rain-Snow&amp;#34;,124 2011-01-08,&amp;#34;2011-1-8&amp;#34;,11,7,4,8,4,-1,87,77,65,1004,997,987,10,10,5,39,23,50,0,5,&amp;#34;Rain&amp;#34;,230 2011-01-09,&amp;#34;2011-1-9&amp;#34;,7,4,3,1,0,-1,87,74,57,1018,1012,1004,10,10,10,24,16,NA,0,NA,&amp;#34;&amp;#34;,242 weather = read.csv(&amp;#34;weather/temp_data.csv&amp;#34;) weather$Date = as.POSIXct(weather$Date) &amp;gt; weather %&amp;gt;% sample_n(10) %&amp;gt;% select(Date, Min_TemperatureC, Mean_TemperatureC, Max_TemperatureC) Date Min_TemperatureC Mean_TemperatureC Max_TemperatureC 1471 2015-01-10 5 9 14 802 2013-03-12 -2 1 4 1274 2014-06-27 14 18 22 848 2013-04-27 5 8 10 832 2013-04-11 6 8 10 717 2012-12-17 6 7 9 1463 2015-01-02 6 9 13 1090 2013-12-25 4 6 7 560 2012-07-13 15 18 20 1230 2014-05-14 9 14 19 timestampToDate &amp;lt;- function(x) as.</description>
    </item>
    
    <item>
      <title>Python/matpotlib: Plotting occurrences of the main characters in How I Met Your Mother</title>
      <link>https://markhneedham.com/blog/2015/01/30/pythonmatpotlib-plotting-occurrences-of-the-main-characters-in-how-i-met-your-mother/</link>
      <pubDate>Fri, 30 Jan 2015 21:29:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/30/pythonmatpotlib-plotting-occurrences-of-the-main-characters-in-how-i-met-your-mother/</guid>
      <description>$ head -n 10 data/import/sentences.csv SentenceId,EpisodeId,Season,Episode,Sentence 1,1,1,1,Pilot 2,1,1,1,Scene One 3,1,1,1,[Title: The Year 2030] 4,1,1,1,&amp;#34;Narrator: Kids, I&amp;#39;m going to tell you an incredible story. The story of how I met your mother&amp;#34; 5,1,1,1,Son: Are we being punished for something? 6,1,1,1,Narrator: No 7,1,1,1,&amp;#34;Daughter: Yeah, is this going to take a while?&amp;#34; 8,1,1,1,&amp;#34;Narrator: Yes. (Kids are annoyed) Twenty-five years ago, before I was dad, I had this whole other life.&amp;#34; 9,1,1,1,&amp;#34;(Music Plays, Title &amp;#34;&amp;#34;How I Met Your Mother&amp;#34;&amp;#34; appears)&amp;#34; import csv from collections import defaultdict episodes = defaultdict(list) with open(&amp;#34;data/import/sentences.</description>
    </item>
    
    <item>
      <title>R: ggplot2 - Each group consist of only one observation. Do you need to adjust the group aesthetic?</title>
      <link>https://markhneedham.com/blog/2015/01/30/r-ggplot2-each-group-consist-of-only-one-observation-do-you-need-to-adjust-the-group-aesthetic/</link>
      <pubDate>Fri, 30 Jan 2015 00:27:53 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/30/r-ggplot2-each-group-consist-of-only-one-observation-do-you-need-to-adjust-the-group-aesthetic/</guid>
      <description>$ cat /tmp/averageTemperatureByMonth.csv &amp;#34;month&amp;#34;,&amp;#34;aveTemperature&amp;#34; &amp;#34;January&amp;#34;,6.02684563758389 &amp;#34;February&amp;#34;,5.89380530973451 &amp;#34;March&amp;#34;,7.54838709677419 &amp;#34;April&amp;#34;,10.875 &amp;#34;May&amp;#34;,13.3064516129032 &amp;#34;June&amp;#34;,15.9666666666667 &amp;#34;July&amp;#34;,18.8387096774194 &amp;#34;August&amp;#34;,18.3709677419355 &amp;#34;September&amp;#34;,16.2583333333333 &amp;#34;October&amp;#34;,13.4596774193548 &amp;#34;November&amp;#34;,9.19166666666667 &amp;#34;December&amp;#34;,7.01612903225806 df = read.csv(&amp;quot;/tmp/averageTemperatureByMonth.csv&amp;quot;) df$month = factor(df$month, month.name) ggplot(aes(x = month, y = aveTemperature), data = df) + geom_line( ) + ggtitle(&amp;quot;Temperature by month&amp;quot;) geom_path: Each group consist of only one observation. Do you need to adjust the group aesthetic? ggplot(aes(x = as.numeric(month), y = aveTemperature), data = df) + geom_line( ) + ggtitle(&amp;quot;Temperature by month&amp;quot;) ggplot(aes(x = month, y = aveTemperature, group=1), data = df) + geom_line( ) + ggtitle(&amp;quot;Temperature by month&amp;quot;) </description>
    </item>
    
    <item>
      <title>Python: Find the highest value in a group</title>
      <link>https://markhneedham.com/blog/2015/01/25/python-find-the-highest-value-in-a-group/</link>
      <pubDate>Sun, 25 Jan 2015 12:47:01 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/25/python-find-the-highest-value-in-a-group/</guid>
      <description>$ head -n 10 data/import/episodes.csv NumberOverall,NumberInSeason,Episode,Season,DateAired,Timestamp 1,1,/wiki/Pilot,1,&amp;#34;September 19, 2005&amp;#34;,1127084400 2,2,/wiki/Purple_Giraffe,1,&amp;#34;September 26, 2005&amp;#34;,1127689200 3,3,/wiki/Sweet_Taste_of_Liberty,1,&amp;#34;October 3, 2005&amp;#34;,1128294000 4,4,/wiki/Return_of_the_Shirt,1,&amp;#34;October 10, 2005&amp;#34;,1128898800 5,5,/wiki/Okay_Awesome,1,&amp;#34;October 17, 2005&amp;#34;,1129503600 6,6,/wiki/Slutty_Pumpkin,1,&amp;#34;October 24, 2005&amp;#34;,1130108400 7,7,/wiki/Matchmaker,1,&amp;#34;November 7, 2005&amp;#34;,1131321600 8,8,/wiki/The_Duel,1,&amp;#34;November 14, 2005&amp;#34;,1131926400 9,9,/wiki/Belly_Full_of_Turkey,1,&amp;#34;November 21, 2005&amp;#34;,1132531200 import csv from collections import defaultdict seasons = defaultdict(list) with open(&amp;#34;data/import/episodes.csv&amp;#34;, &amp;#34;r&amp;#34;) as episodesfile: reader = csv.reader(episodesfile, delimiter = &amp;#34;,&amp;#34;) reader.next() for row in reader: seasons[int(row[3])].append(int(row[0])) print seasons $ python blog.py defaultdict(&amp;lt;type &amp;#39;list&amp;#39;&amp;gt;, { 1: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], 2: [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], 3: [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64], 4: [65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], 5: [89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], 6: [113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136], 7: [137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160], 8: [161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], 9: [185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]}) for season, episode_ids in seasons.</description>
    </item>
    
    <item>
      <title>Python/pdfquery: Scraping the FIFA World Player of the Year votes PDF into shape</title>
      <link>https://markhneedham.com/blog/2015/01/22/pythonpdfquery-scraping-the-fifa-world-player-of-the-year-votes-pdf-into-shape/</link>
      <pubDate>Thu, 22 Jan 2015 00:25:24 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/22/pythonpdfquery-scraping-the-fifa-world-player-of-the-year-votes-pdf-into-shape/</guid>
      <description>import pdfquery pdf = pdfquery.PDFQuery(&amp;#34;fboaward_menplayer2014_neutral.pdf&amp;#34;) pdf.load() pdf.tree.write(&amp;#34;/tmp/yadda&amp;#34;, pretty_print=True) $ head -n 10 /tmp/yadda &amp;lt;pdfxml ModDate=&amp;#34;D:20150110224554+01&amp;#39;00&amp;#39;&amp;#34; CreationDate=&amp;#34;D:20150110224539+01&amp;#39;00&amp;#39;&amp;#34; Producer=&amp;#34;Microsoft&amp;amp;#174; Excel&amp;amp;#174; 2010&amp;#34; Creator=&amp;#34;Microsoft&amp;amp;#174; Excel&amp;amp;#174; 2010&amp;#34;&amp;gt; &amp;lt;LTPage bbox=&amp;#34;[0, 0, 841.8, 595.2]&amp;#34; height=&amp;#34;595.2&amp;#34; pageid=&amp;#34;1&amp;#34; rotate=&amp;#34;0&amp;#34; width=&amp;#34;841.8&amp;#34; x0=&amp;#34;0&amp;#34; x1=&amp;#34;841.8&amp;#34; y0=&amp;#34;0&amp;#34; y1=&amp;#34;595.2&amp;#34; page_index=&amp;#34;0&amp;#34; page_label=&amp;#34;&amp;#34;&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTTextLineHorizontal bbox=&amp;#34;[31.08, 546.15, 122.524, 556.59]&amp;#34; height=&amp;#34;10.44&amp;#34; width=&amp;#34;91.444&amp;#34; word_margin=&amp;#34;0.1&amp;#34; x0=&amp;#34;31.08&amp;#34; x1=&amp;#34;122.524&amp;#34; y0=&amp;#34;546.15&amp;#34; y1=&amp;#34;556.59&amp;#34;&amp;gt;&amp;lt;LTTextBoxHorizontal bbox=&amp;#34;[31.08, 546.15, 122.524, 556.59]&amp;#34; height=&amp;#34;10.44&amp;#34; index=&amp;#34;0&amp;#34; width=&amp;#34;91.444&amp;#34; x0=&amp;#34;31.08&amp;#34; x1=&amp;#34;122.524&amp;#34; y0=&amp;#34;546.15&amp;#34; y1=&amp;#34;556.59&amp;#34;&amp;gt;FIFA Ballon d&amp;#39;Or 2014 &amp;lt;/LTTextBoxHorizontal&amp;gt;&amp;lt;/LTTextLineHorizontal&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;lt;LTAnon&amp;gt; &amp;lt;/LTAnon&amp;gt; &amp;gt;&amp;gt;&amp;gt; name_element = pdf.</description>
    </item>
    
    <item>
      <title>Python/NLTK: Finding the most common phrases in How I Met Your Mother</title>
      <link>https://markhneedham.com/blog/2015/01/19/pythonnltk-finding-the-most-common-phrases-in-how-i-met-your-mother/</link>
      <pubDate>Mon, 19 Jan 2015 00:24:23 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/19/pythonnltk-finding-the-most-common-phrases-in-how-i-met-your-mother/</guid>
      <description>Following on from last week&amp;rsquo;s blog postwhere I found the most popular words in How I met your mother transcripts, in this post we&amp;rsquo;ll have a look at how we can pull out sentences and then phrases from our corpus.
The first thing I did was tweak the scraping script to pull out the sentences spoken by characters in the transcripts.import csv import nltk import re import bs4 from bs4 import BeautifulSoup, NavigableString from soupselect import select from nltk.</description>
    </item>
    
    <item>
      <title>Python: Counter - ValueError: too many values to unpack</title>
      <link>https://markhneedham.com/blog/2015/01/12/python-counter-valueerror-too-many-values-to-unpack/</link>
      <pubDate>Mon, 12 Jan 2015 23:16:58 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/12/python-counter-valueerror-too-many-values-to-unpack/</guid>
      <description>&amp;gt;&amp;gt; from collections import Counter &amp;gt;&amp;gt; counter = Counter([&amp;#34;word1&amp;#34;, &amp;#34;word2&amp;#34;, &amp;#34;word3&amp;#34;, &amp;#34;word1&amp;#34;]) &amp;gt;&amp;gt; print counter Counter({&amp;#39;word1&amp;#39;: 2, &amp;#39;word3&amp;#39;: 1, &amp;#39;word2&amp;#39;: 1}) &amp;gt;&amp;gt;&amp;gt; for key, value in counter: ... print key, value ... Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; ValueError: too many values to unpack &amp;gt;&amp;gt;&amp;gt; for key, value in counter.iteritems(): ... print key, value ... word1 2 word3 1 word2 1 </description>
    </item>
    
    <item>
      <title>Python: scikit-learn: ImportError: cannot import name __check_build</title>
      <link>https://markhneedham.com/blog/2015/01/10/python-scikit-learn-importerror-cannot-import-name-__check_build/</link>
      <pubDate>Sat, 10 Jan 2015 08:48:04 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/10/python-scikit-learn-importerror-cannot-import-name-__check_build/</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; from sklearn.feature_extraction.text import CountVectorizer Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/sklearn/__init__.py&amp;#34;, line 37, in &amp;lt;module&amp;gt; from . import __check_build ImportError: cannot import name __check_build &amp;gt;&amp;gt;&amp;gt; from sklearn.feature_extraction.text import CountVectorizer Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/sklearn/__init__.py&amp;#34;, line 38, in &amp;lt;module&amp;gt; from .base import clone File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/sklearn/base.py&amp;#34;, line 10, in &amp;lt;module&amp;gt; from scipy import sparse ImportError: No module named scipy $ pip install scipy $ python Python 2.</description>
    </item>
    
    <item>
      <title>Python: gensim - clang: error: unknown argument: &#39;-mno-fused-madd&#39; [-Wunused-command-line-argument-hard-error-in-future]</title>
      <link>https://markhneedham.com/blog/2015/01/10/python-gensim-clang-error-unknown-argument-mno-fused-madd-wunused-command-line-argument-hard-error-in-future/</link>
      <pubDate>Sat, 10 Jan 2015 08:39:15 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/10/python-gensim-clang-error-unknown-argument-mno-fused-madd-wunused-command-line-argument-hard-error-in-future/</guid>
      <description>$ pip install gensim ... cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe -I/Users/markneedham/projects/neo4j-himym/himym/build/gensim/gensim/models -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -I/Users/markneedham/projects/neo4j-himym/himym/lib/python2.7/site-packages/numpy/core/include -c ./gensim/models/word2vec_inner.c -o build/temp.macosx-10.9-intel-2.7/./gensim/models/word2vec_inner.o clang: error: unknown argument: &amp;#39;-mno-fused-madd&amp;#39; [-Wunused-command-line-argument-hard-error-in-future] clang: note: this will be a hard error (cannot be downgraded to a warning) in the future command &amp;#39;cc&amp;#39; failed with exit status 1 an integer is required Traceback (most recent call last): File &amp;#34;&amp;lt;string&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/Users/markneedham/projects/neo4j-himym/himym/build/gensim/setup.</description>
    </item>
    
    <item>
      <title>Python NLTK/Neo4j: Analysing the transcripts of How I Met Your Mother</title>
      <link>https://markhneedham.com/blog/2015/01/10/python-nltkneo4j-analysing-the-transcripts-of-how-i-met-your-mother/</link>
      <pubDate>Sat, 10 Jan 2015 01:22:56 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2015/01/10/python-nltkneo4j-analysing-the-transcripts-of-how-i-met-your-mother/</guid>
      <description>import requests from bs4 import BeautifulSoup from soupselect import select episodes = {} for i in range(1,3): page = open(&amp;#34;data/transcripts/page-&amp;#34; + str(i) + &amp;#34;.html&amp;#34;, &amp;#39;r&amp;#39;) soup = BeautifulSoup(page.read()) for row in select(soup, &amp;#34;td.topic-titles a&amp;#34;): parts = row.text.split(&amp;#34; - &amp;#34;) episodes[parts[0]] = {&amp;#34;title&amp;#34;: parts[1], &amp;#34;link&amp;#34;: row.get(&amp;#34;href&amp;#34;)} for key, value in episodes.iteritems(): parts = key.split(&amp;#34;x&amp;#34;) season = int(parts[0]) episode = int(parts[1]) filename = &amp;#34;data/transcripts/S%d-Ep%d&amp;#34; %(season, episode) print filename with open(filename, &amp;#39;wb&amp;#39;) as handle: headers = {&amp;#39;User-Agent&amp;#39;: &amp;#39;Mozilla/5.</description>
    </item>
    
  </channel>
</rss>