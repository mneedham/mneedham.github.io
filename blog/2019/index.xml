<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2019s on Mark Needham</title>
    <link>https://markhneedham.com/blog/2019/</link>
    <description>Recent content in 2019s on Mark Needham</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Apr 2019 09:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://markhneedham.com/blog/2019/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>pyspark: Py4JJavaError: An error occurred while calling o138.loadClass.: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI</title>
      <link>https://markhneedham.com/blog/2019/04/17/pyspark-class-not-found-exception-org-graphframes-graphframepythonapi/</link>
      <pubDate>Wed, 17 Apr 2019 09:00:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/04/17/pyspark-class-not-found-exception-org-graphframes-graphframepythonapi/</guid>
      <description>I&amp;#8217;ve been building a Docker Container that has support for Jupyter, Spark, GraphFrames, and Neo4j, and ran into a problem that had me pulling my (metaphorical) hair out!
 The https://hub.docker.com/r/jupyter/pyspark-notebook/ gets us most of the way there, but it doesn&amp;#8217;t have GraphFrames or Neo4j support. Adding Neo4j is as simple as pulling in the Python Driver from Conda Forge, which leaves us with GraphFrames.
 When I&amp;#8217;m using GraphFrames with pyspark locally I would pull it in via the --packages config parameter, like this:</description>
    </item>
    
    <item>
      <title>Neo4j: Delete all nodes</title>
      <link>https://markhneedham.com/blog/2019/04/14/neo4j-delete-all-nodes/</link>
      <pubDate>Sun, 14 Apr 2019 12:52:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/04/14/neo4j-delete-all-nodes/</guid>
      <description>When experimenting with a new database, at some stage we&amp;#8217;ll probably want to delete all our data and start again. I was trying to do this with Neo4j over the weekend and it didn&amp;#8217;t work as I expected, so I thought I&amp;#8217;d write the lessons I learned.
 We&amp;#8217;ll be using Neo4j via the Neo4j Desktop with the default settings. This means that we have a maximum heap size of 1GB.</description>
    </item>
    
    <item>
      <title>Python: Getting GitHub download count from the GraphQL API using requests</title>
      <link>https://markhneedham.com/blog/2019/04/07/python-github-download-count-graphql-requests/</link>
      <pubDate>Sun, 07 Apr 2019 05:03:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/04/07/python-github-download-count-graphql-requests/</guid>
      <description>I was recently trying to use some code I shared just over a year ago to compute GitHub Project download numbers from the GraphQL API, and wanted to automate this in a Python script.
 It was more fiddly than I expected, so I thought I&amp;#8217;d share the code for the benefit of future me more than anything else!
 Pre requisites We&amp;#8217;re going to use the popular requests library to query the API, so we need to import that.</description>
    </item>
    
    <item>
      <title>Finding famous MPs based on their Wikipedia Page Views</title>
      <link>https://markhneedham.com/blog/2019/04/01/famous-mps-wikipedia-pageviews/</link>
      <pubDate>Mon, 01 Apr 2019 05:03:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/04/01/famous-mps-wikipedia-pageviews/</guid>
      <description>As part of the Graphing Brexit series of blog posts, I wanted to work out who were the most important Members of the UK parliament, and after a bit of Googling I realised that views of their Wikipedia pages would do the trick.
 I initially found my way to tools.wmflabs.org, which is great for exploring the popularity of an individual MP, but not so good if you want to extract the data for 600 of them.</description>
    </item>
    
    <item>
      <title>Neo4j: From Graph Model to Neo4j Import</title>
      <link>https://markhneedham.com/blog/2019/03/27/from-graph-model-to-neo4j-import/</link>
      <pubDate>Wed, 27 Mar 2019 06:42:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/03/27/from-graph-model-to-neo4j-import/</guid>
      <description>In this post we&amp;#8217;re going to learn how to import the DBLP citation network into Neo4j using the Neo4j Import Tool.
 In case you haven&amp;#8217;t come across this dataset before, Tomaz Bratanic has a great blog post explaining it.
 The tl;dr is that we have articles, authors, and venues. Authors can write articles, articles can reference other articles, and articles are presented at a venue. Below is the graph model for this dataset:</description>
    </item>
    
    <item>
      <title>Neo4j: Delete/Remove dynamic properties</title>
      <link>https://markhneedham.com/blog/2019/03/14/neo4j-delete-dynamic-properties/</link>
      <pubDate>Thu, 14 Mar 2019 06:42:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/03/14/neo4j-delete-dynamic-properties/</guid>
      <description>Irfan and I were playing with a dataset earlier today, and having run a bunch of graph algorithms, we had a lot of properties that we wanted to clear out.
 The following Cypher query puts Neo4j into the state that we were dealing with.
 CREATE (:Node {name: &#34;Mark&#34;, pagerank: 2.302, louvain: 1, lpa: 4 }) CREATE (:Node {name: &#34;Michael&#34;, degree: 23, triangles: 12, betweeness: 48.70 }) CREATE (:Node {name: &#34;</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Date ranges</title>
      <link>https://markhneedham.com/blog/2019/01/13/neo4j-cypher-date-ranges/</link>
      <pubDate>Sun, 13 Jan 2019 06:42:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/01/13/neo4j-cypher-date-ranges/</guid>
      <description>As part of a dataset I&amp;#8217;ve been working with this week, I wanted to generate a collection of a range of dates using the Cypher query language.
 I&amp;#8217;ve previously used the duration function, which lets you add (or subtract) from a specific date, so I thought I&amp;#8217;d start from there. If we want to find the day after 1st January 2019, we could write the following query:
 neo4j&amp;gt; WITH date(&#34;</description>
    </item>
    
    <item>
      <title>Neo4j: APOC - Caused by: java.io.RuntimeException: Can&#39;t read url or key file (No such file or directory)</title>
      <link>https://markhneedham.com/blog/2019/01/12/neo4j-apoc-file-not-found-exception-no-such-file-directory/</link>
      <pubDate>Sat, 12 Jan 2019 19:05:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/01/12/neo4j-apoc-file-not-found-exception-no-such-file-directory/</guid>
      <description>I&amp;#8217;ve been using Neo4j&amp;#8217;s APOC library to load some local JSON files this week, and ran into an interesting problem.
 The LOAD CSV tool assumes that any files you load locally are in the import directory, so I&amp;#8217;ve got into the habit of putting my data there. Let&amp;#8217;s check what I&amp;#8217;m trying to import by opening the import directory:
   What&amp;#8217;s in there?
   Just the one JSON file needs processing.</description>
    </item>
    
    <item>
      <title>Neo4j: Cypher - Remove consecutive duplicates from a list</title>
      <link>https://markhneedham.com/blog/2019/01/12/neo4j-cypher-remove-consecutive-duplicates/</link>
      <pubDate>Sat, 12 Jan 2019 04:32:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/01/12/neo4j-cypher-remove-consecutive-duplicates/</guid>
      <description>I was playing with a dataset this week and wanted to share how I removes duplicate consecutive elements from a list using the Cypher query language.
 For simplicity&amp;#8217;s sake, imagine that we have this list:
 neo4j&amp;gt; return [1,2,3,3,4,4,4,5,3] AS values; +-----------------------------+ | values | +-----------------------------+ | [1, 2, 3, 3, 4, 4, 4, 5, 3] | +-----------------------------+   We want to remove the duplicate 3&amp;#8217;s and 4&amp;#8217;s, such that our end result should be:</description>
    </item>
    
    <item>
      <title>Python: Add query parameters to a URL</title>
      <link>https://markhneedham.com/blog/2019/01/11/python-add-query-parameters-url/</link>
      <pubDate>Fri, 11 Jan 2019 09:42:00 +0000</pubDate>
      
      <guid>https://markhneedham.com/blog/2019/01/11/python-add-query-parameters-url/</guid>
      <description>I was recently trying to automate adding a query parameter to a bunch of URLS and came across a neat approach a long way down this StackOverflow answer, that uses the PreparedRequest class from the requests library.
 Let&amp;#8217;s first get the class imported:
 from requests.models import PreparedRequest req = PreparedRequest()   And now let&amp;#8217;s use use this class to add a query parameter to a URL. We can do this with the following code:</description>
    </item>
    
  </channel>
</rss>